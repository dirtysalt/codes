{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost\n",
    "import sklearn\n",
    "# import seaborn as sns\n",
    "%matplotlib inline\n",
    "data_path = '/Users/dirlt/.kaggle/competitions/bike-sharing-demand/'\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn.metrics\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "import skopt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "links:\n",
    "- https://www.kaggle.com/miteshyadav/comprehensive-eda-with-xgboost-top-10-percentile/notebook\n",
    "- https://www.kaggle.com/viveksrinivasan/eda-ensemble-model-top-10-percentile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mytrain.csv')\n",
    "test_df = pd.read_csv('mytest.csv')\n",
    "X, y = df.drop(['casual', 'registered', 'count'], axis = 1), np.log1p(df[['casual', 'registered', 'count']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(x, casual = True):\n",
    "    drop_fields = ['dt_day', 'dt_hour', 'season', 'weather', 'dt_year', 'dt_month', 'dt_weekday', 'atemp']\n",
    "    if 'datetime' in x.columns:\n",
    "        drop_fields.append('datetime')\n",
    "    return x.drop(drop_fields, axis = 1)\n",
    "\n",
    "def make_cv(X,n = 2):\n",
    "    for i in range(n):\n",
    "        days = [x for x in [18-i, 19-i]]\n",
    "        train_idx = X[X['dt_day'].apply(lambda x: x not in days)].index\n",
    "        test_idx = X[X['dt_day'].apply(lambda x: x in days)].index\n",
    "        yield train_idx, test_idx\n",
    "\n",
    "def rmse(x, y):\n",
    "    return mean_squared_error(x, y) ** 0.5\n",
    "\n",
    "def print_features(names, values, thres = 0.01):\n",
    "    fts = list(zip(names, values))\n",
    "    fts.sort(key = lambda x: -x[1])\n",
    "    ns = []\n",
    "    for idx, (name, value) in enumerate(fts):\n",
    "        if value < thres: break\n",
    "        print('- {} {:.2f}'.format(name, value))\n",
    "        ns.append(name)\n",
    "    print(format(','.join(ns)))\n",
    "\n",
    "class MyEstimator(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, **kwargs):\n",
    "        if 'ma' in kwargs:\n",
    "            self.ma = kwargs['ma']\n",
    "            del kwargs['ma']\n",
    "        if 'mb' in kwargs:\n",
    "            self.mb = kwargs['mb']\n",
    "            del kwargs['mb']\n",
    "        kwargs['init'] = True\n",
    "        self.set_params(**kwargs)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        input_a = input_fn(X, casual=True)\n",
    "        input_b = input_fn(X, casual=False)\n",
    "        self.ma.fit(input_a, y['casual'])\n",
    "        self.mb.fit(input_b, y['registered'])\n",
    "        self.ca = input_a.columns\n",
    "        self.cb = input_b.columns\n",
    "        \n",
    "    def predict(self, X, n = None):\n",
    "        if n:\n",
    "            ma_est = self.ma.estimators_\n",
    "            mb_est = self.mb.estimators_\n",
    "            self.ma.estimators_ = ma_est[:n]\n",
    "            self.mb.estimators_ = mb_est[:n]\n",
    "        ya = self.ma.predict(input_fn(X, casual=True))\n",
    "        yb = self.mb.predict(input_fn(X, casual=False))\n",
    "        y = np.log1p(np.expm1(ya) + np.expm1(yb))\n",
    "        if n:\n",
    "            self.ma.estimators_ = ma_est\n",
    "            self.mb.estimators_ = mb_est\n",
    "        return y\n",
    "    \n",
    "    def score(self, X, y , n = None):\n",
    "        y2 = self.predict(X, n = n)\n",
    "        return -rmse(y['count'], y2)\n",
    "        \n",
    "    def set_params(self, **params):\n",
    "        pa = {}\n",
    "        pb = {}\n",
    "        for k in params:\n",
    "            if k.startswith('a_'):\n",
    "                pa[k[2:]] = params[k]\n",
    "            elif k.startswith('b_'):\n",
    "                pb[k[2:]] = params[k]\n",
    "            elif k == 'n_estimators':\n",
    "                # 让两个回归器共享n\n",
    "                pa[k] = params[k]\n",
    "                pb[k] = params[k]\n",
    "            else:\n",
    "                pass\n",
    "        if 'init' not in params:\n",
    "            #print(pa, pb)\n",
    "            pass\n",
    "        self.ma.set_params(**pa)\n",
    "        self.mb.set_params(**pb)\n",
    "        return self\n",
    "        \n",
    "    def get_params(self, deep = True):\n",
    "        pa = self.ma.get_params(deep)\n",
    "        pb = self.ma.get_params(deep)\n",
    "        p = {}\n",
    "        for k in pa:\n",
    "            p['a_' + k] = pa[k]\n",
    "        for k in pb:\n",
    "            p['b_' + k] = pb[k]\n",
    "        p['ma'] = self.ma\n",
    "        p['mb'] = self.mb\n",
    "        return p\n",
    "    \n",
    "    def print_features(self, thres = 0.005):\n",
    "        ca = self.ca\n",
    "        cb = self.cb\n",
    "        print('=====casual=====')\n",
    "        print_features(ca, self.ma.feature_importances_, thres)\n",
    "        print('=====registered=====')\n",
    "        print_features(cb, self.mb.feature_importances_, thres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn(X).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skopt_min_fn(model, X, y, params, n_calls = 10, n_cv = 2):\n",
    "    pitems = list(params.items())\n",
    "    pkeys = [x[0] for x in pitems]\n",
    "    pvalues = [x[1] for x in pitems]\n",
    "    history = {}\n",
    "    def _f(_params):\n",
    "        my_params = dict(zip(pkeys, _params))\n",
    "        print('use params = {}'.format(my_params))\n",
    "        k = tuple(_params)\n",
    "        if k in history:\n",
    "            return history[k]\n",
    "        model.set_params(**my_params)\n",
    "        cv = make_cv(X, n_cv)\n",
    "        scores = []\n",
    "        for train_idx, test_idx in cv:\n",
    "            model.fit(X.loc[train_idx], y.loc[train_idx])\n",
    "            s = model.score(X.loc[test_idx], y.loc[test_idx])\n",
    "            scores.append(s)\n",
    "        s = -np.mean(scores)\n",
    "        print('score = {}'.format(s))\n",
    "        history[k] = s\n",
    "        return s\n",
    "    \n",
    "    res = skopt.forest_minimize(func = _f, dimensions = pvalues, n_calls = n_calls)\n",
    "    res.best_params = dict(zip(pkeys, res.x))\n",
    "    res.best_score = res.fun\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_n(model, X, y, ns, n_cv = 4):\n",
    "    scores = defaultdict(list)\n",
    "    scores2 = dict()\n",
    "    cv = make_cv(X, n_cv)\n",
    "    print('set n_estimators = {}'.format(max(ns)))\n",
    "    model.set_params(**{'n_estimators': max(ns)})\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv):\n",
    "        print('doing fit cv = {} ...'.format(idx))\n",
    "        model.fit(X.loc[train_idx], y.loc[train_idx])\n",
    "        for n in ns:\n",
    "            s = model.score(X.loc[test_idx], y.loc[test_idx], n = n)\n",
    "            scores[n].append(s)\n",
    "    for n in ns:\n",
    "        scores2[n] = np.mean(scores[n])\n",
    "    tmp = list(scores2.items())\n",
    "    tmp.sort(key = lambda x: -x[1])\n",
    "    return scores2, tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print('cv for rf model')\n",
    "rf0 = RandomForestRegressor(n_estimators=200, random_state = 42, verbose=0, n_jobs=4)\n",
    "rf1 = RandomForestRegressor(n_estimators=200, random_state = 42, verbose=0, n_jobs=4)\n",
    "rf = MyEstimator(ma = rf0, mb = rf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# params = {'a_min_samples_split': [3, 10], 'b_min_samples_split': [3, 10]}\n",
    "# rf_opt = skopt_min_fn(rf, X, y, params, n_calls = 20, n_cv = 4)\n",
    "# print(rf_opt.best_params, rf_opt.best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'a_min_samples_split': [8,9,10,11,12], 'b_min_samples_split': [4,5,6,7,8]}\n",
    "# rf_cv = GridSearchCV(rf, params, cv = make_cv(X,2), n_jobs = 1, verbose = 1)\n",
    "# rf_cv.fit(X, y)\n",
    "# print(rf_cv.best_score_, rf_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# rf.set_params(**{'a_min_samples_split': 10, 'b_min_samples_split': 7})\n",
    "# rf_scores = select_n(rf, X, y, ns = range(100, 2000, 100), n_cv = 4)\n",
    "# print(rf_scores[1][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf_best_params = {'a_min_samples_split': 10, 'b_min_samples_split': 7, 'n_estimators': 1700}\n",
    "rf.set_params(**rf_best_params)\n",
    "rf.fit(X, y)\n",
    "output_y = rf.predict(test_df)\n",
    "output = np.round(np.expm1(output_y)).astype(int)\n",
    "output[output < 0] = 0\n",
    "df_output = pd.DataFrame({'datetime': test_df['datetime'], 'count': output}, columns=('datetime', 'count'))\n",
    "df_output['count'] = df_output['count'].astype(int)\n",
    "df_output.to_csv('submission-rf.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c bike-sharing-demand -f submission-rf.csv -m 'ms=(10,7), n = 1700'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print('cv for gbm model')\n",
    "gbm0 = GradientBoostingRegressor(n_estimators=200, random_state = 42, verbose=0)\n",
    "gbm1 = GradientBoostingRegressor(n_estimators=200, random_state = 42, verbose=0)\n",
    "gbm = MyEstimator(ma = gbm0, mb = gbm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# params = {'a_max_depth': [3,4,5,6,7,8], 'b_max_depth': [3,4,5,6,7,8]}\n",
    "# gbm_opt = skopt_min_fn(gbm, X, y, params, n_calls = 20, n_cv = 4)\n",
    "# print(gbm_opt.best_params, gbm_opt.best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'a_max_depth': [3,4,5,6,7,8], 'b_max_depth': [3,4,5,6,7,8]}\n",
    "# gbm_cv = GridSearchCV(gbm, params, cv = make_cv(X,2), n_jobs = 4, verbose = 1)\n",
    "# gbm_cv.fit(X, y)\n",
    "# print(gbm_cv.best_score_, gbm_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# gbm.set_params(**{'a_max_depth': 4, 'b_max_depth':6})\n",
    "# gbm_scores = select_n(gbm, X, y, ns = range(100, 2000, 20), n_cv = 4)\n",
    "# print(gbm_scores[1][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gbm_best_params = {'a_max_depth': 4, 'b_max_depth':6, 'n_estimators': 360}\n",
    "gbm.set_params(**gbm_best_params)\n",
    "gbm.fit(X, y)\n",
    "output_y = gbm.predict(test_df)\n",
    "output = np.round(np.expm1(output_y)).astype(int)\n",
    "output[output < 0] = 0\n",
    "df_output = pd.DataFrame({'datetime': test_df['datetime'], 'count': output}, columns=('datetime', 'count'))\n",
    "df_output['count'] = df_output['count'].astype(int)\n",
    "df_output.to_csv('submission-gbm.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c bike-sharing-demand -f submission-gbm.csv -m 'ms=(4,6), n = 360'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print('cv for xgb model')\n",
    "xgb0 = XGBRegressor(n_estimators=200, random_state = 42, verbose=0, n_jobs=4)\n",
    "xgb1 = XGBRegressor(n_estimators=200, random_state = 42, verbose=0, n_jobs=4)\n",
    "xgb = MyEstimator(ma = xgb0, mb = xgb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'a_max_depth': [3,4,5,6,7,8], 'b_max_depth': [3,4,5,6,7,8], 'n_estimators': [100,1000]}\n",
    "# xgb_opt = skopt_min_fn(xgb, X, y, params, n_calls = 50, n_cv = 4)\n",
    "# print(xgb_opt.best_params, xgb_opt.best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'a_max_depth': [3,4,5,6,7,8], 'b_max_depth': [5,6,7,8]}\n",
    "# xgb_cv = GridSearchCV(xgb, params, cv = make_cv(X,2), n_jobs = 1, verbose = 1)\n",
    "# xgb_cv.fit(X, y)\n",
    "# print(xgb_cv.best_score_, xgb_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb_best_params = {'a_max_depth': 5, 'b_max_depth': 4,'n_estimators': 925}\n",
    "xgb.set_params(**xgb_best_params)\n",
    "xgb.fit(X, y)\n",
    "output_y = xgb.predict(test_df)\n",
    "output = np.round(np.expm1(output_y)).astype(int)\n",
    "output[output < 0] = 0\n",
    "df_output = pd.DataFrame({'datetime': test_df['datetime'], 'count': output}, columns=('datetime', 'count'))\n",
    "df_output['count'] = df_output['count'].astype(int)\n",
    "df_output.to_csv('submission-xgb.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf = pd.read_csv('submission-rf.csv')\n",
    "df_gbm = pd.read_csv('submission-gbm.csv')\n",
    "df_xgb = pd.read_csv('submission-xgb.csv')\n",
    "df_avg = pd.DataFrame(df_rf)\n",
    "df_avg['count'] = np.round((df_rf['count'] + df_gbm['count'] + df_xgb['count'] + 1) * 0.33).astype(int)\n",
    "# df_avg['count'] = np.round((df_rf['count'] + df_gbm['count'] + 1) * 0.5).astype(int)\n",
    "df_avg.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c bike-sharing-demand -f submission.csv -m 'avg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[submission link](https://www.kaggle.com/c/bike-sharing-demand/submissions?sortBy=date&group=all&page=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
