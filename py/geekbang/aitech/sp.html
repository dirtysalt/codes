
<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta  name="viewport" content="width=device-width, initial-scale=1" />
<title>Single Page Document</title>
<meta  name="generator" content="Org-mode" />
<meta  name="author" content="dirtysalt" />

<style type="text/css">html {
    font-family: Georgia, "Microsoft Yahei", "WenQuanYi Micro Hei";
}

/* pre { */
/*     background-color: #eee; */
/*     box-shadow: 5px 5px 5px #888; */
/*     border: none; */
/*     padding: 5pt; */
/*     margin-bottom: 14pt; */
/*     color: black; */
/*     padding: 12pt; */
/*     font-family: Consolas; */
/*     font-size: 95%; */
/*     overflow: auto; */
/* } */

.title  { /* text-align: center; */
          margin-bottom: 1em; }
.subtitle { /* text-align: center; */
            font-size: medium;
            font-weight: bold;
            margin-top:0; }
.todo   { font-family: monospace; color: red; }
.done   { font-family: monospace; color: green; }
.priority { font-family: monospace; color: orange; }
.tag    { background-color: #eee; font-family: monospace;
          padding: 2px; font-size: 80%; font-weight: normal; }
.timestamp { color: #bebebe; }
.timestamp-kwd { color: #5f9ea0; }
.org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
.org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
.org-center { margin-left: auto; margin-right: auto; text-align: center; }
.org-ul { padding-left: 10px; }
.org-ol { padding-left: 20px; }
ul { padding-left: 10px; }
ol { padding-left: 20px; }

.underline { text-decoration: underline; }
#postamble p, #preamble p { font-size: 90%; margin: .2em; }
p.verse { margin-left: 3%; }
pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
}
pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
}
pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
}
pre.src:hover:before { display: inline;}
pre.src-sh:before    { content: 'sh'; }
pre.src-bash:before  { content: 'sh'; }
pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
pre.src-R:before     { content: 'R'; }
pre.src-perl:before  { content: 'Perl'; }
pre.src-java:before  { content: 'Java'; }
pre.src-sql:before   { content: 'SQL'; }

table { border-collapse:collapse; }
caption.t-above { caption-side: top; }
caption.t-bottom { caption-side: bottom; }
td, th { vertical-align:top;  }
th.org-right  { text-align: center;  }
th.org-left   { text-align: center;   }
th.org-center { text-align: center; }
td.org-right  { text-align: right;  }
td.org-left   { text-align: left;   }
td.org-center { text-align: center; }
dt { font-weight: bold; }
.footpara { display: inline; }
.footdef  { margin-bottom: 1em; }
.figure { padding: 1em; }
.figure p { /* text-align: center; */ }
.inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
}
#org-div-home-and-up
{ text-align: right; font-size: 70%; white-space: nowrap; }
textarea { overflow-x: auto; }
.linenr { font-size: smaller }
.code-highlighted { background-color: #ffff00; }
.org-info-js_info-navigation { border-style: none; }
#org-info-js_console-label
{ font-size: 10px; font-weight: bold; white-space: nowrap; }
.org-info-js_search-highlight
{ background-color: #ffff00; color: #000000; font-weight: bold; }

/* http://www.yinwang.org/main.css */

body {
    /* font-family:"lucida grande", "lucida sans unicode", lucida, helvetica, "Hiragino Sans GB", "Microsoft YaHei", "WenQuanYi Micro Hei", sans-serif; */
    font-size: 18px;
    margin: 5% 5% 5% 5%;
    padding: 2% 5% 5% 5%;
    width: 80%;
    line-height: 150%;
    border: 1px solid LightGrey;
}

H1 {
    /* font-family: "Palatino Linotype", "Book Antiqua", Palatino, Helvetica, STKaiti, SimSun, serif; */
}

H2 {
    /* font-family: "Palatino Linotype", "Book Antiqua", Palatino, Helvetica, STKaiti, SimSun, serif; */
    margin-bottom: 60px;
    margin-bottom: 40px;
    padding: 5px;
    border-bottom: 2px LightGrey solid;
    width: 98%;
    line-height: 150%;
    color: #666666;
}


H3 {
    /* font-family: "Palatino Linotype", "Book Antiqua", Palatino, Helvetica, STKaiti, SimSun, serif; */
    margin-top: 40px;
    margin-bottom: 30px;
    border-bottom: 1px LightGrey solid;
    width: 98%;
    line-height: 150%;
    color: #666666;
}


H4 {
    /* font-family: "Palatino Linotype", "Book Antiqua", Palatino, Helvetica, STKaiti, SimSun, serif; */
    margin-top: 40px;
    margin-bottom: 30px;
    border-bottom: 1px LightGrey solid;
    width: 98%;
    line-height: 150%;
    color: #666666;
}


li {
    margin-left: 10px;
}


blockquote {
    border-left: 4px lightgrey solid;
    padding-left: 5px;
    margin-left: 20px;
}


pre {
    font-family: Inconsolata, Consolas, "DEJA VU SANS MONO", "DROID SANS MONO", Proggy, monospace;
    font-size: 75%;
    border: solid 1px lightgrey;
    background-color: Ivory;
    padding: 5px;
    line-height: 130%;
    margin-left: 10px;
    width: 95%;
}


code {
    font-family: Inconsolata, Consolas, "DEJA VU SANS MONO", "DROID SANS MONO", Proggy, monospace;
    font-size: 90%;
}


a {
    text-decoration: none;
    # cursor: crosshair;
    border-bottom: 1px dashed Red;
    padding: 1px;
    # color: black;
}


a:hover {
	background-color: LightGrey;
}


img {
    box-shadow: 0 0 10px #555;
    border-radius: 6px;
    margin-left: auto;
    margin-right: auto;
    margin-top: 10px;
    margin-bottom: 10px;
    -webkit-box-shadow: 0 0 10px #555;
    width: 100%;
    max-width: 600px;
}

img.displayed {
    display: block;
    margin-left: auto;
    margin-right: auto;
}

#table-of-contents {
    border-bottom: 2px LightGrey solid;
}</style>

</head>

<body>
<div id="content">
<h1 class="title">Single Page Document</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<ul>

<li><a href="#anchor0">开篇词 | 你的360度人工智能信息助理</a></li>

<li><a href="#anchor1">001 | 聊聊2017年KDD大会的时间检验奖</a></li>

<li><a href="#anchor2">002 | 精读2017年KDD最佳研究论文</a></li>

<li><a href="#anchor3">003 | 精读2017年KDD最佳应用数据科学论文</a></li>

<li><a href="#anchor4">004 | 精读2017年EMNLP最佳长论文之一</a></li>

<li><a href="#anchor5">005 | 精读2017年EMNLP最佳长论文之二</a></li>

<li><a href="#anchor6">006 | 精读2017年EMNLP最佳短论文</a></li>

<li><a href="#anchor7">007 | 精读2017年ICCV最佳研究论文</a></li>

<li><a href="#anchor8">008 | 精读2017年ICCV最佳学生论文</a></li>

<li><a href="#anchor9">009 | 如何将“深度强化学习”应用到视觉问答系统？</a></li>

<li><a href="#anchor10">010 | 精读2017年NIPS最佳研究论文之一：如何解决非凸优化问题？</a></li>

<li><a href="#anchor11">011 | 精读2017年NIPS最佳研究论文之二：KSD测试如何检验两个分布的异同？</a></li>

<li><a href="#anchor12">012 | 精读2017年NIPS最佳研究论文之三：如何解决非完美信息博弈问题？</a></li>

<li><a href="#anchor13">013 | WSDM 2018论文精读：看谷歌团队如何做位置偏差估计</a></li>

<li><a href="#anchor14">014 | WSDM 2018论文精读：看京东团队如何挖掘商品的替代信息和互补信息</a></li>

<li><a href="#anchor15">015 | WSDM 2018论文精读：深度学习模型中如何使用上下文信息？</a></li>

<li><a href="#anchor16">016 | The Web 2018论文精读：如何对商品的图片美感进行建模？</a></li>

<li><a href="#anchor17">017 | The Web 2018论文精读：如何改进经典的推荐算法BPR？</a></li>

<li><a href="#anchor18">018 | The Web 2018论文精读：如何从文本中提取高元关系？</a></li>

<li><a href="#anchor19">019 | SIGIR 2018论文精读：偏差和“流行度”之间的关系</a></li>

<li><a href="#anchor20">020 | SIGIR 2018论文精读：如何利用对抗学习来增强排序模型的普适性？</a></li>

<li><a href="#anchor21">021 | SIGIR 2018论文精读：如何对搜索页面上的点击行为进行序列建模？</a></li>

<li><a href="#anchor22">022 | CVPR 2018论文精读：如何研究计算机视觉任务之间的关系？</a></li>

<li><a href="#anchor23">023 | CVPR 2018论文精读：如何从整体上对人体进行三维建模？</a></li>

<li><a href="#anchor24">024 | CVPR 2018论文精读：如何解决排序学习计算复杂度高这个问题？</a></li>

<li><a href="#anchor25">025 | ICML 2018论文精读：模型经得起对抗样本的攻击？这或许只是个错觉</a></li>

<li><a href="#anchor26">026 | ICML 2018论文精读：聊一聊机器学习算法的“公平性”问题</a></li>

<li><a href="#anchor27">027 | ICML 2018论文精读：优化目标函数的时候，有可能放大了“不公平”？</a></li>

<li><a href="#anchor28">028 | ACL 2018论文精读：问答系统场景下，如何提出好问题？</a></li>

<li><a href="#anchor29">029 | ACL 2018论文精读：什么是对话中的前提触发？如何检测？</a></li>

<li><a href="#anchor30">030 | ACL 2018论文精读：什么是“端到端”的语义哈希？</a></li>

<li><a href="#anchor31">复盘 7 | 一起来读人工智能国际顶级会议论文</a></li>

<li><a href="#anchor32">031 | 经典搜索核心算法：TF-IDF及其变种</a></li>

<li><a href="#anchor33">032 | 经典搜索核心算法：BM25及其变种（内附全年目录）</a></li>

<li><a href="#anchor34">033 | 经典搜索核心算法：语言模型及其变种</a></li>

<li><a href="#anchor35">034 | 机器学习排序算法：单点法排序学习</a></li>

<li><a href="#anchor36">035 | 机器学习排序算法：配对法排序学习</a></li>

<li><a href="#anchor37">036 | 机器学习排序算法：列表法排序学习</a></li>

<li><a href="#anchor38">037 | “查询关键字理解”三部曲之分类</a></li>

<li><a href="#anchor39">038 | “查询关键字理解”三部曲之解析</a></li>

<li><a href="#anchor40">039 | “查询关键字理解”三部曲之扩展</a></li>

<li><a href="#anchor41">040 | 搜索系统评测，有哪些基础指标？</a></li>

<li><a href="#anchor42">041 | 搜索系统评测，有哪些高级指标？</a></li>

<li><a href="#anchor43">042 | 如何评测搜索系统的在线表现？</a></li>

<li><a href="#anchor44">043 | 文档理解第一步：文档分类</a></li>

<li><a href="#anchor45">044 | 文档理解的关键步骤：文档聚类</a></li>

<li><a href="#anchor46">045 | 文档理解的重要特例：多模文档建模</a></li>

<li><a href="#anchor47">046 | 大型搜索框架宏观视角：发展、特点及趋势</a></li>

<li><a href="#anchor48">047 | 多轮打分系统概述</a></li>

<li><a href="#anchor49">048 | 搜索索引及其相关技术概述</a></li>

<li><a href="#anchor50">049 | PageRank算法的核心思想是什么？</a></li>

<li><a href="#anchor51">050 | 经典图算法之HITS</a></li>

<li><a href="#anchor52">051 | 社区检测算法之“模块最大化 ”</a></li>

<li><a href="#anchor53">052 | 机器学习排序算法经典模型：RankSVM</a></li>

<li><a href="#anchor54">053 | 机器学习排序算法经典模型：GBDT</a></li>

<li><a href="#anchor55">054 | 机器学习排序算法经典模型：LambdaMART</a></li>

<li><a href="#anchor56">055 | 基于深度学习的搜索算法：深度结构化语义模型</a></li>

<li><a href="#anchor57">056 | 基于深度学习的搜索算法：卷积结构下的隐含语义模型</a></li>

<li><a href="#anchor58">057 | 基于深度学习的搜索算法：局部和分布表征下的搜索模型</a></li>

<li><a href="#anchor59">复盘 1 | 搜索核心技术模块</a></li>

<li><a href="#anchor60">058 | 简单推荐模型之一：基于流行度的推荐模型</a></li>

<li><a href="#anchor61">059 | 简单推荐模型之二：基于相似信息的推荐模型</a></li>

<li><a href="#anchor62">060 | 简单推荐模型之三：基于内容信息的推荐模型</a></li>

<li><a href="#anchor63">061 | 基于隐变量的模型之一：矩阵分解</a></li>

<li><a href="#anchor64">062 | 基于隐变量的模型之二：基于回归的矩阵分解</a></li>

<li><a href="#anchor65">063 | 基于隐变量的模型之三：分解机</a></li>

<li><a href="#anchor66">064 | 高级推荐模型之一：张量分解模型</a></li>

<li><a href="#anchor67">065 | 高级推荐模型之二：协同矩阵分解</a></li>

<li><a href="#anchor68">066 | 高级推荐模型之三：优化复杂目标函数</a></li>

<li><a href="#anchor69">067 | 推荐的Exploit和Explore算法之一：EE算法综述</a></li>

<li><a href="#anchor70">068 | 推荐的Exploit和Explore算法之二：UCB算法</a></li>

<li><a href="#anchor71">069 | 推荐的Exploit和Explore算法之三：汤普森采样算法</a></li>

<li><a href="#anchor72">070 | 推荐系统评测之一：传统线下评测</a></li>

<li><a href="#anchor73">071 | 推荐系统评测之二：线上评测</a></li>

<li><a href="#anchor74">072 | 推荐系统评测之三：无偏差估计</a></li>

<li><a href="#anchor75">073 | 现代推荐架构剖析之一：基于线下离线计算的推荐架构</a></li>

<li><a href="#anchor76">074 | 现代推荐架构剖析之二：基于多层搜索架构的推荐系统</a></li>

<li><a href="#anchor77">075 | 现代推荐架构剖析之三：复杂现代推荐架构漫谈</a></li>

<li><a href="#anchor78">076 | 基于深度学习的推荐模型之一：受限波兹曼机</a></li>

<li><a href="#anchor79">077 | 基于深度学习的推荐模型之二：基于RNN的推荐系统</a></li>

<li><a href="#anchor80">078 | 基于深度学习的推荐模型之三：利用深度学习来扩展推荐系统</a></li>

<li><a href="#anchor81">复盘 2 | 推荐系统核心技术模块</a></li>

<li><a href="#anchor82">079 | 广告系统概述</a></li>

<li><a href="#anchor83">080 | 广告系统架构</a></li>

<li><a href="#anchor84">081 | 广告回馈预估综述</a></li>

<li><a href="#anchor85">082 | Google的点击率系统模型</a></li>

<li><a href="#anchor86">083 | Facebook的广告点击率预估模型</a></li>

<li><a href="#anchor87">084 | 雅虎的广告点击率预估模型</a></li>

<li><a href="#anchor88">085 | LinkedIn的广告点击率预估模型</a></li>

<li><a href="#anchor89">086 | Twitter的广告点击率预估模型</a></li>

<li><a href="#anchor90">087 | 阿里巴巴的广告点击率预估模型</a></li>

<li><a href="#anchor91">088 | 什么是“基于第二价位的广告竞拍”？</a></li>

<li><a href="#anchor92">089 | 广告的竞价策略是怎样的？</a></li>

<li><a href="#anchor93">090 | 如何优化广告的竞价策略？</a></li>

<li><a href="#anchor94">091 | 如何控制广告预算？</a></li>

<li><a href="#anchor95">092 | 如何设置广告竞价的底价？</a></li>

<li><a href="#anchor96">093 | 聊一聊“程序化直接购买”和“广告期货”</a></li>

<li><a href="#anchor97">094 | 归因模型：如何来衡量广告的有效性</a></li>

<li><a href="#anchor98">095 | 广告投放如何选择受众？如何扩展受众群？</a></li>

<li><a href="#anchor99">096 | 如何利用机器学习技术来检测广告欺诈？</a></li>

</ul>
</div>


<div class="outline-2">
<h2 id="anchor0">开篇词 | 你的360度人工智能信息助理<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>你好，我是洪亮劼，目前在电子商务网站Etsy任数据科学主管，很高兴能和你在这里相识，也很期待在接下来的时间里，通过“AI技术内参”这个专栏和你共同探讨与人工智能有关的话题。</p>
<p>在未来的一年里，我会为你讲解人工智能的核心基础，介绍顶级学术会议的最新研究成果，为广大工程师和数据科学家的个人成长出谋划策，也期待能为计划成立和管理数据科学家团队的工程管理领导提供一些意见和建议。我希望“AI技术内参”能够成为你的360度人工智能信息助理，帮助你在这个高速发展的领域稳步前行。</p>
<p>那么，我为什么愿意来写这么一个专栏呢？这让我想起了最近发生的一个片段，我在波士顿参加一个有关数据科学的工业界会议，会场上，一位目前在美国一家时装品牌J.Crew工作的数据科学家和我聊天，中间问我，如果想在数据科学、人工智能这个领域进阶，需要看什么样的资料、需要怎样才能不断学习和进步。我当时发现，自己很难为这位数据科学家推荐某一本书、某几篇论文、某一个资料，就能够起到这样的作用。</p>
<p>事实上，回想我自己在人工智能这个领域的成长，一个突出的特点就是，需要学习的东西太多、太杂而且很细。</p>
<p>比方说，对于一个人工智能领域的从业人员来说，基础阶段需要系统地学习有关机器学习、概率统计的很多书，还要会使用相关的专业软件以及人工智能框架，然后如果你希望能够在某一个专业领域（比如搜索、推荐、图像技术、语音技术、智能驾驶等）有所发展，还需要阅读这些相关领域的很多技术论文，并且去实践相关的算法模型。</p>
<p>更进一步，要想在技术公司能够真正成长下去，还有很多的工程技巧以及实际经验需要你慢慢习得。这些情况都导致人工智能领域专业人才的培养和成长有很高的门槛。</p>
<p>我自己，以及很多希望能够在这个领域有所发展的朋友，都很急迫地需要有这么一个集中地、有计划地获取信息，获取高质量信息的平台。这让我萌生了自己来写这么一个专栏的想法。</p>
<p>我希望“AI技术内参”这个专栏能够成为你在人工智能领域成长的灯塔，当你在茫茫的知识海洋里航行时，帮助你快速找到核心的、主干的信息和资源。我希望这个专栏能够成为你在职业发展上的朋友，让你对快速发展的行业不再焦虑，不再担心自己的知识会落伍，不再为如何在日新月异的信息中寻找有价值的学习资料而发愁。</p>
<p>同时，我也希望这个专栏能够为你拓宽视野，让数据科学家、人工智能工程师了解到团队管理者是如何构建一个团队、如何来招聘从业人士的，让数据科学的领导者意识到如何培养数据科学家成长，让你对整个行业的生态系统有一个更加完整的认识。</p>
<p>我为这个专栏精心打磨了三个模块。</p>
<p><strong>第一，我会为你讲解一些经典的人工智能技术。</strong>这些技术涵盖搜索、推荐系统、广告系统、图像处理等领域。了解这些经典技术能够让你迅速入门并能为今后的学习打下基础。这部分内容帮助你分析核心的算法模型，并为你进行系统性学习提供纲要和指引。</p>
<p><strong>第二，我会带给你最新的顶级学术会议动态，帮助你了解和掌握这些学术会议最火热和最新的研究成果。</strong>每一年和人工智能相关的顶级学术会议有十余个，每个会议都会有上百篇甚至几百篇论文发表。从这些论文和成果中找到有价值的信息，对于初学者，甚至是有一定经验的从业人员来说都是非常困难、也非常耗时的一件事情。那么，在这个专栏里，我会为你精选内容，可以让你不错过任何有价值的最新成果。</p>
<p><strong>第三，我会在这个专栏里为人工智能的从业人员提供指南，帮助数据科学家和工程师提升自我价值，帮助人工智能团队的管理者构建团队，为你在职场发展中的关键步骤出谋划策。</strong></p>
<p><img src="https://static001.geekbang.org/resource/image/5c/08/5c89fe07fe0e5a5f1e4f8491ac592408.jpg" alt=""></p>
<p>希望我们在今后的一年时间里，通过“AI技术内参”这个平台，共同学习、共同成长。“AI技术内参”只是一个起点，希望你能够从这个专栏出发，在人工智能这个领域前行得更好、更高、更远。</p>
<p><img src="https://static001.geekbang.org/resource/image/ef/b2/efd991ee74e55356bb2776f3d8d375b2.jpg" alt=""></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor1">001 | 聊聊2017年KDD大会的时间检验奖<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>国际数据挖掘与知识发现大会<strong>ACM SIGKDD</strong>（ACM SIGKDD Conference on Knowledge Discovery and Data Mining），简称<strong>KDD</strong>，是由美国计算机协会<strong>ACM</strong>（The Association for Computing Machinery）的数据挖掘与知识发现专委会<strong>SIGKDD</strong>（Special Interest Group on Knowledge Discovery and Data Mining）主办，堪称数据挖掘研究领域的顶级会议。</p>
<p>KDD最早是从1989年开始的KDD 研讨班（Workshop）发展而来，当时的研讨班依托于人工智能顶级会议IJCAI大会或者AAAI大会，而后在1995年升级成为会议的模式，到现在已经有20多年的历史。今年的KDD大会于8月13日至17日在加拿大哈利法克斯成功召开。</p>
<p>SIGKDD每年都会奖励一篇论文，这篇论文要在过去十年间对研究、方法论以及实践产生重大影响，这就是所谓的<strong>时间检验奖</strong>（Test of Time Award），引用次数以及对一个领域的影响力度是评选这个奖项的重要指标。</p>
<p>2017年的KDD时间检验奖授予了美国康奈尔大学信息科学系主任、计算机科学系教授索斯藤·乔基姆斯（Thorsten Joachims）。这次授予是为了表彰他的论文《线性时间内训练线性支持向量机》（Training Linear SVMs in Linear Time），这篇论文也是2006年的KDD最佳论文，引用数超过1600多次。</p>
<h2>Thorsten的学术贡献</h2>
<p>Thorsten是一位机器学习界享有盛誉的学者，也是ACM和AAAI的双料院士，他所有论文的引用数加起来超过了4万次。2001年从德国多特蒙德大学博士毕业后，他正式加入康奈尔大学从事机器学习研究。</p>
<p>获得这个奖项之前，Thorsten曾多次获得重要奖项，比如2017年ACM WSDM的最佳论文奖（Best Paper Award）、2016年ACM SIGIR的时间检验奖、2015年ACM KDD的时间检验奖、2009年ECML的最佳论文奖、2009年ICML的10年最佳论文奖（Best 10-Year Paper Award）、2006年ACM KDD的最佳论文奖、2005年ICML的最佳论文奖、2005年ICML的优秀学生论文奖、2005年ACM KDD的最佳学生论文奖等。</p>
<p>Thorsten在机器学习领域一直有着非常特殊的贡献。首先，他在支持向量机（SVM）的应用上做出了诸多努力。比如这次的时间检验奖，<strong>就是奖励他如何把支持向量机的训练达到线性复杂度，从而使支持向量机在大规模数据上的应用成为可能。</strong></p>
<p>Thorsten还致力于把支持向量机的基本算法，也就是仅仅支持分类问题和回归问题的算法，应用到更加复杂的有结构的输出结果上，俗称结构化的支持向量机算法。得益于这项工作，支持向量机可以对信息检索中很多复杂的、非二分的评估指标进行直接优化，如F1值（F-score）、平均精度均值（Mean Average Precision），从而让支持向量机的应用变得更加广阔。</p>
<p>在让支持向量机能够顺利应用到信息检索的过程中，Thorsten还发现了另外一个问题，那就是如何利用搜索引擎的间接用户反馈（Implicit Feedback）来训练排序算法（经常是一个结构化的支持向量机模型）。具体来说，传统的搜索系统和信息检索系统主要是依靠人工标注的训练数据来进行优化和评估。这里所说的人工标注训练数据，主要是指人为地评价目标查询关键字和所对应的网页是否相关。</p>
<p>早期大家发现，虽然搜索引擎可以利用这样的数据来优化排序算法，但是搜索引擎在使用过程中会产生很多用户数据。这些数据可以是用户点击搜索页面结果产生的信息，也可以是其他的信息（比如用户在搜索页面的驻留时间等等）。早期这些信息并没有用于优化搜索引擎。以Thorsten为主的一批学者意识到点击信息的重要性，然后开始利用这些数据来训练和评估排序算法。这是Thorsten的第二个主要学术贡献。</p>
<p>Thorsten第三个主要学术贡献，也是他最近几年的学术成功，那就是把<strong>因果推论（Causal Inference）</strong>和机器学习相结合，从而能够更加无偏差地训练模型。可以说这部分工作开创了一个新领域。</p>
<p>长期以来，如何有效地应用用户产生的交互数据来进行模型训练，都是大规模机器学习特别是工业界机器学习的难点。一方面，工业系统能够产生很多用户数据；另一方面，这些用户数据又受到当前部署系统的影响，一般都有一定的偏差。</p>
<p>因此工业级机器学习系统面临一个长期挑战，那就是，如何能够在评估模型以及训练模型的时候考虑到这样的偏差，从而去除这样的偏差。</p>
<!-- [[[read_end]]] -->
<p>Thorsten利用因果推论中的倾向评分（Propensity Scoring）技术以及多臂赌博机（Multi-armed Bandit）思想，把这样的方法成功地引入到机器学习中，使得无偏差地训练模型成为可能。目前，这方面的新研究和新思想正在机器学习以及应用界产生越来越多的共鸣。</p>
<h2>线性大规模支持向量机</h2>
<p>回到这篇时间检验奖的论文，它解决的是大规模优化支持向量机的问题，特别是线性支持向量机。这篇文章<strong>第一次提出了简单易行的线性支持向量机实现</strong>，包括对有序回归（Ordinal Regression）的支持。算法对于分类问题达到了O(sn)（其中s是非0的特征数目而n是数据点的个数），也就是实现了线性复杂度，而对有序回归的问题达到了O(snlog(n))的复杂度。算法本身简单、高效、易于实现，并且理论上可以扩展到核函数（Kernel）的情况。</p>
<p>在此之前，很多线性支持向量机的实现都无法达到线性复杂度 。比如当时的LibSVM（台湾国立大学的学者发明）、SVM-Torch、以及早期的SVM-Light中采用的分解算法（Decomposition Method）都只能比较有效地处理大规模的特征。而对于大规模的数据(n)，则是超线性（Super-Linear）的复杂度。</p>
<p>另外的一些方法，能够训练复杂度线性地随着训练数据的增长而增长，但是却对于特征数N呈现了二次方(N^2)的复杂度。因此之前的这些方法无法应用到大规模的数据上。这样的情况对于有序回归支持向量机更加麻烦。从德国学者拉尔夫·赫布里希（Ralf Herbrich）提出有序回归支持向量机以来，一直需要通过转化为普通的支持向量机的分类问题而求解。这个转换过程需要产生O(n^2)的训练数据，使得整个问题的求解也在这个量级的复杂度。</p>
<p>这篇文章里，Thorsten首先做的是对普通的支持向量机算法的模型形式（Formalism）进行了变形。他把传统的分类支持向量机（Classification SVM）写成了<strong>结构化分类支持向量机（Structural Classification SVM）</strong>，并且提供了一个定理来证明两者之间的等价性。粗一看，这个等价的结构化分类支持向量机并没有提供更多有价值的信息。然而这个新的优化目标函数的对偶（Dual）形式，由于它特殊的稀疏性，使它能够被用来进行大规模训练。紧接着，Thorsten又把传统的有序回归支持向量机的优化函数，写成了结构化支持向量机的形式，并且证明了两者的等价性。</p>
<p>把两种模型表达成结构化向量机的特例之后，Thorsten开始把解决结构化向量机的一种算法——<strong>切割平面算法（Cutting-Plane）</strong>，以下称CP算法，运用到了这两种特例上。首先，他展示了CP算法在分类问题上的应用。简单说来，这个算法就是保持一个工作集合（Working Set），来存放当前循环时依然被违反的约束条件（Constraints），然后在下一轮中集中优化这部分工作集合的约束条件。</p>
<p>整个流程开始于一个空的工作集合，每一轮优化的是一个基于当前工作集合的支持向量机子问题，算法直到所有的约束条件的误差小于一个全局的参数误差为止。Thorsten在文章中详细证明了这个算法的有效性和时间复杂度。相同的方法也使得有序回归支持向量机的算法能够转换成为更加计算有效的优化过程。</p>
<p>Thorsten在文章中做了详尽的实验来展现新算法的有效性。从数据的角度，他使用了5个不同的数据集，分别是路透社RCV1数据集的好几个子集。数据的大小从6万多数据点到80多万数据点不等，特征数也从几十到四万多特征不等，这几种不同的数据集还是比较有代表性的。从方法的比较上来说，Thorsten主要比较了传统的分解方法。</p>
<p>有两个方面是重点比较的，第一就是训练时间。在所有的数据集上，这篇文章提出的算法都比传统算法快几个数量级，提速达到近100倍。而有序回归的例子中，传统算法在所有数据集上都无法得到最后结果。Thorsten进一步展示了训练时间和数据集大小的线性关系，从而验证了提出算法在真实数据上的表现。</p>
<p>第二个重要的比较指标是算法的准确度是否有所牺牲。因为有时候算法的提速是在牺牲算法精度的基础上做到的，因此验证算法的准确度就很有意义。在这篇文章里，Thorsten展示，提出的算法精度，也就是分类准确度并没有统计意义上的区分度，也让这个算法的有效性有了保证。</p>
<p>Thorsten在他的软件包SVM-Perf中实现了这个算法。这个软件包一度成了支持向量机研究和开发的标准工具。</p>
<h2>小结</h2>
<p>今天我和你分享了Thorsten的这篇论文，堪称支持向量机文献史上的经典。一起来回顾下要点：第一，Thorsten在机器学习领域有三大主要学术贡献；第二，这篇论文理论论证非常扎实，算法清晰，而且之后通过有效的实验完全验证了提出算法的有效性。文章开启了支持向量机在搜索领域的广泛应用，不愧为2006年的KDD最佳论文以及今年的时间检验奖论文。</p>
<p>最后，给你留一个思考题，在什么应用场景下，线性大规模支持向量机可以有比较好的效果？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p>扩展阅读：<a href="https://www.cs.cornell.edu/people/tj/publications/joachims_06a.pdf">Training Linear SVMs in Linear Time</a></p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor2">002 | 精读2017年KDD最佳研究论文<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>前面我们介绍过KDD大会的时间检验奖，每年大会的另外一个亮点奖项就是最佳论文奖，有两类，一类是最佳研究论文，一类是最佳应用数据科学论文。今天我就先来说说前者。</p>
<p>大会每年都会在众多的学术研究论文中，选择最有新意和价值的研究论文，评选出最佳研究论文的第一名和第二名。从过去十多年的经验来看，KDD历年的最佳研究论文，都会对之后很多领域的研究有开创性的影响。因此，不论是从阅读经典文献的角度，还是从学习最新研究成果的角度来说，认真分析和探讨每年的最佳研究论文都是一个不错的选择。</p>
<p>今天，我就带你认真剖析一下KDD 2017年的最佳研究论文《通过挖掘类比关系加速创新》（Accelerating Innovation Through Analogy Mining）。</p>
<h2>作者群信息介绍</h2>
<p>第一作者汤姆·霍普（Tom Hope）来自耶路撒冷的希伯来大学（The Hebrew University of Jerusalem），计算机博士，在读第三年。同时，他还是英特尔以色列的资深数据科学员，对深度学习的很多方面都有研究。目前他正在写一本基于TensorFlow的深度学习简明技术书籍。</p>
<p>第四作者达夫娜·沙哈夫（Dafna Shahaf）是霍普的博士导师，目前在希伯来大学计算机系任助理教授。达夫娜于2012年从卡内基梅隆大学博士毕业。她曾经在微软研究院以及富士通公司实习，并在斯坦福大学攻读博士后。达夫娜的论文曾获得2010年的KDD最佳研究论文，可以说她一直站在机器学习研究的前沿。</p>
<p>第二作者乔尔（Joel Chan）是来自卡内基梅隆大学人机交互学院的科学家。乔尔于2014年从匹兹堡大学毕业，获得认知心理学博士学位。他一直在人机交互领域进行研究。</p>
<p>第三作者安尼凯特·科图（Aniket Kittur）是来自卡内基梅隆大学人机交互学院的副教授。他于2009年从加州大学洛杉矶分校毕业，获得认知心理学博士学位，之后就一直在卡内基梅隆大学任教。</p>
<p>从整个作者群的情况来看，这篇文章是一个比较典型的机器学习技术与人机交互领域的交叉成果。</p>
<h2>论文的主要贡献</h2>
<p>我们先来看一下这篇文章的主要贡献。当然，要想深入理解这篇文章的贡献，我们还要先弄明白，这篇文章主要解决的是一个什么场景下的问题。</p>
<!-- [[[read_end]]] -->
<p><strong>这篇文章主要阐述了帮助创新的一个重要步骤，那就是如何找到合适并且有效的类比案例</strong>。什么叫作类比案例？在人类发展的历史上，特别是科学技术的革新历程中，有很多重要的发明发现，都是因为当时的科学家借鉴了一些类似场景中的解决方案，或者是从这些场景中获取了灵感，进一步做出了创新。在这个步骤中，从类似场景中借鉴往往被称作类比。</p>
<p>比如，莱特兄弟从自行车中得到灵感，制造出了可以滑行的飞行器。再比如，诺贝尔生理学或医学奖得主萨尔瓦多·卢里亚从对赌博机运行的观察中，进一步发现了细菌基因突变的规律。同时，类比在很多国家的法律，不管是成文中或者是运行中都比比皆是。因此，我们可以看到，<strong>如何找到合适的类比，并能从中获取灵感，可能就是创新的一个关键因素</strong>。</p>
<p>时至互联网时代的今天，我们已经有很多数据库、文献库可以作为获取类比灵感的重要数据源泉。比如，谷歌学术搜索（Google Scholar）有上百万的论文和专利信息；OpenIDEO有上百份关于社会问题的分析；Quirky有超过两百万份的产品构想；InnoCentive有超过四万份的社会、政治以及科技方面的解决方案；美国专利局有超过九百万份的专利信息，类似的例子还有很多。</p>
<p>与此同时，海量数据也为寻找灵感带来了很大的挑战。如何才能在这些百万级别的信息库里快速定位可能的类比场景，就成了阻碍创新速度的一大瓶颈。</p>
<p>找到类比场景有一个很大的挑战，那就是如何定义“类似”或者“相似”。如果仅从一些表面特征来看，很多场景之间的相似程度是很低的。因此，好的类比场景一定是能够找到，刨除表象相似以外的深层次相似的案例。另外一个挑战就是，寻找类比场景中，是否能有一个<strong>非常丰富的数据结构</strong>来支持推理，如果有，往往就能有比较简单的方法。</p>
<p>这篇论文的重点是如何从海量的无结构或者弱结构的文本数据中找到这样的类比。我们可以看出，这确实是一个巨大的挑战。</p>
<p>理解了这篇论文的目的，我这里就直接给你总结一下它的贡献，那就是提出了一种自动的在海量无结构的文本数据中挖掘类比场景的方法。这篇文章关注的是产品信息数据。作者们通过实际的数据，验证了提出的方法比之前的一些文本处理方法更加有效。</p>
<h2>论文的核心方法</h2>
<p>了解了这篇文章的目的和贡献后，接下来，我就来剖析一下作者们究竟提出了一个什么方法。</p>
<p>首先，作者们提出了一组叫“<strong>目的</strong>”（Purpose）和“<strong>机制</strong>”（Mechanism）的概念。什么叫“目的”呢？那就是当前的产品是要解决什么问题的。什么叫“机制”呢？那就是当前的产品是使用什么手段或者方法来解决这个问题的。对于一个产品，如果我们能够明确这个产品的目的和机制，找到类比就变得更加容易。</p>
<p>比如，我们可以针对某一个问题，相同的目的，采用不同的机制或者对不同的问题采用相同的机制。作者们认为，<strong>这种对产品信息的分类符合很多工程设计的过程，是创新过程中的一个必要环节</strong>。</p>
<p>有了这种想法以后，很自然的下一个步骤就是如何从数据中学习到目的和机制，如何自动挖掘出海量产品信息的目的和机制。要想学习到这样的信息，作者们提出了一种依靠标签数据的监督学习（Supervised Leanring）机制。具体说来，作者们把文本信息中的每句话、短语交给亚马逊土耳其机器人（Amazon Mechanical Turk）上的在线工人，来标注每个文本信息是目的信息还是机制信息。也就是说，作者们依靠有标注的数据来训练提出的算法。</p>
<p>首先，我们有一组文本，每组文本都有这些文本的原始文字。<strong>针对每个文档，我们都收集K个目的标注和K个机制标注</strong>。这时，我们定义一组“目的标注”（Purpose Annotation）向量，其实也就是一组0或者1的向量。当文本原始文字中的某个字被标识为目的的时候，这个向量的相应元素置1，反之置0。类似的，我们也可以定义“机制标注”（Mechanism Annotation）向量。因为我们有K个标注，因此我们也有相应的K个“目的标注”向量和“机制标注”向量。这两组向量可以说是原始标签信息的一种向量的表达。</p>
<p>下一步就是从每一个有标签信息的文档里<strong>产生唯一的目的向量和机制向量</strong>。这篇文章采用的方法是，利用每个单词的<strong>嵌入向量</strong>（Embedding）来获得这个唯一的向量。</p>
<p>具体方法是这样的，首先，针对每一个标注（总共有K个），我们收集属于这个标注的单词的嵌入向量，并把这些嵌入向量都拼接起来。然后计算这组拼接好的向量所对应单词的<strong>TF-IDF值</strong>（Term Frequency–Inverse Document Frequency，词频-逆向文件频率），并且取TF-IDF值最高的一些单词相对应的嵌入向量，加权平均以后，就得到了相应的唯一的目的向量或者是机制向量。作者们发现这种利用TF-IDF值加权的方法可以更加有效地表达文本的各种重要信息。注意，这个步骤是依赖于文档标签的，也就是说，我们只能对训练数据进行这样的构造。</p>
<p>到目前为止，我们描述了如何从文本到达文本对应的目的向量和机制向量的步骤。那么，如何基于这样的数据以及向量，来对未知的文档进行提取目的向量和机制向量呢？文章采用了深度模型<strong>RNN</strong>（Recurrent Neural Network，循环神经网络），具体说来是双向的RNN并且有一个<strong>GRU</strong>（Gated Recurrent Unit，门控循环单元）。</p>
<p>这里我就不复述细节了，总体的思路就是，根据文档的嵌入向量信息，我们希望得到一组文档的<strong>隐含表达</strong>（中间参数），然后可以从这个隐含表达来预测目的向量和机制向量。注意，因为需要预测两组目标，目的向量和机制向量，因此，这里至少需要分别有两组参数。</p>
<p>除了预测文档的目的向量和机制向量以外，作者们还提出了一个用<strong>少数关键词</strong>来解释这两组变量的机制。具体说来，就是设立一个新的学习目标函数，希望通过少数关键词所对应的嵌入向量来重构目的向量或者机制向量，让得到的误差最小。</p>
<h2>方法的实验效果</h2>
<p>作者们使用了Quirky数据集，通过亚马逊土耳其机器人标注了八千多组产品信息。首先，检测了利用学习到的目的向量和机制向量，是否能够比较容易地从海量数据中提取相应的类比信息。这里，作者们直接利用把目的向量和机制向量拼接的方式来表达问题。答案是，效果非常显著。<strong>在前1%到25%的提取结果中，精度（Precision）和召回（Recall）都比之前的标准文本处理方法，比如LDA、TF-IDF、全局的嵌入向量要好10%到20%</strong>，可以说这是非常有效果的。</p>
<p>作者们还测试了，通过提出的方法，是否能够为用户推荐比较好的类比场景。这里，文章又找了38个亚马逊土耳其机器人的虚拟工人来为12个产品思路打分。在不知道推荐方法的情况下，虚拟工人认为这篇文章提出的方法能够推荐更有新意、在深层次上更加类似的场景。这也部分解决了我们前面说到的文章希望解决的问题。</p>
<h2>小结</h2>
<p>今天我为你讲了KDD 2017年的年度最佳研究论文，这篇论文提出了一种自动的方法来挖掘类比信息，为快速创新铺平道路。一起来回顾下要点：第一，我简单地介绍了这篇文章的作者群信息，帮你了解到这篇文章是机器学习和人机交互研究的一个结合。第二，我详细地介绍了这篇文章想要解决的问题以及贡献。第三，我简要地介绍了文章所提出方法的核心内容。</p>
<p>最后，给你留一个思考题，这篇文章提出的是使用标注信息来获取目的向量和机制向量，我们有没有办法能够不使用标注信息，采用完全无监督的方式呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p>拓展阅读：<a href="http://www.hyadatalab.com/papers/analogy-kdd17.pdf">Accelerating Innovation Through Analogy Mining</a></p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor3">003 | 精读2017年KDD最佳应用数据科学论文<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>周一我们讲了2017年KDD最佳研究论文，今天我们继续来聊今年的KDD最佳应用数据科学论文。</p>
<p>与研究类论文不同的是，KDD的应用类学术论文更加强调论文所描述的方法或者系统在实际应用中发挥的作用。比如，很多论文都是对现有的已部署的系统进行总结，对工业界的很多研究人员和工程师往往都有不小的借鉴意义。和研究类论文一样，从阅读经典文献和学习最新研究成果的角度，我们都应该认真分析和探讨每年的最佳应用类论文。</p>
<p>2017年KDD最佳应用数据科学论文题目是，《HinDroid：基于结构性异构信息网络的智能安卓恶意软件检测系统》（HinDroid: An Intelligent Android Malware Detection System Based on Structured Heterogeneous Information Network）。可以说2017年是信息安全备受关注的一年，2016年美国大选过程中传出了种种关于俄罗斯利用黑客入侵大选候选人的新闻，让整个社会对信息安全的话题变得异常敏感。这是一篇有关如何智能地分析安卓恶意软件的论文，真是非常应景。</p>
<h2>作者群信息介绍</h2>
<p>文章的第一作者和第二作者都来自西弗吉尼亚大学（West Virginia University）的计算机科学与电气工程系。第一作者Shifu Hou是该系的博士生，先后发表过多篇论文。第二作者叶艳芳（Yanfang Ye）是该系的助理教授。叶艳芳2010年从厦门大学博士毕业，先后在金山公司和科摩多（Comodo Security Solutions）从事信息安全方面的研究和开发工作。2013年，她加入西弗吉尼亚大学任教。这篇KDD论文因为第一作者也是在读学生，因此也是最佳学生论文。</p>
<p>第三作者宋阳秋（Yangqiu Song）是来自香港科技大学的计算机系助理教授。宋阳秋有丰富的学术和工业界经历。2016年加入香港科技大学，在这之前曾经在西弗吉尼亚大学任教。2012年到2015年之间他曾在伊利诺伊大学香槟分校、香港科技大学、华为诺亚方舟实验室等地访问。2009年到2012年曾在微软亚洲研究院和IBM研究院工作。2009年于清华大学博士毕业。</p>
<p>最后一位作者是土耳其企业家米勒夫·阿杜勒哈尤格鲁（Melih Abdulhayoğlu）。他是科摩多（Comodo）的CEO，于1998年创立了公司。这篇论文挂了他的名字是因为使用了科摩多的数据。</p>
<h2>论文的主要贡献</h2>
<p>我们首先来看一下这篇文章的主要贡献。类似地，按照我们周一分析最佳研究论文的思路，首先必需弄明白，这篇文章主要解决了什么场景下的问题。</p>
<!-- [[[read_end]]] -->
<p>这篇文章希望解决的问题描述起来很直观，那就是<strong>如何有效地监测安卓手机系统下的恶意软件</strong>。经预测，到2019年，全球的手机市场中，77.7%将是智能手机，这里面安卓系统的市场占有率至少是80%。由于安卓系统的开放性以及分散的各类安卓手机软件市场，对安卓软件进行监控和分析存在很大难度。各类恶意软件在安卓生态系统中可以说层出不穷，比如Geinimi、DroidKungfu以及Lotoor等等。更悲观的统计来自赛门铁克（Symantec）的《互联网安全威胁报告》，认为五分之一的安卓软件是恶意软件。</p>
<p>之前很多恶意软件的分析和检测都是基于某种“<strong>指纹签字</strong>”技术，然而这种技术常常被恶意软件开发者的新手段绕过。因此，寻找更加复杂有效的检测方式就成了各种信息安全公司所追逐的目标。</p>
<p><strong>这篇论文的主要贡献是根据安卓的API，提出了一种新的基于结构性异构信息网络的方法，来对安卓程序的API模式进行更加复杂的建模，从而能够理解整个安卓程序的语义</strong>。作者们还采用了<strong>多核学习</strong>（Multi-Kernel Learning）的方法，在结构性异构信息网络的基础上对程序语义模式进行分类。</p>
<p>最后，文章提出的方法在科摩多的真实数据上达到了非常高的准确度，远远优于现在的一些主流方法。并且，科摩多已经在产品中部署了这个方法。</p>
<h2>论文的核心方法</h2>
<p>了解了这篇文章的目的和贡献，接下来，我就来剖析一下作者们提出的方法。</p>
<p>首先，需要<strong>将安卓的程序代码转换为可以分析的形式</strong>。一般来说，安卓的软件被打包为后缀名为Dex的Dalivik执行文件，这个执行文件无法被直接分析。于是，需要把这个执行文件通过一个叫 <strong>Smali</strong> 的反汇编器解析成Smali代码。这个时候，软件的语义就能够通过Smali代码来解析了。作者们从Smali代码中提取所有的API调用，通过对API的分析来对程序行为建模。</p>
<p>下一步，就是要<strong>从繁复的API调用中摸索出这里面的规律</strong>。作者们这个时候构建了<strong>四类矩阵</strong>来表达API和某个App之间的基本特征：</p>
<ol>
<li>
<p>某一个App是否包含了某一个API；</p>
</li>
<li>
<p>某两个API是否同时出现在某一段代码中；</p>
</li>
<li>
<p>某两个API是否出现在同一个App中；</p>
</li>
<li>
<p>某两个API是否使用了相同的调用方法。</p>
</li>
</ol>
<p>可以看出，这些矩阵可以抓住API和App之间的一个基本信息，还可以抓住一系列API同时出现进行某种操作的特征信息。这些矩阵成了发现高阶规律的基础。</p>
<p>为了发现更加复杂的规律，作者们在这里引入了一个工具叫<strong>异构信息网络</strong>。异构信息网络的概念最早由伊利诺伊大学香槟分校的数据挖掘权威韩家炜（Jiawei Han）和他当时的学生孙怡舟（Yizhou Sun，目前在加州大学洛杉矶分校任教）提出。异构信息网络的核心思想就是希望能够表达一系列实体（Entity）之间的复杂规律。</p>
<p>传统的方法把实体表达成图（Graph）的节点，实体之间的关系表达成节点之间的链接。这样的方式忽略了实体本身的不同以及关系的类型也有所不同。异构信息网络就是更加完整和系统地表达多种不同实体和实体关系的一种建模工具。在这篇文章中，有两类实体：App和API调用，有四类关系（和刚才定义的矩阵相同）。而刚才定义的矩阵其实就是这四类关系所对应的图的邻接矩阵。</p>
<p>把App和API的关系描述成为异构信息网络以后，下面的工作就是<strong>定义更高阶的规律关系</strong>。为了更好地定义这些复杂关系，作者们使用了一个叫<strong>元路径</strong>（Meta-Path）的工具。元路径其实是提供一个描述性的模板语言来定义高阶关系。</p>
<p>比如，我们可以定义一个从App到API再到App的“路径”，用于描述两个App可能都含有相同的API调用。这个路径就可以帮助我们从最开始的四个矩阵推出更加复杂的矩阵来表达一些信息。那么，根据人们的领域知识（这里就是安全领域），作者们就定义了多达<strong>16种元路径</strong>，从而全面捕捉App和API之间的各种关系。</p>
<p>利用异构信息网络和元路径构建了程序的语义表达后，下一步就是<strong>进行恶意软件的判别</strong>。这里，作者们采用了多核学习的思想。简而言之，就是把之前通过元路径所产生的新矩阵看作一个“核”。这里的多核学习就是要学习一个线性的分类器，特征是每个App到某一个核的一个非线性转换，这个转换是在学习过程中得到的。换句话说，这个多核学习的流程要同时学习一个分类器来判断一个程序是不是恶意程序，还需要在这个过程中学习从App到核的转换。</p>
<h2>方法的实验效果</h2>
<p>作者们使用了科摩多的数据集，收集了2017年两个月里1834个App的信息。正常程序和恶意程序几乎各一半。另外还有一个数据集包含3万个App信息，也几乎是正例负例各一半。从实验结果来看，结合了16个定义好的元路径的多核学习能够<strong>实现高达98%的F1值</strong>。F1值可以认为是精度和召回的一个平衡，同时<strong>准确率也是高达98%</strong>。</p>
<p>文章还比较了一些其他比较流行的方法，比如神经网络、朴素贝叶斯（Naïve Bayes）分类器、决策树以及支持向量机，这些方法基本的F1值都在85%和95%之间，和文章提到的方法有较大差距。另外，文章还和现在的一些商业软件，比如Norton、Lookout、CM做了比较。这些商业软件的准确度也在92%上下徘徊。因此，文章所采用的方法的确比之前的很多方法都更有效果。</p>
<h2>小结</h2>
<p>今天我为你讲了KDD 2017年的最佳应用类论文。这篇论文提出了，如何来分析安卓手机软件的行为进而检测手机应用是否是恶意软件。一起来回顾下要点：第一，简要介绍了这篇文章的作者群信息。第二，详细介绍了这篇文章要解决的问题以及贡献。第三，简要分析了文章提出方法的核心内容 。</p>
<p>总结一下，文章解决的问题就是如何有效监测安卓手机系统下的恶意软件，主要贡献是提出了一种新的基于结构性异构信息网络的方法，来理解安卓程序的语义。使用元路径的工具定义复杂关系，还采用了多核学习的方法完成恶意软件的判别。论文使用科摩多的数据集，验证了所提出的方法比当下流行的一些其他方法都更加有效。</p>
<p>最后，给你留一个思考题，文章中提到的多核学习方法这个步骤，是不是必需的？能否换成其他方法呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p>拓展阅读：<a href="http://delivery.acm.org/10.1145/3100000/3098026/p1507-hou.pdf?ip=104.245.8.202&amp;id=3098026&amp;acc=OPENTOC&amp;key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E054E54E275136550&amp;CFID=824613284&amp;CFTOKEN=25201339&amp;__acm__=1509500476_9d244f060207e966c107eb505646ed55">HinDroid: An Intelligent Android Malware Detection System Based on Structured Heterogeneous Information Network</a></p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor4">004 | 精读2017年EMNLP最佳长论文之一<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>自然语言处理实证方法会议<strong>EMNLP</strong>（Conference on Empirical Methods in Natural Language Processing），是由国际计算语言学协会<strong>ACL</strong>（Association for Computational Linguistics）的专委会<strong>SIGDAT</strong>（Special Interest Group on Linguistic Data and Corpus-based Approaches to NLP）主办，每年召开一次，颇具影响力和规模，是自然语言处理类的顶级国际会议。从1996年开始举办，已经有20多年的历史。2017年的EMNLP大会于9月7日到11日在丹麦的哥本哈根举行。</p>
<p>每年大会都会在众多的学术论文中挑选出两篇最具价值的论文作为最佳长论文（Best Long Paper Award）。 今天，我就带你认真剖析一下EMNLP今年的最佳长论文，题目是《男性也喜欢购物：使用语料库级别的约束条件减少性别偏见的放大程度》（Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints） 。这篇文章也是很应景，近期学术圈对于数据和机器学习算法有可能带来的“<strong>偏见</strong>”（Bias）感到关切，有不少学者都在研究如何能对这些偏见进行评估、检测，进而可以改进甚至消除。</p>
<h2>作者群信息介绍</h2>
<p>第一作者赵洁玉（Jieyu Zhao），论文发表的时候在弗吉尼亚大学计算机系攻读博士学位，目前，已转学到加州大学洛杉矶分校，从事如何从机器学习算法中探测和消除偏见的研究。之前她从北京航空航天大学获得学士和硕士学位，曾于2016年在滴滴研究院实习。</p>
<p>第二作者王天露（Tianlu Wang）也是来自弗吉尼亚大学计算机系的博士生，之前在浙江大学获得计算机学士学位。第三作者马克·雅茨卡尔（Mark Yatskar）是来自华盛顿大学的计算机系博士生，已在自然语言处理以及图像处理领域发表过多篇高质量论文。</p>
<p>第四作者文森特（Vicente Ordóñez）目前在弗吉尼亚大学计算机系任助理教授。他的研究方向是自然语言处理以及计算机视觉的交叉学科。他于2015年从北卡罗来纳大学教堂山分校计算机系博士毕业。博士期间，他在微软研究院、eBay研究院以及谷歌都有过实习经历。他是第二作者王天露的博士导师。</p>
<p>文章最后一位作者是Kai-Wei Chang，也是第一作者赵洁玉的导师。他目前在加州大学洛杉矶分校任助理教授，之前在弗吉尼亚大学任职。他于2015年从伊利诺伊大学香槟分校博士毕业，师从著名教授丹·罗斯（Dan Roth）。在之前的研究生涯中，曾先后3次在微软研究院实习，也在谷歌研究院实习过。在他研究的早期，曾参与了LibLinear这个著名支持向量机软件的研发工作。</p>
<h2>论文的主要贡献</h2>
<p>机器学习的一个重要任务就是通过数据来学习某些具体事项。最近机器学习的研究人员发现，数据中可能蕴含着一些社会赋予的偏见，而机器学习算法很有可能会放大这些偏见。这种情况在自然语言处理的相关任务中可能更为明显。比如，在一些数据集里，“做饭”这个词和“女性”这个词一起出现的比例可能要比和“男性”一起出现的比例高30%，经过机器学习算法在这个数据集训练之后，这个比例在测试数据集上可能就高达68%了。因此，虽然在数据集里，社会偏见已经有所呈现，但是这种偏见被机器学习算法放大了。</p>
<p>因此，<strong>这篇文章的核心思想就是，如何设计出算法能够消除这种放大的偏见，使得机器学习算法能够更加“公平”</strong>。注意，这里说的是消除放大的偏见，而不是追求绝对的平衡。比如，我们刚才提到的数据集，训练集里已经表现出“女性”和“做饭”一起出现的频率要高于“男性”和“做饭”一起出现的频率。那么，算法需要做的是使这个频率不会进一步在测试集里升高，也就是说，保持之前的30%的差距，而不把这个差距扩大。这篇文章并不是追求把这个差距人为地调整到相同的状态。</p>
<p>文章提出了一个<strong>限制优化（Constrained Optimization）算法</strong>，为测试数据建立限制条件，使机器学习算法的结果在测试集上能够得到和训练集上相似的偏见比例。注意，这是对已有测试结果的一个调整（Calibration），因此可以应用在多种不同的算法上。</p>
<p>作者们使用提出的算法在两个数据集上做了实验，得到的结果是，新的测试结果不但能够大幅度（高达30%至40%）地减小偏见，还能基本保持原来的测试准确度。可见，提出的算法效果显著。</p>
<h2>论文的核心方法</h2>
<p>那么，作者们提出的究竟是一种什么方法呢？</p>
<!-- [[[read_end]]] -->
<p>首先，引入了一个叫“<strong>偏见值</strong>”（Bias Score）的概念。这个值检测某一个变量和目标变量之间的比例关系。例如，“男性”这个词和某个动词（比如之前我们举了“做饭”）一起出现的比例关系以及“女性”这个词和同一个动词一起出现的比例关系。</p>
<p>注意，因为“男性”和“女性”都是“性别”的可选项，因此，这两个词对于同一个动词的比例关系的和一定是1。偏见值在训练集上和测试集上的差别，构成了衡量偏见是否被放大的依据。在之前的例子中，“女性”和“做饭”一起出现的的偏见值在训练集上是0.66，而到了测试集则变成了0.84，这个偏见被算法放大。</p>
<p>有了偏见值这个概念以后，作者们开始<strong>为测试集的结果定义限制条件</strong>（Constraint）。这里的一个基本思想就是，要对测试集的预测标签进行重新选择，使测试标签的预测结果和我们期待的分布相近。用刚才的例子就是说，我们要让“女性”在“做饭”这个场景下出现的可能性从0.84回归到0.66附近。能够这么做是因为这个算法需要对测试结果直接进行调整。</p>
<p>对所有的限制条件建模其实就变成了一个经典的限制优化问题。这个问题需要对整个测试数据的预测值进行优化，那么，这个优化就取决于测试数据集的大小，往往是非常困难的。于是，作者们在这里采用了<strong>拉格朗日简化法</strong>（Lagrangian Relaxation）来对原来的优化问题进行简化。</p>
<p>也就是说，原来的限制优化问题经过拉格朗日简化法后，变成了非限制优化问题，原来的算法就可以成为一个动态更新的过程。针对每一个测试用例，都得到当前最优的标签更改方案，然后又进一步更新拉格朗日参数，这样对整个测试数据集遍历一次后算法就中止了。</p>
<h2>方法的实验效果</h2>
<p>作者们使用了两个实验数据。一个是<strong>imSitu</strong>，一个是<strong>MS-COCO</strong>。imSitu是一个视觉语义角色识别（Visual Semantic Role Labeling）的任务，里面有多达12万张图片和这些图片的文字语义信息。比如一些图片是关于做饭场景的，里面的角色就是男性或者是女性。作者们整理出了212个动词用作实验。MS-COCO是一个多标签图片分类问题（Multi-label Classification），需要对80类物品进行标签预测。</p>
<p>对于这两个任务，作者们都选择了<strong>条件随机场</strong>（Conditional Random Field）来作为基础模型。条件随机场往往是解决往往是解决这类问题方法的方法的第一选择。对于特征，作者们采用了数据集提供的基于深度学习的各种特征。在条件随机场的基础上，对测试集采用了提出的偏见调整算法。</p>
<p>值得指出的是，虽然算法本身需要使用测试数据，但并不需要知道测试数据的真实标签。标签信息仅仅是从训练集中得到。这一点也是作者们反复强调的。</p>
<p>从两个数据集的结果来看，效果都不错。原本的预测准确度并没有很大的降低，但是性别偏见值则在测试集的调整结果后大幅度降低，最大的结果可以降低40%以上。</p>
<h2>小结</h2>
<p>今天我为你讲了EMNLP 2017年的年度最佳长论文，这篇论文针对数据集可能带来的社会偏见以及机器学习算法可能进一步扩大这种偏见的问题，提出了一个对测试数据集的预测结果进行调整的算法。这个算法的核心是减小这种偏见，使偏见值在测试数据集中和训练数据集中的水平相当。</p>
<p>一起来回顾下要点：第一，简要介绍了这篇文章的作者群信息。第二，详细介绍了这篇文章要解决的问题以及贡献 。第三，介绍了文章提出方法的的核心内容 。</p>
<p>最后，给你留一个思考题，为什么机器学习算法可能扩大训练集上已有的偏见呢？这跟某些具体的算法有什么关系呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p>拓展阅读：<a href="https://arxiv.org/abs/1707.09457">Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints</a></p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor5">005 | 精读2017年EMNLP最佳长论文之二<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>EMNLP每年都会选出两篇最佳长论文，我们已经分析过第一篇《男性也喜欢购物：使用语料库级别的约束条件减少性别偏见的放大程度》。今天我继续来讲第二篇。</p>
<p>EMNLP 2017年最佳长论文的第二篇是《在线论坛中抑郁与自残行为风险评估》（Depression and Self-Harm Risk Assessment in Online Forums）。这篇文章探讨了利用自然语言处理技术来解决一个社会问题。最近一段时间以来，如何利用机器学习、数据科学等技术来解决和处理社会问题，正逐渐成为很多社会科学和机器学习研究的交叉领域。</p>
<h2>作者群信息介绍</h2>
<p>第一作者安德鲁·耶特斯（Andrew Yates），计算机博士，毕业于美国华盛顿的乔治城大学（Georgetown Univeristy），目前在德国马克思普朗克信息学院（Max Planck Institute for Informatics）攻读博士后。他在博士阶段已经发表了多篇采用深度学习技术和信息检索、自然语言处理相关的论文。</p>
<p>第二作者阿曼·可汗（Arman Cohan），来自伊朗，是乔治城大学计算机系博士生。阿曼已在信息检索和自然语言处理相关方向发表了多篇论文。2016年，在华盛顿的Medstar Health实习并发表了两篇论文。2017年暑假，在美国加州圣何塞（San Jose）的奥多比（Adobe）研究院实习。</p>
<p>第三作者纳兹利·哥汗（Nazli Goharian）也来自乔治城大学计算机系，目前在系里担任计算机教授。第一作者是他之前的学生，第二作者是他当前的学生。纳兹利在长达20年的职业生涯中先后在工业界和学术圈任职，可以说有很深厚的学术和工业背景，他在信息检索和文本分析领域已发表20多篇论文。</p>
<h2>论文的主要贡献</h2>
<p>在理解这篇文章的主要贡献之前，我们还是先来弄明白，这篇文章主要解决了一个什么场景下的问题。</p>
<p>现代社会，人们生活工作的压力越来越大。研究表明，很多人都可能受到各式各样精神疾病（Mental Conditions）的困扰。在当下发达的互联网时代，在线场所为这些精神疾病患者寻求帮助提供了大量的资源和信息，特别是一些专业的在线支持社区，或是一些更大的在线社区比如Twitter或者Reddit。</p>
<p>因此，研究这些人在各种在线社区的行为，对设计更加符合他们需要的系统有很大帮助。对于很多社会研究人员来说，分析这些人的精神状态，才能更好地帮助他们长期发展。</p>
<p>这篇文章提出了一个比较通用的框架，来分析这些精神疾患者的在线行为。在这个框架下，可以比较准确地分析发布信息的人是否有自残（Self-Harm）行为，还可以比较容易地分析哪些用户有可能有抑郁症（Depression）的状况。</p>
<p>整个框架利用了近年来逐渐成熟的深度学习技术对文本进行分析。所以，这里的应用思路很值得借鉴和参考，也可以用于其他场景。</p>
<h2>论文的核心方法</h2>
<p>在介绍这篇文章提出的方法之前，作者们用不小的篇幅介绍了文章使用的数据集和如何产生数据的标签。</p>
<!-- [[[read_end]]] -->
<p>首先，作者们从著名的在线社区Reddit中找到和精神疾病有明确联系的帖子。这些帖子是按照一个事先准备的语料库来筛选的，这个语料库是为了比较高精度地发现与精神疾病相关的帖子。利用语料库里的句式，比如“我已经被诊断得了抑郁症”，这样就可以保证，找到的帖子在很大程度上是来自精神疾病患者的。</p>
<p>如果一个用户发布了这样的帖子，但在这之前发布的帖子少于100条，这个用户就不会包含在数据库中。做这样的筛选可能作者们的考虑是，太少的帖子无法比较全面地包含用户方方面面的行为。</p>
<p>作者们在Reddit社区中挖掘了从2006年到2016年十年时间里符合条件的所有帖子，并利用人工标注的方式筛选出了9210个有精神疾病困扰的用户。这些可以当做机器学习的正例。</p>
<p>那么如何寻找负例呢？作者们当然可以利用所有的用户，但是这样带来的后果很可能是研究没有可比性。如果正例的用户和负例的用户之间差别太大，我们就很难说这些差别是因为精神疾病造成的还是由其他区别带来的。于是，作者们想到的方法则是尽可能地对于每一个正例的用户都找到最接近的负例用户。</p>
<p>实际操作中，作者们采取了更加严格的方式，那就是负例的用户必须没有发布过任何与精神疾病相关的帖子，并且在其他方面都需要和正例用户类似。在这样的条件下，作者们找到了107274个负例用户。</p>
<p>对于数据集中的用户而言，每个用户平均发布969个帖子，平均长度都多于140个字。可以说，由这些用户构成的这个数据集也是本文的一个主要贡献，这个数据集用于分析抑郁症。</p>
<p>对于自残行为而言，作者们利用了一个叫ReachOut的在线社区的数据，收集了包括65024个论坛的帖子，其中有1227个帖子提到了自残。而对于提及自残的程度，数据分了五个等级用于表示不同的紧急情况。</p>
<p>这篇论文主要提出了基于卷积神经网络的文本分析框架，分别用于检测抑郁症用户和检测自残倾向度的两个任务中。虽然这两个任务使用的数据不同，最终采用的模型细节不同，但是两个任务使用的都是同一个框架。下面我就来说一说这个框架的主要思想。</p>
<p><img src="https://static001.geekbang.org/resource/image/99/92/9973fb1c41652299ba033610c5979392.png" alt="" /></p>
<p>首先，作者们利用每个用户的发帖信息来对每一个用户进行建模，基本的思路是通过神经网络来对用户的每一个帖子建模，从中提取出有效信息，然后把有效信息汇总成用户的一个表达。有了这个思路，我们再来看看具体是怎么做的。</p>
<p>每个帖子一个范围内的单词首先通过卷积层（Convolutional Layer）提取特征，然后提取的特征再经过最大抽取层（Max Pooling Layer）集中。这个步骤基本上就是把目前图像处理的标准卷积层应用到文本信息上。每一个帖子经过这样的变换就成了特征向量（Feature Vector）。有了这样的特征向量之后，用户的多个特征向量整合到一起，根据不同的任务形成用户的整体表征。</p>
<p>在检测抑郁症的任务上，作者们采用的是“平均”的方式，也就是把左右的帖子特征向量直接平均得到。而在检测自残的任务上，作者们则采用了一种比较复杂的形式，把所有的帖子都平铺到一起，然后再把当前帖子之前的帖子，作为负例放在一起，注意，不是平均的形式，而是完全平铺到一起，从而表达为用户的整体特征。</p>
<p>在经过了这样的信息提取之后，后面的步骤就是构建分类器。这个步骤其实也是深度学习实践中比较常见的做法，那就是利用多层全联通层（Fully Connected Layer），最终把转换的信息转换到目标的标签上去。</p>
<p>可以说在整体的思路上，作者们提出的方法清晰明了。这里也为我们提供了一种用深度学习模型做文本挖掘的基本模式，那就是用卷积网络提取特征，然后通过联通层学习分类器。</p>
<h2>方法的实验效果</h2>
<p>作者们在上面提到的实验数据集上做了很充分的实验，当然也对比了不少基本的方法，比如直接采用文本特征然后用支持向量机来做分类器。</p>
<p>在辨别抑郁症的任务上，本文提出的方法综合获取了0.51的F1值，其中召回（Recall）达到0.45，而直接采用支持向量机的方法，精度（Precision）高达0.72，但是召回指数非常低只有0.29。</p>
<p>而在检测自残的任务上，提出方法的准确度能够达到0.89，F1值达到0.61，都远远高于其他方法。</p>
<p>应该说，从可观的数值上，本文的方法效果不错。</p>
<h2>小结</h2>
<p>今天我为你讲了EMNLP 2017年的第二篇年度最佳长论文，这篇文章介绍了一个采用深度学习模型对论坛文本信息进行分析的应用，那就是如何识别有精神疾病的用户的信息。</p>
<p>一起来回顾下要点：第一，我简要介绍了这篇文章的作者群信息。第二，这篇文章是利用自然语言处理技术解决一个社会问题的应用，论文构建的数据集很有价值。第三，文章把目前图像处理的标准卷积层应用到文本信息上，提出了基于卷积神经网络的文本分析框架，用于辨别抑郁症和检测自残倾向，都实现了不错的效果。</p>
<p>最后，给你留一个思考题，如果说在图像信息上采用卷积层是有意义的，那为什么同样的操作对于文本信息也是有效的呢？文本上的卷积操作又有什么物理含义呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p>拓展阅读：<a href="https://arxiv.org/pdf/1709.01848.pdf">Depression and Self-Harm Risk Assessment in Online Forums</a></p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor6">006 | 精读2017年EMNLP最佳短论文<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>在今年的EMNLP大会上，有两类研究论文得到发表，一类是8页的长研究论文，主要是比较完整的研究结果；另一类是4页的短研究论文，主要是比较新的有待进一步推敲的研究结果。大会从长研究论文中选出两篇最佳论文，从短论文中选出一篇最佳论文。</p>
<p>前面我们分别讨论了两篇最佳长论文，今天，我就带你认真剖析一下EMNLP 2017年的最佳短论文《多智能体对话中，自然语言并非“自然”出现》（Natural Language Does Not Merge ‘Naturally’ in Multi-Agent Dialog）。我们今天讲的论文虽然是最佳短论文，但是作者们已经在arXiv发表了较长的文章版本，因此我今天的讲解将基于arXiv的长版本。</p>
<p>这篇文章研究的一个主要命题就是，多个“机器人”（Agent）对话中如何才能避免产生“非自然”（Unnatural）的对话。以前很多机器人对话的研究都关注准确率的高低，但实际上机器人产生的对话是不自然的，人类交流不会用这样的方式。这篇文章希望探讨的就是这样非自然的对话是如何产生的，有没有什么方式避免这样的结果。</p>
<h2>作者群信息介绍</h2>
<p>第一作者萨特维克·库托儿（Satwik Kottur）来自卡内基梅隆大学，博士第四年，研究领域为计算机视觉、自然语言和机器学习。2016年暑假他在Snapchat的研究团队实习，研究对话系统中的个性化问题。2017年暑假在Facebook研究院实习，做视觉对话系统（Visual Dialog System）的研究。近两年，萨特维克已在多个国际顶级会议如ICML 2017、IJCAI 2017、CVPR 2017、ICCV 2017以及NIPS 2017发表了多篇高质量研究论文，包括这篇EMNLP 2017的最佳短论文，可以说是一颗冉冉升起的学术新星。</p>
<p>第二作者何塞·毛拉（José M. F. Moura）是萨特维克在卡内基梅隆大学的导师。何塞是NAE（美国国家工程院）院士和IEEE（电气电子工程师学会）院士，长期从事信号处理以及大数据、数据科学的研究工作。他当选2018年IEEE总裁，负责IEEE下一个阶段的发展。</p>
<p>第三作者斯特凡·李（Stefan Lee）是来自乔治亚理工大学的研究科学家，之前在弗吉尼亚理工大学任职，长期从事计算机视觉、自然语言处理等多方面的研究。斯特凡2016年博士毕业于印第安纳大学计算机系。</p>
<p>第四作者德鲁·巴塔（Dhruv Batra）目前是Facebook研究院的科学家，也是乔治亚理工大学的助理教授。德鲁2010年博士毕业于卡内基梅隆大学；2010年到2012年在位于芝加哥的丰田理工大学担任研究助理教授；2013年到2016年在弗吉尼亚大学任教。德鲁长期从事人工智能特别是视觉系统以及人机交互系统的研究工作。文章的第三作者斯特凡是德鲁长期的研究合作者，他们一起已经发表了包括本文在内的多篇高质量论文。</p>
<h2>论文的主要贡献</h2>
<p>我们先来看看这篇文章主要解决了一个什么场景下的问题。</p>
<p>人工智能的一个核心场景，或者说想要实现的一个目标，就是能够建立一个目标导向（Goal-Driven）的自动对话系统（Dialog System）。具体来说，在这样的系统中，机器人能够感知它们的环境（包括视觉、听觉以及其他感官），然后能和人或者其他机器人利用自然语言进行对话，从而实现某种目的。</p>
<p>目前对目标导向的自动对话系统的研究主要有两种思路。</p>
<!-- [[[read_end]]] -->
<p>一种思路是把整个问题看做静态的监督学习任务（Supervised Learning），希望利用大量的数据，通过神经对话模型（Neural Dialog Models）来对对话系统进行建模。这个模式虽然在近些年的研究中取得了一些成绩，但是仍然很难解决一个大问题，那就是产生的“对话”其实不像真人对话，不具备真实语言的很多特性。</p>
<p>另外一种思路则把学习对话系统的任务看做一个连续的过程，然后用强化学习（Reinforcement Learning）的模式来对整个对话系统建模。</p>
<p>这篇文章尝试探讨，在什么样的情况下能够让机器人学习到类似人的语言。文章的一个核心发现就是，自然语言并不是自然出现的。在目前的研究状态下，<strong>自然语言的出现还是一个没有确定答案的开放问题</strong>。可以说，这就是这篇最佳短论文的主要贡献。</p>
<h2>论文的核心方法</h2>
<p>整篇文章其实是建立在一个虚拟的机器人交互场景里，也就是有两个机器人互相对话的一个环境。这个环境里有非常有限的物件（Object），每个物件包括三种属性（颜色、形状和样式），每一个属性包括四种可能取值，这样，在这个虚拟的环境中一共就有64个物件。</p>
<p><img src="https://static001.geekbang.org/resource/image/4d/b9/4d90d38df883967df26166748c9346b9.png" alt="" /></p>
<p>交互任务其实是两个机器人进行“猜谜”。为了区分，我们把两个机器人分为Q机器人和A机器人。猜谜一开始的时候，A机器人得到一个物件，也就是三种属性的某种实现组合，Q机器人并不知道这个物件。这个时候，Q机器人拿到两个属性的名字，需要通过对话最终猜出A拿到的这个物件所对应属性的取值。</p>
<p>在这个“游戏”的过程中，A是不知道Q手上的两个属性究竟是什么的，而Q也不知道A所拿的物件以及物件所对应属性的取值。因此，对话就是Q能够取得成功的关键因素。</p>
<p>在这篇文章里，Q和A的这个游戏<strong>通过强化学习进行建模</strong>。Q保持一组参数用于记录当前的状态。这组状态有最开始需要猜的属性，以及后面到当前状态为止所有Q的回答以及A的问题。类似地，A也保持这么一组状态，用于记录到目前位置的信息。这个强化学习最终的回馈是，当最后的预测值完全正确时，会有一个正1的反馈，而错误的话就是负10的反馈。</p>
<p>Q和A的模型都有三个模块：听、说和预测。以Q来举例，“听”模块是从要猜的属性这个任务开始，往后每一个步骤接受A的语句，从而更新自己的内部状态。“说”模块是根据当前的内部状态，决定下一步需要说的语句。最后“预测”模块则是根据所有的状态预测最后的属性值。</p>
<p>A机器人的结构是对称的。每一个模块本身都是一个 <strong>LSTM</strong> （Long Short-Term Memory，长短期记忆）模型。当然，所有这些LSTM模型的参数是不一样的。整个模型采用了<strong>REINFORCE算法</strong>（也被称作“vanilla” policy gradient，“基本”策略梯度）来学习参数，而具体的实现则采用了PyTorch软件包。</p>
<h2>方法的实验效果</h2>
<p>在提出的方法上，作者们展示了Q均能很快地以比较高的准确度做出预测，并且在和A的互动中产生了“语言”。不过遗憾的是，通过观察，作者们发现这样的“语言”往往并不自然。最直观的一种情况就是，A可以忽视掉Q的各种反应，而直接把A的内部信息通过某种编码直接“暴露”给Q，从而Q可以很快赢得游戏，取得几乎完美的预测结果。这显然不是想要的结果。</p>
<p>作者们发现，在词汇量（Vocabulary）非常大的情况下，这种情况尤其容易发生，那就是A把自己的整个状态都暴露给Q。于是，作者们假定<strong>要想出现比较有意义的交流，词汇数目一定不能过大</strong>。</p>
<p>于是，作者们采用了限制词汇数目的方式，让词汇数目与属性的可能值和属性数目相等，这样就限制了在完美情况下交流的复杂度，使得A没办法过度交流。然而，这样的策略可以很好地对一个属性做出判断，但是无法对属性的叠加（因为Q最终是要猜两个属性）做出判断。</p>
<p>文章给出的一个解决方案是，让A机器人忘记过去的状态，强行让A机器人学习使用相同的一组状态来表达相同的意思，而不是有可能使用新的状态。<strong>在这样的限制条件以及无记忆两种约束下，A和Q的对话呈现出显著的自然语言的叠加性特征，而且在没有出现过的属性上表现出了接近两倍的准确率</strong>，这是之前的方法所不能达到的效果。</p>
<h2>小结</h2>
<p>今天我为你讲了EMNLP 2017年的最佳短论文，这篇文章介绍了在一个机器人对话系统中，如何能让机器人的对话更贴近人之间的行为。</p>
<p>这篇文章也是<strong>第一篇从谈话的自然程度</strong>，而不是从预测准确度去分析对话系统的论文。文章的一个核心观点是，如果想让对话自然，就必须避免机器人简单地把答案泄露给对方，或者说要避免有过大的词汇库。</p>
<p>一起来回顾下要点：第一，我简要介绍了这篇文章的作者群信息，文章作者在相关领域均发表过多篇高质量研究成果论文。第二，这篇文章论证了多智能体对话中自然语言的出现并不自然。第三，论文提出在词汇量限制条件和无记忆约束下，机器人对话可以呈现出一定的自然语言特征。</p>
<p>最后，给你留一个思考题，文章讲的是一个比较简单的对话场景，有一个局限的词汇库，如果是真实的人与人或者机器与机器的对话，我们如何来确定需要多大的词汇量呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p><strong>名词解释</strong>：</p>
<p><strong>ICML 2017</strong>，International Conference on Machine Learning ，国际机器学习大会。</p>
<p><strong>IJCAI 2017</strong>， International Joint Conference on Artificial Intelligence，人工智能国际联合大会。</p>
<p><strong>CVPR 2017</strong>，Conference on Computer Vision and Pattern Recognition，国际计算机视觉与模式识别会议。</p>
<p><strong>ICCV 2017</strong>，International Conference on Computer Vision，国际计算机视觉大会。</p>
<p><strong>NIPS 2017</strong>，Annual Conference on Neural Information Processing Systems，神经信息处理系统大会。</p>
<p>拓展阅读：<a href="http://aclweb.org/anthology/D17-1320">Natural Language Does Not Merge ‘Naturally’ in Multi-Agent Dialog</a></p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor7">007 | 精读2017年ICCV最佳研究论文<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>ICCV（International Conference on Computer Vision，国际计算机视觉大会），是每两年举办一次的计算机视觉顶级会议。从1987年开始举办，已经有30年的历史。2017年的ICCV大会于10月22日至29日在意大利的水城威尼斯举行。</p>
<p>在每届ICCV大会上，都会从众多学术论文中挑选出两篇最有新意和价值的论文作为最佳研究论文和最佳学生论文。ICCV的最佳论文奖又叫作“马尔奖项”（Marr Prize），是为了纪念英国的心理学家和神经科学家大卫·马尔（David Marr）而设计的奖项。马尔将心理学、人工智能和神经生理学的研究成果结合起来，提出了全新的关于视觉处理的理论，他被认为是计算神经科学的创始人。</p>
<p>今天，我就来带你认真剖析一下ICCV 2017年的最佳研究论文“<a href="https://research.fb.com/wp-content/uploads/2017/08/maskrcnn.pdf">Mask R-CNN</a>”。这篇论文是一个集大成的工作，介绍了一个新的方法可以用于同时解决图像的“<strong>物体识别</strong>”（Object Detection）、“<strong>语义分割</strong>”（Semantic Segmentation）和“<strong>数据点分割</strong>”（Instance Segmentation）的工作。</p>
<p>什么意思呢？通俗地讲，那就是给定一个输入的图像，利用这篇论文提出的模型可以分析这个图像里究竟有哪些物体，比如是一只猫，还是一条狗；同时能够定位这些物体在整个图像中的位置；并且还能针对图像中的每一个像素，知道其属于哪一个物体，也就是我们经常所说的，把物体从图像中“抠”出来。</p>
<h2>作者群信息介绍</h2>
<p>这篇论文的作者全部来自Facebook的人工智能研究院（Facebook AI Research）。</p>
<p>第一作者就是近几年在计算机视觉领域升起的学术之星何恺明博士（Kaiming He）。他于2016年加入Facebook人工智能研究院，之前在微软亚洲研究院进行计算机视觉的研究工作；他还是CVPR 2016年和CVPR 2009年的最佳论文得主。目前，何恺明在计算机视觉领域有三项重大贡献。</p>
<p>第一，他与其他合作者发明的ResNet从2016年以来成为了计算机视觉深度学习架构中的重要力量，被应用到了计算机视觉以外的一些领域，比如机器翻译和AlphaGo等，相关论文引用数超过5千次。</p>
<p>第二，他与其他合作者开发的Faster R-CNN技术，发表于NIPS 2015上，是图像物体识别和语义分析的重要技术手段，也是今天我们要讨论的这篇论文的基础，论文引用数超过2千次。</p>
<p>第三，他与其他合作者在ICCV 2015年发表论文《深入研究整流器：在ImageNet分类上超越人类水平》（<a href="https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/He_Delving_Deep_into_ICCV_2015_paper.pdf">Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification</a>），研究了一种改进的ReLU（Rectified Linear Unit，线性整流函数，又称修正线性单元）结构从而达到了更好的效果，论文引用数近2千次。</p>
<p>第二作者乔治亚⋅吉克里奥夏里（Georgia Gkioxari）目前是Facebook人工智能研究院的博士后研究员。乔治亚可以说是师出名门，在Facebook工作之前才从加州大学伯克利毕业，师从计算机视觉泰斗吉腾德拉⋅马利克（Jitendra Malik）。乔治亚之前还分别在谷歌大脑和谷歌研究院实习过。在过去几年中，乔治亚在计算机视觉界已经发表了多篇高质量论文。</p>
<p>第三作者皮奥特⋅多拉（Piotr Dollár）是Facebook人工智能研究院的一名经理。2007年从加州大学圣地亚哥分校获得博士学位，2014年加入Facebook，这之前在微软研究院工作。皮奥特长期从事计算机视觉的研究工作。</p>
<p>最后一个作者罗斯⋅吉尔什克（Ross Girshick）是Facebook人工智能研究院的一名科学家。他于2012年毕业于芝加哥大学，获得计算机博士。罗斯之前也在微软研究院工作，也曾在计算机视觉泰斗吉腾德拉的实验室里担任博士后的研究工作。</p>
<h2>论文的主要贡献</h2>
<p>我们首先来看一下这篇文章的主要贡献。还是要先去理解，这篇文章主要解决的是一个什么场景下的问题。</p>
<!-- [[[read_end]]] -->
<p>刚才我们已经简单地谈到了，这篇文章要解决的问题，就是对输入图像的物体识别、语义分割，以及数据点分割，是这三个任务的一个集成。在之前的一个工作中，“Faster R-CNN”[1]已经解决了前两个任务。那么，这篇论文其实就是Faster R-CNN在逻辑上的一个扩展。然而，这个扩展也并不是那么显而易见的。<strong>为了解决数据点分割的任务，Mask R-CNN提出了深度学习网络结构上的一个创新，这是本篇论文的一个重要贡献</strong>。</p>
<p>本文提出的模型不仅在数据点分割的标准数据集COCO上表现强劲，击败所有之前提出的模型以外，还能够很容易地扩展到其他的任务中，比如“人体形态估计”（Human Pose Estimation），从而<strong>奠定了Mask R-CNN作为一个普适性框架的地位</strong>。</p>
<h2>论文的核心方法</h2>
<p>要想理解Mask R-CNN的核心思想，我们就必须先简要理解Faster R-CNN的一些基本原理。刚才说到了，Mask R-CNN就是在其之上的一种改进和延伸。</p>
<p><strong>Faster R-CNN对于每一个输入图像中的每一个候选物体，都会有两个输出</strong>，一个是候选物体的<strong>标签</strong>（比如，猫、狗、马等），还有一个就是一个<strong>矩形框</strong>（Bounding Box），用于表达这个物体在图像中的位置。第一个<strong>标签输出是一个分类问题</strong>（Classification），而第二个<strong>位置预测则是一个回归问题</strong>（Regression）。</p>
<p>Faster R-CNN分为两个阶段（Stage）。第一个阶段叫作“<strong>区域提交网络</strong>”（Region Proposal Network），目的是从图像中提出可能存在的候选矩形框。第二个阶段，从这些候选框中使用一个叫“<strong>RoIPool</strong>”的技术来提取特征从而进行标签分类和矩形框位置定位这两个任务。这两个阶段的一些特性可以共享。</p>
<p>区域提交网络的大体流程是这样的。最原始的输入图像经过经典的卷积层变换之后形成了一个图像特征层。在这个新的图像特征层上，模型使用了一个移动的小窗口（Sliding Window）来对区域进行建模。这个移动小窗口有这么三个任务需要考虑。</p>
<p>首先移动小窗口所覆盖的特征经过一个变换达到一个中间层，然后经过这个中间层，直接串联到两个任务，也就是物体的分类和位置的定位。其次，移动的小窗口用于提出一个候选区域，有时候也叫ROI，也就是矩形框。而这个矩形框也参与刚才所说的定位信息的预测。</p>
<p>当区域提交网络“框”出了物体的大致区域和类别之后，模型再使用一个“物体检测”（Object Detection）的网络来对物体进行最终的检测。在这里，物体检测实际是使用了Fast R-CNN[2]的架构。所以，也就是为什么Faster R-CNN的名字里用“Faster”来做区分。Faster R-CNN的贡献，在于区域提交网络和Fast R-CNN的部分，也就是物体检测的部分达到了共享参数，或者叫共享网络架构，这样也就起到了加速的作用。</p>
<p><strong>Mask R-CNN在第一部分完全使用Faster R-CNN所提出的区域提交网络，在此基础上，对第二部分进行了更改</strong>。也就是说，不仅仅在第二部分输出区域的类别和框的相对位置，同时，还输出具体的像素分割。然而，和很多类似工作的区别是，像素分割、类别判断、位置预测是三个独立的任务，并没有互相的依赖，这是作者们认为Mask R-CNN能够成功的一个重要的关键。对比之前的一些工作，像素分割成了类别判断的依赖，从而导致这几个任务之间互相干扰。</p>
<p>Mask R-CNN在进行像素分割的时候，因为要在原始的图像上进行分割，因此需要在整个流程中保留原始图像的位置关系。这个需求是类别判断和位置预测所不具备的。而在Faster R-CNN中，因为不需要这个需求，因此类别判断和位置预测所依赖的信息是一个压缩过后的中间层。那么很明显，Mask R-CNN依靠这个压缩层就不够了。在这篇文章中，作者们<strong>提出了一个叫RoIAlign的技术来保证中间提取的特征能够反映在最原始的像素中</strong>。如果对这部分内容感兴趣，建议你去细读文章。</p>
<h2>方法的实验效果</h2>
<p>作者们使用Mask R-CNN在目前流行的图像物体检测任务数据集COCO 2015和COCO 2016上做了检测，相对于之前的这两个竞赛的冠军，实验结果表明Mask R-CNN的精度都大幅度增加。在一个“平均精度”（Average Precision）的度量上，Mask R-CNN比COCO 2015的最佳结果好了近13%，而比COCO 2016的最佳结果好了4%，可以说效果非常明显。在实验结果中，作者们非常细致地测试了整个Mask R-CNN中每一个部件的效果。其中，把三个任务分开、以及RoIAlign方法都有非常显著的作用，证明了这些模型组件是优秀结果的必要步骤。</p>
<h2>小结</h2>
<p>今天我为你讲了ICCV 2017年的最佳研究论文，这篇文章介绍了目前在图像物体识别中的最新算法Mask R-CNN的大概内容。</p>
<p>一起来回顾下要点：第一，我们简要介绍了这篇文章的作者群信息。第二，我们详细介绍了这篇文章要解决的问题以及贡献 。第三，我们简要地介绍了文章提出方法的核心内容 。</p>
<p>最后，给你留一个思考题，你觉得为什么Mask R-CNN，包括之前的一些工作，要把物体检测的工作分为两步，第一步先分析一个大的矩形框，第二步进行物体检测，这两步都是必要的吗？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p><strong>参考文献</strong></p>
<ol>
<li>
<p>Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. <a href="https://arxiv.org/pdf/1506.01497.pdf">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</a>. IEEE Trans. Pattern Anal. Mach. Intell. 39, 6 (June 2017), 1137-1149, 2017.</p>
</li>
<li>
<p>Ross Girshick. <a href="https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf">Fast R-CNN</a>. Proceedings of the 2015 IEEE International Conference on Computer Vision (ICCV) (ICCV '15). IEEE Computer Society, Washington, DC, USA, 1440-1448, 2015.</p>
</li>
</ol>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor8">008 | 精读2017年ICCV最佳学生论文<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>周一我们认真剖析了ICCV 2017年的最佳研究论文“Mask R-CNN”。今天我们来分享ICCV 2017的最佳学生论文《焦点损失用于密集物体检测》（<a href="https://arxiv.org/pdf/1708.02002.pdf">Focal Loss for Dense Object Detection</a>）。</p>
<p>可以说，这篇文章是我们周一分享的最佳论文的孪生兄弟。首先，这篇论文的作者群也基本是Facebook人工智能研究院的班底。其次，这篇文章解决的问题也很类似，也是物体识别和语义分割，只是不解决数据点分割的问题。</p>
<h2>作者群信息介绍</h2>
<p>除第一作者外，这篇论文的作者都来自Facebook的人工智能研究院。</p>
<p>第一作者林仓义（Tsung-Yi Lin），目前在谷歌大脑（Google Brain）团队工作，发表论文的时候在Facebook人工智能研究院实习。林仓义在台湾国立大学获得本科学位，在加州大学圣地亚哥分校获得硕士学位，2017年刚从康奈尔大学博士毕业。博士期间，他师从计算机视觉专家塞尔盖⋅比隆基（Serge Belongie），发表了多篇高质量的计算机视觉论文。</p>
<p>第二作者皮里亚⋅高耶（Priya Goyal）是Facebook人工智能研究院的一名研究工程师。在加入Facebook之前，皮里亚从印度理工大学获得了学士和硕士学位。</p>
<p>第三作者罗斯⋅吉尔什克（Ross Girshick），第四作者何恺明，还有最后一个作者皮奥特⋅多拉（Piotr Dollár），这三位作者也是周一的最佳研究论文的作者，我们已经介绍过了，你可以回去再了解一下。</p>
<h2>论文的主要贡献</h2>
<p>我们首先来看一下这篇文章的主要贡献。</p>
<p>刚才我们已经简单地谈到了，<strong>这篇文章要解决的问题，就是对输入图像进行物体识别和语义分割这两个任务</strong>。对于这个问题有两种主要的思路，这两个思路都在不断地发展。</p>
<!-- [[[read_end]]] -->
<p>第一种思路，那就是直接从输入图像入手，希望能够从输入图像中提取相应的特征，从而能够直接从这些特征中判断当前的图像区域是否属于某个物体，然后也能够一次性地找到矩形框的位置用于定位这个物体。</p>
<p>这种思路虽然直观，但有一个致命的问题，那就是对于一个输入图像来说，大量的区域其实并不包含目标物体，因此也就可以被认为是学习过程中的“负例”（Negative Instance）。如何有效地学习这么一个“不均衡”（Imbalanced）的数据集是这种思路需要考虑的问题。</p>
<p>因为这个因素，研究者们就开始思考另外一种思路，那就是先学习一个神经网络用于找到一些候选区域，然后在第二个阶段根据候选区域再去最终确定物体的类别和矩形框的位置。</p>
<p>在最近几年的实际评测中，基于<strong>两个阶段</strong>（Two-stage）的模型，包括我们在上一篇分享中提到的Faster R-CNN以及其他变种一般都有比较好的表现。而基于<strong>一个阶段</strong>（One-stage）的模型，在这篇文章发布之前还不能达到两个阶段模型的水平。</p>
<p><strong>本篇文章提出了一个新的目标函数，叫作“焦点损失”（Focal Loss），用于取代传统的“交叉熵”（Cross Entropy）的目标函数</strong>。这个新目标函数的主要目的就是让一个阶段模型能够在正负例比例非常不协调的情况下，依然能够训练出较好的模型，从而使得一个阶段模型在效果上能够和两个阶段模型媲美。同时，文章还提出了一种比较简单易用的深度网络结构，可以简单地训练出整个模型。</p>
<h2>论文的核心方法</h2>
<p>在这一节，我们来讲一讲“焦点损失”的含义。因为这是一个新的目标函数，建议你还是阅读原文来理解这个目标函数的数学性质。这里，我们针对这个新的目标函数进行一个高度概括性的解释。</p>
<p>我们从普通的二分分类问题中常用的交叉熵，我们简称为CE目标函数说起。首先，我们认为模型预测类别是正例的概率是P。CE目标函数基本上可以认为是这个概率的对数的负数，也就是在机器学习中经常使用的“<strong>负对数似然</strong>”（Negative Log Likelihood）。模型的目的是最小化“负对数似然”，从而学习模型参数。</p>
<p>作者们观测到这么一个现象，那就是CE目标函数在P是一个比较大的数值时，比如大于0.5的时候，依然会有一个“损失”（Loss）。什么意思呢？就是说，某一个数值点，我们现在已经知道它可能是正例的可能性大于0.5了，也就是我们其实已经大体知道这个结果了，但是目标函数依然认为学习算法需要去对这个数据点进行作用，从而减少这个“损失”。</p>
<p>这其实也就是整个问题的核心，那就是传统的CE目标函数，并没有指导机器学习算法用在“应该使劲”的地方，而是分散到了一些原本已经不需要再去关注的数据点上。当然，这也就造成了学习困难的局面。</p>
<p>这篇文章提出的“焦点损失”对CE进行了一个看上去很小的改动，那就是在CE目标函数的“负对数似然”之前乘以一个“相反概率”的<strong>系数</strong>，并且这个系数有一个指数参数去调节这个系数的作用。如果你对这个内容感兴趣，建议你参考原论文查看细节。如果对细节不感兴趣，那重点理解这个目标函数的作用就可以了。</p>
<p><strong>“焦点损失”有两个性质</strong>。第一，当一个数据点被分错类的时候，并且这个数据点的真实概率很小，那么，损失依然和CE类似。当一个数据点的真实概率趋近1，也就是原本算法就可以比较自信的时候，损失会相对于CE变小。第二，刚才所说的系数起到了一个调节作用，决定究竟需要对哪些“容易分类的数据点”降低损失到什么程度。</p>
<p><strong>文章在新的“焦点损失”的基础上提出了一个新的网络结构叫RetinaNet，使用一个阶段的思路来解决物体检测和语义分割的任务</strong>。这里我简要概括一下RetinaNet的一些特点。</p>
<p>第一，RetinaNet使用了ResNet来从原始的输入图像中抽取基本的图像特性。</p>
<p>第二，文章采用了一种叫FPN（Feature Pyramid Net）的网络架构来对图像的不同分辨率或者不同大小的情况进行特性抽取。</p>
<p>第三，和Faster R-CNN相似的，RetinaNet也是用了Anchor的思想，也就是说从小的一个移动窗口中去寻找一个比较大的矩形框的可能性。</p>
<p>最后，RetinaNet把从FPN抽取出来的特性用于两个平行的网络结构，一个用于物体分类，一个用于矩形框的定位。这一点很类似两个阶段模型的做法。</p>
<h2>方法的实验效果</h2>
<p>作者们使用RetinaNet在目前流行的图像物体检测任务数据集COCO上做了检测。首先，RetinaNet的“平均精度” （Average Precision）要好于之前的所有一个阶段模型，初步验证了提出的目标函数和网络架构的优越性。并且，在实验中，作者们分别使用了不同的“焦点损失”指数参数来展示这个参数对于结果的重要性。同时，作者们还展示了，RetinaNet能够比Faster R-CNN这种经典的两阶段模型，以及一些变种在实验结果上至少持平甚至要更好。</p>
<h2>小结</h2>
<p>今天我为你讲了2017年ICCV的最佳学生论文，这篇文章介绍了目前在图像物体识别中的最新目标函数“焦点损失”的大概内容。</p>
<p>一起来回顾下要点：第一，我们简要介绍了这篇文章的作者群信息。第二，我们分析了这篇文章要解决的问题和主要贡献 。第三，我们详细介绍了文章提出方法的核心内容 。</p>
<p>最后，给你留一个思考题，除了这篇文章介绍的更改目标函数的方法，针对不平衡的数据集，你觉得还有哪些通常使用的方法？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor9">009 | 如何将“深度强化学习”应用到视觉问答系统？<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>本周我们一起来剖析ICCV 2017的论文，周一和周三分别讲了最佳研究论文和最佳学生论文。今天，我们来分享一篇完全不同的文章，题目是《使用深度强化学习研究协作性视觉对话机器人》（Learning  Cooperative Visual Dialog Agents with Deep Reinforcement Learning），讲的是如何通过“深度强化学习”来解决视觉问答系统。</p>
<h2>作者群信息介绍</h2>
<p>第一作者阿布谢克·达斯（Abhishek Das）是一名来自佐治亚理工大学的在读博士生。他于2017年和2018年在Facebook人工智能研究院实习，已经获得了Adobe的研究奖学金和Snapchat的研究奖学金，可以说是一名非常卓越的博士生。之前在智能系统，特别是在利用强化学习研究智能机器人会话系统的领域已经发表了多篇论文。</p>
<p>共同第一作者萨特维克·库托儿（Satwik Kottur）来自卡内基梅隆大学，博士第四年，研究领域为计算机视觉、自然语言和机器学习。2016年暑假他在Snapchat的研究团队实习，研究对话系统中的个性化问题。2017年暑假在Facebook研究院实习，研究视觉对话系统。近两年，萨特维克已在多个国际顶级会议如ICCV 2017、ICML 2017、IJCAI 2017、CVPR 2017、NIPS 2017以及EMNLP 2017发表了多篇高质量研究论文，可以说是一颗冉冉升起的学术新星。</p>
<p>第三作者何塞·毛拉（José M. F. Moura）是萨特维克在卡内基梅隆大学的导师。何塞是美国工程院院士和IEEE院士，长期从事信号处理以及大数据、数据科学的研究工作。他当选2018年IEEE总裁，负责IEEE下一个阶段的发展。</p>
<p>第四作者斯特凡·李（Stefan Lee）是来自乔治亚理工大学的研究科学家，之前在弗吉尼亚理工大学任职，长期从事计算机视觉、自然语言处理等多方面的研究。斯特凡2016年博士毕业于印第安纳大学计算机系。</p>
<p>第五作者德鲁·巴塔（Dhruv Batra）目前是Facebook研究院的科学家，也是乔治亚理工大学的助理教授。德鲁2010年博士毕业于卡内基梅隆大学；2010年到2012年在位于芝加哥的丰田理工大学担任研究助理教授；2013年到2016年在弗吉尼亚大学任教。德鲁长期从事人工智能特别是视觉系统以及人机交互系统的研究工作。文章的第四作者斯特凡是德鲁长期的研究合作者，他们一起已经发表了包括本文在内的多篇高质量论文。</p>
<h2>论文的主要贡献</h2>
<p>我们首先来看一下这篇文章的主要贡献，理解这篇文章主要解决了什么场景下的问题。</p>
<p>这篇论文是建立在这么一个虚拟“游戏”（Game）的基础上的。</p>
<!-- [[[read_end]]] -->
<p>首先，我们有两个“机器人”（Agent），一个叫“Q机器人”（Q-Bot），一个叫“A机器人”（A-Bot）。这个游戏的规则是这样的。一开始，A机器人得到一张图片I，Q机器人一开始得到I的一个文字描述c，而并不知道图片本身。然后，Q机器人开始问A机器人关于图片的各种问题，A机器人听到问题之后进行作答，帮助Q机器人更进一步理解图片。Q机器人最终的目的是能够把这个图片“猜到”，也就是说能够把图片从一个数据库中“提取”（Retrieve）出来。当然在实际的操作中，这一步可以是去衡量Q机器人对于图像的理解，也就是“描述图像的向量”和“真实图像的描述向量”的差距，差距越小说明越成功。</p>
<p>那么，你可以看到，这其实是一个很难的问题。Q机器人必须从A机器人提供的图像文字描述中寻找线索，并且能够提出有意义的问题。而A机器人必须了解Q机器人到目前为止究竟理解什么信息，才能帮助Q机器人成功。</p>
<p>整个游戏，或者叫任务，常常被称作是“协作性的视觉对话系统”（Cooperative Visual Dialog System）。<strong>这篇文章的主要贡献就是第一个利用深度加强学习来对这样一个系统进行建模，并且，与之前的非加强学习模型相比，提出的解决方案极大地提高了准确度</strong>。</p>
<h2>论文的核心方法</h2>
<p>那么，既然要把整个问题使用深度强化学习来建模，我们肯定就需要定义强化学习的一些构件。</p>
<p>第一，我们来看看模型的<strong>“动作”（Action）</strong>。两个机器人的动作空间就是自然语言的词汇表。因为，在这个游戏或者说在强化学习的每一轮中，两个机器人都是需要根据现在的状态，来进行下一步的动作，也就是问问题的语句。这是一个离散的动作空间。除此以外，Q机器人还需要在每一轮之后对自己理解的图像向量进行更新。那么，这是一个连续的动作空间。</p>
<p>第二，我们来看看模型的<strong>“状态”（State）</strong>。对于Q机器人来说，每一轮的状态，是一个这些信息的集合，包括最初的A机器人提供的图像的描述，以及到目前为止所有轮问答的每一句话。而A机器人的状态空间，则包括最初的图像本身，图像的描述，以及到目前为止所有轮的对话。</p>
<p>第三，我们来看看模型的<strong>“策略”（Policy）</strong>。对A机器人和Q机器人来说，都是要根据现在的状态，来评估下面的语句的可能性。这里，评估的机制其实分别用两个神经网络来学习A机器人和Q机器人的策略。同时，Q机器人还需要有一个神经网络来根据现有的A机器人的回答，来更新对图像的一个认识。</p>
<p>第四，我们来看一看模型的<strong>“环境”（Environment）和“回馈”（Reward）</strong>。在这个游戏里，两个机器人都会得到一样的回馈，而这个回馈的根据是Q机器人对图像的认识所表达的向量和图像的真实表达向量的一个距离，或者更加准确地说是距离的变化量。</p>
<p>以上就是整个模型的设置。</p>
<p>那么，我们来看两个模型策略神经网络的一些细节。首先，对于Q机器人来说，有这么四个重要的部件。第一，Q机器人把当前轮自己问的问题和A给的回答，当做一个组合，用LSTM进行编码产生一个中间变量F。第二，当前步骤的F和以前的所有F都结合起来，再经过一个LSTM，产生一个中间变量S。然后第三步，我们根据这个S来产生下一步的语句，以及当前对图像的一个重新的认识。也就是说，<strong>F其实就是一个对历史所有状态的描述，而S则是一个压缩了的当前描述信息，并且我们使用S来作为下一步的一个跳板</strong>。A机器人的策略神经网络的架构非常类似，这里就不赘述了，区别在于不需要去产生图像的理解。</p>
<p>整个模型采用了目前深度强化学习流行的<strong>REINFORCE算法</strong>来对模型的参数进行估计。</p>
<p>这篇文章其实有不少技术细节，我们在今天的分享里只能从比较高的维度帮助你进行总结，如果有兴趣一定要去阅读原文。</p>
<h2>方法的实验效果</h2>
<p>作者们在一个叫VisDial的数据集上做了实验。这个数据集有6万8千幅图像，是从我们之前提到过的COCO数据集里抽取出来的，并且提供了超过68万对问答。可以说这个数据集还是比较大型的。</p>
<p>文章比较了利用普通的监督学习以及“课程学习”（Curriculum Learning）的方法。从效果来看，强化学习的效果还是很明显的。<strong>最直接的效果是，强化学习能够产生和真实对话相近的对话效果</strong>，而其他的办法，比如监督学习，则基本上只能产生“死循环”的对话，效果不理想。不过从图像提取的角度来讲，强化学习虽然比监督学习的效果好，但是差距并不是特别明显，基本上可以认为目前的差距依然是在误差范围内的。</p>
<h2>小结</h2>
<p>今天我为你讲了ICCV 2017的一篇有意思的文章。这篇文章介绍了如何利用深度强化学习来搭建一个模型去理解两个机器人的对话并能够理解图像信息。</p>
<p>一起来回顾下要点：第一，我们简要介绍了这篇文章的作者群信息。第二，我们详细介绍了这篇文章要解决的问题以及贡献 。第三，我们重点介绍了的文章提出方法核心内容 。</p>
<p>最后，给你留一个思考题，你认为把强化学习用在这样的对话场景中，难点是什么？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor10">010 | 精读2017年NIPS最佳研究论文之一：如何解决非凸优化问题？<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>机器学习与人工智能领域的顶级会议NIPS（Conference on Neural Information Processing Systems，神经信息处理系统大会）从1987年开始举办，已经有30多年的历史。NIPS 2017大会于2017年12月4日到9日在美国加利福尼亚州的长滩（Long Beach）举行。</p>
<p>每年大会都会在众多的学术论文中挑选出几篇最有新意和价值的论文作为最佳研究论文。在NIPS 2017上，一共有三篇论文获得了最佳论文的称号。今天，我就来带你认真剖析一下其中的一篇《具有凸目标的基于方差的正则化》（<a href="https://papers.nips.cc/paper/6890-variance-based-regularization-with-convex-objectives.pdf">Variance-based Regularization with Convex Objectives</a>）。这篇论文的两位作者都是来自斯坦福大学的学者。</p>
<p>这篇文章理论性很强，主要研究的是一种“健壮的优化问题”（Robust Optimization），也就是说我们在优化一个“损失函数”（Loss Function）的时候，不仅要考虑损失函数的“均值”（Mean），还要考虑损失函数的“方差”（Variance）。然而，一个既要考虑均值又要考虑方差的综合的损失函数，往往是一个“非凸”（Non Convex）的问题。对于一般的非凸优化问题来说，我们往往不能找到一个全局的最优解，甚至是找到局部最优解也很困难。这篇文章就是要来解决这么一个问题。</p>
<h2>作者群信息介绍</h2>
<p>第一作者洪升⋅南空（Hongseok Namkoong）是斯坦福大学“运筹学”（Operations Research）的一名在读博士研究生。他的导师分别是约翰⋅达齐（John C. Duchi）和彼得⋅格林（Peter W. Glynn）。2013年到斯坦福之前，南空在韩国的韩国科学与技术高级研究所（Korea Advanced Institute of Science and Technology），有时候又称为KAIST，获得工业工程和数学学士学位。最近两三年，南空已经在发表了两篇NIPS的文章（包括这篇最佳论文），以及一篇ICML的论文。</p>
<p>第二作者约翰⋅达齐（John C. Duchi）是南空的导师之一。达奇可以说是师出名门，他于2007年从斯坦福本科毕业，接着在斯坦福跟随机器学习权威达菲⋅科勒（Daphne Koller），拿到了计算机科学的硕士学位；然后又到加州大学伯克利分校跟随统计学习权威迈克尔⋅乔丹（Michael Jordan）拿到了计算机科学的博士学位。在博士阶段的暑假里，达奇还到Google研究院中追随约然⋅辛格（Yoram Singer）积累了非常有价值的实习经验。之后，他来到了斯坦福大学担任统计和电气电子工程系的助理教授。</p>
<p>有了这些良好的基础，达奇的学术成绩也是非常扎实。他于2010年获得了ICML最佳论文奖。紧接着，2011年在Google实习期间的工作AdaGrad，成为了现在机器学习优化领域的经典算法，这个工作的论文有超过2500次的引用，而且也是深度学习优化算法的一个重要基础。目前，达奇所有论文的引用数超过6千次。</p>
<h2>论文的主要贡献</h2>
<p>我们首先来看一下这篇文章的主要贡献，理解文章主要解决了一个什么场景下的问题。</p>
<p><strong>很多机器学习问题其实都可以最终归结于优化一个目标函数（Objective Function）或者有时候叫做损失函数（Loss Function）的问题</strong>。针对训练数据集上损失函数的优化（即最大化或最小化）并且在测试集上表现优异，是可以被证明为最终能够较好“泛化”（Generalization）的一种体现。</p>
<p>那么，<strong>通常情况下，这个损失函数都是针对均值的一个描述，比如在整个训练数据集上的平均误差，或者说在整个训练数据集上的平均准确度</strong>。然而，我们都知道，在一些很“偏斜”（Skewed）的数据分布上，均值并不是很好的一个数据描述。即便我们的函数能够在“平均”的情况下优化一个损失函数，这个函数也有可能在一些，甚至大部分数据点上表现得不尽如人意。</p>
<!-- [[[read_end]]] -->
<p>于是，研究人员就引入了“健壮的优化问题”。也就是我们希望损失函数在更多的点上有优异的表现。那么，<strong>损失函数的健壮性是用损失函数的方差来衡量的</strong>。也就是说，我们希望损失函数在不同数据点上的波动要小。</p>
<p>有了这个概念之后，下一步就显得比较自然了，那就是把损失函数的均值部分，也就是我们通常要做的部分和有方差的部分串联起来，形成一个新的目标函数。<strong>这个目标函数有两个部分，第一部分就是均值部分，第二个部分就是方差的部分，中间有一个自由的参数，把这两个部分衔接起来</strong>。这样，我们就有了一个既考虑均值又考虑方差的新的健壮化的优化问题。</p>
<p>然而，一个既要考虑均值又要考虑方差的综合的损失函数，往往是一个“非凸”（Non Convex）的问题。什么叫做非凸函数？<strong>一个“凸”（Convex）问题可以简单理解为函数只有唯一的最小值，并且我们具备有效算法来找到这个最小值</strong>。而对于非凸问题来说，我们往往不能找到一个全局的最优解，或者找到局部最优解也很困难。</p>
<p>健壮优化问题已经在之前的研究中提了出来，那么这篇文章的主要贡献在于，为健壮优化问题找到了一个“凸”问题的逼近表达，并基于此提出了一个优化算法，解决了这个新提出的凸问题的近似解。</p>
<p>这里，值得注意的一点是，<strong>对于非凸问题提出凸问题的近似表达，是解决非凸问题的一个重要思路</strong>。有很多经典的非凸问题，都是通过凸问题的近似来得到解决或者部分解决的。从这个思路来说，这篇文章是延续了解决这种问题的一贯的策略。</p>
<h2>论文的核心方法</h2>
<p>这篇论文的核心方法以及证明都有很强的理论性，需要有一定的数学功底和类似研究背景，才能更好地理解。如果对文章内容有兴趣，建议不仅要阅读原本的NIPS论文，还需要去阅读其附加的文档，一共有50多页，才能比较全面地理解这篇文章的细节。我们在这里仅仅从概念上做一个高度浓缩的概括。</p>
<p>作者们在文章中<strong>提出了一种叫“健壮化的正则风险”（Robustly Regularized Risk）的目标函数</strong>。这个新的目标函数是建立在一个叫“经验分布”（Empirical Distribution）上的“散度”（Divergence）。而这个新的健壮化正则风险是一个凸问题。</p>
<p>直白一点说，这个健壮化的正则风险可以被认为是一个包含两项的式子，这两项是在数据集上的损失函数的期望加上一个损失函数的方差。在这个新的两项的式子中，期望和方差都是定义在数据的经验分布上的。于是这样就把这个新提出的风险式子和我们实际需要解决的问题挂上了钩。当然后面大段的论文就是要证明这两个式子之间的差距到底有多少，是不是新的式子提供了一个比较“紧”的“界限“（Bound）。</p>
<p>紧接着，这篇文章其实讨论了这个健壮化的正则风险可以写成一个更加简单的优化问题，然后文章在附录中提供了这个简化后的优化问题的求解。</p>
<h2>方法的实验效果</h2>
<p>虽然这篇文章的核心内容是一个理论结果，或者是算法革新。但是这篇文章依然是在两个数据集中做了实验，一个是在UCI ML的数据集上，展示了提出的新的健壮化的目标函数达到了比一般的目标函数更好的效果；另外一个则是在RCV1文本分类的问题上比一般的优化目标函数有更好的效果。</p>
<h2>小结</h2>
<p>今天我为你讲了NIPS 2017年的最佳研究论文之一，文章非常理论化。文章的一个核心观点是希望能够通过对损失函数的均值和方差同时建模从而达到让目标函数健壮化的目的。</p>
<p>一起来回顾下要点：第一，我们简要介绍了这篇文章的作者群信息。第二，我们详细介绍了这篇文章要解决的问题以及贡献 。第三，我们简要地介绍的文章提出方法的核心内容 。</p>
<p>最后，给你留一个思考题，要想控制目标函数的预测结果的方差，除了本文提出的把均值和方差都设计到目标函数里，还有没有别的方法？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor11">011 | 精读2017年NIPS最佳研究论文之二：KSD测试如何检验两个分布的异同？<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>本周我们来分析和探讨NIPS 2017上的三篇最佳论文。周一我们分享的文章主要研究的是一种“健壮的优化问题”，也就是说我们在优化一个“损失函数”的时候，不仅要考虑损失函数的“均值”，还要考虑损失函数的“方差”。</p>
<p>今天，我们来看另外一篇最佳论文《线性时间内核拟合优度测试》（<a href="https://papers.nips.cc/paper/6630-a-linear-time-kernel-goodness-of-fit-test.pdf">A Linear-Time Kernel Goodness-of-Fit Test</a>），讲的是如何来衡量一组数据是否来自于某一个分布。</p>
<p>今天的这篇文章理论性也很强，这里我尝试从更高的维度为你做一个归纳，如果对文章内容感兴趣，建议你一定要去阅读原文。</p>
<h2>作者群信息介绍</h2>
<p>本文一共有五位作者，我们在这里进行一个简要介绍。</p>
<p>第一作者叫维特瓦特·吉特克鲁特（Wittawat Jitkrittum），刚从伦敦大学学院（University College London）的“加斯比计算人脑科学所”（Gatsby Computational Neuroscience Unit）博士毕业。他在博士期间的主要研究是“统计测试”（Statistical Tests），特别是如何利用“核方法”（Kernel Method）来对“分布特征”（Distributional Features）进行测试。吉特克鲁特在泰国完成本科学习，于日本京的东京科技学院（Tokyo Institute Of Technology）获得硕士学位。最近几年，吉特克鲁特已经在NIPS、ICML、UAI等会议连续发表了多篇高质量论文，可以说是统计测试界的学者新秀。</p>
<p>第二作者许文凯（Wenkai Xu）是加斯比计算人脑科学所的一名博士生。</p>
<p>第三作者佐尔坦·萨博（Zoltán Szabó）来自法国一所著名的理工大学“巴黎综合理工学院”（École Polytechnique）。萨博之前也曾在加斯比计算人脑科学所工作过，目前在巴黎综合理工学院任职研究副教授（类似于研究员），长期从事核方法、信息论（Information Theory）、统计机器学习等方面的研究。</p>
<p>第四作者福水健次（Kenji Fukumizu）是“统计数学学院”（The Institute of Statistical Mathematics）的教授，长期从事核方法的研究，可以说是这方面的专家。</p>
<p>最后一个作者阿瑟·格里顿（Arthur Gretton）是加斯比计算人脑科学所的机器学习教授，长期从事机器学习，特别是核方法的研究。他的论文有9千多次的引用数。</p>
<h2>论文的主要贡献和核心方法</h2>
<p>我们首先来看一下这篇文章的主要贡献，理解这篇文章主要解决了什么场景下的问题。</p>
<p>在一般的建模场景里，我们常常会对一组数据提出一个模型，来描述产生这些数据背后的过程。这个过程我们通常是看不见的，是一个隐含的过程。那么，当我们提出了模型之后，如何知道用这个模型描述现实就是准确的呢？这时候我们就需要用到一些<strong>统计检验</strong>（Statistical Testing）的方法。</p>
<p>一种比较普遍的方法，那就是假设我们的模型是P，而数据的产生分布是Q。说得直白一些，就需要去验证P是不是等于Q，也就是需要验证两个分布是否相等。一个基本的做法就是，从P里“产生”（Generate）一组样本，或者叫一组数据，然后我们已经有了一组从Q里产生的数据，于是用“<strong>两个样本假设检验</strong>”（Two Sample Tests）来看这两组数据背后的分布是否相等。</p>
<p>这个想法看似无懈可击，但是在实际操作中往往充满困难。<strong>最大的操作难点就是从P中产生样本</strong>。比如P是一个深度神经网络模型，那从中产生样本就不是一个简单且计算效率高的流程，这就为基于“两个样本假设检验”带来了难度。</p>
<!-- [[[read_end]]] -->
<p>另一方面，我们在做这样的统计检验的时候，最好能够针对每一个数据点，得到一个数值，来描述当前数据点和模型之间的关系，从而能够给我们带来更加直观的认识，看模型是否符合数据。</p>
<p>这里，有一种叫作“<strong>最大均值差别</strong>”（Maximum Mean Discrepancy），或者简称为 <strong>MMD</strong> 的检验方法能够达到这样的效果。MMD的提出者就是这篇论文的最后一位作者阿瑟·格里顿，MMD是在NIPS 2016提出的一个检验两个样本是否来自同一个分布的一种方法。当MMD值大的时候，就说明这两个样本更有可能来自不同的分布。</p>
<p>和一般的衡量两个分布距离的方法相比，MMD的不同之处是把两个分布都通过核方法转换到了另外一个空间，也就是通常所说的“<strong>再生核希尔伯特空间</strong>”（Reproducing Kernel Hilbert Space），或者简称为 <strong>RKHS</strong>。在这个空间里，测量会变得更加容易。然而遗憾的是，MMD依然需要得到两个分布的样本，也就是说我们依然需要从P里得到样本。</p>
<p>那么，<strong>这篇文章的最大贡献，就是使用了一系列的技巧让P和Q的比较不依赖于从P中得到样本，从而让数据对于模型的验证，仅仅依赖于P的一个所谓的“打分函数”</strong>（Score Function）。</p>
<p>其实在MMD里，这个打分函数就是存在的，那就是针对我们从P或者是Q里抽取出来的样本，我们先经过一个函数F的变换，然后再经过一个叫“核函数”T的操作，最后两个样本转换的结果相减。</p>
<p>在这篇文章里，作者们提出了一个叫“核斯特恩差异”（Kernel Stein Discrepancy），或者叫<strong>KSD测试</strong>的概念，本质上就是希望能够让这两个式子中关于P的项等于零。</p>
<p>什么意思呢？刚才我们说了MMD的一个问题是依然要依赖于P，依赖于P的样本。假设我们能够让依赖P的样本这一项成为零，那么我们这个测试就不需要P的样本了，那也就是绕过了刚才所说的难点。</p>
<p><strong>KSD的本质就是让MMD的第二项在任何时候都成为零</strong>。注意，我们这里所说的是“任何时候”，也就是说，KSD构造了一个特殊的T，这个T叫作“斯特恩运算符”（Stein Operator），使得第二项关于P的样本的计算，在任何函数F的情况下都是零，这一点在文章中提供了详细证明。于是，整个KSD就不依赖于P的样本了。</p>
<p>这篇文章不仅阐述了KSD的思想，而且在KSD的思想上更进了一步，<strong>试图把KSD的计算复杂度，也就是在平方级别的计算复杂度变为线性复杂度</strong>。什么意思呢？也就是说，希望能够让KSD的计算复杂度随着数据点的增加而线性增加，从而能够应用到大数据上。这个内容我们就不在这里复述了。</p>
<h2>方法的实验效果</h2>
<p>虽然这篇文章的核心内容是一个理论结果，或者是算法革新，文章还是在“受限波兹曼机”（Restricted Boltzmann Machine），简称RBM上做了实验。本质上就是在RBM的某一个链接上进行了简单的改变而整个模型都保持原样。</p>
<p>如果我们有从这两个RBM中得到的样本，其实是很难知道他们之间的区别的。在实验中，传统的MMD基本上没法看出这两个样本的差别。然而不管是KSD，还是线性的KSD都能够得出正确的结论，而最终的线性KSD基本上是随着数据点的增多而性能增加，达到了线性的效果。</p>
<p>最后，作者们用了芝加哥犯罪记录来作为说明，使用“打分函数”来形象地找到哪些点不符合模型。应该说，理论性这么强的论文有如此直观的结果，实在难能可贵。</p>
<h2>小结</h2>
<p>今天我为你讲了NIPS 2017年的另外一篇最佳研究论文，文章的一个核心观点是希望能够通过构建一个特殊的运算符，使得传统的通过样本来检验两个分布的异同的方法，比如MMD方法，可以不依赖于目标分布的样本，并且还能达到线性计算速度。</p>
<p>一起来回顾下要点：第一，我们简要介绍了这篇文章的作者群信息。第二，我们详细介绍了这篇文章要解决的问题以及贡献 。第三，我们简要地介绍了文章的实验结果 。</p>
<p>最后，给你留一个思考题，这种衡量分布之间距离的想法，除了在假设检验中使用以外，在机器学习的哪个环节也经常碰到？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor12">012 | 精读2017年NIPS最佳研究论文之三：如何解决非完美信息博弈问题？<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>今天，我们来分享一下NIPS 2017的最后一篇最佳论文《安全和嵌套子博弈解决非完美信息博弈问题》（<a href="http://https://www.cs.cmu.edu/~sandholm/safeAndNested.aaa17WS.pdf">Safe and Nested Subgame Solving for Imperfect-Information Games</a>）。这篇文章讲的是什么内容呢？讲的是如何解决“<span class="orange">非完美信息的博弈</span>”问题。</p>
<p>和前两篇分享的文章类似，这篇文章也是理论性很强，并不适合初学者，我们在这里仅仅对文章的主要思想进行一个高度概括。如果你对文章内容感兴趣，还是建议要阅读原文。</p>
<p>另外一个值得注意的现象是，即便在深度学习如日中天的今日，我们本周分享的三篇NIPS最佳论文均和深度学习无关。这一方面展现了深度学习并不是人工智能的全部，另一方面也让我们看到机器学习和人工智能领域的宽广。</p>
<h2>作者群信息介绍</h2>
<p>本文一共两位作者。</p>
<p>第一作者叫诺阿·布朗（Noam Brown）。布朗是卡内基梅隆大学计算机系的博士生，目前的主要研究方向是利用强化学习和博弈论的思想来解决大规模的多机器人交互的问题。这篇文章提到的“非完美信息博弈”也是这里面的一个分支问题。布朗已经在这个方向发表了多篇论文，包括三篇AAAI论文、两篇NIPS论文、一篇ICML论文、以及一篇IJCAI论文。</p>
<p>和本文非常相关的一个研究内容在2017年发表于《科学》（Science）杂志上，讲述了如何利用博弈论来解决“Heads-up无限制扑克”（Heads-up No Limit Poker）的问题，并且在现实比赛中已经超过了人类的表现。这个工作也得到了不少媒体的报道。布朗2017年也在伦敦的Google DeepMind实习；在博士阶段之前，他曾经在金融领域工作。</p>
<p>第二作者是布朗的导师托马斯·桑德霍姆（Tuomas Sandholm）。桑德霍姆是卡内基梅隆大学计算机系的教授，其在“机制设计”（Mechanism Design）以及“拍卖理论”（Auction Theory）等领域有长期的研究，发表了450多篇学术论文，并且有超过2万多的引用数。除了他在学术上的造诣以外，桑德霍姆还有一些轶事，比如，他还有非常广泛的兴趣爱好，在他的主页就列举了他冲浪、喜好魔术以及对飞行的热爱。</p>
<h2>论文的主要贡献和核心方法</h2>
<p>我们首先来看一下这篇文章的主要贡献，弄明白这篇文章主要解决了什么场景下的问题。</p>
<p>对于一篇理论性很强的文章来说，我们通常需要不断地提问，这篇文章的核心主旨到底是什么，这样才能够帮助我们了解到文章的主干。</p>
<p>首先，文章讲的是一个“<strong>非完美信息的博弈</strong>”问题。这是什么意思呢？要理解“非完美信息博弈”，我们就必须要说一下“<strong>完美信息博弈</strong>”。</p>
<p>简单来说，“完美信息博弈”指的是博弈双方对目前的整个博弈状况都完全了解，对于博弈之前，以及整个博弈时候的初始状态也完全了解。在这种定义下，很多大家熟悉的游戏都是“完美信息博弈”，比如围棋、象棋等等。那么，DeepMind开发的AlphaGo以及后来的AlphaGo Zero都是典型的针对“完美信息博弈”的人工智能算法。</p>
<p>“非完美信息博弈”并不是说我们不知道对方的任何信息，而只是说信息不充分。什么意思呢？比如，我们可能并不知道对手在这一轮里的动作，但我们知道对手是谁，有可能有怎样的策略或者他们的策略的收益（Payoff）等。</p>
<p>除了在表面定义上的区别以外，在整个问题的机构上也有不同。</p>
<!-- [[[read_end]]] -->
<p>“完美信息博弈”有这样的特征，那就是在某一个时刻的最优策略，往往仅需要在问题决策树当前节点的信息以及下面子树对应的所有信息，而并不需要当前节点之前的信息，以及其他的旁边节点的信息。</p>
<p>什么意思呢？比如我们看AlphaGo。本质上在这样“完美信息博弈”的场景中，理论上，我们可以列出所有的棋盘和棋手博弈的可能性，然后用一个决策方案树来表达当前的决策状态。在这样的情况下，走到某一个决策状态之后，往往我们仅仅需要分析后面的状态。尽管这样的情况数目会非常巨大，但是从方法论的角度来说，并不需要引用其他的信息来做最优决策。</p>
<p>“非完美信息博弈”的最大特点就正好和这个相反，也就是说，每一个子问题，或者叫子博弈的最佳决策，都需要引用其他信息。而实际上，<strong>本篇论文讲述了一个事实，那就是“非完美信息博弈”在任何一个决策点上的决策往往取决于那些根本还没有“达到”（Reach）的子博弈问题</strong>。</p>
<p>在这一点上，论文其实引用了一个“掷硬币的游戏”来说明这个问题。限于篇幅，我们就不重复这个比较复杂的问题设置了，有兴趣的话可以深读论文。</p>
<p>但是从大体上来说，这个“掷硬币的游戏”，其核心就是想展示，两个人玩掷硬币，在回报不同，并且两个人的玩法在游戏规则上有一些关联的情况下，其中某一个玩家总可以根据情况完全改变策略，而如果后手的玩家仅仅依赖观测到先手玩家的回馈来决策，则有可能完全意识不到这种策略的改变，从而选择了并非优化的办法。这里的重点在于先后手的玩家之间因为规则的牵制，导致后手玩家无法观测到整个游戏状态，得到的信息并不能完全反应先手玩家的策略，从而引起误判。</p>
<p>为解决这样博弈问题，<strong>这篇文章提出的一个核心算法就是根据当前的情况，为整个现在的情况进行一个“抽象”（Abstraction）</strong>。这个抽象是一个小版本的博弈情况，寄希望这个抽象能够携带足够的信息。然后，我们根据这个抽象进行求解，当在求解真正的全局信息的时候，我们利用这个抽象的解来辅助我们的决策。<strong>有时候，这个抽象又叫作“蓝图”（Blueprint）策略</strong>。<strong>这篇文章的核心在于如何构造这样的蓝图，以及如何利用蓝图来进行求解</strong>。</p>
<h2>方法的实验效果</h2>
<p>文章在“Heads-up无限制扑克”的数据集上做了实验，并且还比较了之前在《科学》杂志上发表的叫作“利不拉图斯”（Libratus）的算法版本。人工智能算法都大幅度领先人类的玩家。</p>
<p>有一种算法叫“非安全子博弈算法”（Unsafe Subgame Solving），也就是说并不考虑“非完美信息的博弈”状态，把这个情况当做完美信息来做的一种算法，在很多盘游戏中均有不错的表现，但是有些时候会有非常差的结果，也就是说不能有“健壮”（Robust）的结果。这里也从实验上证明了为什么需要本文提出的一系列方法。</p>
<h2>小结</h2>
<p>今天我为你讲了NIPS 2017的第三篇最佳研究论文，文章的一个核心观点是希望能够通过构建蓝图来引导我们解决非完美信息博弈的问题，特别是在扑克上面的应用。</p>
<p>一起来回顾下要点：第一，我们简要介绍了这篇文章的作者群信息。第二，我们详细介绍了这篇文章要解决的问题以及贡献 。第三，我们简要地介绍了文章的实验结果 。</p>
<p>最后，给你留一个思考题，为什么非完美博弈的整个问题求解现在并没有依靠<em>深度加强学习</em>呢，大家在这个问题上有什么直观上的体会呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor13">013 | WSDM 2018论文精读：看谷歌团队如何做位置偏差估计<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>WSDM（International Conference on Web Search and Data Mining，国际搜索和数据挖掘大会）是每年举办一次的搜索、数据挖掘以及机器学习的顶级会议，其从2008年开始举办，已经有11届的历史。</p>
<p>尽管WSDM仅仅举办了11届，在计算机科学领域算是一个非常年轻的会议。但是，WSDM快速积累的影响力已经使其成为了数据挖掘领域的一个顶级会议。根据谷歌学术搜索公布的数据，目前WSDM已经是数据挖掘领域仅次于KDD的学术会议，而KDD已经举办了20多年。</p>
<p>WSDM的一大特点就是有大量工业界的学者参与，不管是投稿和发表论文还是评审委员会或者大会组织委员会的成员，都有很多工业界背景的人员参加。这可能也是WSDM备受关注的一个原因，那就是大家对于工业界研究成果的重视，同时也希望能够从中学习到最新的经验。</p>
<p>2018年的WSDM大会于2月5日到9日在的美国的洛杉矶举行。今天，我们就来分享WSDM 2018上来自谷歌的一篇文章《无偏排序学习在个人搜索中的位置偏差估计》（<a href="https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/46485.pdf">Position Bias Estimation for Unbiased Learning to Rank in Personal Search</a>）。这篇文章的核心内容是如何结合“因果推断”（Causal Inference）和排序学习（Learning to Rank）来对用户数据进行进一步无偏差的估计。</p>
<h2>作者群信息介绍</h2>
<p>这篇论文的所有作者都来自谷歌，我们这里对作者群做一个简单的介绍。</p>
<p>第一作者王选珲（Xuanhui Wang）2015年起在谷歌工作。他之前在Facebook工作了三年，一直从事广告系统的开发；再往前，是在雅虎担任了两年的科学家。王选珲于2009年毕业于伊利诺伊大学香槟分校，获得计算机博士学位，他的博士生导师是信息检索界著名的华人学者翟成祥（Chengxiang Zhai）。</p>
<p>第二作者纳达夫⋅古尔班迪（Nadav Golbandi）于2016年加入谷歌，之前在雅虎研究院担任了8年的主任级研究工程师（Principal Research Engineer），一直从事搜索方面的研发工作。在雅虎研究院之前，古尔班迪在以色列的IBM研究院工作了6年。他拥有以色列理工大学的计算机硕士学位。</p>
<p>第三作者迈克尔⋅本德斯基（Michael Bendersky）于2012年加入谷歌，一直从事个人以及企业信息系统（Google Drive）的研发工作。本德斯基于2011年从马萨储塞州阿姆赫斯特分校（University of Massachusetts Amherst）毕业，获得计算机博士学位，他的导师是信息检索界的学术权威布鲁斯⋅夸夫特（Bruce Croft）。</p>
<p>第四作者唐纳德⋅梅泽尔（Donald Metzler）也是2012年加入谷歌的，一直负责个人以及企业信息系统（Google Drive）搜索质量的研发工作。梅泽尔曾在雅虎研究院工作过两年多，然后还在南加州大学（University of South California）担任过教职。梅泽尔是2007年从马萨储塞州阿姆赫斯特分校计算机博士毕业，导师也是信息检索界的学术权威布鲁斯⋅夸夫特。</p>
<p>文章的最后一个作者是马克⋅诺瓦克（Marc Najork）于2014年加入谷歌，目前担任研发总监（Research Engineering Director）的职位。诺瓦克之前在微软研究院硅谷分部工作了13年，再之前在DEC研究院工作了8年。诺瓦克是信息检索和互联网数据挖掘领域的学术权威，之前担任过ACM顶级学术期刊ACM Transactions on the Web的主编。他发表过很多学术文章，引用数在七千以上。</p>
<h2>论文的主要贡献</h2>
<p>按照我们阅读论文的方法，首先来看这篇文章的主要贡献，梳理清楚这篇文章主要解决了什么场景下的问题。</p>
<p>众所周知，所有的搜索系统都会有各种各样的“<strong>偏差</strong>”（Bias），如何能够更好地对这些偏差进行建模就成为了对搜索系统进行机器学习的一个重要的挑战。</p>
<p>一种方式就是像传统的信息检索系统一样，利用人工来获得“相关度”（Relevance）的标签，不需要通过通过人机交互来获取相关度的信息。所以，也就更谈不上估计偏差的问题。</p>
<p>第二种，文章中也有谈到的，那就是利用传统的“<strong>点击模型</strong>”（Click Model）。点击模型是一种专门用来同时估计相关度和偏差的概率图模型，在过去10年左右的时间内已经发展得相对比较成熟。文章中也提到，大多数点击模型的应用主要是提取相关度信息，而并不在乎对偏差的估计是否准确。</p>
<p>第三种，也是最近几年兴起的一个新的方向，那就是利用“因果推断”（Causal Inference）和排序学习的结合直接对偏差进行建模。在WSDM 2017的最佳论文[1]中，已经让我们见识了这个思路。然而，在去年的那篇文章里，并没有详细探讨这个偏差的估计和点击模型的关系。</p>
<!-- [[[read_end]]] -->
<p>简言之，<strong>这篇论文主要是希望利用点击模型中的一些思路来更加准确地估计偏差，从而能够学习到更好的排序结果</strong>。同时，这篇文章还探讨了如何能够在较少使用随机数据上来对偏差进行更好的估计。这里，作者们提出了一种叫作“<strong>基于回归的期望最大化</strong>”（Regression-based EM）算法。</p>
<h2>论文的核心方法</h2>
<p>文章首先讨论了如果已知“偏差值”（Propensity Score），也就是用户看到每一个文档或者物品时的概率，我们就可以构造“无偏差”的指标，比如“<strong>无偏差的精度</strong>”（Unbiased Precision）来衡量系统的好坏。</p>
<p>这里，无偏差的效果主要是来自于重新对结果进行权重的调整。意思就是说，并不是每一个点击都被认为是同样的价值。总的来说，如果文档位于比较高的位置上，那权重反而会比较低，反之，如果文档位于比较低的位置上，权重反而较高。<strong>这里的假设是一种“位置偏差”（Position Bias）假设。意思就是不管什么文档，相对来说，放在比较高的位置时都有可能获得更多的点击。因此，在较低位置的文档被点击就显得更加难得</strong>。</p>
<p>这种情况下，一般都无法直接知道“偏差值”。因此，如何去估计偏差值就成了一个核心问题。</p>
<p>这篇文章在进行“偏差值”估计的方法上，首先利用了一个叫“<strong>位置偏差模型”</strong>（Position Bias Model）的经典点击模型，对偏差值和相关度进行了建模。“位置偏差模型”的假设是用户对于每一个查询关键字的某一个位置上的文档点击概率，都可以分解为两个概率的乘积，一个是用户看到这个位置的概率，一个就是文档本身相关度的概率。那么，位置偏差模型的主要工作就是估计这两个概率值。</p>
<p>如果我们能够对每一个查询关键字的结果进行随机化，那么，我们就不需要估计第一个概率，而可以直接利用文档的点击率来估计文档的相关度。但是，作者们展示了，彻底的随机化对于用户体验的影响。</p>
<p>另外一种方法，相对来说比较照顾用户体验，那就是不对所有的结果进行随机化，而仅仅针对不同的“配对”之间进行随机化。比如，排位第一的和第二的文档位置随机互换，然后第二的和第三的随机互换等等。在这样的结果下，作者们依然能够对偏差和相关度进行估计，不过用户的体验就要比第一种完全随机的要好。只不过，在现实中，这种方法依然会对用户体验有所损失。</p>
<p>于是，作者们提出了第三种方法，那就是<strong>直接对位置偏差模型进行参数估计</strong>。也就是说，不希望利用随机化来完全消除其中的位置概率，而是估计位置概率和相关度概率。</p>
<p>这里，因为有两个概率变量需要估计，于是作者利用了传统的“期望最大化”（EM）算法，并且提出了一种叫做“基于回归的期望最大化”的方法。为什么这么做呢？原因是在传统的期望最大化中，作者们必须对每一个关键字和文档的配对进行估计。然而在用户数据中，这样的配对其实可能非常有限，会陷入数据不足的情况。因此，作者们提出了利用一个回归模型来估计文档和查询关键字的相关度。也就是说，<strong>借助期望最大化来估计位置偏差，借助回归模型来估计相关度</strong>。</p>
<h2>方法的实验效果</h2>
<p>这篇文章使用了谷歌的邮件和文件存储的搜索数据，采用了2017年4月两个星期的日志。数据大约有四百万个查询关键字，每个关键字大约有五个结果。作者们在这个数据集上验证了提出的方法能够更加有效地捕捉文档的偏差。利用了这种方法训练的排序模型比没有考虑偏差的模型要好出1%～2%。</p>
<h2>小结</h2>
<p>今天我为你讲了WSDM 2018年的一篇来自谷歌团队的文章，这篇文章介绍了如何估计文档的位置偏差，然后训练出更加有效的排序算法。</p>
<p>一起来回顾下要点：第一，我们简要介绍了这篇文章的作者群信息；第二，我们详细介绍了这篇文章要解决的问题以及贡献；第三，我们简要地介绍了文章提出方法的核心内容 。</p>
<p>最后，给你留一个思考题，如果要估计位置偏差，对数据的随机性有没有要求？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p><strong><span class="reference">参考文献</span></strong></p>
<p><span class="reference"> 1. Thorsten Joachims, Adith Swaminathan, and Tobias Schnabel. <a href="http://delivery.acm.org/10.1145/3020000/3018699/p781-joachims.pdf?ip=185.211.133.206&amp;id=3018699&amp;acc=CHORUS&amp;key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E6D218144511F3437&amp;__acm__=1518920527_3cf6dd96729ff3e596bb6901c8230cb1">Unbiased Learning-to-Rank with Biased Feedback</a>. Proceedings of the Tenth ACM International Conference on Web Search and Data Mining (WSDM '17). ACM, New York, NY, USA, 781-789, 2017.</span></p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor14">014 | WSDM 2018论文精读：看京东团队如何挖掘商品的替代信息和互补信息<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>本周我们来精读WSDM的几篇论文，周一我们分享了一篇来自谷歌团队的文章，其核心是利用点击模型来对位置偏差进行更加有效的估计，从而能够学习到更好的排序算法。</p>
<p>今天，我们来介绍WSDM 2018的最佳学生论文《电子商务中可替代和互补产品的路径约束框架》（<a href="http://http://delivery.acm.org/10.1145/3160000/3159710/p619-wang.pdf?ip=185.211.133.206&amp;id=3159710&amp;acc=OPEN&amp;key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E6D218144511F3437&amp;__acm__=1519027969_cc4a857a03d3bba81f9e3e69a6b774cc">A Path-constrained Framework for Discriminating Substitutable and Complementary Products in E-commerce</a>），这篇文章来自于京东的数据科学实验室。</p>
<h2>作者群信息介绍</h2>
<p>这篇论文的所有作者都来自京东大数据实验室，我们这里对几位主要作者做一个简单介绍。</p>
<p>第三作者任昭春（Zhaochun Ren）目前在京东数据科学实验室担任高级研发经理。他于2016年毕业于荷兰阿姆斯特丹大学，获得计算机博士学位，师从著名的信息检索权威马丁⋅德里杰克（Maarten de Rijke）。任昭春已经在多个国际会议和期刊上发表了多篇关于信息检索、文字归纳总结、推荐系统等多方面的论文。</p>
<p>第四作者汤继良（Jiliang Tang）目前是密歇根州立大学的助理教授。汤继良于2015年从亚利桑那州立大学毕业，获得计算机博士学位，师从著名的数据挖掘专家刘欢（Huan Liu）教授。他于2016年加入密歇根州立大学，这之前是雅虎研究院的科学家。汤继良是最近数据挖掘领域升起的一颗华人学术新星，目前他已经发表了70多篇论文，并且有四千多次的引用。</p>
<p>最后一位作者殷大伟（Dawei Yin）目前是京东数据科学实验室的高级总监。2016年加入京东，之前在雅虎研究院工作，历任研究科学家和高级经理等职务。殷大伟2013年从里海大学（Lehigh University）获得计算机博士学位，师从信息检索领域的专家戴维森（Davison）教授。目前已经有很多高质量的研究工作发表。殷大伟和笔者是博士期间的实验室同学以及在雅虎研究院期间的同事。</p>
<h2>论文的主要贡献</h2>
<p>我们首先来看一下这篇文章的主要贡献，梳理清楚文章主要解决了一个什么场景下的问题。</p>
<p>对于工业级商品推荐系统而言，一般通过两个步骤来产生推荐结果。第一步，产生候选集合，这里主要是从海量的物品中选择出几百到几千款用户可能会购买的商品；第二步，利用复杂的机器学习模型来对所有候选集中的产品进行排序。</p>
<p><strong>这篇文章主要探讨了如何能够更好地产生候选集产品，即如何更好地产生“替代品”（Substitutes）和“互补品”（Complements）来丰富用户的购买体验。</strong></p>
<p>那么，什么是替代品和互补品呢？</p>
<!-- [[[read_end]]] -->
<p>根据这篇文章的定义，替代品就是用户觉得这些商品可以互相被替换的；而互补品则是用户会一起购买的。挖掘这些商品不仅对于产生候选集具有很重要的意义，也对于某些场景下的推荐结果有很好的帮助，比如当用户已经购买了某一件商品之后，给用户推荐其他的互补品。</p>
<p>虽然替代品和互补品对于互联网电商来说是很重要的推荐源，但并没有多少文献和已知方法来对这两类商品进行有效挖掘。而且这里面一个很大的问题是数据的“稀缺”（Sparse）问题。因为替代品或者互补品都牵扯至少两个商品，而对于巨型的商品库来说，绝大多数的商品都不是两个商品一起被同时考虑和购买过，因此如何解决数据的稀缺问题是一大难点。</p>
<p>另一方面，商品的属性是复杂的。同一款商品有可能在某些情况下是替代品，而在另外的情况下是互补品。因此，如何在一个复杂的用户行为链路中挖掘出商品的属性，就成为了一个难题。很多传统方法都是静态地看待这个问题，并不能很好地挖掘出所有商品的潜力。</p>
<p>归纳起来，这篇文章有两个重要贡献。<strong>第一，作者们提出了一种“多关系”（Multi-Relation）学习的框架来挖掘替代品和互补品。第二，为了解决数据的稀缺问题，两种“路径约束”（Path Constraints）被用于区别替代品和互补品。</strong>作者们在实际的数据中验证了这两个新想法的作用。</p>
<h2>论文的核心方法</h2>
<p><strong>文章提出方法的第一步是通过关系来学习商品的表征</strong>（Representation）。这里文章并没有要区分替代品和互补品。<strong>表征的学习主要是用一个类似Word2Vec的方式来达到的</strong>。</p>
<p>也就是说，商品之间如果有联系，不管是替代关系还是互补关系，都认为是正相关，而其他的所有商品都认为是负相关。于是，我们就可以通过Word2Vec的思想来学习商品的表征向量，使得所有正相关的商品之间的向量点积结果较高，而负相关的向量点积结果较低。这一步基本上是Word2Vec在商品集合上的一个应用。</p>
<p>通过第一步得到的每个商品的表征，是一个比较笼统的<strong>综合的表征</strong>。而我们之前已经提到了，那就是不同的情况下，商品可能呈现出不同的属性。因此，我们就需要根据不同的场景来刻画产品的不同表征。<strong>文章采用的方法是，对于不同类型的关系，每个商品都有一个对应的表征</strong>。这个关系特定的表征是从刚才我们学到的全局表征“投影”（Project）到特定关系上的，这里需要学习的就是<strong>一个投影的向量</strong>。</p>
<p><strong>第三个步骤就是挖掘替代关系和互补关系了</strong>。这篇文章使用了一个不太常见的技术，用“<strong>模糊逻辑</strong>”（Fuzzy Logic）来表达商品之间的约束关系。在这里我们并不需要对模糊逻辑有完整的理解，只需要知道这是一种把“硬逻辑关系”（Hard Constraints）转换成为通过概率方法表达的“软逻辑关系”（Soft Constraints）的技术。</p>
<p>在这篇文章里，作者们重点介绍的是如何利用一系列的规则来解决数据稀缺的问题。具体来说，那就是利用一些人们对于替代关系或者互补关系的观察。</p>
<p>比如，商品A是商品B的替代品，那很可能商品A所在的类别就是商品B所在类别的替代品。再比如，商品B是商品A的替代品，而商品C又是商品B的替代品，而如果A、B和C都属于一个类别，那么我们也可以认为商品C是A的替代品。</p>
<p>总之，作者们人工地提出了这样一系列的规则，或者叫做约束关系，希望能够使用这样的约束关系来尽可能地最大化现有数据的影响力。当然，我们可以看到，这样的约束并不是百分之百正确的，这也就是作者们希望用“软逻辑关系”来进行约束的原因，因为这其实也是一个概率的问题。</p>
<p><strong>整个提出的模型最终是一个集大成的优化目标函数，也就是最开始的物品的综合表征，在特定的关系下的投影的学习，以及最后的软逻辑关系的学习，这三个组件共同组成了最后的优化目标。</strong></p>
<h2>方法的实验效果</h2>
<p>这篇文章使用了京东商城的五大类商品来做实验，商品的综述大大超过之前亚马逊的一个公开数据的数量。作者重点比较了之前的一个来自加州大学圣地亚哥团队的模型，以及几个矩阵分解的经典模型，还比较了一个基于协同过滤的模型。</p>
<p>从总的效果上来看，这篇文章提出的模型不管是在关系预测的子任务上，还是在最后的排序任务上均要大幅度地好于其他模型。同时，作者们也展示了逻辑关系的确能够帮助目标函数把替代关系和互补关系的商品区分开来。</p>
<h2>小结</h2>
<p>今天我为你讲了WSDM 2018年的一篇来自京东数据科学团队的文章，这篇文章介绍了如何利用多关系学习以及模糊逻辑来挖掘商品的替代信息和互补信息，然后训练出更加有效的排序算法。</p>
<p>一起来回顾下要点：第一，我们简要介绍了这篇文章的作者群信息；第二，我们详细介绍了这篇文章要解决的问题以及贡献 ；第三，我们简要地介绍了文章提出方法的核心内容以及实验的结果。</p>
<p>最后，给你留一个思考题，互补商品或者替代商品是双向关系还是单向关系，为什么呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor15">015 | WSDM 2018论文精读：深度学习模型中如何使用上下文信息？<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>今天，我们继续来精读WSDM 2018的一篇论文《隐含交叉：在循环推荐系统中利用上下文信息》（Latent Cross: Making Use of Context in Recurrent Recommender Systems）。这篇文章同样出自谷歌团队，其核心思想是希望通过深度模型来模拟并实现在推荐系统中广泛使用的“交叉特征”（Cross Feature）的效果。</p>
<h2>作者群信息介绍</h2>
<p>这篇论文的所有作者都来自谷歌，我们这里对其中的主要作者做一个简单介绍。</p>
<p>文章的第一作者亚力克斯·布伦特（Alex Beutel）是谷歌的资深科学家，于2016年加入谷歌。布伦特毕业于卡内基梅隆大学，获得计算机科学博士学位，师从机器学习的权威亚力克斯·斯莫拉（Alex Smola）。</p>
<p>最后一位作者艾德·池（Ed H. Chi）是谷歌的主任科学家，他拥有39项专利，已经发表了110多篇论文。在加入谷歌之前，池是帕罗奥图（Palo Alto）研究中心的主任研究员。池毕业于明尼苏达大学，获得计算机科学博士学位。</p>
<h2>论文的主要贡献</h2>
<p>我们首先来看这篇文章的主要贡献，梳理文章主要解决了一个什么场景下的问题。</p>
<p>推荐系统经常需要对当下的场景进行建模，有时候，这些场景被称作“<strong>上下文</strong>”（Context）。在过去比较传统的方法中，已经有不少方法是探讨如何利用上下文信息进行推荐的，比如使用“张量”（Tensor）的形式进行建模；还有一些方法是利用对时间特性的把握，从而对上下文信息进行处理。</p>
<p>近些年，随着深度学习的发展，越来越多的深度学习模型被应用到推荐系统领域中，但还没有直接探究如何在深度学习模型中使用上下文。这篇文章就想在这一方面做一个尝试。</p>
<p>这里面有一个比较棘手的问题。过去，这样的上下文常常使用“<strong>交叉特性</strong>”，也就是两个特征的乘积成为一个新的特征。这样的方法在矩阵分解或者张量分解的模型中得到了非常广泛的使用。然而在深度学习中，过去的经验是不直接使用这样的特性。但是，在上下文非常重要的推荐系统中，不使用交叉特性的的结果，往往就是效果不尽如人意。</p>
<p>这篇文章提出了一个叫“隐含交叉”（<strong><span class="orange">Latent Cross</span></strong>）的概念，直接作用在嵌入（Embedding）这一层，从而能够在深度模型的架构上模拟出“交叉特性”的效果。</p>
<!-- [[[read_end]]] -->
<h2>论文的核心方法</h2>
<p>作者们首先探讨了推荐系统中一个常见的特性，那就是利用交叉特性来达到一个“<strong>低维</strong>”（Low-Rank）的表达方式，这是矩阵分解的一个基本假设。比如每一个评分（Rating）都可以表达成一个用户向量和物品向量的点积。</p>
<p>那么，作者们就提出了这样一个问题：作为深度学习的基石，<strong>前馈神经网络</strong>（Feedforward Neural Network）是否能够很好地模拟这个结构呢？</p>
<p>通过模拟和小规模实验，作者们从经验上验证了深度学习的模型其实并不能很好地抓住这样的交叉特性所带来的“低维”表达。实际上，深度学习模型必须依赖更多的层数和更宽的层数，才能得到相同的交叉特性所达到的效果。对于这一点我们或多或少会感到一些意外。同时，作者们在传统的RNN上也作了相应的比较，这里就不复述了。</p>
<p>得到了这样的结果之后，作者们提出了一个叫作“隐含交叉”的功能。这个功能其实非常直观。传统的深度学习建模，是把多种不同的信息输入直接拼接在一起。“隐含交叉”是<strong>让当前的普通输入特性和上下文信息进行乘积，从而直接对“交叉特性”进行建模</strong>。</p>
<p>这样做的好处是不言而喻的。之前，我们寄希望于深度学习模型自身能够学习到这样的交叉关系。而现在，作者们直接让上下文信息作用于输入信息和其他的中间特征，使得上下文信息的作用得到了提升。</p>
<p>这篇文章提出的办法可以说是第一个尝试解决传统推荐系统的一些想法，使之移植到深度学习的语境中。</p>
<h2>方法的实验效果</h2>
<p>这篇文章使用了谷歌的Youtube数据来做实验。作者们比较了一系列的方法，得出的结论是RNN配合“隐含交叉”比仅仅使用RNN的效果要好2%~3%，这个提升已经是一个非常可观的数字了。</p>
<h2>小结</h2>
<p>今天我为你讲了WSDM 2018的一篇来自谷歌团队的文章，这篇文章介绍了在传统推荐系统的模型中（比如矩阵分解等）都有的交叉特性如何应用在深度学习中。</p>
<p>一起来回顾下要点：第一，我们简要介绍了这篇文章的作者群信息；第二，我们详细介绍了这篇文章要解决的问题以及贡献 ；第三，我们分析了文章提出方法的核心内容以及实验结果。</p>
<p>最后，给你留一个思考题，深度学习模型在默认状态下并不能很好地抓住交叉特性，这是深度模型的问题吗？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor16">016 | The Web 2018论文精读：如何对商品的图片美感进行建模？<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>“万维网大会”（The Web Conference 2018）前身叫作“国际万维网大会”（International World Wide Web Conference），从1994年开始举办，已有20多年的历史了，在Google学术排名上，是“信息系统”排名第一的国际顶级学术会议。</p>
<p>从万维网大会最初举办开始，这个会议就成为了互联网方面独一无二的权威学术会议。会议包含搜索、推荐、广告、数据库、信息提取、互联网安全等诸多领域的优秀论文，每年都吸引着上千名世界各地的学者和工程师来分享他们的最新研究成果。</p>
<p>2018年的万维网大会于4月23日~27日在法国里昂举行。整个会议收录了171篇论文，还有27个研讨班（Workshop）、19个讲座（Tutorial）、61个展板论文（Poster）和30个演示（Demo）。</p>
<p>万维网大会的一大特点就是论文成果涵盖了非常广的领域。要在这些论文中找到有价值的学习信息是一件非常耗时、很辛苦的任务。这里给你分享几篇我认为今年这个会议上最有价值的论文，希望能起到抛砖引玉的作用。</p>
<p>今天，我们就来看一篇优秀论文提名，题目是《基于美感的服装推荐》（<a href="https://www.comp.nus.edu.sg/~xiangnan/papers/www18-clothing-rec.pdf">Aesthetic-based Clothing Recommendation</a>）。这篇论文一共有六位作者，除了两位分别来自新加坡国立大学和美国的埃默里大学之外，绝大多数作者都来自清华大学。</p>
<h2>论文的主要贡献</h2>
<p>在现代的电商推荐系统中，商品特别是服装服饰的图片，其美观和质量是用户进行购买决策的关键参考因素。不少过去的商品推荐系统已经考虑了图片的属性，特别是尝试同时利用图片信息和文字信息来实现<strong>多模（Multi-Modal）数据理解</strong>的目的，从而能够进行更加智能的推荐。不过，当前的大多数方案都只是考虑基本的图片特性。</p>
<p>从思路上来说，大多数的类似工作都是利用某种深度神经网络提取图片特性，然后和其他特性（例如我们说过的文本信息）加以组合，从而能够扩宽我们对商品信息的提取。这样提取出来的图像特征自然没有显式地对图像的“美感”（Aesthetic）进行建模。</p>
<p>这篇文章的作者们认为，商品图片的“美感”是非常重要的属性，针对美感进行建模会有更显著的商品推荐效果。概括来说，这篇论文的一个贡献就是提供了一种模型，来对图片的美感和一般性的图片语义特性同时进行建模。这是一个在过去的工作中都没有的创新点，我们接下来会详细说明一这个模型的架构。</p>
<p>当作者们提取出了图片的美感信息以后，接下来的一个问题就是如何利用这些特性。这篇论文使用了<strong>张量分解</strong>（Tensor Factorization）的思路。我们在前面介绍推荐系统的时候曾经提到过，张量分解是一种很有效且常用的<strong>利用上下文语义信息</strong>的推荐模型。和一些之前的工作类似，这里作者们采用了三维的张量来表达用户、商品和时间之间的关系。同时，作者们还把图片信息有效地结合到了张量分解中，从而能够利用美感信息来影响推荐结果。</p>
<h2>论文的核心方法</h2>
<p>了解了这篇论文的大体思路以后，我们现在来看看论文的第一个核心部件：<strong>如何利用深度神经网络来提取图片的美感信息？</strong></p>
<!-- [[[read_end]]] -->
<p>首先，这篇论文提出的模型假设对于每一个商品，我们都有一个<strong>综合的美感标签</strong>，并且还有一个<strong>细节标签</strong>来表达这个商品图案的“<strong>图像风格</strong>”（Style）。美感的综合标签是一个1~10的打分，而图像风格则是文字的图像特征，比如“高曝光”、“对比色”等。那么，我们需要一个神经网络模型，来同时对美感标签和细节的图像风格进行建模。</p>
<p>具体来说，文章提出的模型分为了两个层次。第一个层次是用来解释细节的图像风格。在本文采用的数据中，一共有14种图像风格，作者们就用了14个<strong>子网络</strong>（Sub Network）来针对这些风格。每个风格都对应一个独立的<strong>子神经网络</strong>。每一个子神经网络都是标准的“<strong>卷积网络</strong>”（CNN）。他们的目标是尽可能地学习到特性来表示每个细节的图像风格。</p>
<p>当我们有了第一层的14个子网络之后，再把这些子网络学习到的特性都整合起来，形成<strong>中间特性层</strong>，然后再经过一个卷积网络，从而学习到一个对商品的整体美感评分进行解释的神经网络。</p>
<p>在文章中，作者们提到这两个层次的神经网络并不是分类进行训练的，而是<strong>在一个整体中进行训练</strong>。意思就是说，我们同时训练底层的针对图像风格的14个子网络的参数，以及高层次的针对美感评分的网络的参数。</p>
<p>当我们得到了图片的美感信息之后，下一步，就来看一下<strong>如何利用张量分解来进行商品推荐</strong>。</p>
<p>相比于传统的张量分解，在这篇文章中，作者们提出了一种新颖的，针对商品推荐的张量表达模式，叫作“动态协同过滤”（Dynamic Collaborative Filtering），或简称 <strong>DCF</strong>。</p>
<p>DCF认为，每一个用户对于某个商品的购买取决于两个方面的因素。第一，用户是否对这个商品有喜好。第二，这个商品是不是符合时间维度上面的“流行度”。作者们认为，只有当这两个条件同时满足的时候，也就是用户喜欢某个当季的商品时才会做出购买的决定。因此，作者们使用了<strong>两个矩阵分解</strong>来分别代表这两个假设。</p>
<p>第一个矩阵分解是针对用户和商品这个矩阵，这里我们会学习到用户对商品的<strong>喜好度</strong>。第二个矩阵分解是针对时间和商品这个矩阵，这里我们会学习到时间和商品的<strong>流行度</strong>。然后，作者把这两个矩阵分解（或者说是把两个矩阵）相乘，这就得到了一个张量，来表达<strong>用户在时间维度上对商品的喜好</strong>。</p>
<p>那么，如何把刚才学习到的图片美感信息给融入到这个新的张量学习框架下呢？作者们是这么做的，针对我们刚才所说的两个矩阵分解进行“扩展”。</p>
<p>刚才我们说，这个张量分解是基于一个假设，那就是用户在时间维度上的购买决定取决于，用户是否对这个商品有喜好，以及这个商品是不是符合时间维度上面的“流行度”。我们用了两个矩阵分解来表达这两个假设。每一个矩阵分解都是把一个大的矩阵分解成两个向量，比如用户和商品的矩阵就被分解为用户特性和商品特性。</p>
<p>基于此，作者们就在这个用户和商品的矩阵后面，再加上一个商品和图片美感信息矩阵，用来混合这两种信息。也就是说，我们刚才的第一个假设，用户对商品的好感，就被扩展成了<strong>两个矩阵的加和</strong>，用户和商品矩阵以及商品和图片信息矩阵，这两个矩阵的加和依然是一个矩阵。同理，时间和商品的流行度，被扩展成了时间和商品矩阵以及商品和图片信息矩阵的加和。也就是说，新的模型是两个矩阵的乘积组成的张量分解，而这里的每个矩阵分别又是两个矩阵的加和。这就是作者们最终提出的模型。</p>
<h2>方法的实验效果</h2>
<p>作者们在亚马逊的衣服数据集上做了实验来验证模型的有效性。这个亚马逊的数据集由将近四万的用户、两万多的商品和超过二十七万的购买信息构成。除了这篇文章提出的模型以外，作者们还比较了一些其他算法，例如完全随机的算法、只推荐最流行的商品、传统的矩阵分解模型以及只有基本图像信息但没有美感信息的算法。文章汇报了排序的精度NDCG以及“召回”（Recall）等指标。</p>
<p>从实验效果来看，这篇文章提出的模型要明显好于矩阵分解以及只有基本图像信息的算法，表明针对产品的图像美感进行建模是有价值的。并且，作者们提出的新的张量分解方法也被证明是切实有效的。</p>
<h2>小结</h2>
<p>今天我为你讲了今年万维网大会的一篇优秀论文。文章介绍了如何对商品的图片美感进行建模，以及如何把提取到的信息融入到一个基于张量分解的推荐系统中。</p>
<p>一起来回顾下要点：第一，我们详细介绍了这篇文章要解决的问题以及贡献；第二，我们简要地介绍了文章提出方法的核心内容；第三，我们简单分享了一下模型的实验成果。</p>
<p>最后，给你留一个思考题，有没有在没有标签情况下对图片的美感进行建模的呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor17">017 | The Web 2018论文精读：如何改进经典的推荐算法BPR？<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>今天，我们来看万维网大会上的一篇优秀短论文。在万维网大会上，主要发表两类论文。一类是10页的长论文，一类是2页的短论文或称作展板论文。短论文主要是发表短小的成果或者是还在研究过程中的重要成果。每一届的万维网大会，都会评选出一篇最佳短论文奖。</p>
<p>今天我和你分享的论文，题目是《利用查看数据，贝叶斯个性化排序的一种改进的取样器》（<a href="https://www.comp.nus.edu.sg/~xiangnan/papers/www18-improvedBPR.pdf">An Improved Sampler for Bayesian Personalized Ranking by Leveraging View Data</a>）。这篇论文也有六位作者，和我们介绍的上一篇论文一样，都来自清华大学和新加坡国立大学。</p>
<h2>贝叶斯个性化排序</h2>
<p>要想理解这篇论文的内容，我们必须要讲一下什么是“<strong>贝叶斯个性化排序</strong>”（Bayesian Personalized Ranking），或者简称是<strong>BPR</strong>。有关BPR的详细介绍，可以阅读参考文献[1]。我们在这里仅对BPR进行一个高维度的总结。</p>
<p>简单来说，<strong>BPR是推荐系统中的一个配对排序（Pairwise）学习算法</strong>。在我们前面介绍搜索算法的时候，曾经提到了各种配对排序学习算法。配对排序学习不是针对每一个数据实例来学习其标签或者响应变量，而是学习一个相对的顺序，希望能够把所有的正例都排列到负例之前。也就是说，对于配对排序来说，每一个数据实例的预测值本身并不重要，排序算法在意的是对于一正一负的一个配对来说，是否能够把正例给准确地排列到负例之上。这其实就要求BPR在数值上对正例的预测值能够比负例的预测值高。</p>
<p>BPR主要是解决了在推荐系统中长期以来只对单个数据点进行预测，比如需要对用户物品的喜好矩阵建模的时候，之前的大多数算法都无法有效地对没有观测到的数据进行建模。而BPR是配对算法，因此我们只需要关注观测的数据以及他们之间的关系，从而能够对用户的喜好，特别是有“<strong>隐反馈</strong>”（Implicit Feedback）数据的时候，取得更加明显的效果。这里的隐反馈指的并不是用户告诉系统其对每一个物品的喜好程度，而是用户在和系统的交互过程中通过一些行为表达出的喜好。这些用户的行为往往并不全面，因此需要算法和模型能够对这些行为进行有效建模。</p>
<h2>论文的主要贡献和核心方法</h2>
<p>了解了BPR大概是怎么回事以后，我们来看一看这篇论文的主要贡献和核心方法。</p>
<!-- [[[read_end]]] -->
<p>首先我们刚才讲到BPR的核心是学习一个配对的排序问题。那么在训练的时候，我们需要对一个正例和一个负例的配对进行学习，更新参数。然而在一个自然的用户隐反馈数据集里，正例相对来说往往是少数，负例则是绝大多数。因此，一个传统的方法就是在组成一个配对的时候，相对于一个正例来说，我们都“均匀地”（Uniformly）选取负样本来组成配对，这个过程有时候也叫“采样”（Sampling）。</p>
<p>这篇论文有两个主要贡献。第一个贡献是，作者们发现，如果在全局均匀地采样负样本，第一没有必要，第二可能反而会影响最后学习的效果。第二个贡献是，针对电子商务的应用，作者们发明了一种负样本采样的方法，使得学习算法可以利用到更多的用户“浏览”（View）信息，从而能够对算法的整体训练效果有大幅度的提升。</p>
<h2>方法的实验效果</h2>
<p>这篇论文的数据集分别使用了母婴产品“贝贝网”和天猫的数据。其中，贝贝网有约16万用户、12万商品、260万次购买和4600万次浏览；天猫的数据则有3万用户、3万多商品、46万次购买和150多万次浏览。两个数据集都呈现了大于99%的“稀疏度”（Sparsity）。</p>
<p>首先，作者们实验了不从全局中选取负样本而仅仅采样一部分，而且是相比于原来的空间非常小的样本，比如仅仅几百个负样本而不是几万个的情况。实验效果在贝贝网上不仅没有影响算法的精确度，算法的精确度反而还有提升。而在天猫的数据集上，算法效果没有提升，而有一些小幅度的下降，但是作者们认为这样的代价还是值得的，因为数据集的减少，算法的训练时间会大幅度降低。从这个实验中，作者们得出了不需要从全局进行采样的结论。</p>
<p>紧接着，作者们提出了一个新的概念，那就是，对用户的数据集合进行划分，把用户的行为分为“购买集”（C1）、“浏览但没有购买集”（C2）、“剩下的数据”（C3）这三个集合。作者们提出，BPR要想能够达到最好的效果，需要对这三种数据集进行采样。也就是说，我们需要组成C1和C2、C1和C3以及C2和C3的配对来学习。</p>
<p>具体来说，用户在贝贝网和天猫的数据中尝试了不同的比例来对这三种集合进行采样。总体的经验都是C3中采样的数据要大于C2中的，然后要大于C1中的。这其实就是说训练算法要更好地学习到用户不喜欢某件东西的偏好。采用这样的采样方式，作者们展示了模型的效果比传统的BPR或仅仅使用“最流行的物品”作为推荐结果要好60%左右。</p>
<h2>小结</h2>
<p>今天我为你讲了今年万维网大会的一篇优秀短论文。文章介绍了如何对一个经典的推荐算法BPR进行改进，从而提高效率并且大幅度提升算法有效度。</p>
<p>一起来回顾下要点：第一，我们从高维度介绍了BPR的含义；第二，我们简要介绍了论文的主要贡献和思路；第三，我们简单分享了论文的实验成果。</p>
<p>最后，给你留一个思考题，除了这篇论文提出的组成正例和负例的配对思路以外，你能不能想到在用户浏览网站的时候，还有哪些信息可以帮助我们组成更多的配对呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p><strong><span class="reference">参考文献</span></strong></p>
<p><span class="reference">1.  Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. BPR: Bayesian personalized ranking from implicit feedback. Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence (UAI '09). AUAI Press, Arlington, Virginia, United States, 452-461, 2009.</span></p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor18">018 | The Web 2018论文精读：如何从文本中提取高元关系？<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>今天我们来看万维网大会2018的最佳论文，标题是“HighLife: Higher-arity Fact Harvesting”。作者都来自德国著名的“马克斯·普朗克计算机科学研究所”（Max Plank Institute for Informatics）。这个研究所是德国最大的基础科学研究组织“马克斯·普朗克学会”（Max-Planck-Gesellschaft）的分支研究机构，致力于在科学刊物上发表新的研究成果，开发软件系统和培养新的科学研究工作者。马克斯·普朗克学会因其杰出的科研成果在德国甚至全世界都获得了很高的声誉。</p>
<h2>什么是高元关系？</h2>
<p>这篇论文主要是涉及到<strong><span class="orange">高元（Higher-Artiy）关系</span></strong>的提取。那什么是高元关系呢？</p>
<p>传统的信息提取和知识库主要是关注二元关系的提取和存储。例如，我们可以知道居里夫人分别于1903年和1911年获得了诺贝尔奖。但是关系数据库中并不知道这两年的奖项分别是物理和化学。同理，我们可以在知识库中存放居里夫人获得过诺贝尔物理奖以及诺贝尔化学奖的信息，但是就无法和1903年和1911年这两个信息进行配对。通过这个例子我们可以看出，基于二元关系的信息提取和知识库虽然简单易行，但是有其先天的局限性。</p>
<p>这篇论文要讨论的高元关系，就是希望能够直接对“居里夫人在1903年获得了诺贝尔物理学奖”这样的三元甚至更高元的关系进行提取和表征。作者们认为这篇论文是较少的关注高元关系提取的先驱工作。</p>
<h2>论文的主要贡献</h2>
<!-- [[[read_end]]] -->
<p>我们刚才说了，这篇论文的一个重要贡献就是针对高元关系的提取所作出了很多努力。</p>
<p>具体来说，作者们使用“<strong>种子事实</strong>”（Seed Facts）作为一种监督信息来学习<strong>模式</strong>（Patterns），并且利用这些学习到的模式来寻找更多的“<strong>候选事实</strong>”（Facts Candidates），如此循环。这是把过去的一种针对二元关系提取的方法给扩展到高元关系。这个方法的潜在问题是：在能够保证“高召回”（High Recall）的情况下，得到的很多关系可能存在“<strong>噪声</strong>”和“<strong>目标浮动</strong>”（Target Drifts）。这里所说的目标浮动指的是我们提取的事实有可能存在主题上的偏差。</p>
<p>为了解决这个问题，作者们在这篇论文里利用了“<strong>限制推理</strong>”（Constraint Reasoning），来对已经得到的事实进一步筛选以得到最后的结果。这里的限制可以是“类型”（Type）上的，比如，我们限制提取到的普利策奖为“书籍”而非“电影”或“音乐”。通过这些在取值或者类型上的限制，我们可以对获取到的事实进行清理。</p>
<p>论文解决的另外一个难点就是很多高元信息在原始的文本中就是缺失的，或者是不完全的。比如，“Google于2014年收购了Nest”这个事实就没有提及金额，而“Google以32亿美元收购了Nest”这个事实又没有提及时间。作者们针对这个情况，把整个框架给扩展到了缺失信息中，从而能够从原始文本中拼凑多元关系。</p>
<h2>论文的核心方法</h2>
<p>文章提出了一个由好几个组件组成的系统用于信息的提取。</p>
<p>首先，有一个叫作 <strong>NERD</strong>的组件，即“人名识别和去歧义”组件，用于从句子中提取不同的“实体”。这里面运用到了很多外部的信息库，比如医疗生物实体库“联合医疗语言系统”（Unified Medical Language System）、支持新闻实体的AIDA系统以及WordNet语料库。同时，在这个部分，NERD还依赖于“斯坦福自然语言处理核心库”（Stanford CoreNLP）提供“人名识别”以及“词类分析”（Part of Speech）等基础功能。</p>
<p>在提取了人名和实体名之后，作者们就开始构建一个从词类分析得到的<strong>树型数据结构</strong>。这个数据结构的目的是反映N元关系和内部信息的架构。这个部分基本上也是依赖传统的自然语言处理所得到的树结构，只不过进行了简单的修正。</p>
<p>得到树结构之后，接下来的一系列工作都是<strong>在这个树结构上获取不同的模式，从而能够得到想要的高元关系</strong>。这里面有很多细节，我们在这里就不赘述了。比如，作者们利用“<strong>树挖掘</strong>”（Tree Mining）技术来发现频繁出现的子树结构，从而认定某个子树模式是不是一个好的候选事实。这里的思路其实和经典的“<strong>频繁模式挖掘</strong>”（Frequent Pattern Mining）一样，都是去不断地计算一个结构的“<strong>支持度</strong>”（Support）和“<strong>置信度</strong>”（Confidence），从而通过两个值来决定是不是要把这个模式给留下来。</p>
<p>除此以外，这一部分的部件还需要支持“<strong>部分N元候选事实</strong>”（Partial N-ary Fact Candidate）的匹配。之前我们也讲过了，这个功能也算是这篇论文的一个贡献。这里面的重要职能就是能够对树的一部分结构进行匹配，而不需要对所有的部分都能够完全一致。</p>
<p>当作者们通过树挖掘从而发现了基本的候选事实之后，下面需要做的工作就是针对这些候选事实进行推理盘查，看是不是所有的事实都能经得住推敲。也就是说，我们需要查看有没有存在多个事实不一致的地方。</p>
<p>需要指出的是，从整体上来看，所有组件的流程基本上都是<strong>无监督的数据挖掘操作</strong>。也就是说，整个系统并不需要依赖于什么训练数据。</p>
<h2>方法的实验效果</h2>
<p>作者们在纽约时报数据集以及PubMed数据集上都进行了实验，主要观测的指标是“<strong>精度</strong>”（Precision）。我们之前提到过，这篇文章所研究的高元关系提取，这个问题很新颖。因此，作者们还利用CrowdFlower众包平台来获取了数据的标签，用于检测所提取关系的准确度。当然这部分数据量相对来说是比较小的。</p>
<p>从实验的效果上来说，文章提出的方法能够达到平均接近80%~90%的精度，这可以说是非常令人振奋的结果了，而达到这样的结果仅仅需要几百个种子事实。</p>
<h2>小结</h2>
<p>今天我为你讲了今年万维网大会的优秀论文。文章介绍了如何从文本中提取高元关系，这是一个比较新的研究领域。</p>
<p>一起来回顾下要点：第一，我们简单讨论了高元关系的含义；第二，我们重点介绍了论文的主要贡献和核心思路；第三，我们简单分享了提出方法的实验成果。</p>
<p>最后，给你留一个思考题，在什么样的应用中，我们可以利用到这篇文章提出的高元关系？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor19">019 | SIGIR 2018论文精读：偏差和“流行度”之间的关系<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>2018年的SIGIR（国际信息检索研究与发展大会）于7月8日~12日在美国密歇根州的安娜堡举行。从今天开始，我将精选几篇大会上最有价值的论文，和你一起来读。</p><p>我先简单介绍一下这个大会。SIGIR从1978年开始举办，有40年的历史，是信息检索和搜索领域的顶级会议。SIGIR 2018，全称是The 41st International ACM SIGIR Conference on Research and Development in Information Retrieval。</p><p>从最初举办开始，这个会议就成为了信息检索领域，特别是搜索技术和推荐技术方面的权威学术会议。会议的内容往往包含了搜索、推荐、广告、信息提取、互联网数据挖掘等诸多领域的优秀论文，每年都吸引着来自世界各地的学者和工程师参会，来分享他们最新的研究成果。</p><p>今天，我们首先来看一看今年的最佳论文，标题是《推荐系统中流行度有效性的概率分析》（<a href="http://ir.ii.uam.es/pubs/sigir2018.pdf">Should I Follow the Crowd? A Probabilistic Analysis of the Effectiveness of Popularity in Recommender Systems</a>）。</p><p>这篇论文一共有两位作者，均来自马德里自治大学（Universidad Autónoma de Madrid）。第一作者罗西奥·卡纳马雷斯（Rocio Cañamares）已经发表了好几篇相关主题的论文，第二作者帕布罗·卡斯蒂罗斯（Pablo Castells）是马德里自治大学、甚至是整个欧洲的信息检索学术权威。论文有超过5千次的引用。</p><!-- [[[read_end]]] --><h2>论文的主要贡献</h2><p>想要理解清楚这篇论文的主要贡献，我们首先要从推荐系统，或者是从更大的方向上，来看所有信息检索系统都存在的一个核心问题，那就是“<strong>偏差</strong>”（Bias）。偏差会带来一系列问题。这对推荐系统甚至信息检索系统的建模和评价都带来了巨大的挑战。</p><p>那么，为什么信息检索系统会有偏差呢？</p><p>我这里举一个简单的例子来说明。假设我们有两个物品和很多用户。对于每一个用户来说，系统都按照随机的顺序，分别给用户展示这两个物品，并且询问用户是否喜欢。</p><p>在这样的假设里，顺序是随机的，因此对于同一个用户来说，用户是否喜欢某一个商品，就完全是取决于这个物品本身的属性。对于所有用户来说，在整体上呈现的用户对这两个物品的喜好，则完全来自于大家对这两个物品本身的一种评价。那么，我们可以看到这里面没有任何的偏差。</p><p>然而，只要这个场景稍微有一些改变，就很容易引入各种偏差。比如，我们有超过一万件物品。尽管我们还是随机地展示给用户，但用户可能在看过一定数量的物品之后就慢慢厌倦了，那么，用户对于物品的喜好判断或许就会受到厌倦的影响，甚至，用户还很有可能直接放弃查看后面的物品。</p><p>还有很多相似的情况，比如我们不是把每个商品逐一展示给用户看，而是提供一个列表。那么，用户很有可能会以为这个列表有一定的顺序，比如在列表排名上方的物品可能是比较重要的。有研究表明，在有列表的情况下，用户很可能会按照列表的顺序提供某种喜好判断。很明显，在这样的情况下，用户的喜好判断就受到了这个列表顺序的干扰。</p><p>上面我们提到的都是“<strong>表现偏差</strong>”（Presentation Bias）。除此以外，一个信息系统其实还有很多类型的偏差，比如<strong>系统性偏差</strong>：一个新闻系统，只给用户推荐娱乐新闻，而不给用户看时政新闻，在这样的情况下，用户表现出来的喜好性就是有偏差的，因为系统没有给用户表达对时政新闻喜好的可能性。</p><p>信息检索和推荐系统的学者其实很早就意识到了偏差对于建模的影响。不管是我们这里提到的表现偏差还是系统性偏差，如果我们直接利用用户和系统交互产生的数据，那么训练出来的模型以及我们采用的衡量模型的办法也会有偏差，那我们得出的结论有可能就是不精准的。</p><p>这篇论文就是希望能够<strong>系统性地讨论偏差在推荐系统中所带来的问题</strong>。具体来说，这篇论文主要是探讨偏差和“<strong>流行度</strong>”（Popularity）之间的关系。</p><p>这里描述的是这样一种情况：有一些物品很有可能曾经给很多人推荐过，或者同时还被很多人喜欢过或者评价过，那么，这种流行度高的物品会不会对推荐结果的评价带来意想不到的偏差呢？</p><p>在过去的研究中，大家只是对这种流行度高的物品有一种直观上的怀疑，认为如果一个推荐系统仅仅能够推荐流行的物品，那肯定是有偏差的。但之前的很多工作并没有定量地去解释这里面偏差和评价之间的关系。<strong>这篇论文就提供了一个理论框架，指导我们去理解偏差以及偏差带来的评测指标的一些变化</strong>。</p><h2>论文的核心方法</h2><p>今天我们不去讲这篇论文的理论框架细节，我会重点提供一个大体的思路，帮助你理解这篇论文希望达到的目的。</p><p>简单来说，为了表达偏差和流行度之间的关系，作者们用了这么几个<strong>随机变量</strong>：用户是否对某个物品打分，用户是否对某个物品有喜好，以及用户是否观看某个物品。这里面的一个细节，或者说技巧，就是如何用概率的语言把这三者之间的关系给表达清楚。</p><p>作者其实采用了一些简化的假设，比如假设在测试集上的物品是训练集上没有出现过的等等。这样，就能够写出在测试集上用户对物品评价的一个<strong>期望关系</strong>，这个期望关系包含用户对所有测试物品是否有喜好。有了这层期望关系以后，就开始推导出，在测试集上<strong>理想状态下的最佳排序是一个什么样子</strong>。在这里的理论讨论其实并没有很大的现实意义，但是这是第一次研究人员用数学模型去详细表征一个最优的在测试集上的按照流行度排序的结论。</p><p>紧接着，作者们还讨论了这个最优排序在两种极端情况下的变化。一种情况是用户过往的行为都是仅依赖于物品本身的属性，而没有任何其他偏差。另外一种情况是用户过往的行为和物品本身的属性无关，意思就是仅依赖于其他的偏差。</p><p>在第一种极端情况下，最优的排序其实也就是我们所能观测到的最优排序，那就是按照物品的流行度。在第二种极端情况下，最优的排序其实是<strong>按照平均打分</strong>。</p><p>当然，你可能会说讨论这两种极端情况并没有现实意义呀。但这两种极端情况的讨论其实就证明了，<strong>只有在没有偏差的情况下，按照物品的流行度排序才是平均情况下最优的</strong>。而很明显，现实存在偏差，因此依靠流行度的排序，即便是平均情况下，也不是最优的选择。</p><p>然后，论文讨论了用户是否观看某一个物品对用户行为的影响。关于这一部分的讨论，其实之前已经有很多工作都做了一些类似的探索。不过这篇论文得出了一个有意思的结论。在考虑了用户观看物品的偏差以后，通过模拟的方法，我们会发现：<strong>随机结果的效果其实要比之前的观测值要好很多，而按照流行度的排序虽然不错，但是比随机的效果并没有好很多，而基于平均打分的结果其实要优于按照流行度的排序</strong>。可以说，这是一个有别于之前很多工作的新发现。</p><h2>延申讨论</h2><p>虽然这篇论文获得了SIGIR 2018的最佳论文奖，但是如果我们站在更大的角度上来分析这篇论文，其实就会发现，作实际上作者们是开发了一套特有的理论框架来描述推荐系统中的某一种偏差。<strong>更加普适化的对偏差的建模其实需要有随机化的数据，以及利用因果推断的办法来对任意情况下的偏差进行分析</strong>。文章提出的概率模型仅仅在这篇文章讨论的假设情况下才能成立。</p><p>当然，瑕不掩瑜，这篇文章不管是从结论上，还是从实际的分析过程中，都为我们提供了很多有意义的内容，帮我们去思考偏差对于建模所带来的挑战以及我们应该如何应对。</p><h2>总结</h2><p>今天我为你讲了今年SIGIR 2018的最佳论文。</p><p>一起来回顾下要点：第一，我们详细介绍了这篇文章要解决的问题和贡献，探讨偏差和流行度之间的关系，系统性地来讨论偏差在推荐系统中所带来的问题；第二，我们简要地介绍了文章提出方法的核心内容，包括设定随机变量、期望关系以及推导理想状态下的最佳排序；第三，针对论文我们简单进行了讨论。</p><p>最后，给你留一个思考题，在不考虑偏差的情况下，为什么一般的推荐系统会偏好于推荐流行物品的算法呢？</p><p>欢迎你给我留言，和我一起讨论。</p><p></p>
</div>
</div>

<div class="outline-2">
<h2 id="anchor20">020 | SIGIR 2018论文精读：如何利用对抗学习来增强排序模型的普适性？<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>今天，我们继续来精读SIGIR 2018（国际信息检索研究与发展大会）的论文，今天分享的是本次大会的最佳短论文，标题是《使用对抗学习实现神经排序模型的跨领域正则化》（<a href="https://arxiv.org/pdf/1805.03403.pdf">Cross Domain Regularization for Neural Ranking Models using Adversarial Learning</a>）。</p><p>非常有必要先简单介绍一下这篇文章的作者群，可以说这是一个“明星阵容”。</p><p>第一作者丹尼尔·科恩（Daniel Cohen）来自马萨诸塞大学阿默斯特分校（University of Massachusetts Amherst），是计算机科学系的博士生。2017年曾经在微软研究院剑桥分部实习。这篇获奖论文就是实习项目的总结。在深度学习模型在信息检索的应用这个方向上，科恩已经发表了多篇论文。</p><p>第二作者巴斯卡·米特拉（Bhaskar Mitra）是微软研究院剑桥分部的主任级科学家。近些年米特拉在信息检索领域很活跃，并且极力推动深度学习在这个领域的发展，他在这个领域发表了很多篇论文，在过去几年的很多学术会议上，也主持了多个关于深度学习和信息检索相结合的讲座。</p><p>第三作者卡特娜·霍夫曼（Katja Hofmann）也是来自微软研究院剑桥分部的科学家。霍夫曼在信息检索领域的主要贡献是研究在线排序学习。</p><!-- [[[read_end]]] --><p>论文的最后一位作者，布鲁斯·克罗夫特（W. Bruce Croft）是信息检索领域的学术权威，也是科恩的博士导师。他是美国ACM院士，还是信息检索领域最高学术荣誉奖杰拉德·索尔顿（Gerard Salton）奖的获得者。</p><h2>论文的主要贡献</h2><p>这篇论文主要涉及了这么两个重要概念的结合。第一个概念是“<strong>跨领域</strong>”（Cross Domain）信息检索，第二个概念就是“<strong>对抗学习</strong>”（Adversarial Learning）。</p><p>跨领域信息检索主要是指我们需要对一个以上的领域进行搜索。这里所说的领域主要是指不太相同，或者非常不同的文档集合。例如，如果我们要针对体育新闻、金融新闻等进行搜索，这里的“体育”和“金融”就是不同的领域。</p><p>跨领域信息检索的核心挑战是我们如何针对不同的领域都能进行有效搜索。比如，如果我们的排序算法本身或者其特性依赖于某个特定领域的信息，例如关于体育方面的搜索，需要依赖体育运动员的名字，那这种信息肯定会很少甚至完全不出现在另外一个领域。因此，<strong>依靠某些领域特有的信息很难做到真正的跨领域信息检索</strong>。</p><p>这篇文章的贡献是作者们认为，想要对跨领域的信息进行较好地检索，就<strong>需要训练这样的排序模型：不容易被某一个特定的领域所主导，同时也尽量不偏好某一个特定领域的具体信息</strong>。</p><p>如何实现这个目的呢？作者们使用了一种叫做“<strong>对抗学习</strong>”的技术。这也是这篇论文能够获奖的重要原因。</p><p>我在这里简单介绍一下对抗学习的原理。对抗学习最初的思想来自于利用深度产生模型解决计算机视觉中的一系列问题。最基本的对抗学习的模式主要是用于产生数据，而且是比较复杂的数据，例如图像。</p><p><strong>对抗学习有两个模块，一个模块叫产生器，一个模块叫判别器</strong>。产生器的作用就是产生数据。判别器的作用是判断产生的数据是不是“真实数据”。产生器的最终目的是产生能够以假乱真的数据来扰乱判别器的判断能力。判别器的最终目的是不断提高判断能力从而能够分辨出数据的真假。</p><p>当然，最初的时候，产生器产生数据来源于随机噪声，因此判别器可以很容易地判断数据的真假。但是慢慢的，产生器产生的数据就会越来越接近真实数据，而判别器也很快在这个过程中得到优化，从而能够判别数据的真假。当然，这是一个动态的过程，最终，判别器和产生器的状态会稳定下来。</p><p>对抗学习这种思想最初被提出来的时候，主要是应用在计算机视觉领域中，用来产生以假乱真的图片。之后，这种技术被广泛应用到人工智能的各个领域。</p><p>这篇论文最大的一个贡献，就是<strong>利用了对抗学习的理念来增强学习到的排序模型的普适性</strong>，从而尽量避免学习到仅仅对一个领域有用的信息。</p><h2>论文的核心方法</h2><p>具体来说，这篇文章提出了这样一种方法。首先，我们有两套模型，一套是用于学习查询关键词和文档之间的相关关系的；一套是对抗学习的模型。然后，这两套模型的首要任务是更加精准地针对相关的文档和不相关的文档进行建模。这是整个框架里最主要的目标函数。</p><p>文章提出框架中新的模块是<strong>利用对抗学习来分别产生相关的和不相关的文档</strong>。具体来说，某一种类型的文档就像我们刚才提到的图片一样，我们希望能够利用产生器来进行产生这类数据。当然，我们依然需要判别器来引导产生器的工作。</p><p>在这篇文章中，相关的概念主要是看一个文档是不是某一个领域的。也就是说，我们希望对抗学习能够帮助识别某一个文档是不是来自于一个领域。当对抗学习模型被训练好的时候，对于查询关键词和文档的相关模型，我们就会利用一种叫做“<strong>梯度反转</strong>”的技术，强行偏离模型希望去拟合某一个领域的倾向。</p><p>从网络结构上看文章提出的模型，查询关键词和文档都需要经过<strong>卷积层</strong>、<strong>提取层等变换</strong>，然后进行俗称的“<strong>哈达马积</strong>”（Hadamard product），其实就是<strong>对应项乘积</strong>。这样，文档和查询关键词所提取出来的隐含特征就结合在一起。这个结果之后又经过一系列<strong>稠密层的变换</strong>，最终预测一个相关度的标签。对于对抗学习模型来说，对抗中的判别器从刚才所说的架构中提取一些中间层作为输入，然后判断这个文档是不是出现在某个领域中。</p><h2>实验结果</h2><p>在一个雅虎的搜索数据集以及另外两个数据集上，作者们对论文所提出的模型进行了实验。实验主要是看如果我们在某一个领域上训练出的模型，会不会在另外一个领域上表现优异。</p><p>一个不令人意外的结果是，如果我们在全部领域上进行训练数据，自然在所有的领域上效果都不错。当然，文章展示了，如果利用文章提出的方法，针对某一个领域，比如运动类文档，在训练的时候完全移除所有的文档，在测试集上依然有不错的表现。实验的结果比不进行对抗训练的效果要好5%以上。</p><h2>小结</h2><p>今天我为你讲了今年SIGIR上的最佳短论文。</p><p>一起来回顾下要点：第一，这篇论文主要涉及了两个概念，分别是跨领域信息检索和对抗学习，我们详细介绍了这篇文章的主要贡献，就是利用对抗学习的理念来增强所学排序模型的普适性；第二，我们简要地介绍了文章提出的方法核心内容，训练两套模型，利用对抗学习来分别产生相关的和不相关的文档；第三，我们简单介绍了论文的实验结果，进行对抗训练会有更好的效果。</p><p>最后，给你留一个思考题，除了使用对抗训练，你还能想到什么方法，能够比较好地学习到不属于某一个特定领域信息的排序模型？</p><p>欢迎你给我留言，和我一起讨论。</p><p></p>
</div>
</div>

<div class="outline-2">
<h2 id="anchor21">021 | SIGIR 2018论文精读：如何对搜索页面上的点击行为进行序列建模？<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>今天我们将继续来精读SIGIR 2018的论文。</p><p>我们已经分享了SIGIR 2018的最佳论文，介绍了如何对推荐系统中的偏差进行建模，从而能够利用这种对偏差的理解，来更加准确地对待基于流行度的推荐结果。周一我们分享了本次大会的最佳短论文，主要讲了如何利用对抗学习的技术来让学习的排序模型更加“健壮”，可以被应用到多个领域上。</p><p>今天我们分享的论文题目是《页面搜索的点击序列模型》（A Click Sequence Model for Web Search）。</p><p>文章的第一作者阿列克谢·博里索夫（Alexey Borisov）来自俄罗斯的搜索引擎Yandex，并且在阿姆斯特丹大学攻读博士学位。之前，他已经发表过了多篇关于“点击模型”（Click Model）和深度学习模型结合的论文。</p><p>文章的第二作者马丁·万德纳（Martijn Wardenaar）、第三作者伊雅·马尔科夫（Ilya Markov）和最后的作者马顿·德里克（Maarten de Rijke）也都来自阿姆斯特丹大学。其中，马顿是荷兰的计算机科学家，欧洲的信息检索学术权威，并且还是荷兰皇家科学院成员。</p><h2>论文的主要贡献</h2><p>我先对这篇论文的核心思想做一个提炼，就是利用深度学习模型，来对用户在搜索页面上的点击行为进行建模。</p><!-- [[[read_end]]] --><p>传统上，这种对用户在搜索页面上的点击行为进行建模的思路就是“<strong>点击模型</strong>”。从2000年开始，对点击模型的研究，就成为了信息检索以及搜索领域中一个非常活跃的课题。在最近10年的时间里，研究人员提出了几十种不同的点击模型。总体来说，不同的点击模型主要是对不同的用户行为进行编码，从而能够更加准确地对用户的点击行为进行预测。</p><p>在很多传统的点击模型中，为了简化模型，经常使用的一个假设是：针对每一个查询关键词，用户在搜索结果页只进行一次点击。在这种简化了的假设下，研究人员对用户的浏览、点击以及页面的偏差（例如位置偏差）进行建模，就会变得更加容易。然而，在很多场景中，这种假设就显得过于简化了。在同一个查询关键词的搜索结果页面下，很多用户都会点击多个结果。因此，对于多个点击结果的建模就变得重要起来。</p><p>这篇论文就是<strong>针对用户在搜索页面上的点击行为进行了序列建模</strong>，使得我们可以轻松地对每一个搜索页面进行预测，比如会有多少点击以及在什么位置点击等。</p><p>同时，这篇论文还有一个贡献，就是<strong>利用了深度学习中的循环神经网络（RNN）来对查询关键词的结果进行建模，扩宽了传统的完全基于概率建模的点击模型在深度学习时代下的表现力</strong>。</p><h2>论文的核心方法</h2><p>论文提出方法的核心思路是针对每一个查询关键词，模型需要对所有可能的点击序列进行建模。这个任务是通过构建一个神经网络来完成的。</p><p>具体来说，文章提出的模型有两个重要的模块，<strong>编码器</strong>（Encoder）和<strong>解码器</strong>（Decoder）。</p><p>编码器的作用是利用查询关键词和搜索结果为输入，生成它们的“<strong>嵌入向量</strong>”（Embedding Vector）。近年来，嵌入向量是深度学习建模中的一个重要技术手段，它的目的往往是先把一些离散变量信息转化为连续信息。在这里，查询关键词和搜索结果都可以首先表征为离散的输入信息，然后需要映射到一个共同的语义空间。这可以被认为是一个中间结果，或者在概率模型中，这往往被认为是一个隐含变量。</p><p>解码器的作用是根据这个中间的嵌入向量表达下的查询关键词和搜索结果，然后决定在哪一个位置上可能会或者不会发生点击。这其实就是一个<strong>多类的分类问题</strong>。那么，怎么才能让解码器终止在某一个状态呢？作者们引入了一个特殊的符号代表序列的终止。这样，解码器也需要预测是否需要终止。类似的对解码器的操作在深度序列建模中十分常见。</p><p>可以说，作者们在设计编码器和解码器的结构上也是费了一番功夫的。</p><p>对于编码器而言，作者们认为一个好的嵌入向量必须包含当前的结果信息，以及当前结果周围的结果，或者说是上下文的信息，以及查询关键词的信息。这样，可以把每一个搜索结果都当做是一个独立的单元，有着足够丰富的信息来进行后面的建模。</p><p>因此，作者们首先把查询关键词和每一个搜索结果转换成为第一个层次的嵌入向量，组成一个大的第一层次的嵌入向量。然后，作者们利用这个第一层次的嵌入向量，并且引入了循环神经网络，来对当前结果前后的结果进行了两次编码，一次正向，一次逆向，从而形成了第二层次的嵌入向量。这个第二层次的嵌入向量就是最终表征每一个搜索结果的向量。</p><p>对于解码器而言，作者们利用了“<strong>关注</strong>”（Attention）机制来对每一个搜索结果施加不同的权重，或者说是关注度。每个时间点，也就是每一次做“是否要点击”的决策之后，都会重新生成一个关注向量，或者说是一组新的关注权重。这里的核心是一个<strong>循环神经网络</strong>，自己更新内部的状态变量，并且根据关注向量以及输入的嵌入向量，来预测下面一个点击的位置。</p><p>有了编码器和解码器之后，一个难点是<strong>如何生成最有可能的点击序列</strong>。我们刚才提到了，整个模型其实可以预测多种不同的点击序列。因此，<strong>生成最优可能的K个序列</strong>就成为了必要的一个步骤。在这篇文章里，作者们利用了“<strong>集束搜索</strong>”（Beam Search）的方法来近似生成最佳的K个序列，在文章中，K的值是1024。</p><p>模型的训练采用了标准的<strong>SGD</strong>以及<strong>Adam优化法</strong>，同时作者们还采用了“<strong>梯度裁剪</strong>”（Gradient Clipping）的方式来防止在优化过程中发生“爆炸问题”（Gradient Clipping）。</p><h2>实验结果</h2><p>作者们在Yandex，俄罗斯的搜索引擎数据上进行了实验。因为之前没有类似的模型，因此文章并没有可以直接比较的其他模型。作者们主要进行评估的地方是，看历史数据中已经发生的点击序列，会不会被正确预测出，会不会出现在K个模型认为最有可能发生的点击序列中。这也就是作者们为什么选择K等于1024的原因，因为在这种情况下，接近97%的历史序列都在模型的预测序列中。</p><p>作者们还评估了模型能否预测出总的点击次数等一系列和点击预测有关的任务，论文中提出的模型都能够以接近1的概率预测所有的点击，并击败一些过去的基于概率的点击模型。可以说，提出的模型的确可以对用户在搜索页面的点击行为进行有效的建模。</p><h2>小结</h2><p>今天我为你讲了今年SIGIR 2018的一个篇精彩论文。</p><p>一起来回顾下要点：第一，我们详细介绍了这篇文章要解决的问题以及贡献，主要是对用户在搜索页面上的点击行为进行序列建模；第二，我们简要介绍了文章提出方法的核心内容，主要是编码器和解码器两个模块；第三，我们简单介绍了论文的实验结果。</p><p>最后，给你留一个思考题，如果针对多个连续的查询关键词的点击行为进行建模，你能否用这篇论文提出的思路来扩展模型呢？</p><p>欢迎你给我留言，和我一起讨论。</p><p></p>
</div>
</div>

<div class="outline-2">
<h2 id="anchor22">022 | CVPR 2018论文精读：如何研究计算机视觉任务之间的关系？<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>今年6月18 日~22日，计算机视觉和模式识别大会CVPR（Conference on Computer Vision and Pattern Recognition），在美国的盐湖城举行。CVPR大会从1985年开始举办，已经有30多年的历史，是计算机视觉领域的顶级会议。</p><p>最近几年，CVPR大会发展成为了人工智能领域的盛会。受人工智能浪潮的影响，大会的投稿数量和参会人数都有了明显增加。大会今年共收到了3300份论文投稿，录取了979篇，录取率将近30%。最终，选出了70篇论文做口头报告，224篇论文做快速汇报。近两年的参会人数都保持着近1千人的增长势头，而今年更是达到了6千多人，是2014年参会人数的3倍多。同时，大会的审稿人也达到了惊人的1万人。</p><p>除了主会议以外，CVPR大会还组织了21个讲座，48个研讨班和博士论坛，有超过115家公司的赞助。</p><p>想要在这么多论文里找到最有价值、最有影响力的信息，可以说是大海捞针。我在这里为你精选了三篇今年CVPR的论文，希望能够起到抛砖引玉的作用。</p><p>今天，我们来分享大会的最佳论文，题目是——Taskonomy: Disentangling Task Transfer Learning。</p><!-- [[[read_end]]] --><p>我先来简单介绍下论文的作者群。</p><p>第一作者阿米尔·扎米尔（Amir R. Zamir）目前是斯坦福大学和加州大学伯克利分校的博士后研究员，已经在计算机视觉领域发表了30多篇论文，还获得过CVPR 2016的最佳学生论文奖。</p><p>第二作者亚历山大·萨克斯（Alexander Sax）刚刚从斯坦福大学计算机系硕士毕业，即将前往加州大学伯克利分校攻读博士，已经以硕士生的身份发表了两篇CVPR论文。</p><p>第三作者沈博魁刚从斯坦福大学计算机系本科毕业，即将在本校继续攻读博士。尽管是本科刚刚毕业，他已经发表了2篇CVPR论文和1篇ICCV论文。</p><p>第四作者利昂奈达·圭巴斯（Leonidas Guibas）是斯坦福大学计算机系教授，也是ACM和IEEE院士，还是美国工程院和科学院院士。他的博士导师是图灵奖获得者高德纳（Donald Knuth）。</p><p>第五作者吉腾德拉·马立克（Jitendra Malik）是加州大学伯克利分校计算机系教授，也是ACM和IEEE院士，并且是美国工程院以及科学院院士。马立克是计算机视觉方向的学术权威。</p><p>最后一位作者西尔维奥·萨瓦瑞斯（Silvio Savarese）是斯坦福大学计算机系的教授。他的研究方向是计算机视觉和计算机图形学。我们对华人学者李飞飞都很熟悉，萨瓦瑞斯是李飞飞的丈夫。</p><h2>论文的主要贡献</h2><p>概括来说，这篇论文主要是研究了计算机视觉任务之间的关系，并且提出了一个计算框架，能够定量地学习到这些任务之间的相似度。同时，这些相似的任务可以帮助数据较少的任务达到比较好的效果。这其实就是<strong>迁移学习</strong>（Transfer Learning）的核心思想：如何从已经学习到的任务或者领域迁移到数据较少、学习更加困难的任务或者领域。</p><p>很多研究人员在平时的研究过程中可能都会有这样的感觉，一些计算机视觉任务之间有某种逻辑或者直觉上的联系。例如，在计算机视觉界，像物体识别（Object Recognition）、景深估计（Depth Estimation）、边界发掘（Edge Detection）以及姿势估计（Pose Estimation）这些任务，大家都普遍认为它们是有关系的一系列任务。但是，有一些视觉任务之间的关系则显得没有那么直观，比如，边界发掘和光影（Shading）如何帮助姿势估计，就不得而知了。</p><p>如果我们单独来解决每一类任务，必然会有很大的挑战。这篇论文其实展示了，很多任务之间是有关联性的，而利用这些任务的关联性其实可以带来数据上的巨大便利。也就是说，我们可以利用更少的数据来学习到更多的任务。从这个角度来看，迁移学习也为新任务带来了希望，当我们没有大量的人工标注的数据时，依然能够在新任务上获得有效的结果。</p><p>这篇论文的另外一个重要贡献是提出了一个计算框架，这个框架并不需要事先准备的知识，比如人为地决定哪两个任务之间是有关联的，或者说，并不像之前的一些利用概率建模的方法，需要对任务之间的结构加以一个先验概率。<strong>这篇论文提出的框架完全从数据和结果的角度出发，从而避免了这些先验信息的不完整和不准确</strong>。</p><h2>论文的核心方法</h2><p>这篇论文提出的方法由四个组成部分，分别是：<strong>任务相关的建模、迁移建模、任务与任务关系归一化以及最后计算任务的关系图谱</strong>。每一个组成部分都有不同的目标。</p><p><strong>首先，我们需要建立的是每一个独立任务自己的一个模型</strong>。这些模型有两个任务：第一就是尽可能地提高对自身任务的精度；第二就是在这个过程中，尽可能提取有代表性的中间表征结果，能够有助于迁移学习。</p><p><strong>第二个部分就是迁移建模</strong>。这个部分主要是利用第一部分学习到的中间表现层，然后再在目标任务上学习到从原本的表现层到任务目标的迁移。这里面，除了一个原表现层，或者是原任务可以借鉴以外，作者们提出还可以利用多个原任务，来达到提升效果的目的。这样也就把多个任务和一个目标任务关联了起来。</p><p><strong>第三个部分是任务关系的归一化</strong>。这一部分其实是这篇文章的一个亮点。当我们得到迁移学习的结果以后，我们就可以利用每两个任务之间的关系来获得一个矩阵，这个矩阵就完全表征了所有任务的联系。然而，如果直接利用任务的迁移损失函数的值来刻画两个任务之间的关系，那么每两个任务之间的这个数值其实是没办法直接比较的。如果我们采用机器学习界归一化数据的办法，比如把数据归一到0和1之间，也是不行的，因为这样就完全没有考虑损失函数变化的速度和目标任务精度之间的关系。</p><p>所以，这篇论文的作者们提出了一种<strong>按照次序来做归一化的方法</strong>。简单来说，就是不再看两个任务之间的绝对的迁移数值，而是看在测试集上哪一个原任务相比于其他任务能够更多地获取目标任务的精度。这样所有的任务就可比了。总之，<strong>任务关系归一化的目的就是构建了任务与任务之间关系的矩阵</strong>。</p><p>最后一个部分的目的就是<strong>从这个关系矩阵中提取出所有任务的一个真正的关系图谱</strong>。也就是说，我们希望从一个完全的全连通图，找到一个最有价值的子图。在这里，作者们采用了一种叫作“<strong>布尔值整数规划</strong>”（Boolean Integer Programming）的方法，在一些限制条件下，挖掘出了一个有代表性的子图。</p><h2>实验结果</h2><p>作者们提出了一个有4百多万张图片的新的数据集。在这个数据集里，有26个计算机视觉任务。从实验中，作者们挖掘出了这样一些情况，例如3D的、2D的任务自然被归类到了一起，而其他的例如上下文分割、景象识别这种高层次的任务则被分在了一起。</p><p>为了研究这种挖掘出的结构是否真的能够实现迁移学习的目的，作者们还把不同的两两任务随机组合在一起，也就是某种随机任务的图谱，按照学习到的结构进行迁移学习，看是不是比随机结果要好。答案是，的确要好很多。在这篇论文里，作者们展示了学习到的结构不仅能够帮助目标任务提升性能，而且在任务之间关系的解释性上效果也非常不错。</p><h2>小结</h2><p>今天我为你讲了CVPR 2018的最佳论文。</p><p>一起来回顾下要点：第一，我们详细介绍了这篇文章要解决的问题以及贡献，论文研究了计算机视觉任务之间的关系，并且提出了一个计算框架，能够起到迁移学习的作用；第二，我们简要介绍了文章提出的核心方法，主要有四个组成部分；第三，我们简单介绍了论文的实验结果。</p><p>最后，给你留一个思考题，当前挖掘的关系主要是任务的两两关系，能否有一个方法挖掘任务的高维度关系，比如三个任务之间的关系？</p><p>欢迎你给我留言，和我一起讨论。</p><p></p>
</div>
</div>

<div class="outline-2">
<h2 id="anchor23">023 | CVPR 2018论文精读：如何从整体上对人体进行三维建模？<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>今天我们来分享CVPR大会的最佳学生论文，标题是《全方位捕捉：用于跟踪面部表情，手势和身体运动的3D变形模型》（<a href="http://www.cs.cmu.edu/~hanbyulj/totalbody/totalcapture.pdf">Total Capture: A 3D Deformation Model for Tracking Faces, Hands and Bodies</a>）。</p><p>很多学术会议都利用最佳学生论文这个奖项来鼓励学生参与学术研究活动，所以这个奖项的一般要求是第一作者必须是在校学生。</p><p>这篇论文的作者群来自卡内基梅隆大学。</p><p>第一作者周寒星（Hanbyul Joo）是来自韩国的学者，目前在卡内基梅隆大学机器人学院（The Robotics Institute）攻读博士。他的博士论文方向是“计算行为科学”（Computational Behavioral Science）。他已经在计算机视觉方向发表了多篇CVPR、ICCV论文。</p><p>第二作者托马斯·西蒙（Tomas Simon）也是卡内基梅隆大学机器人学院的博士生。他的研究方向是“三维运动的时空建模”（Spatiotemporal Modeling of 3D Motion）。</p><p>最后一位作者是这两位学生的导师亚瑟尔·舍艾克（Yaser Sheikh），是机器人学院的教授。</p><h2>论文的主要贡献</h2><p>这篇论文想要解决的问题很直观，那就是希望对人体进行三维建模，并且能够跟踪（Track）人体的行为以及活动。</p><!-- [[[read_end]]] --><p>这个任务看似简单，但有不少难点。</p><p>首先，过去绝大多数的对人体进行三维建模的工作，都是针对人体的不同部分分别进行的，比如对脸部、对身体和对手部分别建模。在对这些部位进行建模的时候，整体的设定都不太一样。例如，对脸部的建模一般是近景（Close-Up），而对身体则主要是看身体的整体行动。也就是，对于人体不同部位的建模经常在不同的尺度下进行，那就无法把各个部分的建模很容易地对接上。</p><p>其次，还有一些人体的部位，过去并没有太多专门的建模工作，比如针对头发和脚，但这些在全身的建模中也是必不可少的部分。</p><p>这篇论文就加入了对头发和脚这些部分建模的讨论，提供了对人体从整体上进行建模的一个框架。确切地说，论文提供了两个模型：一个叫“弗兰肯斯坦”（Frankenstein），一个叫“亚当”（Adam）。</p><p>“弗兰肯斯坦”主要还是依靠对人体不同部分的建模，然后把这些模型连接起来，通过一些处理，能够让最终呈现的三维建模符合现实。在这个模型的基础上，“亚当”则加入了头发和脚的元素，抛弃了“弗兰肯斯坦”的一些特殊处理的地方，从模型的角度来说更加简单，并且达到了更加逼真的程度。</p><h2>论文的核心方法</h2><p>首先，我们来看一看这个叫“弗兰肯斯坦”的模型。这个模型的思路是尽量把能够对人体各个部分建模的最好的模型先拼接到一起。总体来说，每一个部分基本上都由三组参数组成：<strong>运动参数</strong>（Motion Parameters）、<strong>形状参数</strong>（Shape Parameters）和<strong>全局翻译参数</strong>（Global Translation Parameter）。</p><p>对于人的身体部分，作者们采用了<strong>SMPL模型</strong>[1]。这个模型根据<strong>人体形状的均值</strong>和<strong>形状的变化量</strong>进行线性的叠加，然后经过一个<strong>LBS变换</strong>来得到对身体部分的最终建模。</p><p>对人脸的部分，作者们采用了一个叫<strong>FaceWarehouse的模型</strong>[2]。这个模型是根据<strong>人脸形状的均值</strong>、<strong>形状的变化量，<strong>以及</strong>动态的变化量</strong>来进行线性的叠加。</p><p>对于手而言，目前并没有模型可以直接用。作者们在这篇论文中<strong>提出了自己的模型</strong>，总的来说就是对手的骨架和关节进行建模，然后进行类似于身体的LBS变换。同样，也对人体的脚进行了类似的建模。</p><p>当我们有了身体、人脸、手和脚的模型以后，下面的工作就是把这些部分衔接上。首先，作者们保留了人体模型，移除这个模型上的人脸、手和脚。然后利用人脸模型、手的模型以及脚的模型相应的全局翻译参数，使得这些部分的坐标能够拼接上。最后，作者们还应用了一个“<strong>融合函数</strong>”来构建出一个平滑的人体结构。</p><p>“弗兰肯斯坦”的模型有一个<strong>四项的目标优化函数</strong>。这个函数的第一项是拟合“<strong>关键点</strong>”（Key Points），让人体的躯干骨架能够拟合上运动轨迹。第二项是拟合“<strong>三维点云</strong>”（3D Point Cloud），也就是让人体大部分躯体的实体能够拟合运动轨迹。第三项就是作者们附加的一个“小技巧”（Heuristic）用来把人体的每个部分连接在一起。这一项解决的就是整个模型设计带来的问题，也就是每个部分都是单独的形状参数，而并没有完全在模型上连接起来。最后一项是<strong>高斯先验概率</strong>，用来帮助模型找到唯一的解。</p><p>在“弗兰肯斯坦”的基础上，作者们开发了“亚当”模型。为了构建“亚当”，他们捕捉了70个人体的形态数据，首先构建这些人体的“弗兰肯斯坦”模型。在这些模型基础之上，作者们加入了人体的<strong>头发和衣服的形态</strong>，并且重新定义了整个模型的框架。</p><p>和“弗兰肯斯坦”相比，“亚当”是对所有的人体部件直接进行建模。这个模型和我们前面描述的某个具体部分的模型其实很类似，也是把人体的形态均值、形态的变化值和人脸表现值进行线性叠加，然后进行LBS变换。</p><p>因为“亚当”在模型上进行了简化和创新，所以在目标优化函数中只有三项变量。而我们刚刚讲过的用于“弗兰肯斯坦”模型的小技巧在“亚当”中就变得不需要了。</p><h2>实验结果</h2><p>在实验中，作者们使用了140个VGA照相机对三维身体的关键点进行重建，用了480个VGA照相机，对脚进行重建，31个高清照相机用于脸部和手部关键点的重建以及三维点云的构建。</p><p>作者们显示了利用“弗兰肯斯坦”和“亚当”这两个模型对人体的三维运动进行建模。总体来说，这两个模型的表现非常相似。“亚当”因为有了头发和衣服的形态，在运动中显得更加真实。只是在有一些情况下，“亚当”构建的腿会显得有一些不协调的瘦，出现这种情况的原因，作者们归结于数据的缺失。</p><p>不过，从总体效果上来讲，这篇论文作为第一个对于人体的全身进行三维建模并动态跟踪的工作，应该算是达到了满意的结果。</p><h2>小结</h2><p>今天我为你讲了CVPR 2018的最佳学生论文。</p><p>一起来回顾下要点：第一，我们详细介绍了这篇文章要解决的问题，就是从整体上对人体的运动进行三维建模；第二，我们简要介绍了文章提出的两个模型，“弗兰肯斯坦”和“亚当”核心内容；第三，我们简单介绍了这篇论文所取得的不错的实验结果。</p><p>最后，给你留一个思考题，如果我们需要对“亚当”这个模型进行改进，你认为下一步应该做什么？</p><p>欢迎你给我留言，和我一起讨论。</p><p><strong><span class="reference">参考文献</span></strong></p><p><span class="reference">1.  M. Loper, N. Mahmood, J. Romero, G. Pons-Moll, and M. J. Black. <strong>SMPL: A Skinned Multi-Person Linear Model</strong>. In TOG, 2015.</span></p><p><span class="reference">2.  C. Cao, Y. Weng, S. Zhou, Y. Tong, and K. Zhou. <strong>FaceWareHouse: A 3D Facial Expression Database for Visual Computing</strong>. In TVCG, 2014.</span></p><p></p>
</div>
</div>

<div class="outline-2">
<h2 id="anchor24">024 | CVPR 2018论文精读：如何解决排序学习计算复杂度高这个问题？<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>今天，我们来看这次大会的一篇最佳论文提名，标题是《基于排序的损失函数的有效优化》（Efficient Optimization for Rank-based Loss Functions）。</p><p>还是先简单介绍下论文的作者群。这篇论文的作者来自好几个不同的学术机构。</p><p>第一作者普里迪什·莫哈帕德拉（Pritish Mohapatra）是印度海得拉巴的国际信息科技大学（International Institute of Information Technology，Hyderabad）的计算机科学博士生。他已经在NIPS、CVPR、ICCV、AISTATS等国际机器学习权威会议上发表了多篇论文。</p><p>第二作者米卡尔·罗莱内克（Michal Rolinek）来自德国的马克思普朗克智能系统大学（Max Planck Institute for Intelligent Systems），博士后研究员。在这篇论文中，第一作者和第二作者的贡献相当。</p><p>第三作者贾瓦哈（C.V. Jawahar）是来自印度国际信息科技学院的教授。他是第一作者莫哈帕德拉的博士生导师。</p><p>第四作者弗拉迪米尔·科莫格罗夫（Vladimir Kolmogorov）是奥地利科技大学（Institute of Science and Technology Austria）的机器学习教授。</p><!-- [[[read_end]]] --><p>最后一个作者帕万·库玛（M. Pawan Kumar）来自牛津大学。</p><h2>论文的主要贡献</h2><p>这篇论文提出了一个针对排序学习中<strong>基于整个排序的损失函数</strong>的快速优化算法，这是一个重要贡献。</p><p>在计算机视觉中，有很多机器学习的任务都需要针对两个图像进行一个偏好的排序。而在信息检索或者搜索中，排序是一个核心问题。因此，任何对于排序学习算法的重大改进都会有广泛的应用。</p><p>先来回顾下我们学过的三种形态的排序学习算法。</p><p>第一种是<strong>单点法排序</strong>。这个算法针对每一个查询关键词和相对应的某个文档，我们仅仅判断每一个文档是不是相关的。大多数的单点法排序算法都把整个问题转换成为分类或者回归问题。这样就可以利用大规模机器学习的便利来快速地学习排序函数。</p><p>第二种是<strong>配对法排序</strong>。这个算法是以单点法为基础。因为单点法完全忽略两个文档之间的相对关系。所以配对法是对两个文档与同一个查询关键词的相对相关度，或者说是相关度的差值进行建模。</p><p>第三种是<strong>列表法排序</strong>。列表法是直接针对排序的目标函数或者指标进行优化。这种方法虽然在理论上有优势，但是计算复杂度一般都比较高，在现实中对排序效果的提升比较有限，因此在实际场景中，依然有大量的应用采用单点法或者配对法排序。</p><p>这篇论文就是针对列表法排序学习的“<strong>计算复杂度高</strong>”这个问题，作者们发明了一套叫作“<strong>基于快速排序机制</strong>”（Quicksort flavoured algorithm）的优化框架。在这个优化框架下，排序学习计算复杂度高的这个问题得到了大幅度优化。作者们然后证明了流行的针对NDCG和MAP进行排序学习都满足所发明的优化框架，这样也就在理论上提供了快速优化的可能性。</p><h2>论文的核心方法</h2><p>要理解这篇论文的核心方法，我们先从配对法排序学习讲起。</p><p>针对每一个查询关键词，我们可以构建一个<strong>文档和文档的矩阵</strong>。这个矩阵的每一个元素代表两个文档在当前查询关键词下的关系。如果这个矩阵元素是+1，那么就表明这一行所代表的文档排位要优先于这一列所代表的文档。如果这个矩阵元素是-1，那么就表明这一行所代表的文档要比这一列所代表的文档排位低。当然，还有矩阵元素是0的情况，那就是这两个文档的排位可以是一样的。在这个数据基础上，我们可以从所有这些二元关系中推导出一个整体的排序。</p><p>下面来看配对法排序的核心思路。对于同一个查询关键词而言，我们从和这个查询关键词相关的文档中，随机抽取一个文档，然后从和这个查询关键词不相关的文档中也抽取一个文档，这两个抽取出来的文档就组成一个配对。我们希望<strong>建立一个模型或者函数</strong>，对于这样任意的配对，总能够让<strong>相关文档的函数值大于不相关文档的函数值</strong>。</p><p>如果我们对这个配对法稍微做一些更改，得到的就是列表法排序。首先，我们依然针对每一个正相关的文档进行函数值预测，也针对每一个负相关的文档进行函数值预测。我们把这两个函数值的差值，当做是预测的配对矩阵中这两个文档相对应的那一个元素。只不过在这个时候，我们关注的不是这两个文档的关系，而是配对矩阵所代表的排序和真实排序之间的<strong>差别</strong>。这个差别越小，我们就认为最终的基于列表的损失函数就小；如果差别大，那损失函数的差别就大。</p><p>如何针对这个基于列表的损失函数进行优化，从而能让我们针对单一文档的函数打分最优呢？这就是列表法排序学习的一个核心困难。</p><p>有一个优化办法，就是找到在当前函数打分的情况下，有哪个文档配对违反了排序原则。什么是<strong>违反排序原则</strong>呢？我们刚才说了，模型是希望把正相关的文档排在负相关的文档前面。但是，如果函数并没有完全被学习好，那么负相关的文档也会排到正相关的文档之前，这就叫违反排序原则。</p><p>如果我们找到这样的配对，那么就可以通过调整函数的参数，让这样的违反配对不出现。很显然，当我们有很多这样的配对时，找到违反排序原则最严重的那个配对，也就是负相关的函数值要远远大于正相关函数值的这个配对，对于我们改进函数的参数就会很有帮助。所以，这里的关键就变成了<strong>如何找到违反排序原则最严重的配对</strong>（Most-violating ranking）。</p><p>作者们针对这个任务发明了一个框架，叫作“<strong>基于快速排序机制</strong>”。具体来说，作者们发现，违反排序原则最严重的配对需要满足一些原则。我们需要对当前的数据序列进行快速排序，从而能够找到这个违反排序原则的配对。这里有很多的细节，有兴趣的话建议去读读原论文。你只需要记住，这个快速排序机制利用了<strong>快速排序的时间复杂度</strong>，来实现寻找违反排序原则最严重配对的这个目的。</p><p>那么，是不是大多数排序指标都符合这个机制呢？作者们提供的答案是普遍的MAP和NDCG都符合这个机制。论文给出了证明，因此我们就可以直接使用论文的结论。</p><h2>实验结果</h2><p>作者们在PASCAL VOC 2011数据集上进行了实验，主要是比较了直接进行单点法排序以及直接进行列表法优化，和这篇论文提出的优化算法之间的性能差距。在这个比较下，本文提出的方法优势非常明显，基本上是以单点法的时间复杂度达到了列表法的性能。</p><h2>小结</h2><p>今天我为你讲了CVPR 2018的最佳论文提名。</p><p>一起来回顾下要点：第一，这篇文章的主要贡献是提出了一个基于整个排序的损失函数的快速优化算法；第二，文章提出方法的核心内容是发明了一个框架，叫作“基于快速排序机制”；第三，我们简单介绍了一下论文的实验结果。</p><p>最后，给你留一个思考题，回忆一下我们曾经讲过的LambdaMART算法，那里其实也有这么一个寻找违反排序原则配对的步骤，你能想起来是什么步骤吗？</p><p>欢迎你给我留言，和我一起讨论。</p><p></p>
</div>
</div>

<div class="outline-2">
<h2 id="anchor25">025 | ICML 2018论文精读：模型经得起对抗样本的攻击？这或许只是个错觉<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>2018年7月10日~15日，国际机器学习大会ICML 2018（The 35th International Conference on Machine Learning），在瑞典的斯德哥尔摩举行。</p><p>ICML从1980年开始举办，已有30多年的历史 ，是机器学习、人工智能领域的顶级会议。</p><p>今年ICML大会共收到了2473份投稿，投稿量和去年相比增加了45%。今年最后录取了621篇论文，录取率近25%。除了主会议以外，ICML大会还组织了9个讲座，67个研讨班。</p><p>在接下来的几期内容里，我会为你精选三篇ICML 2018的论文，我们一起来讨论。</p><p>今天，我和你分享的是大会的最佳论文，题目是《梯度混淆带来的安全错觉：绕过对对抗样本的防御》（Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples）。</p><p>先简单介绍下这篇论文的作者群。</p><p>第一作者阿尼什·阿提耶（Anish Athalye）是麻省理工大学的博士生，主要研究方向是机器学习算法的安全。他在今年的ICML大会上就发表了3篇论文。</p><p>第二作者尼古拉·泽多维奇（Nickolai Zeldovich）是阿提耶的导师。他是麻省理工大学计算机系的教授，做安全相关的研究。</p><!-- [[[read_end]]] --><p>第三作者大卫·瓦格纳（David Wagner）来自加州大学伯克利分校，是计算机系教授，也是安全研究方面的专家。</p><h2>论文的背景</h2><p>这篇论文的内容对于大对数人来说可能是比较陌生的。想要弄清楚这篇论文的主要贡献，我们首先来熟悉一下这篇论文所要解决的问题。</p><p>试想我们比较熟悉的监督学习任务。一般来说，在监督学习任务中，我们会有一个数据集，用各种特性（Feature）来表征这个数据集里的数据点。拿最普通的监督学习来说，比如需要把图像分类为“猫”、“狗”等，机器学习算法就是学习一个分类器，可以根据不同的输入信息来做分类的决策。</p><p>当然，我们所说的是在正常情况下使用分类器的场景。有一类<strong>特别的应用场景</strong>，或者说是“对抗”场景，其实是希望<strong>利用一切方法来破坏或者绕开分类器的决策结果</strong>。</p><p>一个大类的“<strong>对抗机制</strong>”是尝试使用“<strong>对抗样本</strong>”（Adversarial Examples）。什么是对抗样本呢？就是说一个数据样本和原来正常的某个样本是非常类似的，但是可以导致分类决策出现很大不同。例如在我们刚才的图像识别的例子中，一个有效的对抗样本就是一张非常像狗的图片，但是可以导致分类器认为这是一只猫或者别的动物。利用这种类似的样本，可以使分类器的训练和测试都产生偏差，从而达到攻击分类器的目的。</p><p>除了“对抗样本”的概念以外，我们再来看一看<strong>攻击分类器</strong>的一些基本的模式。</p><p>一般来说，对分类器的攻击有两种模式，一种叫作“<strong>白盒攻击</strong>”（White-Box），一种叫作“<strong>黑盒攻击</strong>”（Black-Box）。白盒攻击主要是指攻击者可以完全接触到分类器的所有内部细节，比如深度模型的架构和各种权重，但无法接触到测试数据。而黑盒攻击则是指攻击者无法接触分类器的细节。</p><p>这篇论文考虑的场景是白盒攻击。攻击方尝试针对每一个合法的数据点，去寻找一个距离最近的数据变形，使得分类器的结果发生变化。通俗地说，就是希望对数据进行最小的改变，从而让分类器的准确率下降。</p><p>在完全白盒的场景下，最近也有一系列的工作，希望让神经网络更加健壮，从而能够抵御对抗样本的攻击。但是到目前为止，学术界还并没有完全的答案。</p><h2>论文的主要贡献</h2><p>通过上面的介绍，我们知道目前有一些防御对抗样本的方法，似乎为分类器提供了一些健壮性的保护。这篇文章的一个重要贡献，就是指出，<strong>这些防御方法有可能只是带来了一种由“梯度混淆”（Obfuscated Gradients）所导致的错觉</strong>。</p><p>梯度混淆是“梯度屏蔽”（Gradient Masking）的一种特殊形式。对于迭代攻击方法来说，如果发生梯度混淆，防御方会形成防御成功的假象。</p><p>作者们在这篇论文中对梯度混淆进行了分析，提出了三种类型的梯度混淆：“<strong>扩散梯度</strong>”（Shattered Gradients）、“<strong>随机梯度</strong>”（Stochastic Gradients）和“<strong>消失梯度或者爆炸梯度</strong>”（Vanishing/Exploding gradients）。</p><p>针对这三种不同的梯度混淆，作者们提出了相应的一些攻击方案，使得攻击方可以绕过梯度混淆来达到攻击的目的，并且在ICLR 2018的数据集上展示了很好的效果。</p><p>值得注意的是，这篇论文针对的是在防御过程中“<strong>防御方</strong>”的方法所导致的梯度混淆的问题。目前学术界还有相应的工作是从攻击方的角度出发，试图学习打破梯度下降，例如让梯度指向错误的方向。</p><h2>论文的核心方法</h2><p>我们首先来看一看这三种类型的梯度混淆。</p><p><strong>扩散梯度主要是指防御方发生了“不可微分”（Non-Differentiable）的情况</strong>。不可微分的后果是直接导致数值不稳定或者梯度不存在。扩散梯度其实并不意味着防御方有意识地希望这么做，这很有可能是因为防御方引入了一些看似可以微分但是并没有优化目标函数的情况。</p><p><strong>随机梯度主要是由随机防御（Randomized Defense）引起的</strong>。这有可能是神经网络本身被随机化了，或者是输入的数据被随机化，造成了梯度随机化。</p><p><strong>消失梯度和爆炸梯度主要是通过神经网络的多次迭代估值（Evaluation）所导致</strong>。例如，让一次迭代的结果直接进入下一次迭代的输入。</p><p>刚才我们说了，梯度混淆可能是防御方无意识所产生的结果，并不是设计为之。那么，攻击方有什么方法来识别防御方是真的产生了有效果的防御，还是仅仅发生了梯度混淆的情况呢？</p><p>作者们做了一个总结，如果出现了以下这些场景，可能就意味着出现了梯度混淆的情况。</p><p>第一种情况，<strong>一步攻击的效果比迭代攻击（也就是攻击多次）好</strong>。在白盒攻击的情况下，迭代攻击是一定好于一步攻击的。因此如果出现了这种一步攻击好于迭代攻击的情况，往往就意味着异常。</p><p>第二种情况，<strong>黑盒攻击的效果比白盒好</strong>。理论上，白盒攻击的效果应该比黑盒好。出现相反的情况，往往意味着不正常。</p><p>第三种情况，<strong>无局限（Unbounded Attack）效果没有达到100%</strong>。最后的这种情况，就是随机寻找对抗样本，发现了比基于梯度下降的攻击要好的对抗样本。</p><p>那么，针对梯度混淆，攻击方有什么办法呢？</p><p>针对扩散梯度，作者们提出了一种叫<strong>BPDA</strong>（Backward Pass Differentiable Approximation）的方法。如果有兴趣，建议你阅读论文来了解这种算法的细节。总体说来，BPDA就是希望找到神经网络不可微分的地方，利用简单的可微分的函数对其前后进行逼近，从而达到绕过阻碍的目的。</p><p>针对随机梯度，作者们提出了“<strong>变换之上的期望</strong>”（Expectation over Transformation）这一方法。这个方法的特点是针对随机变化，变换的期望应该还是能够反映真实的梯度信息。于是作者们就让攻击方作用于变换的期望值，从而能够对梯度进行有效的估计。</p><p>针对消失或者爆炸的梯度，作者们提出了“<strong>重新参数化</strong>”（Reparameterization）这一技术。重新参数化是深度学习中重要的技术。在这里，作者们使用重新参数化，其实就是对变量进行变换，从而使得新的变量不发生梯度消失或者爆炸的情况。</p><h2>小结</h2><p>今天我为你讲了今年ICML的最佳论文。</p><p>一起来回顾下要点：第一，这篇论文讨论了一个比较陌生的主题，我们简要介绍了论文的背景；第二，我们详细介绍了论文提出的三种类型的梯度混淆。</p><p>最后，给你留一个思考题，我们为什么要研究深度学习模型是否健壮，是否能够经得起攻击呢？有什么现实意义吗？</p><p>欢迎你给我留言，我们一起讨论。</p><p></p>
</div>
</div>

<div class="outline-2">
<h2 id="anchor26">026 | ICML 2018论文精读：聊一聊机器学习算法的“公平性”问题<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>在上一次的分享里，我们介绍了今年ICML大会的一篇最佳论文，这是一篇非常优秀的机器学习和计算机安全相结合的论文。这篇论文剖析了目前在白盒攻击的场景下，攻击方如何绕过一种叫作“混淆梯度”的情况，来实现有效攻击的目的。</p><p>今天，我们来分享ICML 2018的另一篇最佳论文，题目Delayed Impact of Fair Machine Learning。这篇论文主要探讨了“公平”（Fair）在机器学习中的应用。论文的五位作者都来自加州大学伯克利分校。</p><h2>论文的背景</h2><p>这篇论文所探讨的主题是机器学习的“公平性”问题。近些年，这个主题受到了学术界越来越多的关注，但是对于普通的人工智能工程师和数据科学家来说，这个议题依然显得比较陌生和遥远。所以，我先来简单梳理一下这方面研究的核心思想。</p><p>机器学习有一个重要的应用，就是在各类<strong>决策场景</strong>中提供帮助，例如申请贷款、大学入学、警察执勤等。一个不可否认的特点是，这些决策很有可能会对社会或者个人产生重大的不可逆转的后果。其中一个重要的后果就是，针对不同的人群，有可能会产生意想不到的“不公平”的境况。比如，有一些普遍使用的算法，在帮助警察判断一个人是否可能是罪犯的时候，系统会认为美国黑人相对于白人更容易犯罪，这个判断显然存在一定的问题。</p><!-- [[[read_end]]] --><p>机器学习研究者已经注意到了这种算法中的“公平”问题，并且开始探讨没有任何限制条件的机器学习算法，是否会对少数族裔（Underrepresented Group）产生不公平的决策判断。基于这些探索，研究者们提出了一系列的算法，对现有的各种机器学习模型增加附带了公平相关的限制条件，希望通过这种方法来解决各种不公平定义下的决策问题。</p><h2>论文的主要贡献</h2><p>这篇论文从理论角度展开讨论，基于什么样假设和条件下的具有公平性质的机器学习算法，在决策场景中能够真正为少数族群带来长期的福祉。值得注意的是，这里所谓的少数族裔是一个抽象化的概念，指的是数目相对较少的，或者在某种特性下比较少的一组数据群体。这篇论文并不直接讨论社会学意义下的少数族群的定义。</p><p>作者们主要是比较两个人群A和B，在不同的公平条件下，看这两组人群的某种“<strong>效用</strong>”（Utility）的差值会发生什么变化。这个差值可以是正的，没变化或者是负的。</p><p>论文的主要结论是，在不同的公平条件下，效用差值会有各种可能性。这其实是一个非常重要的结论。有一些公平条件，直觉上我们感觉会促进少数族群的效用，但这篇论文向我们展示了，即便出发点是好的，在某些情况下，效用差值也可能是负的。</p><p>除此以外，这篇论文还探讨了“<strong>测量误差</strong>”（Measurement Error）对效用差值的影响。作者们认为测量误差也应该被纳入整个体系中去思考公平的问题。</p><p>需要指出的是，论文的分析方法主要建立在时序关系的“<strong>一步预测</strong>”（One Time Epoch）基础上的。也就是说，我们利用当前的数据和模型对<strong>下一步的决策判断</strong>进行分析，并不包括对未来时间段所有的预测。从理论上说，如果在无限未来时间段的情况下，结论有可能发生变化。</p><h2>论文的核心方法</h2><p>这篇文章的核心思路是探讨针对人群A和B所采取的一种“策略”（Policy），是怎么样影响这两组人群的效用差别的。如果某种策略会导致某个群体的<strong>效用差别为负</strong>，那么我们就说这个策略对群体产生了“<strong>绝对损坏</strong>”（Active Harm）作用；如果<strong>效用差别是零</strong>，就说明这个策略对群体产生了“<strong>停滞</strong>”（Stagnation）作用；如果<strong>效用差别是正的</strong>，就说明这个策略对群体产生了“<strong>推动</strong>”（Improvement）作用。</p><p>除此以外，我们认为有一种不考虑人群A和B具体特征的期望最大化效用的策略，称之为“<strong>最大化效用</strong>”（MaxUtil）。这种策略其实就是在没有约束条件的情况下，利用一般的机器学习算法达到的效果。我们需要把新策略和这个策略进行比较，如果新的策略比这个策略好，就是产生了“<strong>相对推动</strong>”（Relative Improvement），反之我们说新的策略产生了“<strong>相对损害</strong>”（Relative Harm）。</p><p>为了进一步进行分析，作者们引入了一个叫“<strong>结果曲线</strong>”（Outcome Curve）的工具来视觉化策略和效用差值的关系。具体来说，曲线的横轴就是因为策略所导致的对某一个群体的选择概率，纵轴就是效用差值。当我们有了这个曲线之后，就能非常直观地看到效用差值的变化。</p><p><img src="https://static001.geekbang.org/resource/image/98/ab/98a16f6db74ef6470792ef6cd618c6ab.png" alt=""></p><p>从这个曲线上我们可以看到，效用差值的确在一个区间内是“相对推动”的，而在另一个区间是“相对损害”的，在最右边的一个区间里是“绝对损害”的。这就打破了我们之前的看法，认为有一些选择策略会一致性地导致唯一结果。</p><p>在此基础上，我们专门来看这两种特殊的策略。第一种叫“<strong>种族公平</strong>”（Demographic Parity），思路是希望在两个人群中保持一样的选择概率。另一种策略叫“<strong>公平机会</strong>”（Equal Opportunity），思路是希望某个人群中成功的概率（例如申请到贷款、学校录取等）和人群无关。这两种策略都是典型的试图利用限制条件来达到公平的方法。我们希望来比较的就是这两种策略以及之前说的最大化效用之间的一些关系，得出以下三个主要结论。</p><p>第一个比较出乎意料的结论是最大化效用这个策略并不会导致“绝对损害”。意思就是说，和人们之前的一些想法不同，最大化效用也有可能让少数族裔的效用得到提升或者不变。</p><p>第二个结论是，这两种公平策略都可能会造成“相对推动”。这也是推出这两种策略的初衷，希望能够在选择概率上进行调整，从而让少数族裔的效用得到提升。</p><p>第三个结论是，这两种公平策略都可能会造成“相对损害”。这是本篇论文的一个重要结论，正式地证明了公平策略在某个区间上其实并没有带来正向的“推动”反而是“损害”了少数族群。作者们进一步比较了“种族公平”和“公平机会”这两个策略，发现“公平机会”可以避免“绝对损害”而“种族公平”则无法做到。</p><h2>小结</h2><p>今天我为你讲了今年ICML的另一篇最佳论文。</p><p>一起来回顾下要点：第一，这篇论文讨论了计算机算法的公平性问题；第二，我们详细介绍了论文提出的两种策略以及得出的主要结论。</p><p>最后，给你留一个思考题，研究算法的公平性对我们日常的应用型工作有什么启发作用？</p><p>欢迎你给我留言，和我一起讨论。</p><p></p>
</div>
</div>

<div class="outline-2">
<h2 id="anchor27">027 | ICML 2018论文精读：优化目标函数的时候，有可能放大了“不公平”？<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>今天我们要分享的是ICML 2018的一篇最佳论文提名，题目是Fairness Without Demographics in Repeated Loss Minimization。</p><p>这篇论文讨论了这样一个话题，在优化目标函数的时候，如何能够做到针对不同的子群体，准确率是相当的，从而避免优化的过程中过分重视多数群体。这篇论文的作者都来自斯坦福大学。</p><h2>论文的主要贡献</h2><p>这篇论文其实也是希望讨论算法带来的“公平性”问题，但是出发的角度和我们上一篇讨论公平性的论文非常不一样。这篇论文的核心思想，是希望通过机器学习目标函数优化的原理，来讨论机器学习和公平性的关系。</p><p>作者们发现，基于“平均损失”（Average Loss）优化的机器学习算法，常常会给某一些少数群体带来巨大的不准确性。这其实并不是模型本身的问题，而是优化的目标函数的问题。在这样的情况下，目标函数主要是关注有较多数据的群体，保证这些群体的损失最小化，而可能忽略了在数量上不占优势的少数群体。</p><p>在此基础上，还带来了另外一个用户“<strong>留存度</strong>”（Retention）的问题。因为少数群体忍受了比较大的优化损失，因此这些群体有可能离开或者被这个系统剔除。所以，长期下去，少数群体的数目就可能逐渐变少。这也许是目标函数的设计者们无从想到的一个平均损失函数的副产品。作者们还把这个现象命名为“<strong>不公平的放大</strong>”（Disparity Amplification）。</p><!-- [[[read_end]]] --><p>这篇论文的一个重要贡献是发现<strong>ERM（Empirical Risk Minimization，经验风险最小化）其实就存在这种不公平的放大性</strong>。ERM包含了很多经典的机器学习模型的目标函数，例如支持向量机（Support Vector Machines）、对数回归模型（Logistic Regression）以及线性回归等。作者们还发现，ERM可以让即便在最初看上去公平的模型，在迭代的过程中逐渐倾向于不公平。</p><p>为了解决ERM的问题，作者们开发了一种新的算法框架，DRO（Distributionally Robust Optimization，分布式健壮优化）。这种框架是为了最小化“最差场景”（Worst-Case）的风险，而不是平均风险。作者们在真实的数据中展示了DRO相比于ERM更能够解决小众群体的不公平性问题。</p><h2>论文的核心方法</h2><p>为了解决在ERM下的对不同群体的不公平性问题，作者们首先对数据做了一种<strong>新的假设</strong>。</p><p>作者们假设数据中有隐含的K个群体。每一个数据点，都有一定的概率属于这K个群体。我们当然并不知道这K个群体本身的数据分布，也不知道每个数据点对于这K个群体的归属概率，这些都是我们的模型需要去估计的隐含变量。</p><p>对于每一个数据点而言，在当前模型下，我们都可以估计一个“<strong>期望损失</strong>”（Expected Loss）。在新的假设框架下，因为每个数据点可能属于不同的K个群体，而每个群体有不同的数据分布，因此会导致在当前群体下的期望损失不一样，也就是会出现K个不一样的期望损失。我们的目的，是要控制这K个损失中的<strong>最差的损失</strong>，或者叫<strong>最差场景</strong>。如果我们可以让最差的损失都要小于某一个值，那么平均值肯定就要好于这种情况。这也就从直观上解决了不公平放大的问题。</p><p>那么，如果我们直接在这样的设置上运用ERM，会有什么效果呢？这里，有一个数值是我们比较关注的，那就是在整个框架假设下，每个群体的<strong>期望人数</strong>。这个数值等于在期望损失的情况下，当前群体剩余的人数加上新加入的人数。作者们在论文中建立了对这个期望人数的理论界定。</p><p>这个结论的直观解释是，如果在当前更新的过程中，期望人数的数值估计能够达到一个稳定的数值状态，那么就有可能稳定到这里，不公平放大的情况就不会发生；而如果没有达到这个稳定的数值状态，那么不公平放大的情况就一定会发生。也就是说，在ERM优化的情况下，群体的大小有可能会发生改变，从而导致人群的流失。</p><p>在这个理论结果的基础上，作者们提出了DRO。DRO的核心想法就是<strong>要改变在优化过程中，可能因为数据分配不均衡，而没有对当前小群体进行足够的采样</strong>。</p><p>具体来说，<strong>DRO对当前群体中损失高的人群以更高的权重，也就是说更加重视当前目标函数表现不佳的区域</strong>。对于每一个数据点而言，损失高的群体所对应的群体概率会被放大，从而强调这个群体当前的损失状态。换句话说，DRO优先考虑那些在当前情况下损失比较大的小群体。这样的设置就能够<strong>实现对最差情况的优化从而避免不公平放大</strong>。</p><p>作者们在文章中展示了DRO所对应的目标函数可以在递归下降的框架下进行优化，也就是说任何当前利用ERM的算法，都有机会更改为DRO的优化流程，从而避免不公平放大的情况。</p><h2>论文的实验结果</h2><p>作者们在一个模拟的和一个真实的数据集上进行了实验。我们这里简单讲一讲真实数据的实验情况。</p><p>作者们研究了一个“自动完成”（Auto Completion）的任务。这个任务是给定当前的词，来预测下一个词出现的可能性。而数据则来自两个不同人群，美国白人和黑人所产生的推特信息。在这个实验中，作者们就是想模拟这两个人群的留存度和模型损失。这里面的隐含假设是，美国白人和黑人的英语词汇和表达方式是不太一样的。如果把两个人群混合在一起进行优化，很有可能无法照顾到黑人的用户体验从而留不住黑人用户。</p><p>在实验之后，DRO相比于ERM更能让黑人用户满意，并且黑人用户的留存度也相对比较高。从这个实验中，DRO得到了验证，的确能够起到照顾少数人群的作用。</p><h2>小结</h2><p>今天我为你讲了今年ICML的最佳论文提名。</p><p>一起来回顾下要点：第一，这篇论文也讨论了算法带来的“公平性”问题，是从机器学习目标函数优化的角度来考虑这个问题的；第二，这篇论文的一个重要贡献是发现ERM确实存在不公平的放大性，基于此，作者们开发了一种新的算法框架DRO；第三，文章的实验结果验证了DRO的思路，确实能够解决小众群体的不公平性问题。</p><p>最后，给你留一个思考题，这两期内容我们从不同的角度讨论了算法的公平性问题，你是否有自己的角度来思考这个问题？</p><p>欢迎你给我留言，和我一起讨论。</p><p></p>
</div>
</div>

<div class="outline-2">
<h2 id="anchor28">028 | ACL 2018论文精读：问答系统场景下，如何提出好问题？<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>今年7月15日~20日，计算语言学协会年会ACL 2018（56th Annual Meeting of the Association for Computational Linguistics），在澳大利亚的墨尔本举行，这是自然语言处理和计算语言学领域的顶级会议。</p><p>计算语言学协会（ACL）最早成立于1962年，每年都赞助举行各种学术交流和研讨大会。ACL大会是ACL的旗舰会议，可以说这个会议是了解自然语言处理每年发展情况的重量级场所。</p><p>会议今年收到了1018篇长论文和526篇短论文的投稿。最终，大会接收了256篇长论文以及125篇短论文，综合录用率达到24.7%。</p><p>今天，我们来看这次会议的一篇最佳论文，题目是《学习提出好问题：使用完美信息的神经期望价值对澄清问题进行排序》（<a href="http://aclweb.org/anthology/P18-1255">Learning to Ask Good Questions: Ranking Clarification Questions using Neural Expected Value of Perfect Information</a>）。</p><p>首先给你简单介绍下论文的作者。</p><p>第一作者萨德哈·饶（Sudha Rao）来自马里兰大学学院市分校（University of Maryland, College Park），是计算机系的博士生。她已经在ACL，EMNLP、NAACL等自然语言处理大会上发表了多篇论文，并且在微软研究院实习过。</p><!-- [[[read_end]]] --><p>第二作者是饶的导师哈尔·道姆三世（Hal Daume III），是马里兰大学学院市分校计算机系的一名教授，目前也在纽约的微软研究院工作。他是机器学习和自然语言处理领域的专家，在诸多领域都发表过不少研究成果，论文引用数达到9千多次。</p><h2>论文的主要贡献</h2><p>这篇论文关注的是“<strong>问答系统</strong>”（Question &amp; Answering）。问答系统不仅在实用领域受到大量用户的青睐，产生了诸如Quora、知乎、Stack Overflow等知名的在线问答服务，也在人工智能系统开发领域受到研究者的关注。</p><p>我们曾经提到过“图灵测试”，用来衡量一个系统或者说是一个机器人是否具有真正的人工智能，这个测试其实就是建立在人机问答的交互场景下的。因此，建立有效的问答系统一直是人工智能研究，特别是自然语言处理研究的核心课题之一。</p><p>这篇论文的作者们认为，在问答系统的场景中，一个非常重要的手段是针对已经提出的问题进行“<strong>澄清式</strong>”（Clarification）提问，从而能够引导其他回答者更加有效地进行回答。也就是说，作者们研究的主题是，<strong>如何找到这些具有桥梁作用的“澄清式问题”</strong>，这是这篇论文的第一个重要贡献。</p><p>论文的第二个主要贡献是利用了“决策论”（Decision Theoretic）框架下的<strong>EVPI</strong>（Expected Value of Perfect Information，完美信息的期望价值），来衡量一个澄清式问题会对原始的问题增加多少有用的信息。简而言之，<strong>EVPI就是这篇论文提出来的一个衡量有用信息的测度</strong>（Measure）。</p><p>论文的第三个贡献是通过Stack Exchange平台（Stack Overflow是其一个子站点），构造了一个7万7千条含有澄清式问题的数据集。作者们从这个数据集中选取了500个样本进行了实验，并且发现，提出的模型要明显好于一些之前在问题系统中的类似算法。</p><h2>论文的核心方法</h2><p>既然这篇论文的一个核心贡献是提出了“澄清式提问”这么一个新的概念，用于帮助问答系统的开发。那么，<strong>究竟什么是“澄清式提问”呢</strong>？</p><p>实际上在这篇文章里，作者们并没有对“澄清式提问”给出一个清晰的定义，而是仅仅提供了一个实例来解释什么是“澄清式提问”。</p><p>例如，一个用户在Ask Ubuntu这个子论坛里，询问在安装APE程序包时遇到的问题。这个时候，如果我们需要问“澄清式问题”，究竟什么样的问题可以激发其他人或者提出澄清式问题的人来进一步解答原始的问题呢？</p><p>我们看下面几个从不同角度提出的问题：可以问这个用户使用的Ubuntu系统具体的版本号；也可以问用户的WiFi网卡信息，还可以问用户是不是在X86体系下运行Ubuntu。</p><p>那么，在这一个场景下，后两个问题要么无法为原始的问题提供更多有价值的信息，要么就是彻底的不相关，而第一个问题关于具体的版本号，很明显是用户可以提供的，并且可以帮助回答问题的人来缩小问题的范围。</p><p>这也带出了这篇论文的第二个贡献点，<strong>如何衡量一个帖子的价值呢</strong>？</p><p>要回答这个问题，我们需要知道这里有两种帖子是模型需要处理的。第一种帖子集合是候选的澄清式问题集合。第二种帖子集合是候选的最终回答集合。我们最终的目的是得到最佳的最终回答。这里面起到“搭桥”作用的就是澄清式问题。</p><p>所以，作者们就构造了一个针对每一个最终问题的EVPI值，用于衡量这个问题的“期望价值”。为什么是期望价值呢？因为这里面有一个不确定的因素，那就是根据不同的澄清式问题，可能会产生不同的回答。因此，作者们在这里使用了概率化的表达。</p><p>也就是说，EVPI的核心其实就是计算给定当前的原始问题以及某一个澄清式回答的情况下，某一个最终回答的概率，乘以这个回答所带来的“收益”。当我们针对候选最终回答集合中所有的回答都进行了计算以后，然后求平均，就得到了我们针对某一个澄清式回答的EVPI。换句话说，<strong>某一个澄清式回答的EVPI就是其所能产生的所有可能的最终回答的加权平均收益</strong>。</p><p>从上面这个定义中，我们有两点不确定。第一，我们并不知道给定当前的原始问题以及某一个澄清式回答的情况下，某一个最终回答的条件概率；第二，我们并不知道问题的收益。因此，作者们利用了两个<strong>神经网络模型</strong>来对这两个未知量进行<strong>联合学习</strong>（Joint Learning）。这可以算是本文在建模上的一个创新之处。</p><p>具体来说，首先，作者们利用<strong>LSTM</strong>来针对原始问题、候选澄清问题、以及最后解答产生相应的<strong>表达向量</strong>。然后，原始问题和某一个候选澄清问题的表达向量，通过一个神经网络产生一个<strong>综合的表达</strong>。最后，作者们定义了一个<strong>目标函数</strong>来针对这些初始的表达向量进行优化。</p><p>这个目标是需要我们学习到的答案的表达靠近初始得到的答案的表达，同时，也要靠近最终答案的表达，如果这个最终答案所对应的问题也靠近原来的问题。换句话说，<strong>如果两个问题的表达相近，答案的表达也需要相近</strong>。</p><p>那什么样的问题是相近的问题呢？作者们利用了Lucene这个信息检索工具，根据一个原始的问题寻找相近的问题。这里，作者们并没有真实的标签信息，所以利用了一些方法来标注数据，从而能够让模型知道两个问题是否相关。</p><h2>论文的实验结果</h2><p>作者们利用了Stack Exchange来构建一个分析澄清式问题的数据集。具体的思路是，如果原始问题曾经被作者修改过，那么后面的某一个帖子中所提出的问题就会被当作是澄清式问题，而原始问题就被当作是因为澄清式问题而得以改进的帖子。很明显，这是一个非常粗略的数据收集条件。当原始问题被作者修改过以后，并且最后因为这个修改得到回复，就被认为是一个最终的答案。经过这么一番构建，作者们整理了7万7千多条帖子。</p><p>作者们利用论文提出的方式和其他的经典模型进行比较。最后的结论是，提出的模型能够更好地找到最佳的澄清式问题，效果要好于仅仅是简单利用神经网络，来匹配原始问题和相应的澄清式问题。</p><h2>小结</h2><p>今天我为你讲了ACL 2018的一篇最佳论文。</p><p>一起来回顾下要点：第一，这篇论文提出了“澄清式提问”这个概念，来帮助问答系统的开发；第二，文章提出了一系列方法，对澄清式问题进行描述和衡量；第三，文章构建了一个数据集，通过实验论证了所提出方法的有效性。</p><p>最后，给你留一个思考题，通过这篇文章关于澄清式问题的介绍，你能否给澄清式问题下一个定义呢？</p><p>欢迎你给我留言，和我一起讨论。</p><p></p>
</div>
</div>

<div class="outline-2">
<h2 id="anchor29">029 | ACL 2018论文精读：什么是对话中的前提触发？如何检测？<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>今天，我来和你分享ACL 2018的第二篇最佳论文，题目是《让我们“再”次做到：检测副词前提触发词的第一种计算方法》（<a href="https://www.cs.mcgill.ca/~jkabba/acl2018paper.pdf">Let’s do it “again”: A First Computational Approach to Detecting Adverbial Presupposition Triggers</a>）。</p><p>这篇论文的作者都来自加拿大麦吉尔大学（McGill University）的计算机系。前三位学生作者是这篇论文的共同第一作者，对论文的贡献相同。他们的导师张智杰（Jackie Chi Kit Cheung）助理教授是这篇论文的最后一个作者。张智杰于2014年从多伦多大学博士毕业，之前曾两次在微软研究院实习过，他长期从事自然语言处理的研究。</p><h2>论文的主要贡献</h2><p>这篇论文的背景要从“语用学”（Pragmatics）说起。语用学是语言学的一个分支学科，与符号学理论相互交叉、渗透，研究语境对语言含义产生的影响和贡献。语用学包括言语行为理论、对话内涵义、交流中的对话，以及从哲学、社会学、语言学以及人类学等角度解析人类语言行为的研究。</p><p>语用学分析研究语言行为（如招呼、回答、劝说）的文化准绳和发言规则。不同的文化之间皆有约定俗成、客套的对话，在跨文化交流中，为了避免因为语言规范的差异而在交谈之中产生误解，社会语言学的知识与务实能力是语言学习者所不能忽视的。</p><!-- [[[read_end]]] --><p>在语用学中，“前提”（Presuppositions）是交谈的参与者共同约定的假设和认知，而且在谈话中被广泛使用。同时，在这篇论文中，作者们把提示“前提”的“表达”（Expression）定义为“<strong>前提触发</strong>”（Presupposition Triggers），包括一些动词、副词和其他短语。为了更加清晰地说明这些概念，作者们举了这么一个例子。</p><p>假设我们现在有两句话：</p><ol>
<li>
<p>约翰再次要去那家餐厅（John is going to the restaurant <em>again</em>）。</p>
</li>
<li>
<p>约翰已经去过了那家餐厅（John has been to the restaurant）。</p>
</li>
</ol><p>第一句话要能够成立必须要建立在第二句话的基础上。特别是“前提触发”词“再”（Again）的使用，是建立在第二句话真实的情况下。换句话说，第一句话必须在第二句话的上下文中才能够被理解。值得一提的是，即便我们对第一句话进行否定，“约翰不打算再去那家餐厅了”（John is not going to the restaurant again），依然需要第二句话的支持。也就是说，“前提触发”词在这里并不受到否定的影响。</p><p><strong>这篇论文的核心贡献就是对以副词为主的前提触发词进行检测</strong>。这里面包括“再”（Again）、“也”（Also）和“还”（Still）等。再此之前，还没有对这方面词汇进行检测的学术研究工作。能够对这类前提触发词进行检测，可以应用到<strong>文本的归纳总结</strong>（Summarization）和<strong>对话系统</strong>等场景中。</p><p>为了更好地研究这个任务，作者们还基于著名的自然语言处理数据Penn Treebank和English Gigaword，建立了两个新的数据集从而能够进行触发词的分类检测工作。最后，作者们设计了一个基于“关注”（Attention）机制的时间递归神经网络（RNN）模型来针对前提触发词进行检测，达到了很好的效果。</p><h2>论文的核心方法</h2><p>现在，我们来讨论这篇论文的一些细节。</p><p>首先，我们来看看<strong>数据集是如何生成的</strong>。数据中的每一个数据点都是一个<strong>三元组</strong>，分别是标签信息（正例还是负例），文本的单词，文本单词所对应的“词类标签”或简称为POS标签（例如动词、名词）。</p><p>数据点正例就表明当前数据包含前提触发词，反之则是负例。另外，因为我们需要检测的是副词性的前提触发词，因此我们还需要知道这个词所依靠的动词。作者们把这个词叫作副词的“<strong>管理词</strong>”（Governor）。</p><p>作者们首先针对文档扫描，看是否含有前提触发词。当发现有前提触发词的时候，提取这个触发词的管理词，然后提取管理词前50个单词，以及管理词后面到句子结束的所有的单词。这就组成了正例中的单词。当找到了所有的正例之后，作者们利用管理词来构建负例。也就是说，在文本中寻找哪些句子含有一样的管理词，但并不包括后面的前提触发词，这样的句子就是负例。</p><p>下面，我们来看一下作者们提出模型的一些构成。从大的角度来说，为了识别前提触发词，作者们考虑了一个<strong>双向LSTM</strong>的基本模型架构，在此之上有一个“关注机制”，在不同的情况下来选择LSTM的中间状态。</p><p>具体来说，整个模型的输入有两部分内容。</p><p>第一部分，是<strong>文本的单词进行了词向量（Embedding）的转换</strong>。我们已经反复看到了，这是在自然语言处理场景中利用深度学习模型必不可少的步骤。这样做的好处就是把离散数据转换成了连续的向量数据。</p><p>第二部分，是<strong>输入这些单词相对应的POS标签</strong>。和单词不一样的是，POS标签依然采用了离散的特性表达。</p><p>然后，连续的词向量和离散POS标签表达合并在一起，成了双向LSTM的输入。这里，利用双向LSTM的目的是让模型针对输入信息的顺序进行建模。跟我们刚才提到的例子一样，前提触发词和其所依靠的动词，在一个句子的段落中很明显是和前后的其他单词有关联的。因此，双向LSTM就能够达到对这个结构进行记忆的目的，并且提取出有用的中间变量信息。</p><p>下面需要做的就是<strong>从中间变量信息到最终的分类结果的变换</strong>。这里，作者们提出了一个叫“<strong>加权池化网络</strong>”（Weighted Pooling Network）的概念，并且和“关注”机制一起来进行这一步的中间转换。</p><p>可以说，作者们这一步其实是借助了计算机视觉中的经常使用的卷积神经网络CNN中的池化操作来对文档进行处理。具体来说，作者们把所有LSTM产生的中间状态堆积成一个矩阵，然后利用同一个矩阵乘以其自身的转置就得到了一个类似于相关矩阵的新矩阵。可以说，这个新矩阵是完全抓住了当前句子通过LSTM中间变量转换后所有中间状态的两两关系。</p><p>然后，作者们认为最后的分类结构就是从这个矩阵中抽取信息而得到的。至于怎么抽取，那就需要不同的权重。这种根据不同的情况来设置权重的机制就叫作“关注”机制。经过矩阵中信息的抽取，然后再经过全联通层，最终就形成了标准的分类输出。</p><h2>论文的实验结果</h2><p>作者们在我们上面提到的两个新数据集上进行了实验，并且和一系列的方法进行了比较。其他的方法包括简单的对数几率回归方法（Logistic Regression），简化了的但是依然利用了双向LSTM结构的模型，还有一个利用CNN来进行提取信息的模型。</p><p>在两个数据集上，论文提出的方法比对数几率回归以及CNN的方法都要好10%～20%左右。和简化的LSTM模型相比，优势并没有那么大，但依然有统计意义上的好效果。</p><h2>小结</h2><p>今天我为你讲了ACL 2018的另外一篇最佳论文。</p><p>一起来回顾下要点：第一，这篇论文的背景是语用学，核心贡献是对以副词为主的前提触发词进行检测；第二，论文的核心方法是提出一个双向LSTM的基本模型架构，并利用“关注机制”，根据不同的情况来设置权重；第三，论文构建了两个数据集，取得了较好的实验结果。</p><p>最后，给你留一个思考题，这篇论文使用了双向LSTM的架构，能不能使用单向LSTM呢？</p><p>欢迎你给我留言，和我一起讨论。</p><p></p>
</div>
</div>

<div class="outline-2">
<h2 id="anchor30">030 | ACL 2018论文精读：什么是“端到端”的语义哈希？<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>今天，我们来看今年ACL大会的一篇最佳论文提名，题目是《NASH：面向生成语义哈希的端到端神经架构》（<a href="http://people.ee.duke.edu/~lcarin/acl2018_hashing.pdf">NASH: Toward End-to-End Neural Architecture for Generative Semantic Hashing</a>）。</p><p>先来简单介绍下论文的作者群，我着重介绍三位。</p><p>第一作者沈丁涵（Dinghan Shen音译）是杜克大学计算机科学系的博士生。他已经发表了多篇自然语言处理和机器学习相关的论文，并且在NEC实验室和微软研究院都实习过。</p><p>论文的共同第一作者苏勤亮（Qinliang Su音译），目前是中山大学数据科学与计算机学院的副教授。他在香港大学取得博士学位，之后曾在杜克大学从事博士后研究工作。</p><p>作者中的劳伦斯·卡林（Lawrence Carin）是杜克大学教授。卡林是机器学习的权威，也是沈丁涵的导师。</p><h2>论文的主要贡献</h2><p>在很多的应用中，我们都需要根据一个已有的文档表达和一个文档库，找到最相近的，或者说最类似的文档。这经常被叫作“<strong>相似查找</strong>”（Similarity Search）或者“<strong>最近邻查找</strong>”（Nearest-Neighbor Search），在推荐系统、信息检索、图片检索等领域都有非常广泛的应用。</p><!-- [[[read_end]]] --><p><strong>“语义哈希”（Semantic Hashing）被认为是解决“相似查找”的一个重要并且行之有效的方法</strong>。简单来说，“语义哈希”要做的就是把文档表达为离散的，也就是二元的向量。这些向量保留了文档在原始空间中的相似关系。因此常常被认为是带有语义的哈希过程，这也就是“语义哈希”这个名字的来历。</p><p>当我们把文档转换为语义哈希空间之后，文档之间相似度的计算就变成了利用“<strong>汉明距离</strong>”（Hamming Distance）来计算离散向量之间的距离。在当下的计算机体系架构中，上百万文档之间的“汉明距离”都可以在几个毫秒间完成计算。因此，我们可以看到，<strong>“语义哈希”的一个优势就是计算快捷，并且保持了原始空间的语义信息</strong>。</p><p>那么，看似这么有优势的“语义哈希”有没有什么劣势呢？</p><p>虽然已经有相当多的研究针对文字数据产生哈希，但是这些现有的方法都有一些明显的问题，其中最紧要的一个问题就是这些方法大多都需要两个阶段。</p><p>具体是哪些方法呢？我把这些方法归纳为两种思路。</p><p>第一种思路，我们首先需要在无监督的条件下学习文档的二元哈希；然后，我们需要训练L个二元分类器来预测L个二元位的哈希值，这个步骤是监督学习过程。</p><p>第二种思路，我们首先针对文档学习连续的表达向量，然后在测试阶段再把连续值进行二元离散化。</p><p>很明显，不管是哪一种思路，这种两个步骤的方法都不可避免地会仅仅得到次优的结果。这是因为两个步骤的优化流程是脱节的。而且，在从连续的表达向量到二元离散化的过程中，往往利用的是经验法则（Heuristic），因此语义信息可能被丢失。</p><p>基于这些问题，这篇论文提出了“<strong>端到端</strong>”（End-to-End）的“语义哈希”训练过程。作者们认为，经过一个阶段就可以得到完整哈希值的研究工作，这篇文章是第一个。在此之上，作者们利用了最新的<strong>NVI框架</strong>（Neural Variational Inference，神经化的变分推断），来学习文档的二元编码，在无监督和监督环境下都取得了不错的结果。</p><p>这篇论文的另一个贡献就是在提出的方法和“比率损失理论”（Rate Distortion Theory）之间建立了联系。在这个联系的基础上，作者们展示了如何在模型的训练过程中“注入”（Inject）“<strong>数据相关的噪音</strong>”（Data-Dependent Noise）来达到更好的效果。</p><h2>论文的核心方法</h2><p>作者们首先把从文档生成“语义哈希”看作是一种<strong>编码（Encode）和解码（Decode）的流程</strong>。文档的二元哈希向量则被看成了表达文档的一种隐变量（Latent Variable）。也就是说，作者们认为文档的哈希向量是从文档的特性（可以是TF-IDF值）产生的一组隐变量，这也被认为是一种编码的过程，是从文档的特性向量到哈希向量的编码。</p><p>在过去的模型中，编码过程是被反复关注的，但是解码过程则很少有模型去直接建模。所谓的解码过程就是从已经产生的哈希向量转换成为文档的特性向量的过程。也就是说，我们希望能够重新从哈希向量中生成原始的数据。</p><p>对原始数据和中间隐变量的编码过程统一进行建模，是当前神经网络生成式模型的一种标准方法。在这里，编码和解码都各自有不同的神经网络，用于表达相应的条件概率分布。</p><p>具体来说，数据的原始信息X首先经过一个多层感知网，然后再变换成为二元的中间变量Z。这时候，Z其实就是我们需要得到的哈希向量了。只不过在提出的模型中，还有第二个部分，那就是从Z得到X的一个重现，也就是我们刚才提到的利用哈希来重构数据。很明显，我们希望重构的X和原始的X之间要非常相似，也就是说距离最小。</p><p>作者们发现，从数据中学习一个二元编码是“信息论”（Information Theory）中典型的“有损源编码”（Lossy Source Coding）问题。因此，<strong>“语义哈希”其实也可以被看作是一个“比率损失平衡”（Rate Distortion Tradeoff）问题</strong>。</p><p>什么意思呢？就是说，我们希望用较少的比率来对信息进行编码，同时又希望从编码中重构的数据能够和原始的数据尽量相近。很明显，这两者有一点“鱼与熊掌不可兼得”的意思，也就是这两者需要一个平衡才能达到最优。</p><p>把重写模型的目标函数定为“比率损失平衡”，通过这种形式，作者们意识到模型中的从编码到重构数据的条件分布，也就是一个高斯分布中的<strong>方差值</strong>，其实控制了这个平衡的关系。那么，就需要针对不同的文档对这个方差值进行调整，从而达到最优的编码效果，同时又是比率损失平衡的。作者们并没有采用去优化这个方差值的办法，而是在一个固定的方差值周围加入一些随机噪声，从而在实际实验中收到了不错的效果。</p><h2>论文的实验结果</h2><p>作者们利用了三个数据集进行实验，所有的数据集都首先转换成为TF-IDF的形式。作者们把提出的方法和其他的五种基本方法进行了比较。</p><p>从总体上来说，文章提出的方法在没有随机噪声的情况下，已经比其他五种方法要好得多。加入随机噪声之后，模型就有了更好的表现力。同时，作者还展示了学到的二元哈希值的确能够保持语义信息，相同文本类别的文档，它们的哈希值非常类似，也就是我们之间说过的，他们之间的汉明距离很近。</p><h2>小结</h2><p>今天我为你讲了今年ACL的一篇最佳论文提名，至此，我们关于ACL 2018的分享就告一段落。</p><p>一起来回顾下要点：第一，这篇文章针对语义哈希产生过程的劣势，提出了“端到端”的语义哈希训练过程；第二，论文的核心方法是把文档生成语义哈希看作是一种编码和解码的流程，进一步发现“语义哈希”其实也可以被看作是一个“比率损失平衡”问题；第三，论文取得了不错的实验效果。</p><p>最后，给你留一个思考题，在现实中利用语义哈希，有没有什么障碍？比如要在推荐系统中做语义哈希，最大的挑战会是什么？</p><p>欢迎你给我留言，和我一起讨论。</p><p></p>
</div>
</div>

<div class="outline-2">
<h2 id="anchor31">复盘 7 | 一起来读人工智能国际顶级会议论文<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>今天我准备了 30 张知识卡，和你一起来复盘“人工智能国际顶级会议”模块。在这个模块里，我总共介绍了10个顶级会议，包括机器学习方面的ICML、NIPS；机器视觉的CVPR、ICCV；自然语言处理的ACL、EMNLP；数据挖掘和数据科学的KDD、WSDM；信息检索和搜索的SIGIR；互联网综合的WWW。</p>
<p><span class="reference">提示：点击知识卡跳转到你最想看的那篇文章，温故而知新。</span></p>
<h2>KDD 2017（数据挖掘与知识发现大会）论文精讲</h2>
<p><a href="https://time.geekbang.org/column/article/159"><img src="https://static001.geekbang.org/resource/image/10/06/10cb191bddde32920cfb9d48971ce806.jpg" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/391"><img src="https://static001.geekbang.org/resource/image/b7/cc/b77e0dd9b5422fc483605dfa18519fcc.jpg" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/394"><img src="https://static001.geekbang.org/resource/image/6e/42/6edea80c0a378d8e4a8196aa3cb34942.jpg" alt="" /></a></p>
<h2>EMNLP 2017（自然语言处理实证方法会议）论文精讲</h2>
<p><a href="https://time.geekbang.org/column/article/397"><img src="https://static001.geekbang.org/resource/image/99/0c/998b153a3e799873d0a74490b073170c.jpg" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/658"><img src="https://static001.geekbang.org/resource/image/32/d5/32bbe7013a33e4e6f4902e465104edd5.jpg" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/661"><img src="https://static001.geekbang.org/resource/image/76/3b/767fc3b2298a9705c7b2f731c7b12f3b.jpg" alt="" /></a></p>
<h2>ICCV 2017（国际计算机视觉大会）论文精讲</h2>
<p><a href="https://time.geekbang.org/column/article/2681"><img src="https://static001.geekbang.org/resource/image/55/38/55eb3ea8693c70200aafd3f5f4277038.jpg" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/2717"><img src="https://static001.geekbang.org/resource/image/fb/2f/fbb4b50ec209879b3d1e1da5a426212f.jpg" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/2782"><img src="https://static001.geekbang.org/resource/image/e2/03/e2bd4edfd5d3cc2b818d9e371584fe03.jpg" alt="" /></a></p>
<h2>NIPS 2017（神经信息处理系统大会）论文精讲</h2>
<p><a href="https://time.geekbang.org/column/article/2868"><img src="https://static001.geekbang.org/resource/image/61/2c/617ffdf73e8f41a36a11ac5ea5f0862c.jpg" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/2941"><img src="https://static001.geekbang.org/resource/image/11/27/115484986db70b94b363237a09d3d227.jpg" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/3211"><img src="https://static001.geekbang.org/resource/image/28/2a/2811bcf14a2e16759d6afaa8e15dcc2a.jpg" alt="" /></a></p>
<h2>WSDM 2018（网络搜索与数据挖掘国际会议）论文精讲</h2>
<p><a href="https://time.geekbang.org/column/article/3946"><img src="https://static001.geekbang.org/resource/image/80/ae/809abe856cc2482c2b8f80728dda82ae.jpg" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/3961"><img src="https://static001.geekbang.org/resource/image/5b/ec/5b47edfe3db4fec97e5b1975bdc983ec.jpg" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/4024"><img src="https://static001.geekbang.org/resource/image/e6/d5/e6d5f263155a9d7e8a964516dedfa4d5.jpg" alt="" /></a></p>
<h2>The Web 2018（国际万维网大会）论文精讲</h2>
<p><a href="https://time.geekbang.org/column/article/8106"><img src="https://static001.geekbang.org/resource/image/40/f7/40c75bfcf277690085923effd015e1f7.jpg" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/8234"><img src="https://static001.geekbang.org/resource/image/7d/95/7d273597ba638065e3b1286e07a4e495.jpg" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/8293"><img src="https://static001.geekbang.org/resource/image/80/9d/80b6558a51f71d7fc5eda9b3a31f5a9d.jpg" alt="" /></a></p>
<h2>CVPR 2018（国际计算机视觉与模式识别会议）论文精讲</h2>
<p><a href="https://time.geekbang.org/column/article/12010"><img src="https://static001.geekbang.org/resource/image/45/86/45b1fa4c83680b7be3e2247298a33086.jpg" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/12100"><img src="https://static001.geekbang.org/resource/image/ab/75/ab3714f22d7729600aaaa2fff2c8fa75.jpg" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/12190"><img src="https://static001.geekbang.org/resource/image/a8/9b/a867d7e402b26eef0ac152e24dc90a9b.jpg" alt="" /></a></p>
<h2>SIGIR 2018（国际信息检索大会）论文精讲</h2>
<p><a href="https://time.geekbang.org/column/article/11367"><img src="https://static001.geekbang.org/resource/image/e9/ba/e9384d0b367a2a54570b345acd7bf2ba.jpg" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/11636"><img src="https://static001.geekbang.org/resource/image/11/13/11039fa5ef4bae821c3b0e2313195f13.jpg" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/11851"><img src="https://static001.geekbang.org/resource/image/c2/dc/c21379bb9909723a3f1df50aa33fd9dc.jpg" alt="" /></a></p>
<h2>ICML 2018（国际机器学习大会）论文精讲</h2>
<p><a href="https://time.geekbang.org/column/article/12443"><img src="https://static001.geekbang.org/resource/image/6a/80/6aa4bbbe32cd70673416c1cd31705280.jpg" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/12648"><img src="https://static001.geekbang.org/resource/image/d3/6b/d3bffb14410259a1ca768447bd41f36b.jpg" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/12834"><img src="https://static001.geekbang.org/resource/image/09/2e/09dadd6ef090c20da82ba628caf5f52e.jpg" alt="" /></a></p>
<h2>ACL 2018（计算语言学学会年会）论文精讲</h2>
<p><a href="http://uhttps://time.geekbang.org/column/article/13014"><img src="https://static001.geekbang.org/resource/image/ad/4f/adc4f44971972753870205b15016244f.jpg" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/13193"><img src="https://static001.geekbang.org/resource/image/7c/77/7c2fca243d7761290af3286f7f20fa77.jpg" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/13276"><img src="https://static001.geekbang.org/resource/image/80/fd/8093da74b265592edd46f74dcb8f53fd.jpg" alt="" /></a></p>
<h2>积跬步以至千里</h2>
<p>学习是独立的，需要你一个人去完成。但学习者从来都不必孤独，我们走进这些国际顶级学术会议的论文，其实就是和每一篇论文背后的作者进行一场对话。与优秀的人同行一定能让我们走得更快。</p><!-- [[[read_end]]] -->
<p>这个模块我根据自己的经验，为你选择了10个顶级会议。针对每一个会议，我都会在会议结束后用3篇文章来详细剖析这个会议的精髓和一些前沿信息。我希望通过我的眼睛和思考让你看到在这个领域里那些激动人心的发展，收获新知、拓展视野，同时也把我的学习方法分享给你。</p>
<p>我想你应该已经掌握了我分析论文的套路了，对于每一篇文章，我一定会先去做一些背景研究，了解作者群，了解对应的学术机构或者公司信息；然后弄清楚论文解决了什么问题，核心贡献是什么；再详细研究论文的具体方法。这个方法很简单，就是牢牢抓住一个主线，找到最核心的内容来消化吸收。但是<strong>真正让这个方法内化成你的思维模式，还是需要大量的阅读和练习</strong>。相信我，如果想在人工智能领域继续深耕，阅读大量论文，一定是一个最值得做的投资，因为回报极大。</p>
<p>那回到阅读论文本身，最后想跟你分享的一点只有八个字：<strong>学好英语，阅读原文</strong>。我知道你可能会说我英语还真不好，但是到达能够阅读原文的水平其实也并没那么难。你不妨直接找一篇我们专栏里讲过的论文原文，就把每一段的第一句读一下，看看能否学到东西。先开始看起来，遇到不会的且影响你理解的单词或句子再去查，你的英语水平就已经开始变得越来越好了。</p>
<p>以上就是我们对论文精读这个模块的一个复盘，希望专栏里的这三十篇论文是一个起点，能够帮助你养成关注国际顶级会议、阅读论文的习惯，拥有这一强大的学习利器，提升自己的学习效率。</p>
<p>最后，关于这一模块，关于国际会议，或者是在论文阅读方面，你还有什么问题和想法，欢迎你留言和我讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor32">031 | 经典搜索核心算法：TF-IDF及其变种<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>从本周开始我们进入人工智能核心技术模块，本周我会集中讲解经典的搜索核心算法，今天先来介绍TF-IDF算法。</p>
<p>在信息检索（Information Retrieval）、文本挖掘（Text Mining）以及自然语言处理（Natural Language Processing）领域，TF-IDF算法都可以说是鼎鼎有名。虽然在这些领域中，目前也出现了不少以深度学习为基础的新的文本表达和算分（Weighting）方法，但是TF-IDF作为一个最基础的方法，依然在很多应用中发挥着不可替代的作用。</p>
<p>了解和掌握TF-IDF算法对初学者大有裨益，能够帮助初学者更快地理解其它更加深入、复杂的文本挖掘算法和模型。今天我就来谈谈TF-IDF的历史、算法本身的细节以及基于TF-IDF的几个变种算法。</p>
<h2>TF-IDF的历史</h2>
<p>把查询关键字（Query）和文档（Document）都转换成“向量”，并且尝试用线性代数等数学工具来解决信息检索问题，这样的努力至少可以追溯到20世纪70年代。</p>
<p>1971年，美国康奈尔大学教授杰拉德·索尔顿（Gerard Salton）发表了《SMART检索系统：自动文档处理实验》（The SMART Retrieval System—Experiments in Automatic Document Processing）一文，文中首次提到了把查询关键字和文档都转换成“向量”，并且给这些向量中的元素赋予不同的值。这篇论文中描述的SMART检索系统，特别是其中对TF-IDF及其变种的描述成了后续很多工业级系统的重要参考。</p>
<p>1972年，英国的计算机科学家卡伦·琼斯（Karen Spärck Jones）在《从统计的观点看词的特殊性及其在文档检索中的应用》（A Statistical Interpretation of Term Specificity and Its Application in Retrieval） 一文中第一次详细地阐述了IDF的应用。其后卡伦又在《检索目录中的词赋值权重》（Index Term Weighting）一文中对TF和IDF的结合进行了论述。可以说，卡伦是第一位从理论上对TF-IDF进行完整论证的计算机科学家，因此后世也有很多人把TF-IDF的发明归结于卡伦。</p>
<p>杰拉德本人被认为是“信息检索之父”。他1927年出生于德国的纽伦堡，并与1950年和1952年先后从纽约的布鲁克林学院获得数学学士和硕士学位，1958年从哈佛大学获得应用数学博士学位，之后来到康奈尔大学参与组建计算机系。为了致敬杰拉德本人对现代信息检索技术的卓越贡献，现在，美国计算机协会ACM（Association of Computing Machinery）每三年颁发一次“杰拉德·索尔顿奖”（Gerard Salton Award），用于表彰对信息检索技术有突出贡献的研究人员。卡伦·琼斯在1988年获得了第二届“杰拉德·索尔顿奖”的殊荣。</p>
<h2>TF-IDF算法详解</h2>
<p>要理解TF-IDF算法，第一个步骤是理解TF-IDF的应用背景。TF-IDF来源于一个最经典、也是最古老的信息检索模型，即“<strong>向量空间模型</strong>”（Vector Space Model）。</p>
<p>简单来说，<strong>向量空间模型就是希望把查询关键字和文档都表达成向量，然后利用向量之间的运算来进一步表达向量间的关系</strong>。比如，一个比较常用的运算就是计算查询关键字所对应的向量和文档所对应的向量之间的“<strong>相关度</strong>”。</p>
<p>因为有了向量的表达，相关度往往可以用向量在某种意义上的“<strong>相似度</strong>”来进行近似，比如<strong>余弦相似性</strong>（Cosine Similarity）或者是<strong>点积</strong>（Dot Product）。这样，相关度就可以用一个值来进行表达。不管是余弦相似度还是点积都能够从线性代数或者几何的角度来解释计算的合理性。</p>
<!-- [[[read_end]]] -->
<p>在最基本的向量空间模型的表达中，查询关键字或是文档的向量都有V维度。这里的V是整个词汇表（Vocabulary）的总长度。比如，我们如果有1万个常用的英文单词，那么这个V的取值就是1万，而查询关键字和每个文档的向量都是一个1万维的向量。 对于这个向量中的每一个维度，都表示英文中的一个单词，没有重复。</p>
<p>你可以看到，在这样的情况下，如果当前的词出现在这个向量所对应的文档或者关键字里，就用1来表达；如果这个词没出现，就用0来表达。这就是给每个维度赋值（Weighting）的最简单的方法。</p>
<p><strong>TF-IDF就是在向量空间模型的假设下的一种更加复杂的赋值方式。TF-IDF最基础的模式，顾名思义，就是TF和IDF的乘积</strong>。</p>
<p>TF其实是“<strong>单词频率</strong>”（Term Frequency）的简称。意思就是说，我们计算一个查询关键字中某一个单词在目标文档中出现的次数。举例说来，如果我们要查询“Car Insurance”，那么对于每一个文档，我们都计算“Car”这个单词在其中出现了多少次，“Insurance”这个单词在其中出现了多少次。这个就是TF的计算方法。</p>
<p>TF背后的隐含的假设是，查询关键字中的单词应该相对于其他单词更加重要，而文档的重要程度，也就是相关度，与单词在文档中出现的次数成正比。比如，“Car”这个单词在文档A里出现了5次，而在文档B里出现了20次，那么TF计算就认为文档B可能更相关。</p>
<p>然而，信息检索工作者很快就发现，仅有TF不能比较完整地描述文档的相关度。因为语言的因素，有一些单词可能会比较自然地在很多文档中反复出现，比如英语中的“The”、“An”、“But”等等。这些词大多起到了链接语句的作用，是保持语言连贯不可或缺的部分。然而，如果我们要搜索“How to Build A Car”这个关键词，其中的“How”、“To”以及“A”都极可能在绝大多数的文档中出现，这个时候TF就无法帮助我们区分文档的相关度了。</p>
<p>IDF，也就是“<strong>逆文档频率</strong>”（Inverse Document Frequency），就在这样的情况下应运而生。这里面的思路其实很简单，那就是我们需要去“惩罚”（Penalize）那些出现在太多文档中的单词。</p>
<p>也就是说，真正携带“相关”信息的单词仅仅出现在相对比较少，有时候可能是极少数的文档里。这个信息，很容易用“文档频率”来计算，也就是，有多少文档涵盖了这个单词。很明显，如果有太多文档都涵盖了某个单词，这个单词也就越不重要，或者说是这个单词就越没有信息量。因此，我们需要对TF的值进行修正，而IDF的想法是用DF的倒数来进行修正。倒数的应用正好表达了这样的思想，DF值越大越不重要。</p>
<p>在了解了TF和IDF的基本计算方法后，我们就可以用这两个概念的乘积来表达某个查询单词在一个目标文档中的重要性了。值得一提的是，虽然我们在介绍TF-IDF这个概念的时候，并没有提及怎么把查询关键字和文档分别表达成向量，其实TF-IDF算法隐含了这个步骤。</p>
<p>具体来说，对于查询关键字，向量的长度是V，也就是我们刚才说过的词汇表的大小。然后其中关键字的单词出现过的维度是1，其他维度是0。对于目标文档而言，关键词出现过的维度是TF-IDF的数值，而其他维度是0。在这样的表达下，如果我们对两个文档进行“点积”操作，则得到的相关度打分（Scoring）就是TF-IDF作为相关度的打分结果。</p>
<h2>TF-IDF算法变种</h2>
<p>很明显，经典的TF-IDF算法有很多因素没有考虑。在过去的很长一段时间里，研究人员和工程师开发出了很多种TF-IDF的变种。这里我介绍几个经典的变种。</p>
<p>首先，很多人注意到TF的值在原始的定义中没有任何上限。虽然我们一般认为一个文档包含查询关键词多次相对来说表达了某种相关度，但这样的关系很难说是线性的。拿我们刚才举过的关于“Car Insurance”的例子来说，文档A可能包含“Car”这个词100次，而文档B可能包含200次，是不是说文档B的相关度就是文档A的2倍呢？其实，很多人意识到，超过了某个阈值之后，这个TF也就没那么有区分度了。</p>
<p><strong>用Log，也就是对数函数，对TF进行变换，就是一个不让TF线性增长的技巧</strong>。具体来说，人们常常用1+Log(TF)这个值来代替原来的TF取值。在这样新的计算下，假设“Car”出现一次，新的值是1，出现100次，新的值是5.6，而出现200次，新的值是6.3。很明显，这样的计算保持了一个平衡，既有区分度，但也不至于完全线性增长。</p>
<p>另外一个关于TF的观察则是，经典的计算并没有考虑“长文档”和“短文档”的区别。一个文档A有3,000个单词，一个文档B有250个单词，很明显，即便“Car”在这两个文档中都同样出现过20次，也不能说这两个文档都同等相关。<strong>对TF进行“标准化”（Normalization），特别是根据文档的最大TF值进行的标准化，成了另外一个比较常用的技巧</strong>。</p>
<p><strong>第三个常用的技巧，也是利用了对数函数进行变换的，是对IDF进行处理</strong>。相对于直接使用IDF来作为“惩罚因素”，我们可以使用N+1然后除以DF作为一个新的DF的倒数，并且再在这个基础上通过一个对数变化。这里的N是所有文档的总数。这样做的好处就是，第一，使用了文档总数来做标准化，很类似上面提到的标准化的思路；第二，利用对数来达到非线性增长的目的。</p>
<p>还有一个重要的TF-IDF变种，则是对查询关键字向量，以及文档向量进行标准化，使得这些向量能够不受向量里有效元素多少的影响，也就是不同的文档可能有不同的长度。在线性代数里，可以把向量都标准化为一个单位向量的长度。这个时候再进行点积运算，就相当于在原来的向量上进行余弦相似度的运算。所以，另外一个角度利用这个规则就是直接在多数时候进行余弦相似度运算，以代替点积运算。</p>
<h2>小结</h2>
<p>今天我为你讲了文档检索领域或者搜索领域里最基本的一个技术：TF-IDF。我们可以看到，TF-IDF由两个核心概念组成，分别是词在文档中的频率和文档频率。TF-IDF背后隐含的是基于向量空间模型的假设。</p>
<p>一起来回顾下要点：第一，简要介绍了TF-IDF的历史。第二，详细介绍了TF-IDF算法的主要组成部分。第三，简要介绍了TF-IDF的一些变种 。</p>
<p>最后，给你留一个思考题，如果要把TF-IDF应用到中文环境中，是否需要一些预处理的步骤？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor33">032 | 经典搜索核心算法：BM25及其变种（内附全年目录）<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>周一我们讲了TF-IDF算法和它的四个变种，相对于TF-IDF而言，在信息检索和文本挖掘领域，BM25算法则更具理论基础，而且是工程实践中当仁不让的重要基线（Baseline）算法 。BM25在20世纪70年代到80年代被提出，到目前为止已经过去二三十年了，但是这个算法依然在很多信息检索的任务中表现优异，是很多工程师首选的算法之一。</p>
<p>今天我就来谈谈BM25算法的历史、算法本身的核心概念以及BM25的一些重要变种，帮助你快速掌握这个信息检索和文本挖掘的利器。</p>
<h2>BM25的历史</h2>
<p>BM25，有时候全称是Okapi BM25，是由英国一批信息检索领域的计算机科学家开发的排序算法。这里的“BM”是“最佳匹配”（Best Match）的简称。</p>
<p>BM25背后有两位著名的英国计算机科学家。第一位叫斯蒂芬·罗伯逊（Stephen Robertson）。斯蒂芬最早从剑桥大学数学系本科毕业，然后从城市大学（City University）获得硕士学位，之后从伦敦大学学院（University College London）获得博士学位。斯蒂芬从1978年到1998年之间在城市大学任教。1998年到2013年间在微软研究院剑桥实验室工作。我们之前提到过，美国计算机协会ACM现在每三年颁发一次“杰拉德·索尔顿奖”，用于表彰对信息检索技术有突出贡献的研究人员。2000年这个奖项颁给斯蒂芬，奖励他在理论方面对信息检索的贡献。BM25可谓斯蒂芬一生中最重要的成果。</p>
<p>另外一位重要的计算机科学家就是英国的卡伦·琼斯（Karen Spärck Jones）。周一我们在TF-IDF的文章中讲过。卡伦也是剑桥大学博士毕业，并且毕生致力于信息检索技术的研究。卡伦的最大贡献是发现IDF以及对TF-IDF的总结。卡伦在1988年获得了第二届“杰拉德·索尔顿奖”。</p>
<h2>BM25算法详解</h2>
<p>现代BM25算法是用来计算某一个目标文档（Document）相对于一个查询关键字（Query）的“相关性”（Relevance）的流程。通常情况下，BM25是“非监督学习”排序算法中的一个典型代表。</p>
<p>顾名思义，这里的“非监督”是指所有的文档相对于某一个查询关键字是否相关，这个信息是算法不知道的。也就是说，算法本身无法简单地从数据中学习到相关性，而是根据某种经验法则来“猜测”相关的文档都有什么特质。</p>
<p>那么BM25是怎么定义的呢？我们先来看传统的BM25的定义。一般来说，<strong>经典的BM25分为三个部分</strong>：</p>
<!-- [[[read_end]]] -->
<ol>
<li>
<p>单词和目标文档的相关性</p>
</li>
<li>
<p>单词和查询关键词的相关性</p>
</li>
<li>
<p>单词的权重部分</p>
</li>
</ol>
<p>这三个部分的乘积组成某一个单词的分数。然后，整个文档相对于某个查询关键字的分数，就是所有查询关键字里所有单词分数的总和。</p>
<p>我们先从第一部分说起，即单词和目标文档的相关性。这里相关性的基本思想依然是“词频”，也就是TF-IDF里面TF的部分。词频就是单词在目标文档中出现的次数。如果出现的次数比较多，一般就认为更相关。和TF-IDF不同，BM25最大的贡献之一就是挖掘出了词频和相关性之间的关系是非线性的，这是一个初看有违常理但细想又很有道理的洞察。</p>
<p>具体来说，每一个词对于文档相关性的分数不会超过一个特定的阈值。这个阈值当然是动态的，根据文档本身会有调整。这个特征就把BM25里的词频计算和一般的TF区分开了。也就是说，词频本身需要“标准化”（Normalization），要达到的效果是，某一个单词对最后分数的贡献不会随着词频的增加而无限增加。</p>
<p>那BM25里词频的标准化是怎么做的呢？就是某一个词的词频，除以这个词的词频加上一个权重。这个权重包含两个超参数（Hyper-parameter），这些超参数后期是可以根据情况手动调整的。这个做法在非监督的排序算法中很普遍。同时，这个权重还包括两个重要信息：第一，当前文档的长度；第二，整个数据集所有文档的平均长度。</p>
<p>这几个因素混合在一起，我们就得到了一个新的词频公式，既保证单词相对于文档的相关度和这个单词的词频呈现某种正向关系，又根据文档的相对长度，也就是原始长度和所有文档长度的一个比值关系，外加一些超参数，对词频进行了限制。</p>
<p>有了单词相对于文档的相关度计算公式作为基础，单词相对于查询关键字的相关度可以说是异曲同工。首先，我们需要计算单词在查询关键字中的词频。然后，对这个词频进行类似的标准化过程。</p>
<p>和文档的标准化过程唯一的区别，这里没有采用文档的长度。当然，对于查询关键字来说，如果需要使用长度，也应该是使用查询关键字的长度和平均长度。但是，根据BM25经典公式来说，这一部分并没有使用长度信息进行重新标准化。</p>
<p>接着我来谈谈最后一个部分，单词权重的细节，通常有两种选择。</p>
<p><strong>第一种选择就是直接采用某种变形的IDF来对单词加权</strong>。一般来说，IDF就是利用对数函数（Log函数）对“文档频率”，也就是有多少文档包含某个单词信息进行变换。这里回顾一下周一讲的内容，IDF是“文档频率”的倒数，并且通过对数函数进行转换。如果在这里使用IDF的话，那么整个BM25就可以看作是一个某种意义下的TF-IDF，只不过TF的部分是一个复杂的基于文档和查询关键字、有两个部分的词频函数。</p>
<p><strong>第二种单词的权重选择叫作“罗伯逊-斯巴克-琼斯”权重（Robertson-Spärck-Jones），简称RSJ值</strong>，是由计算机科学家斯蒂芬·罗伯逊和卡伦·琼斯合作发现。我们刚才讲过，这两位都是重要的信息检索学术权威。这个权重其实就是一个更加复杂版本的IDF。一个关键的区别是RSJ值需要一个监督信息，就是要看文档对于某个查询关键字是否相关，而IDF并不需要。</p>
<p>对比以上两种思路，在很多情况下，利用IDF来直接进行单词权重的版本更加普遍。如果在有监督信息的情况下，RSJ值也不失为一个很好的选择。</p>
<p>通过这里简单的介绍，我们可以很容易地发现，<strong>BM25其实是一个经验公式</strong>。这里面的每一个成分都是经过很多研究者的迭代而逐步发现的。很多研究在理论上对BM25进行了建模，从“概率相关模型”（Probabilistic Relevance Model）入手，推导出<strong>BM25其实是对某一类概率相关模型的逼近</strong>。对这一部分我在这里就不展开论述了。需要你记住的是，BM25虽然是经验公式，但是在实际使用中经常表现出惊人的好效果。因此，很有必要对这一类文档检索算法有所了解。</p>
<h2>BM25算法变种</h2>
<p>由于BM25的情况，一方面是经验公式，另一方面是某种理论模型的逼近，这样就出现了各式各样的BM25变种。这里我仅仅介绍一些有代表性的扩展。</p>
<p>一个重要的扩展是<strong>BM25F</strong>，也就是在BM25的基础上再多个“域”（Field）文档上的计算。这里“域”的概念可以理解成一个文档的多个方面。比如，对于很多文档来说，文档包括标题、摘要和正文。这些组成部分都可以认为是不同的“域”。那么，如何结合不同的“域”，让文档的相关性能够统一到一个分数上就是BM25F的核心内容。</p>
<p>具体来说，BM25F对于BM25的扩展很直观。那就是每一个单词对于文档的相关性是把各个域当做一个“小文档”的加权平均。也就是说，我们先把每个域当做单独的文档，计算词频，进行标准化。然后集合每个域的值，进行加权平均，再乘以词的权重（我们上面提到了，用IDF或者是RSJ值）。</p>
<p>另外一个重要的扩展就是<strong>把BM25和其他文档信息（非文字）结合起来</strong>。这个想法是在“学习排序”（Learning To Rank）这一思路出现以前的一种普遍的做法，往往就是用线性加权的形式直接把各种信息相结合。例如，在21世纪初期比较流行的做法是用BM25和PageRank的线性结合来确定网页的相关度。这里面，BM25是和某个查询关键字有联系的信息，而PageRank则是一个网页的总体权重。</p>
<h2>小结</h2>
<p>今天我为你讲了文档检索领域或者说搜索领域里最基本的一个技术：BM25。我们可以看到，BM25由三个核心的概念组成，包括词在文档中相关度、词在查询关键字中的相关度以及词的权重。BM25是一个长期积累的经验公式，也有很深的理论支持，是一个强有力的非监督学习方法的文本排序算法。</p>
<p>一起来回顾下要点：第一，简要介绍了BM25的历史。第二，详细介绍了BM25算法的三个主要组成部分。第三，简要地介绍了BM25的一些变种 。</p>
<p>最后，给你留一个思考题，虽然BM25是非监督的排序方法，并且我们提到其中有一些超参数，那么是否可以通过机器学习的手段来学习到这些超参数的最佳取值呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<hr />
<p><img src="https://static001.geekbang.org/resource/image/5c/08/5c89fe07fe0e5a5f1e4f8491ac592408.jpg" alt="" /></p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor34">033 | 经典搜索核心算法：语言模型及其变种<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>在信息检索和文本挖掘领域，我们之前已经讲过了TF-IDF算法和BM25算法。TF-IDF因其简单和实用常常成为很多信息检索任务的第一选择，BM25则以其坚实的经验公式成了很多工业界实际系统的重要基石。</p>
<p>然而，在信息检索研究者的心里，一直都在寻找一种既容易解释，又能自由扩展，并且在实际使用中效果显著的检索模型。这种情况一直到20世纪90年代末、21世纪初才得到了突破，一种叫“语言模型”（Language Model）的新模型得到发展。其后10多年的时间里，以语言模型为基础的各类变种可谓层出不穷，成了信息检索和搜索领域的重要研究方向。</p>
<p>今天我就来谈谈语言模型的历史，算法细节和语言模型的重要变种，帮助初学者快速掌握这一模型。</p>
<h2>语言模型的历史</h2>
<p>语言模型在信息检索中的应用开始于1998年的SIGIR大会（International ACM SIGIR Conference on Research and Development in Information Retrieval，国际信息检索大会）。来自马萨诸塞州大学阿姆赫斯特分校（UMass Amherst）的信息检索学者杰·庞特（Jay M. Ponte）和布鲁斯·夸夫特（W. Bruce Croft）发表了第一篇应用语言模型的论文，从此开启了一个新的时代。</p>
<p>布鲁斯是信息检索的学术权威。早年他在英国的剑桥大学获得博士学位，之后一直在马萨诸塞州大学阿姆赫斯特分校任教。他于2003年获得美国计算机协会ACM颁发的“杰拉德·索尔顿奖”，表彰他在信息检索领域所作出的突出贡献。另外，布鲁斯也是ACM院士。</p>
<p>从那篇论文发表之后，华人学者翟成祥对于语言模型的贡献也是当仁不让。他的博士论文就是系统性论述语言模型的平滑技术以及各类语言模型的深刻理论内涵。</p>
<p>翟成祥来自中国的南京大学计算机系，并于1984年、1987年和1990年分别获得南京大学的学士、硕士和博士学位，2002年他从美国卡内基梅隆大学计算机系的语言与信息技术研究所获得另外一个博士学位。</p>
<p>翟成祥曾经获得过2004年的美国国家科学基金会职业生涯奖（NSF CAREER Award）和2004年ACM SIGIR最佳论文奖。另外，2004年翟成祥还获得了著名的美国总统奖（PECASE，Presidential Early Career Award for Scientists and Engineers）。</p>
<h2>语言模型详解</h2>
<p><strong>语言模型的核心思想是希望用概率模型（Probabilistic Model）来描述查询关键字和目标文档之间的关系</strong>。语言模型有很多的类型，最简单的、也是最基础的叫做“<strong>查询关键字似然检索模型</strong>”（Query Likelihood Retrieval Model）。下面我就来聊一聊这个模型的一些细节。</p>
<!-- [[[read_end]]] -->
<p>首先，我来描述什么是语言模型。简单来说，<strong>一个语言模型就是一个针对词汇表的概率分布</strong>。比如，词汇表总共有一万个英语单词，那么一个语言模型就是定义在这一万个单词上的离散概率分布。拿骰子来做类比，这里的骰子就有一万种可能性。</p>
<p>一旦语言模型的概念形成。“查询关键字似然检索模型”的下一步，就是认为查询关键字是从一个语言模型中“抽样”（Sample）得到的一个样本。什么意思呢？ 就是说，和我们通常情况下从一个概率分布中抽样相同，“查询关键字似然检索模型”认为查询关键字是从这个语言模型的概率分布中进行采样，从而产生的一个随机过程。这一观点不仅是这个简单语言模型的假设，也是很多语言模型的核心假设。</p>
<p>我们假设这个语言模型，也就是这个概率分布的参数已知，那么，如何来对一个查询关键字打分（Scoring）就变成了计算在这个概率分布的情况下，一组事件，也就是这组词出现的<strong>联合概率</strong>。现实中，因为联合概率可能会很小，因此很多时候都通过一个<strong>对数变换</strong>来把概率的乘积变成概率对数的加和。</p>
<p>然而，现实情况是，我们事先并不知道这个语言模型的参数，这个信息一般来说是未知的。</p>
<p>要想确定这个语言模型的参数，我们<strong>首先要确定语言模型的形态</strong>。我刚才说过，语言模型本质上就是定义在词汇表上的离散概率分布。那么，这里就有几种经典的选择。首先，<strong>我们可以选择“类别分布”（Categorical Distribution）函数</strong>，也就是多项分布（Multinomial Distribution）去除排列组合信息。这也是最常见的语言模型的实现形式。</p>
<p>在类别分布的假设下，我们认为每一个单词都是从类别分布中采样得到的结果，而单词之间互相独立。那么，定义在一万个单词上的类别分布就有一万个参数。每个参数代表所对应的单词出现的概率，或者说可能性。当然，这个参数是未知的。</p>
<p>除了利用类别分布或者多项分布来对语言模型建模以外，其他的离散概率分布也都曾被提出来用作语言模型。比如，伯努利分布（Bernoulli Distribution）或者泊松分布（Poisson Distribution）。这些不同的假设我今天就不展开讲了。但是在实际应用中，其他概率分布假设的语言模型基本上都还属于纯研究状态。</p>
<p>还是回到刚才说的基于类别分布的语言模型。由于参数是未知的，那么问题的核心就变成了<strong>如何估计这样的参数</strong>，这里就回归到基本的统计参数估计的范畴。</p>
<p>因为类别分布是概率分布，在有观测数据的情况下（这个的观测数据就是现实中的文档和查询关键字），最直接的参数估计算法叫“<strong>最大似然估计</strong>”（Maximum Likelihood Estimation）。在这里我不展开这个算法的细节。</p>
<p><strong>最大似然估计的核心思路就是把参数估计问题变换成一个最大化的优化问题，从而通过求解这个优化问题来达到参数估计的目的</strong>。在类别分布的假设下，最大似然估计的最优参数解，恰好有解析形式。</p>
<p>也就是说，在有数据的情况下，我们能够得到一个唯一的最优的参数估计。而且这个解非常直观，也就是每个单词出现的可能性，正好等于这个单词在目标文档中出现的次数，除以所有单词在目标文档中出现的次数。换句话说，每个单词的参数正好等于单词出现的频率。</p>
<p>这样的话，每个文档都对应一个类别分布。有多少个文档就有多少个类别分布，而且每个类别分布都可以从自己这个文档中求得所有的参数。</p>
<p>最大似然估计有一个很大的问题，那就是如果某一个单词没有在训练数据中出现过，那么这个单词的参数，根据上面的最优解，就是零。</p>
<p>什么意思呢？也就是说，在最大似然估计的情况下，没有出现过的单词的参数是零，然后模型认为这个词出现的可能性、或者概率就是零。这显然是一个非常悲观的估计。因为你可以认为，不管在任何情况下，就算一个单词没有出现过，但是出现的概率也不应该绝对是零。</p>
<p>那么，如何针对这些为“零”的概率估计，就成了语言模型研究和实践中的一个重要问题。一个通常的技术叫“<strong>平滑</strong>”（Smoothing）。这个技术的基本思想就是，给这些因为最大似然估计所产生的零值一些非零的估计值。<strong>最简单的一个做法，其实也是很有效的一个做法，就是通过整个数据集的频率来做平滑</strong>。</p>
<p>具体来说，就是对于每一个词，我们计算一个目标文档的频率，同时也计算一个全数据集的平率。然后这个单词的最终估计值，是这两个频率的一个加权平均。这个权重就成了另外一组超参数，可以动态调整。</p>
<p><strong>另外一个常见的平滑策略是借助贝叶斯统计推断（Bayesian Inference）的方法</strong>。也就是说，为类别概率分布加上一个先验分布，通常是狄利克雷分布（Dirichlet Distribution），并且计算出某个单词在先验分布和数据都存在情况下的后验概率，我这里就不展开这个思路了。</p>
<p>在这里需要注意的是，经过研究人员发现，语言模型的平滑其实是不可或缺的。一方面是为了解决我们刚才提到的零概率估计问题；另一方面，经过一个代数变形，语言模型的平滑其实可以写成一个类似TF-IDF的形式。</p>
<p>于是，研究人员指出，这个平滑其实削减了过分流行词汇的概率，使最后的估计值并不完全只是由单词的多少而决定。我在之前介绍TF-IDF算法和BM25算法的时候，都分别提到了这个观点，那就是单词出现的多少和相关性的关系问题。从经验上看，这个关系一定是有一个阈值的。</p>
<h2>语言模型变种</h2>
<p>语言模型有很多类型的变种，我这里简单地提两个比较有代表的方向。</p>
<p><strong>一个方向就是我刚才说的不同类型的平滑策略</strong>，比如，结合全数据集平滑和狄利克雷平滑。或者是先把文档分成一些聚类或者不同的类别（例如不同的话题），然后根据不同的类别或者话题进行平滑等等。</p>
<p><strong>另外一个方向其实就是在语言模型本身的的定义上做文章</strong>。比如，在查询关键字似然检索模型里，我们假定有一个语言模型，查询关键字是这个模型的一个抽样。乍一看这很有道理，但是仔细一想，这个模型并没有明说目标文档和查询关键字之间的关系。目标文档进入视野完全是为了估计这个语言模型的参数，“相关性”这个概念并没有明确定义。</p>
<p>那么，另外一个主流的语言模型，就是认为有两个模型（分布）。查询关键字从一个分布中产生，目标文档从另外一个分布中产生，而这两个分布的距离，成为了相关性的定义。在这样的结构下，文档和查询关键字形成了一种对称的局面，而相关性也根据距离直接得到定义。</p>
<h2>小结</h2>
<p>今天我为你讲了文档检索领域或者说搜索技术里一个很有理论深度的技术：语言模型。我们可以看到，语言模型相对于TF-IDF以及BM25而言，其实更加直观，更好理解。语言模型也是一个强有力的非监督学习方法的文本排序算法。</p>
<p>一起来回顾下要点：第一，简要介绍了语言模型的历史。第二，详细介绍了简单语言模型，即“查询关键字似然检索模型”的主要组成部分。第三，简要地介绍了语言模型的两个变种方向。</p>
<p>最后，给你留一个思考题，如果根据语言模型，也就是概率分布函数的估计，无法得到我们之前提到的最优解析解的话，我们应该怎么求解语言模型的参数呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor35">034 | 机器学习排序算法：单点法排序学习<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>在专栏里我们已经讲解过最经典的信息检索技术。这些技术为2000年之前的搜索引擎提供了基本的算法支持。不管是TF-IDF、BM25还是语言模型（Language Model），这些方法和它们的各类变种在很多领域（不限文本）都还继续发挥着作用。</p>
<p>然而，自从机器学习的思想逐渐渗透到信息检索等领域之后，一个最直观的想法就是如何用机器学习来提升信息检索的性能水平。这个思想引领了2000年到2010年这个领域的研究，产生了各类基于机器学习的排序算法，也带来了搜索引擎技术的成熟和发展。</p>
<p>我今天就从最简单也是最实用的一类机器学习排序算法讲起，那就是单点法排序学习（Pointwise Learning to Rank）。这类方法在工业界非常实用，得到广泛应用，在实际效果中也表现得很强健（Robust）。同时，理解这类模型可以为后面学习复杂的排序算法打下基础。</p>
<h2>单点法排序学习的历史</h2>
<p>早在1992年，德国学者诺伯特·福尔（Norbert Fuhr）就在一篇论文中最早尝试了用机器学习来做搜索系统参数估计的方法。三年之前，他还发表过一篇利用“多项式回归”（Polynomial Regression）来做类似方法的论文。诺伯特因其在信息检索领域的长期贡献，于2012年获得美国计算机协会ACM颁发的“杰拉德·索尔顿奖”。</p>
<p>1992年，加州大学伯克利分校的一批学者在SIGIR上发表了一篇论文，文中使用了“对数几率”（Logistic Regression）分类器来对排序算法进行学习。可以说这篇论文是最早利用机器学习思维来解决排序算法学习的尝试。然而，由于机器学习和信息检索研究在当时都处于起步阶段，这些早期结果并不理想。</p>
<p>2000年之后支持向量机在工业界和学术界逐渐火热，随之，利用机器学习进行排序算法训练重新进入人们的视野。搜索引擎成了第一次互联网泡沫的重要阵地，各类搜索引擎公司都开始投入使用机器学习来提升搜索结果的精度。这股思潮开启了整整十年火热的机器学习排序算法的研究和开发。</p>
<h2>单点法排序学习详解</h2>
<p>要想理解单点法排序学习，首先要理解一些基本概念。这些基本概念可以帮助我们把一个排序问题转换成一个机器学习的问题设置，特别是监督学习的设置。</p>
<p>我之前介绍的传统搜索排序算法比如TF-IDF、BM25以及语言模型，都是无监督学习排序算法的典范，也就是算法本身事先并不知道哪些文档对于哪些关键字是“相关”的。这些算法其实就是“猜测”相关性的一个过程。因此，传统信息检索发展出一系列理论来知道算法对每一个“关键字和文档对”（Query-Document Pair）进行打分，寄希望这样的分数是反映相关性的。</p>
<p>然而，从现代机器学习的角度看，毫无疑问，这样的排序算法不是最优的，特别是当相关信息存在的时候，是可以直接用这些相关信息来帮助算法提升排序精度的。</p>
<p><strong>要想让训练排序算法成为监督学习，首先来看需要什么样的数据集</strong>。我们要建模的对象是针对每一个查询关键字，对所有文档的一个配对。也就是说，每一个训练样本至少都要包含查询关键字和某个文档的信息。这样，针对这个训练样本，就可以利用相关度来定义样本的标签。</p>
<!-- [[[read_end]]] -->
<p>在极度简化的情况下，如果标签定义为，某个文档针对某个关键字是否相关，也就是二分标签，训练排序算法的问题就转换成了二分分类（Binary Classification）的问题。这样，任何现成的二分分类器，几乎都可以在不加更改的情况下直接用于训练排序算法。比如经典的“对数几率”分类器或者支持向量机都是很好的选择。</p>
<p>我们说这样的方法是“单点法排序学习”（Pointwise Learning to Rank）是因为每一个训练样本都仅仅是某一个查询关键字和某一个文档的配对。它们之间是否相关，完全不取决于其他任何文档，也不取决于其他关键字。也就是说，我们的学习算法是孤立地看待某个文档对于某个关键字是否相关，而不是关联地看待问题。显然，单点法排序学习是对现实的一个极大简化，但是对于训练排序算法来说是一个不错的起点。</p>
<p><strong>知道了如何构建一个训练集以后，我们来看一看测试集，重点来看如何评估排序算法的好坏</strong>。测试集里的数据其实和训练集非常类似，也是“查询关键字和文档对”作为一个样本。标签也是这个“配对”的相关度信息。前面说了，如果这是一个二分的相关信息，那么评估排序算法其实也就变成了如何评估二分分类问题。</p>
<p><strong>对二分分类问题来说，有两个主要的评价指标：第一，精度（Precision）</strong>，也就是说，在所有分类器已经判断是相关的文档中，究竟有多少是真正相关的；<strong>第二，召回（Recall）</strong>，即所有真正相关的文档究竟有多少被提取了出来。</p>
<p>因为是排序问题，和普通二分分类问题不太一样的是，这里就有一个<strong>Top-K问题</strong>。什么意思呢？就是说，针对某一个查询关键字，我们不是对所有的文档进行评估，而只针对排序之后的最顶部的K个文档进行评估。</p>
<p>在这样的语境下，精度和召回都是定义在这个K的基础上的。要是没有这个K的限制，在全部数据情况下，精度和召回都退回到了“准确度”，这个最基本的分类问题的评估测量情形。</p>
<p>在实际的应用中，K的取值往往是很小的，比如3、5、10或者25，而可能被评分的文档的数量是巨大的，理论上来说，任何一个文档对于任何一个查询关键字来说都有可能是潜在相关对象。所以，在评价排序算法的时候，这个K是至关重要的简化问题的方法。</p>
<p><strong>除了精度和召回以外，信息检索界还习惯用F1值对排序算法进行评估</strong>。简单来说，F1值就是精度和召回“和谐平均”（Harmonic Mean）的取值。也就是说，F1结合了精度和召回，并且给出了一个唯一的数值来平衡这两个指标。需要指出的是，在很多实际情况中，精度和召回是类似于“鱼与熊掌不可兼得”的一组指标。所以，F1值的出现让平衡这两个有可能产生冲突的指标变得更加方便。</p>
<p>刚才我说的评估主要是基于二分的相关信息来说的。而相关的标签信息其实可以定义为更加丰富的多元相关信息。比如，针对某一个查询关键字，我们不再只关心某个文档是否相关，而是给出一个相关程度的打分，从“最相关”、“相关”、“不能确定”到“不相关”、“最不相关”，一共五级定义。在这种定义下，至少衍生出了另外两个评价排序算法的方法。</p>
<p><strong>我们可以使用多类分类（Multi-Class Classification）的评价方法，也就是把五级相关度当做五种不同的标签，来看分类器的分类准确度</strong>。当然，这样的评价方式对于排序来说是有问题的。因为，对于一个实际的数据集来说，五种相关类型所对应的数据量是不同的。</p>
<p>一般来说，“最相关”和“相关”的文档数量，不管是针对某个查询关键字还是从总体上来看，都是比较少的，而“不相关”和“最不相关”的文档是大量的。因此，单单看分类准确度，很可能会得出不恰当的结果。</p>
<p>比如说，某个排序算法能够通过分类的手段把大量的“最不相关”和“不相关”的文档分类正确，而可能错失了所有的“最相关”文档。即便从总的分类准确度来说，这样的算法可能还“看得过去”，但实际上这样的算法并没有任何价值。所以，从多类分类的角度来评价排序算法是不完整的。</p>
<p>针对这样的情况，研究者们设计出了<strong>基于五级定义的排序评价方法：NDCG（Normalized Discounted Cumulative Gain）</strong>。在这里针对NDCG我就不展开讨论了，你只需要知道NDCG不是一个分类的准确度评价指标，而是一个排序的精度指标。</p>
<p>NDCG这个指标的假设是，在一个排序结果里，相关信息要比不相关信息排得更高，而最相关信息需要排在最上面，最不相关信息排在最下面。任何排序结果一旦偏离了这样的假设，就会受到“扣分”或者说是“惩罚”。</p>
<p>需要特别指出的是，我们这里讨论的NDCG仅仅是针对测试集的一个排序评价指标。我们的排序算法依然可以在训练集上从五级相关度上训练多类分类器。仅仅是在测试集上，采用了不同的方法来评价我们的多类分类器结果，而不是采用传统的分类准确度。从某种意义上来说，这里的NDCG其实就起到了“<strong>模型选择</strong>”（Model Selection）的作用。</p>
<h2>小结</h2>
<p>今天我为你讲了单点法排序学习。可以看到，整个问题的设置已经与传统的文字搜索技术有了本质的区别 。</p>
<p>一起来回顾下要点：第一，单点法排序学习起步于20世纪90年代，直到2000年后才出现了更多有显著效果的研究。第二，详细介绍了单点法排序学习的问题设置，包括训练集、测试集以及测试环境。</p>
<p>最后，给你留一个思考题，有没有什么方法可以把我们之前讨论的TF-IDF、BM25和语言模型，这些传统的排序算法和单点法排序学习结合起来？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor36">035 | 机器学习排序算法：配对法排序学习<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>周一的文章里我分享了最基本的单点法排序学习（Pointwise Learning to Rank）。这个思路简单实用，是把经典的信息检索问题转化为机器学习问题的第一个关键步骤。简单回顾一下，我们介绍了在测试集里使用NDCG（Normalized Discounted Cumulative Gain），在某个K的位置评价“精度”（Precision）和“召回”（Recall），以这些形式来评估排序算法。</p>
<p>你可以看到，单点法排序学习算法的模式和我们最终需要的结果中间还存在明显差距。这个差距并不是算法好坏能够决定的，而是算法所要优化的目标，也就是单个数据点是否相关，和我们的最终目的，一组结果的NDCG排序最优之间的结构化区别。这个结构化区别激发研究者们不断思考，是不是有其他的方法来优化排序算法。</p>
<p>今天我就来讲从单点法引申出来的“配对法”排序学习（Pairwise Learning to Rank） 。相对于尝试学习每一个样本是否相关，配对法的基本思路是对样本进行两两比较，从比较中学习排序，离真正目标又近了一步。</p>
<h2>配对法排序学习的历史</h2>
<p>当人们意识到用机器学习来对排序进行学习，从文档与文档之间的相对关系入手，也就是配对法，就成了一个非常火热的研究方向。机器学习排序这个领域持续活跃了10多年，在此期间很多配对法排序算法被提出，下面我就说几个非常热门的算法。</p>
<p>2000年左右，研究人员开始利用支持向量机（SVM）来训练排序算法，来自康奈尔的索斯藤·乔基姆斯（Thorsten Joachims）就构建了基于特征差值的<strong>RankSVM</strong>，一度成为配对法排序学习的经典算法。索斯藤我们前面讲过，他获得了今年的KDD时间检验奖。</p>
<p>2005年，当时在雅虎任职的研究人员郑朝晖等人，开始尝试用<strong>GBDT</strong>（Gradient Boosting Decision Tree，梯度提升决策树）这样的树模型来对文档之间的两两关系进行建模。郑朝晖后来成为一点资讯的联合创始人。</p>
<p>2005年，微软的学者克里斯·博格斯（Chris Burges）等人，开始使用神经网络训练<strong>RankNet</strong>文档之间两两关系的排序模型。这是最早使用深度学习模型进行工业级应用的尝试。这篇论文在2015年获得了ICML 2015（International Conference on Machine Learning，国际机器学习大会）的10年“经典论文奖”。</p>
<h2>配对法排序学习详解</h2>
<p>在介绍配对法排序学习的中心思路之前，我们先来重温一下测试集的测试原理。总体来说，测试的原理和单点法一样，都是要考察测试集上，对于某一个查询关键字来说，某一组文档所组成的排序是否是最优的。</p>
<p>比如，对于某一个查询关键字，我们针对排序产生的“顶部的K”个文档进行评估，首先查看精度（Precision），即在所有算法已经判断是相关的文档中，究竟有多少是真正相关的；其次看召回（Recall），即所有真正相关的文档究竟有多少被提取了出来。当然，还有F1值，也就是精度和召回“和谐平均”（Harmonic Mean）的取值，一个平衡精度和召回的重要指标。需要再次说明的是， 精度、召回以及F1值都是在二元相关信息的标签基础上定义的。</p>
<p>如果需要利用五级相关信息定义，也就是通常所说的“最相关”、“相关”、“不能确定”到“不相关”、“最不相关”，那么就需要用类似于NDCG这样的评价指标。NDCG的假设是，在一个排序结果里，相关信息要比不相关信息排得更高，最相关信息需要排在最上面，最不相关信息需要排在最下面。任何排序结果一旦偏离了这样的假设，就会受到“扣分”或者“惩罚”。</p>
<p>在清楚了测试集的情况后，再回过头来看一看训练集的设置问题。在今天文章一开篇的时候，我就提到了单点法对于排序学习的“目标不明确”的问题。其实从NDCG的角度来看也好，基于顶部K的精度或者召回的角度来看也好，都可以看出，<strong>对于一个查询关键字来说，最重要的其实不是针对某一个文档的相关性是否估计得准确，而是要能够正确估计一组文档之间的“相对关系”</strong>。只要相对关系估计正确了，那么从排序这个角度来说，最后的结果也就准确了。理解这一个观点，对于深入理解排序和普通的分类之间的区别至关重要。</p>
<p>那么，如何从单点建模再进一步呢？</p>
<!-- [[[read_end]]] -->
<p>很显然，在排序关系中，一个关键关系就是每两个文档之间的比较，也就是我们通常所说的两两关系。试想一下，如果针对某一个查询关键字而言，有一个完美的排序关系，然后通过这个完美的排序关系，可以推导出文档之间的两两相对关系，再从这些相对关系中进行学习，从而可以进一步对其他查询关键字进行排序。</p>
<p>注意，<strong>在这样的架构下，训练集的样本从每一个“关键字文档对”变成了“关键字文档文档配对”</strong>。也就是说，每一个数据样本其实是一个比较关系。试想，有三个文档：A、B和C。完美的排序是“B&gt;C&gt;A”。我们希望通过学习两两关系“B&gt;C”、“B&gt;A”和“C&gt;A”来重构“B&gt;C&gt;A”。</p>
<p>这里面有几个非常关键的假设。</p>
<p><strong>第一，我们可以针对某一个关键字得到一个完美的排序关系</strong>。在实际操作中，这个关系可以通过五级相关标签来获得，也可以通过其他信息获得，比如点击率等信息。然而，这个完美的排序关系并不是永远都存在的。试想在电子商务网站中，对于查询关键字“哈利波特”，有的用户希望购买书籍，有的用户则希望购买含有哈利波特图案的T恤，显然，这里面就不存在一个完美排序。</p>
<p><strong>第二，我们寄希望能够学习文档之间的两两配对关系从而“重构”这个完美排序</strong>。然而，这也不是一个有“保证”的思路。用刚才的例子，希望学习两两关系“B&gt;C”、“B&gt;A”和“C&gt;A”来重构完美排序“B&gt;C&gt;A”。然而，实际中，这三个两两关系之间是独立的。特别是在预测的时候，即使模型能够正确判断“B&gt;C”和“C&gt;A”，也不代表模型就一定能得到“B&gt;A”。注意，这里的关键是“一定”，也就是模型有可能得到也有可能得不到。两两配对关系不能“一定”得到完美排序，这个结论其实就揭示了这种方法的不一致性。也就是说，我们并不能真正保证可以得到最优的排序。</p>
<p><strong>第三，我们能够构建样本来描述这样的两两相对的比较关系</strong>。一个相对比较简单的情况，认为文档之间的两两关系来自于文档特征（Feature）之间的差异。也就是说，可以利用样本之间特征的差值当做新的特征，从而学习到差值到相关性差异这样的一组对应关系。</p>
<p>我前面提到的RankSVM就是这样的思路。RankSVM从本质上来说其实还是SVM，也就是支持向量机，只不过建模的对象从单一文档变成了文档的配对。更加复杂的模型，比如GBRank，就是通过树的聚合模型GBDT来对文档之间的关系直接建模，希望通过函数值的差值来表达文档的相关性差异。</p>
<p>需要注意的是，<strong>配对法排序学习特别是在测试集预测的时候，可能会有计算复杂度的问题</strong>。因为原则上，必须要对所有的两两关系都进行预测。现实中，如果是基于线性特征的差值来进行样本构造的话，那么测试还可以回归到线性复杂度的情况。而用其他方法，就没那么幸运了。有很多计算提速或者是逼近算法为两两比较排序在实际应用中提供了可能性。</p>
<h2>小结</h2>
<p>今天我为你讲了文档检索领域基于机器学习的配对法排序学习。你可以看到，和单点法一样，整个问题的设置和传统的文字搜索技术有本质的区别，但在对文档之间关系的建模上，又比单点法前进了一大步 。</p>
<p>一起来回顾下要点：第一，在火热的机器学习排序研究中，提出了很多配对法排序算法，比如RankSVM、GBDT和RankNet。第二，配对法排序学习测试集的测试原理和单点法一致，我们可以查看精度、召回和F1值，或者利用五级相关信息。第三，针对单点法对于排序学习的“目标不明确”问题，配对法排序学习有不一样的训练集设置，在这个基础上，我介绍了三个关键假设。</p>
<p>最后，给你留一个思考题，有没有什么办法可以把单点法和配对法结合起来呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p><strong>参考文献</strong></p>
<ol>
<li>
<p>Zhaohui Zheng, Keke Chen, Gordon Sun, and Hongyuan Zha. A regression framework for learning ranking functions using relative relevance judgments. <em>Proceedings of the 30th annual international ACM SIGIR conference on research and development in information retrieval</em>, 287-294，2007.</p>
</li>
<li>
<p>Thorsten Joachims. Optimizing search engines using clickthrough data. <em>Proceedings of the eighth ACM SIGKDD international conference on knowledge discovery and data mining</em>，133-142，2002.</p>
</li>
</ol>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor37">036 | 机器学习排序算法：列表法排序学习<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>本周我们已经分别讨论了最基本的单点法排序学习（Pointwise Learning to Rank）和配对法排序学习（Pairwise Learning to Rank）两种思路。单点法排序学习思路简单实用，目的就是把经典的信息检索问题转化成机器学习问题。配对法排序学习则是把排序的问题转化成针对某个查询关键字每两个文档之间的相对相关性的建模问题。不过，这两种思路也都有很明显的问题，需要进一步对算法进行优化，以实现我们需要的最终目标。</p>
<p>今天我就来讲直接优化排序问题的“终极方法”：列表法排序学习（Listwise Learning to Rank）  。相对于尝试学习每一个样本是否相关或者两个文档的相对比较关系，列表法排序学习的基本思路是尝试直接优化像NDCG（Normalized Discounted Cumulative Gain）这样的指标，从而能够学习到最佳排序结果。</p>
<h2>列表法排序学习的历史</h2>
<p>2000年后，学术界和工业界都开始研究如何用机器学习来解决最优排序问题，五六年之后，研究者们才开始尝试直接优化整个排序列表。</p>
<p>这方面的研究工作很多都来自微软研究院。比如2007年左右的AdaRank，就来自微软亚洲研究院的徐君和李航。这篇论文算是较早提出列表法排序观点的研究工作。同一年在国际机器学习大会ICML 2007（International Conference on Machine Learning）上发表的ListNet算是从理论上开启了列表法的大门。这篇论文也来自微软亚洲研究院，是刘铁岩等人的重要工作。类似的研究工作在这一年里如雨后春笋般涌现。</p>
<p>另外一个方向，接下来我会提到，LambdaRank出现稍早，而LambdaMART则稍微晚一点。这方面的工作是在微软西雅图的研究院开发的。主导人是克里斯托弗·博格斯（Christopher J.C. Burges）。博格斯2016年退休，在微软工作了16年，可以说，他领导的团队发明了微软的搜索引擎Bing的算法。</p>
<h2>列表法排序学习详解</h2>
<p>列表法排序学习有两种基本思路。<strong>第一种，就是直接针对NDCG这样的指标进行优化</strong>。目的简单明了，用什么做衡量标准，就优化什么目标。<strong>第二种，则是根据一个已经知道的最优排序，尝试重建这个顺序，然后来衡量这中间的差异</strong>。</p>
<p>我先来说一下第一大思路，直接针对NDCG这样的指标进行优化。</p>
<p>首先，重温一下排序测试集的测试原理。总体来说，所有的基于排序的指标都要考察测试集上，对于某一个查询关键字来说，某一组文档所组成的排序是否是最优的。有两种比较通用的做法。第一个方法主要适用于二分的相关信息，对于某一个查询关键字，针对排序产生的“顶部的K”个文档进行评估，查看精度（Precision）、召回（Recall）等。第二种方法，利用五级相关信息定义，在这样的情况下，就可以利用类似于NDCG这样的评价指标。具体解读你可以回到本周前面两期我们讲解过的内容进行复习。</p>
<p>那么，<strong>直接优化排序指标的难点和核心在什么地方呢？</strong></p>
<!-- [[[read_end]]] -->
<p>难点在于，希望能够优化NDCG指标这样的“理想”很美好，但是现实却很残酷。NDCG以及我之前说过的基于“顶部的K”的精度，都是在数学的形式上的“非连续”（Non-Continuous ）和“非可微分”（Non-Differentiable）。而绝大多数的优化算法都是基于“连续”（Continuous ）和“可微分” （Differentiable）函数的。因此，直接优化难度比较大。</p>
<p>针对这种情况，主要有这么几种方法。</p>
<p><strong>第一种方法是，既然直接优化有难度，那就找一个近似NDCG的另外一种指标</strong>。而这种替代的指标是“连续”和“可微分”的 。只要我们建立这个替代指标和NDCG之间的近似关系，那么就能够通过优化这个替代指标达到逼近优化NDCG的目的。这类的代表性算法的有SoftRank和AppRank。</p>
<p><strong>第二种方法是，尝试从数学的形式上写出一个NDCG等指标的“边界”</strong>（Bound），然后优化这个边界。比如，如果推导出一个上界，那就可以通过最小化这个上界来优化NDCG。这类的代表性算法有SVM-MAP和SVM-NDCG。</p>
<p><strong>第三种方法则是，希望从优化算法上下手，看是否能够设计出复杂的优化算法来达到优化NDCG等指标的目的</strong>。对于这类算法来说，算法要求的目标函数可以是“非连续”和“非可微分”的。这类的代表性算法有AdaRank和RankGP。</p>
<p>说完了第一大思路后，我们再来看看第二大思路。这种思路的主要假设是，已经知道了针对某个搜索关键字的完美排序，那么怎么通过学习算法来逼近这个完美排序。<strong>我们希望缩小预测排序和完美排序之间的差距</strong>。值得注意的是，在这种思路的讨论中，优化NDCG等排序的指标并不是主要目的。这里面的代表有ListNet 和ListMLE。</p>
<p>讲了这两大思路以后，最后我再来提一下第三类思路。<strong>这类思路的特点是在纯列表法和配对法之间寻求一种中间解法</strong>。具体来说，这类思路的核心思想，是从NDCG等指标中受到启发，设计出一种替代的目标函数。这一步还和我刚才介绍的第一大思路中的第一个方向有异曲同工之妙，都是希望能够找到替代品。</p>
<p>这第三类思路更进一步的则是<strong>找到替代品以后，把直接优化列表的想法退化成优化某种配对</strong>。这第二步就更进一步简化了问题。这个方向的代表方法就是微软发明的LambdaRank以及后来的LambdaMART。微软发明的这个系列算法成了微软的搜索引擎Bing的核心算法之一。</p>
<p>我这里简单提一下LambdaRank这个系列模型的基本思想。</p>
<p>首先，微软的学者们注意到，一个排序算法是否达到最优的情况，简单来看，就是查看当前的排序中，相比于最优的情况，有哪些两两文档的关系搞错了。<strong>学习最优排序的问题就被转化成了减小这些两两排错的关系</strong>。更进一步，在设计这个优化过程中，我们其实并不需要知道真正的目标函数的形式，而仅仅需要某种形式的梯度（Gradient）。</p>
<p>这里有这样一个洞察，对于绝大多数的优化过程来说，目标函数很多时候仅仅是为了推导梯度而存在的。而如果我们直接就得到了梯度，那自然就不需要目标函数了。最后，通过实验，微软的学者们把这个NDCG通过梯度变化的差值再乘以这个梯度，这样就达到了增强效果的目的。</p>
<p>早期的LambdaRank，特别是RankNet是采用了神经网络来进行模型训练，而LambdaMART则采用了“集成决策树”的思想，更换到了基于决策树的方法。<strong>后来实践证明，基于决策树的方法对于排序问题非常有效果，也就成了很多类似方法的标准配置</strong>。</p>
<p>最后，有一点需要你注意，我们讨论了不同的列表法思路，列表法从理论上和研究情况来看，都是比较理想的排序学习方法。因为列表法尝试统一排序学习的测试指标和学习目标。尽管在学术研究中，纯列表法表现优异，但是<strong>在实际中，类似于LambdaRank这类思路，也就是基于配对法和列表法之间的混合方法更受欢迎</strong>。因为从总体上看，列表法的运算复杂度都比较高，而在工业级的实际应用中，真正的优势并不是特别大，因此列表法的主要贡献目前还多是学术价值。</p>
<h2>小结</h2>
<p>今天我为你讲了列表法排序学习。你可以看到，列表法排序有很多种思路，在2000年到2010年之间是一个非常活跃的研究领域，积累了大量的成果。</p>
<p>一起来回顾下要点：第一，简要介绍了列表法排序学习的历史。第二，详细介绍了列表法排序学习的三大思路以及每个思路里的主要细节和方法。</p>
<p>最后，给你留一个思考题，列表法是不是就完全解决了排序算法的问题呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p><strong>参考文献</strong></p>
<ol>
<li>
<p>Jun Xu and Hang Li. AdaRank: a boosting algorithm for information retrieval. <em>Proceedings of the 30th annual international ACM SIGIR conference on research and development in information retrieval</em>, 391-398，2007.</p>
</li>
<li>
<p>Zhe Cao, Tao Qin, Tie-Yan Liu, Ming-Feng Tsai, Hang Li. Learning to rank: from pairwise approach to listwise approach. <em>ICML</em>, 129-136, 2017.</p>
</li>
<li>
<p>Q. Wu, C.J.C. Burges, K. Svore and J. Gao. Adapting boosting for information retrieval measures. <em>Journal of Information Retrieval</em>, 2007.</p>
</li>
<li>
<p>C.J.C. Burges, R. Ragno and Q.V. Le. Learning to rank with non-smooth cost functions. <em>Advances in Neural Information Processing Systems</em>, 2006.</p>
</li>
<li>
<p>C.J.C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton and G. Hullender. Learning to rank using gradient descent. <em>Proceedings of the twenty second international conference on machine learning</em>, 2005.</p>
</li>
<li>
<p>F. Xia, T.-Y. Liu, J. Wang, W. Zhang, and H. Li. Listwise approach to learning to rank — Theorem and algorithm. <em>ICML</em>, 1192–1199, 2008.</p>
</li>
<li>
<p>S. Chakrabarti, R. Khanna, U. Sawant, and C. Bhattacharyya. Structured learning for non-smooth ranking losses. <em>SIGKDD</em>, 88–96, 2008.</p>
</li>
<li>
<p>T. Qin, T.-Y. Liu, and H. Li. A general approximation framework for direct optimization of information retrieval measures.<em>Technical Report, Microsoft Research</em>, MSR-TR-2008-164, 2008.</p>
</li>
<li>
<p>M. Taylor, J. Guiver, S. Robertson, and T. Minka. SoftRank: Optimising non-smooth rank metrics. <em>WSDM</em>, 77–86, 2008.</p>
</li>
<li>
<p>J.-Y. Yeh and J.-Y. Lin, and etc. Learning to rank for information retrieval using genetic programming.  <em>SIGIR 2007 Workshop in Learning to Rank for Information Retrieval</em>, 2007.</p>
</li>
<li>
<p>Y. Yue, T. Finley, F. Radlinski, and T. Joachims. A support vector method for optimizing average precision. <em>SIGIR</em>, 271–278, 2007.</p>
</li>
</ol>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor38">037 | “查询关键字理解”三部曲之分类<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>我们在前两周的专栏里主要讲解了最经典的信息检索（Information Retrieval）技术和基于机器学习的排序算法（Learning to Rank）。</p>
<p>经典的信息检索技术为2000年之前的搜索引擎提供了基本的算法支持。从中衍生出的TF-IDF、BM25还有语言模型（Language Model）以及这些方法的各类变种都还在很多领域（不限文本）里继续发挥着作用。</p>
<p>另一方面，排序学习算法引领了2000年到2010年各类基于机器学习的搜索算法的产生和发展，也带来了搜索引擎技术的进一步成熟。</p>
<p>这周我们从排序算法转移到排序问题中一个非常重要的部分：查询关键字理解（Query Understanding）。也就是说，我们希望通过查询关键字来了解用户种种行为背后的目的。查询关键字产生的特征（Feature）往往是很强的指导因素，也是个性化搜索结果非常重要的源泉。因此，深入了解并掌握查询关键字理解方面的技术就变得很有必要。</p>
<p><strong>查询关键字理解最基本的一个步骤就是给查询关键字分类（Classification），看这些查询关键字有什么用户意图（Intent）</strong>。今天我就来聊一聊查询关键字分类的一些基本概念和技术，让你对这方面的开发和研究有一个基本认识。</p>
<h2>查询关键字分类的历史</h2>
<p>从商业搜索引擎开始面世的第一天起，人们就发现，可以从查询关键字中得到很多用户的信息，特别是理解用户的意图。早在1997年，商业搜索引擎Excite就开始了百万级别查询关键字的研究工作。然而，真正对查询关键字分类进行系统阐述的是安德烈·布罗德（Andrei Broder）的论文《网页搜索分类》（A Taxonomy of Web Search）。</p>
<p>安德烈很有名头，在斯坦福大学攻读博士期间师从图灵奖得主高德纳（Donald Knuth），然后在曾经名噪一时的第一代搜索引擎公司AltaVista（后被雅虎收购）担任首席科学家，之后加入位于纽约的IBM研究院组建企业级搜索平台，2012年后加入Google，担任杰出科学家（Distinguished Scientist）。他还是ACM（Association of Computing Machinery，计算机协会）和IEEE（Institute of Electrical and Electronics Engineers，电气电子工程师学会）的双料院士。</p>
<p>安德烈的这篇论文可以说是奠定了查询关键字分类的坚实基础。这之后研究人员的很多工作都是围绕着如何自动化分类、如何定义更加精细的用户意图来展开的。</p>
<h2>查询关键字分类详解</h2>
<p>我就从安德烈这篇非常有名的文章说起。在网络搜索（Web Search）成为比较主流的咨询查询手段之前，传统的信息检索认为，查询的主要目的是完成一个抽象的“信息需求”（Information Needs）。在传统信息检索的世界里，最主要的应用应该是图书馆检索或者政府学校等企事业单位的检索。因此，在这样的场景下，假定每一个查询主要是满足某个“信息需求”就显得很有道理了。</p>
<p>然而，早在2002年，安德烈就认为这样的传统假定已经不适合网络时代了。他开始把查询关键字所代表的目的划分为三个大类：</p>
<!-- [[[read_end]]] -->
<ol>
<li>
<p>导航目的（Navigational）；</p>
</li>
<li>
<p>信息目的（Informational）；</p>
</li>
<li>
<p>交易目的（Transactional）。</p>
</li>
</ol>
<p>此后十多年里，查询关键字的这三大分类都是这个方向研究和实践的基石。我们先来看这个分类的内涵。</p>
<p><strong>第一类，以导航为意图的查询关键字，这类查询关键字的目标是达到某个网站</strong>。这有可能是用户以前访问过这个网站，或者是用户假设有这么一个关于所提交查询关键字的网站。这一类查询关键字包括公司的名字（如“微软”）、人的名字（如“奥巴马”）或者某个服务的名字（如“联邦快递”）等。</p>
<p>此类查询关键字的一个重要特点就是，在大多数情况下，这些查询关键字都对应唯一的或者很少的“标准答案”网站。比如，搜索“微软公司”，希望能够找到的就是微软公司的官方网站。另一方面是说，某些“信息集成”网站也是可以接受的“答案”。比如，查询“奥巴马”，搜索返回的结果是一个列举了所有美国总统的网站。</p>
<p><strong>第二类，以信息为意图的查询关键字，这类查询关键字的目标是搜集信息</strong>。这一类的查询和传统的信息检索非常接近。值得提及的是，从后面的研究结论来看，这一类查询关键字所包含的目标不仅仅是寻找到某类权威性质（Authority）的网页，还包括列举权威信息的俗称“结点”（Hub）的网站。</p>
<p><strong>第三类，以交易为意图的查询关键字，这类查询关键字的目标是到达一个中间站点从而进一步完成“交易”（Transaction）</strong>。这一类查询关键字的主要对象就是“购物”。现在我们对“电子商务”的态度可以说是非常自然了，但是十多年前，在传统信息检索界统治的搜索研究领域，提出“交易”类型的查询关键字可以说是很有新意的。</p>
<p>当然，这样的分类如果仅仅是概念上的区分那就没有太大的意义。安德烈利用搜索引擎AltaVista进行了一次调查研究，这次调查有大约3千多的用户反馈。想到这是在2001年的调查，可以说已经是大规模的研究了。</p>
<p>这次调研的结果是这样的：在用户提交的信息中，导航类型的查询关键字占26%，交易类型的查询关键字占到了24%，而剩下的将近50%是信息类型的查询关键字，用户的日志（Log）分析进一步证实了这一数据。</p>
<p>你可以看到，<strong>这种把查询关键字进行分类的研究是对用户行为进行建模的必要步骤</strong>。于是，很快就有不少研究人员嗅到了查询关键字分类的价值。然而，完全依靠用户直接反馈来获取这类信息则变得越发困难。</p>
<p>这里主要有三个原因。第一，不可能寄希望于用户汇报自己所有关键字的意图；第二，面对亿万用户输入的查询关键字，手工标注也是不可能的；最后，安德烈的三类分类还是太粗犷了，在实际应用中希望得到更加细颗粒度的用户意图。</p>
<p>把查询关键字分类问题转换成为标准的机器学习任务其实很直观。确切地说，这里需要做的是<strong>把查询关键字分类转换成为监督学习任务</strong>。这里，每一个查询关键字，就是一个数据样本，而响应变量，则是对应的类别。具体情况取决于我们的任务是仅仅把查询关键字分为几个类别，并且认为这些类别之间是互相独立的，还是认为这些类别是可以同时存在的。</p>
<p>在最简单的假设下，查询关键字分类就是一个普通的<strong>多类分类问题</strong>，可以使用普适的多类分类器，比如支持向量机（SVM）、随机森林（Random Forest）以及神经网络（Neural Networks）等来解决这类问题。</p>
<p><strong>对于绝大多数监督学习任务而言，最重要的一个组成部分就是选取特征</strong>。随后很多年的研究开发工作中，有一部分就集中在尝试使用不同的特征，然后来看对提高分类的精度是否有效果。</p>
<p>过去的研究反复证明，以下几类特征非常有效。</p>
<p><strong>第一类特征就是查询关键字本身的信息</strong>。比如，查询关键字中已经包括了已知的人名或者公司名，这种时候，分类结果就不太可能是交易意图的类别。也就是说，查询关键字，特别是某些词或者词组和类别有某种关联信息，而这种关联很大程度上能被直接反映出来。</p>
<p><strong>第二类特征是搜索引擎返回的查询关键字相关的页面本身的信息</strong>。你可以想象一下，假如搜索“奥巴马”这个关键字，返回的页面都是维基百科的页面以及奥巴马基金会的页面，那么这些页面上面的内容可能很难包含任何商业的购买信息。而对于“佳能相机”这个查询关键字而言，返回的页面很可能都是电子商务网站的商品信息，从而能够更加准确地判断“佳能相机”的分类。</p>
<p><strong>第三类特征则是用户的行为信息，那就是用户在输入查询关键字以后会点击什么网站，会在哪些网站停留</strong>。一般来说，哪些网站点击率高、停留时间长，就表明这些网站在返回结果中可能更相关。于是，采用这些网站来作为查询关键字所代表的内容，就可能更加靠谱。</p>
<p>在实际的应用中，查询关键字的分类往往还是有很大难度的。因为在普通的现代搜索引擎上，每天可能有三分之一、甚至更多的关键字是之前没有出现过的。因此，如何处理从来没有出现过的关键字、如何处理长尾中的低频关键字，就成了让搜索结果的精度再上一个台阶的重要因素。我今天就不展开相应的话题了，如果你有兴趣，可以查看相关论文。</p>
<h2>小结</h2>
<p>今天我为你讲了现代搜索技术中一个非常基础但是也在实际应用中至关重要的环节，那就是查询关键字理解中的用户意图分类问题。你可以看到<strong>查询关键字从大类上分为信息意图、交易意图以及导航意图三类</strong>。</p>
<p>一起来回顾下要点：第一，简要介绍了查询关键字分类提出的历史背景，安德烈·布罗德的论文奠定了查询关键字分类的坚实基础。第二，详细介绍了主要的分类以及如何通过多类分类器的构建来达到自动化的目的。</p>
<p>最后，给你留一个思考题，在机器学习排序算法中，我们应该如何使用查询关键字分类的结果呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p><strong>拓展阅读</strong>：<a href="https://www.cis.upenn.edu/~nenkova/Courses/cis430/p3-broder.pdf">A taxonomy of web search</a></p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor39">038 | “查询关键字理解”三部曲之解析<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>这周我分享的核心内容是查询关键字理解（Query Understanding）。周一介绍了查询关键字分类（Query Classification）的基本概念和思想。今天，我来讲一个更加精细的查询关键字理解模块：<strong>查询关键字解析</strong>（Parsing）。</p>
<p>如果说查询关键字分类是对查询关键字的宏观把握，那么，对查询关键字的解析就是微观分析。其实，查询关键字解析是一类技术的统称，我今天就来聊几个比较热的话题。</p>
<h2>查询关键字分割</h2>
<p>首先，让我们设想这么一个场景，在英文的搜索引擎中，如果一个用户输入的是“White House Opening”这个查询关键字，这个用户的意图（Intent）是什么呢？要想理解用户的意图，我们就得知道用户输入的单词的涵义。</p>
<p>那么，在上面这个查询关键字里，我们到底是分别理解每一个单词“White”、“House”和“Opening”呢，还是“White House”和“Opening”呢，还是有可能“White House Opening”是一个整体呢？这里说的其实就是“<strong>查询关键字分割</strong>”（Query Segmentation）这个概念。</p>
<p>在刚才的例子中，如何把“White House Opening”进行分割直接关系到搜索结果的质量。试想在一个比较标准的现代搜索引擎里，一般来说，都会有一个模块根据查询关键字来提取“<strong>倒排索引</strong>”（Inverted Index）中的文档。这个阶段的提取数目一般是几百到几千，这个过程常常被称为“<strong>检索流程</strong>”（Retrieval Phase）。</p>
<p>当有了这些文档以后，现代搜索引擎会利用比较复杂的排序算法，通常就是我们之前提到过的基于机器学习的排序学习模型，来对文档进行重新排序（Re-Rank）。</p>
<p>你可以看到，在这样两个阶段的流程里，如果好的文档没有在第一个阶段被提取出来，不管第二个阶段的功能有多强大，搜索的整体结果都不可能有多好。而对于“检索流程”而言，在“倒排索引”中进行查询的关键就是使用什么“单词”或者“词组”进行查找。</p>
<p>用刚才的例子来说，就是看文档究竟是符合“White House”，还是“White或House”，还是“White House Opening”。很明显，这三种情况得到的文档集合是不尽相同的。如果用户的真实意图是搜索美国总统府白宫的开放时间，那么把这个搜索关键字给分割成“White或House”，很明显就会影响提取的文档集合。</p>
<p>那究竟该怎样做查询关键字分割呢？</p>
<!-- [[[read_end]]] -->
<p>这里我介绍一篇论文《重新审视查询关键字分割》（Query Segmentation Revisited ）。在这篇论文里，作者们集中介绍了一些主流的“查询关键字分割”技术，文章非常值得精读。下面我为你归纳一下要点。</p>
<p><strong>第一种技术就是尝试从查询关键字里面产生“N元语法”（N-Grams）</strong>。所谓N元语法其实就是从一组词语中产生连续的子词语。比如刚才的“White House Opening”的例子，我们就可以从这个词组里面产生“White House”和“House Opening”两个二元语法。</p>
<p>而第一种基于N元语法的方法，就是通过这些N元语法在一个大语料中出现的词频来判断这个“分割”是否有意义。当然，直接采用词频可能会比较偏好短的单词，所以在论文中，作者们分别介绍了两种矫正词频的方法。</p>
<p>一种是基于词频本身的矫正，一种是基于维基百科，作为一个外部资源的矫正方式。两种方法的目的都是为了让长短语的打分（Scoring）有机会高于短的单词。文章中所需要的词频采用了谷歌2005年发布的“N元语法”语料，也就是说，所有单词出现的频率都是直接在这个语料中获得的。</p>
<p><strong>第二种技术是基于短语“互信息”（Mutual Information）的方法</strong>。“互信息”计算了两个随机事件的相关程度。在这里，就是计算查询关键字中每两个相邻短语的“互信息”。当这个“互信息”的取值大于某一个预设阈值的时候，我们就认为相邻的两个单词组成了短语。“互信息”的计算需要知道某个单词出现的概率，这些概率是从微软发布的一个“N元语法”语料获得的。</p>
<p><strong>第三种技术则是基于“条件随机场”（Conditional Random Field）</strong>。“条件随机场”是机器学习著名学者乔治·拉菲迪（John D. Lafferty）、安德鲁·麦卡伦（Andrew McCallum）和费尔南多·佩雷拉（Fernando Pereira）在2001年发表的“序列学习”模型（Sequence Model）中提出的。条件随机场的基本思想是对输出的复杂标签进行建模，尝试从特征空间建立到复杂标签的一个对应关系。</p>
<p>在“查询关键字分割”的场景下，我们其实可以把复杂标签看作是从一个查询关键字到多个短语的多个二元决策问题。这里的二元决策是指某一个备选短语是否可以作为分割的短语。条件随机场可以比较直观地对这类问题进行建模，而传统的二分分类器则很难对序列信息进行建模。我在这里就不详细展开条件随机场的介绍了，有兴趣的话可以翻看相关的论文。</p>
<h2>查询关键字标注</h2>
<p>刚才我聊了查询关键字理解最基本的“分割“问题。可以说，“分割问题”是查询关键字理解的第一步。那么，下一步则是更细致地分析查询关键字。</p>
<p>回到刚才的例子“White House Opening”，我们其实不仅是想知道这个查询关键字可以分割为“White House”和“Opening”，而且希望知道“White House”是一个建筑物的名字或者一个地理位置的名字，而“Opening”则可能是一个名词，暗指“开门时间”。也就是说，我们希望为查询关键字中的词组进行“标注”（Annotation），来获取其“属性”（Attribute）信息。希望为查询关键字中分割出来的词组进行标注的组件就叫做“<strong>查询关键字标注</strong>”。</p>
<p>那么，标注信息又是怎样帮助搜索结果的呢？试想一下“苹果价格”这个查询关键字。这取决于用户搜索的场景，如果“苹果”代表“水果”这个属性，那么这个查询的结果是希望找到水果的价格，可能还需要搜索引擎返回附近超市的一些信息。但如果“苹果”其实代表的是“手机”，那这个查询的结果也许最好是返回苹果公司的官方销售网站。你看，“苹果”所代表的属性不同，最优的返回结果可能会有非常大的差别。</p>
<p>对查询关键字进行标注的方法也有很多。我这里再推荐一篇经典的论文《使用伪相关反馈针对搜索查询关键字进行结构化标注》（Structural annotation of search queries using pseudo-relevance feedback），这篇论文<strong>利用一个叫做PRF（Pseudo-Relevance Feedback）的方法来进行标注</strong>。这里面的一个技术难点是，查询关键字的信息实在是太少，需要利用大量的辅助信息来进行标注，因此PRF作为一个技术在这里得到了应用。</p>
<p>另外一个主流的查询关键字标注的方法，依然是利用条件随机场。我前面讲了，条件随机场是很好的序列建模工具。那么，在这里，以“苹果价格”为例，条件随机场是需要预测标签是否是“手机名词”还是“水果名词”这样的组合输出结果。而传统的二分或者多类分类器很难捕捉到这里的序列信息，条件随机场就是解决这方面的利器。</p>
<p>于是，我们需要做的就是为查询关键字构建特征（Feature），然后直接放入条件随机场中。有一点需要注意，条件随机场的应用成功与否与数据的多少有很大关系。因此，<strong>构建一个有标注信息的数据集就变成了查询关键字标注的一个核心挑战</strong>。</p>
<h2>小结</h2>
<p>今天我为你讲了现代搜索技术中的一个重要环节，那就是查询关键字理解中的查询关键字解析问题。你可以看到查询关键字解析从大类上分为查询关键字分割和查询关键字标注两个比较重要的模块。</p>
<p>一起来回顾下要点：第一，简要介绍了查询关键字分割的场景和三种主要技术，分别是“N元语法”、“互信息”和“条件随机场”。第二，详细介绍了查询关键字标注的场景和主要技术，包括利用PRF和利用条件随机场两种主流的标注方法。</p>
<p>最后，给你留一个思考题，我举了英语的查询关键字的解析问题，那么对于中文而言，又有哪些特殊的挑战呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p><strong>参考文献</strong></p>
<ol>
<li>
<p>Matthias Hagen, Martin Potthast, Benno Stein, and Christof Bräutigam. Query segmentation revisited. <em>Proceedings of the 20th international conference on World wide web (WWW '11)</em>. ACM, New York, NY, USA, 97-106. 2011.</p>
</li>
<li>
<p>Michael Bendersky, W. Bruce Croft, and David A. Smith. Structural annotation of search queries using pseudo-relevance feedback. <em>Proceedings of the 19th ACM international conference on Information and knowledge management (CIKM '10)</em>. ACM, New York, NY, USA, 1537-1540. 2010.</p>
</li>
</ol>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor40">039 | “查询关键字理解”三部曲之扩展<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>我们在本周的前两篇文章中分别介绍了查询关键字分类（Query Classification）和查询关键字解析（Query Parsing）的基本概念和思想。今天，我来讲一个稍微有一些不同的查询关键字理解模块：<strong>查询关键字扩展</strong>（Query Expansion）。</p>
<p>查询关键字扩展想要解决的问题和分类以及解析略微不同。其主要目的不仅仅是希望能够对用户输入的关键字进行理解，还希望能够补充用户输入的信息，从而达到丰富查询结果的效果。</p>
<h2>查询关键字扩展的概念</h2>
<p>为什么要提供查询关键字扩展？主要原因还是用户输入的查询关键字信息不足。还记得我们上次提到的“苹果价格”这个例子吗？在这个例子中，用户到底是希望查询“苹果”作为一种水果的价格，还是“苹果”作为手机的价格，其实无法真正从这个查询关键字中得出。因此，作为搜索引擎，如果为用户提供一些“扩展选项”，也就是一个被改写（Reformulated）过的查询关键字，会提供更加好的用户体验和更加精准的搜索结果。</p>
<p><strong>查询关键字扩展除了显示出来能够让用户有更好的体验以外，还有一个作用是增加文档的“召回”（Recall），从而为提高搜索结果奠定基础</strong>。设想这样一个例子，用户搜索“iphone 6 backup”，希望了解如何备份iPhone 6的信息。因为苹果手机的绝大多数机型的备份流程都大同小异，因此，如果把“iphone 6”给扩展到“iphone”其他机型，然后看是否有比较好的介绍备份的网页可以显示。</p>
<p>值得注意的是，在扩展的过程中也有可能失去“精度”（Precision）。比如假设苹果对iPhone 7的备份流程做了很大的改进，那么其他机型的流程也许就不适用了，所以当用户搜索“iphone 7 backup”的时候，如果我们扩展到了其他机型，那让用户看到的很可能就是不那么相关的信息了。因此，<strong>对“精度”和“召回”的平衡，成了查询关键字扩展的一个重要的权衡点</strong>。</p>
<p><strong>查询关键字扩展的另外一个重要应用就是对同义词和缩写的处理</strong>。比如，唐纳德·特朗普（Donald Trump）是美国现任总统。那么，如果用户在搜索“Donald Trump”、“Trump”、“US President”、“POTUS”（这是“President Of The United States”的简称）等类似词汇的时候，搜索引擎应该提供相似的结果。而从词汇的直接联系上，这些词汇在表面形式上可能有很大的差异（比如“Trump”和“POTUS”），因此需要其他手段学习到这些词语内涵的同义。</p>
<h2>查询关键字扩展的技术</h2>
<p>知道了查询关键字扩展的含义以后，我们就来看看有哪些技术可以为查询关键字扩展提供支持。</p>
<p>根据上面提供的一些例子，你可以看到，这里的<strong>核心就是找到搜索结果意义上的“同义词”</strong>。那么，在搜索中，如何挖掘“同义词”呢？</p>
<p>今天我在这里分享两种思路。</p>
<!-- [[[read_end]]] -->
<p><strong>第一种思路，是根据查询关键字和查询结果之间的自然结合产生的同义效果</strong>。这需要对用户的搜索行为数据进行大规模挖掘。这里的基本假设是这样的，假设我们有两个搜索关键字，A和B。从A的搜索结果中，用户可能点击了一些网页，从B的结果中，用户可能点击了另外的一些网页。如果这些被点击的网页恰好非常类似，那么，我们就可以认为A和B其实是同义的查询关键字。</p>
<p>更加完整的做法是把查询关键字和网页分别表示成“图”（Graph）中的两类节点（Node）。每个关键字节点和多个网页节点建立联系（Edge）或者边（Link），象征这些网页对应这个关键字的相关页面。而从每个网页的角度上看，多个关键字节点又和同一个网页节点相连，表示这些关键字都有可能和某个网页相关。</p>
<p>拿上面提到的特朗普的例子来说，美国白宫的首页作为一个节点的话，就有可能会和“Trump”、“US President”以及“POTUS”这几个查询关键字相关。因此你可以看到，寻找同义词的工作就变成了如何在这个图上进行相似节点，特别是相似关键字节点的挖掘工作。</p>
<p>如果把查询关键字的节点放在一边，把网页节点放在一边，我们就看到了典型的“<strong>二分图</strong>”（Bipartite Graph）。二分图的特点是同边的节点之间没有连接（比如关键字和关键字之间没有连接），而所有的连接都发生在不同边的节点之间（关键字和网页之间）。</p>
<p>二分图的聚类问题（Clustering）是机器学习界的经典的问题。而利用二分图的聚类问题来做查询关键字的同义词挖掘也是很多研究人员尝试的方向。文末我列了几个参考文献，比如参考文献[2]就是利用二分图上的“随机游走”（Random Walk）以及随机游走所产生的“到达时间”（Hitting Time）来挖掘出类似的关键字。如果你有兴趣，可以查看这篇经典论文。</p>
<p>说了基于用户行为信息和关键字挖掘的思路以后，我们再来看看第二种思路。</p>
<p><strong>第二种思路的核心是从海量的文本信息中分析出词语之间的相关度</strong>。这里面需要注意的是，这些词语的相关度有可能是语言本身带来的。比如，单词“Male”和“Man”。也可能是语境带来的，比如谈论手机的网页中对于“iPhone 6”和“iPhone 7”的谈论。</p>
<p>总之，这一个思路的想法就是如何为每一个词组都建一个“表达”（Representation），从而通过这个表达找到同义词。近年来流行的一个做法是为单词找到数值表达，也就是通常所说的“嵌入”（Embedding）。如果两个词在“嵌入空间”（Embedding Space），通常是“欧式空间”中距离相近，那么我们就可以认为这两个词是同义词。</p>
<p>如何为词组产生“嵌入”向量呢？这里面也有很多做法。比较通用的有算法Word2Vec（参考文献[3]），目标是通过一个文档的每一句话中某一个词周围的词来预测这个词出现的概率。可以设想一下，在苹果手机的很多帮助文档或者帮助站点中，描述如何帮助iPhone 6或者iPhone 7来做数据备份的字句都是相似的，甚至，可能唯一的区别就是描述机型的名字。</p>
<p>因此在这样的情况下，通过文字周围的“上下文信息”（Contextual）来对单词本身的“嵌入向量”进行学习可以有效地学习到单词的语义。而通过语义，我们就能够找到其他的同义词。当然，要想真正应用到查询关键字扩展中，可能还需要有其他的调试，比如文末我列的参考文献[4]，就是其中的一种。如果你感兴趣，建议去精读。</p>
<p>最后我需要说明的是，第一种思路需要已经有不少的用户交互数据，而第二种思路可以通过其他的语料（比如维基百科）加以学习，并不需要用户数据。这也是另一个值得参考的信息点。</p>
<h2>小结</h2>
<p>今天我为你讲了查询关键字理解中的查询关键字扩展问题。你可以看到，查询关键字扩展从技术上的两种流派，一个是通过用户的交互数据来产生一个图，并且利用图挖掘技术来得到查询关键字之间的关系；另外一个就是通过产生词汇的嵌入向量从而得到同义词。</p>
<p>一起来回顾下要点：第一，简要介绍了查询关键字扩展的内涵。由于用户输入的查询关键字信息不足，通过查询关键字扩展可以提供更好的用户体验和更加精准的搜索结果。第二，详细介绍了查询关键字扩展的两个主要技术。</p>
<p>最后，给你留一个思考题，如何来测试查询关键字扩展的优劣呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p><strong>参考文献</strong></p>
<ol>
<li>
<p>Claudio Carpineto and Giovanni Romano. A Survey of Automatic Query Expansion in Information Retrieval. <em>ACM Computing Surveys</em>. 44, 1, Article 1 (January 2012), 50 pages.2012.</p>
</li>
<li>
<p>Qiaozhu Mei, Dengyong Zhou, and Kenneth Church. Query suggestion using hitting time. <em>Proceedings of the 17th ACM conference on Information and knowledge management (CIKM '08)</em>. ACM, New York, NY, USA, 469-478. 2008.</p>
</li>
<li>
<p>Mikolov, Tomas, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781 (2013).</p>
</li>
<li>
<p>Diaz, Fernando, Bhaskar Mitra, and Nick Craswell. Query expansion with locally-trained word embeddings. arXiv preprint arXiv:1605.07891 (2016).</p>
</li>
</ol>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor41">040 | 搜索系统评测，有哪些基础指标？<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>我在之前几周的专栏文章里主要讲解了最经典的信息检索（Information Retrieval）技术和基于机器学习的排序学习算法（Learning to Rank），以及如何对查询关键字（Query）进行理解，包括查询关键字分类、查询关键字解析以及查询关键字扩展。这些经典的技术是2000年后开始流行的各类搜索引擎的核心技术。</p>
<p>在进一步介绍更多的搜索引擎技术前，我觉得有必要专门抽出一周时间，来好好地看一下搜索系统的评测（Evaluation）以及我们经常使用的各类指标（Metric）。俗话说得好，“如果你不能衡量它，你就不能改进它”（If You Can’t Measure It, You Can’t Improve It）。意思其实就是说，对待一个系统，如果我们无法去衡量这个系统的好坏，没有相应的评测指标，那就很难真正地去琢磨怎么改进这些指标，从而达到提升系统的目的。</p>
<p>虽然我们这里是在搜索系统这个重要场景中讨论评测和指标，但实际上我们这周要讨论的很多细节都可以应用到很多类似的场景。比如，我们后面要讨论的推荐系统、广告系统等，在这些场景中几乎就可以无缝地使用这周要讲的很多内容。</p>
<h2>线下评测</h2>
<p>假设你今天开发了一个新软件，比如说是一个最新的手机软件，你怎么知道你的用户是不是喜欢你的软件呢？你怎么知道你的用户是不是愿意为你的软件掏钱呢？</p>
<p><strong>评测的核心其实就是了解用户的喜好</strong>。最直接的方法，当然是直接询问用户来获得反馈。例如你可以对每一个下载了你手机软件的用户强行进行问卷调查，询问他们对待新软件的态度。</p>
<p>然而，我们很快就会发现这样的方法是行不通的。姑且不说用户是否会因为这样强行的方式产生反感，我们是不是能通过这些调查问卷获得用户的真实反馈，这本身就是一个问题。这里面涉及到调查问卷设计的科学性问题。</p>
<p>即便这些调查问卷都能完整准确地反映出用户对手机软件的看法，真正实施起来也会面临种种困难。如果这款手机软件的用户数量有百万甚至千万，那我们就要进行如此大规模的问卷调查，还要处理调查后的数据，显然这样做的工作量非常大。而这些调查问卷是没法反复使用的，因为下一个版本的软件更新后，用户的态度就会发生改变，这样的方式就没法系统地来帮助软件迭代。</p>
<p>那么如何才能形成一组数据来帮助系统反复迭代，并且还能够减少人工成本，这就成了一个核心问题。</p>
<p>在信息检索系统开发的早年，研究人员和工程师们就意识到了这个核心问题的重要性。英国人赛利尔·克莱温顿（Cyril Cleverdon）可以算是最早开发线下测试集的计算机科学家。</p>
<p>赛利尔生于1914年，在英国的布里斯托（Bristol）图书馆工作了很长时间。从1950年开始，赛利尔就致力于开发信息检索系统，以提高图书馆查询的效率。1953年他尝试建立了一个小型的测试数据集，用于检测图书管理员查找文档的快慢。这个工作最早发表于1955年的一篇论文（参考文献[1]）。</p>
<p>这之后，英美的一些早期信息检索系统的研发都开始顺应这个思路，那就是为了比较多个系统，首先构造一个线下的测试数据集，然后利用这个测试集对现有的系统反复进行改进和提升。如果你想对早期测试集的构造以及信息有所了解，建议阅读文末的参考文献[2]。</p>
<p>那么，当时构造的这些测试数据集有些什么特点呢？</p>
<!-- [[[read_end]]] -->
<p><strong>这些测试数据集都会包含一个查询关键字集合</strong>。这个集合包含几十到几百不等的查询关键字。一方面，这些关键字的选取大多来自于经验。另一方面，从赛利尔就开始认识到，需要保证有一些信息一定能够通过这些关键字来找到。其实，这里就是在测试我们后面要讲的“召回”。</p>
<p>在有了这些查询关键字以后，<strong>这些测试数据集往往有几百到几千不等的文档</strong>。这些文档中的某一部分，研究人员在构造数据集的时候就知道了会包含所对应查询关键字需要的信息，也就是我们后面要说的相关文档。</p>
<p>你可以看到，几十到几百的查询关键字以及几千个文档，很明显不能代表所有可能使用系统的用户的行为。你甚至可以说，这都无法代表绝大多数用户的行为。然而，这种测试集的好处是，查询关键字和文档本身是和要测试的系统无关的。也就是说，今天我们要测试系统A，还是明天要测试系统B，都可以反复利用同样一组测试数据集。这样做的好处相比于我们之前提到的问卷调查是显而易见的。</p>
<p>另外，我需要强调的是，“用户”这个概念在测试数据集中被“抽象”出去了。当我们在讨论文档相对于某个查询关键字的相关度时，我们假定这种相关度是恒定的，是对于所有用户都适用的。因此，究竟是哪位用户在使用这个系统并不重要。只要研发的系统能够在这些“标准化”的查询关键字和文档的集合表现优异，我们就相信这个系统能够满足所有用户的需要。</p>
<p>因为测试数据集并不是用户与产品交互产生的真实回馈结果，所以我们往往又把测试数据集叫作“线下评测数据”。</p>
<h2>基于二元相关度的评测指标</h2>
<p>从线下收集评测数据以后，我们最容易做到的就是利用“二元相关度”所定义的一系列评测指标来衡量手中系统的好坏。</p>
<p>什么叫“二元相关度”呢？简单来说，就是指<strong>针对某一个查询关键字而言，整个测试集里的每一个文档都有一个要么“相关”要么“不相关”的标签</strong>。在这样的情况下，不存在百分比的相关度。而每个文档针对不同的关键字，有不同的相关信息。</p>
<p>假定某个系统针对某个关键字，从测试数据集中提取一定量的文档而不是返回所有文档，我们就可以根据这个提取的文档子集来定义一系列的指标。</p>
<p>有两个定义在“二元相关度”上的指标就成了很多其他重要指标的基石。一个叫<strong>“精度</strong>”（Precision），也就是说，在提取了的文档中，究竟有多少是相关的。另一个叫“<strong>召回</strong>”（Recall），也就是说， 在所有相关的文档中，有多少是提取出来了的。</p>
<p>“精度”和“召回”的相同点在于，分子都是“即被提取出来了又相关的文档数目”。这两个指标所不同的则是他们的分母。“精度”的分母是所有提取了的文档数目，而“召回”的分母则是所有相关的文档数目。如果我们返回所有的文档，“精度”和“召回”都将成为1（也就是说，在这样的情况下是没有意义的）。因此，我们注意到，这两个指标其实都假定，提取的文档数目相比于全集而言是相对比较小的子集。</p>
<p>很快，大家从实践中就体会到，“精度”和“召回”就像是“鱼与熊掌不可兼得”。一个系统很难做到“精度”和“召回”都能够达到很高的数值。也就是说，我们往往需要在这两个指标之间做一些平衡。于是，研究人员开始寻找用一个数字来表达“精度”和“召回”的“平均水平”。来自英国的学者范·李杰斯博格（C. J. van Rijsbergen）最早在论文中采用了 “<strong>调和平均数</strong>” （Harmonic Mean）来计算 “精度”和“召回”的平均（参考文献 [3]）。这个方法被后人称为“<strong>F值</strong>” ，并且一直沿用至今。</p>
<p>这里对“精度”和“召回”还需要注意一点，因为这两个指标都是基于“二元相关度”的。因此，这两个指标都不是“排序指标”（Ranking Metrics）。换句话说，这两个指标其实并不能真正评价排序系统。</p>
<p>比如，我们针对某个关键字提取10个文档，如果有3个相关文档被取出来，不管是“精度”还是“召回”都无法分辨这三个文档在最后序列中的位置，是头三位，还是后面的三位？很遗憾，“精度”和“召回”都无法解决这个问题。“二元相关度”的这个问题也就指引研究人员去开发真正能对排序进行评估的指标。</p>
<h2>小结</h2>
<p>今天我为你讲了现代搜索技术中一个非常重要的一个环节，那就是如何评价我们构建的系统。我们详细讲解了线下测试的由来以及这样的测试相比于调查问卷的优势。</p>
<p>一起来回顾下要点：第一，简要介绍了可重复使用的线下测试集的历史，以及这样的测试集都有什么特点与局限。第二，详细介绍了两个非常流行和重要的基于“二元相关度”的评测指标，那就是“精度”和“召回”。</p>
<p>最后，给你留一个思考题，我们讲了排序的好坏不能简单地从“精度”和“召回”的数值看出，那能不能动一些手脚呢？如果我们就依赖“二元相关度”，有没有什么方法来看“排序”的好坏呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p><strong>参考文献</strong></p>
<ol>
<li>
<p>R.G. THORNE, B.Sc., A.F.R.Ae.S. The Efficiency Of Subject Catalogues and The Cost of Information Searches. <em>Journal of Documentation</em>, Vol. 11 Issue: 3, pp.130-148, 1995.</p>
</li>
<li>
<p>K. SPARCK JONES, C.J. VAN RIJSBERGEN. Information Retrieval Test Collections. <em>Journal of Documentation</em>, Vol. 32 Issue: 1, pp.59-75, 1976.</p>
</li>
<li>
<p>C.J. VAN RIJSBERGEN. Foundation of Evaluation. <em>Journal of Documentation</em>, Vol. 30 Issue: 4, pp.365-373, 1974.</p>
</li>
</ol>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor42">041 | 搜索系统评测，有哪些高级指标？<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>周一我们介绍了基于“二元相关”原理的线下评测指标。可以说，从1950年开始，这种方法就主导了文档检索系统的研发工作。然而，“二元相关”原理从根本上不支持排序的评测，这就成了开发更加准确排序算法的一道障碍。于是，研究人员就开发出了基于“多程度相关”原理的评测标准。今天我就重点来介绍一下这方面的内容。</p>
<h2>基于多程度相关原理的评测</h2>
<p>从“二元相关”出发，自然就是给相关度更加灵活的定义。在一篇发表于NIPS 2007的文章中（参考文献[1]），雅虎的科学家介绍了雅虎基于五分标准的相关评价体系，从最相关到最不相关。而在同一年的SIGIR上，谷歌的科学家也发表了一篇文章（参考文献[2]），介绍了他们的“多程度”相关打分机制。至此之后，基于“多程度相关”原理的评价标准慢慢被各种搜索系统的研发者们所接受。</p>
<p>在这样的趋势下，基于“二元相关”的“精度”（Precision）和“召回”（Recall）都变得不适用了。我们需要新的、基于“多程度相关”的评价指标。</p>
<p>芬兰的科学家在2000年的SIGIR上（参考文献[3]）发表了一种计算相关度评测的方法。这种方法被广泛应用到了“多程度相关”的场景中。那么，芬兰科学家发明的方法是怎样的呢？</p>
<p>这种方法被称作是“<strong>折扣化的累积获得</strong>”（Discounted Cumulative Gain），简称“DCG”。 在介绍DCG之前，我们首先假定，位置1是排位最高的位置，也就是顶端的文档，而位置数随着排位降低而增高，位置10就是第一页最后的文档。</p>
<p>DCG的思想是这样的。</p>
<!-- [[[read_end]]] -->
<p><strong>首先，一个排序的整体相关度，是这个排序的各个位置上的相关度的某种加权</strong>。这样用一个数字就描述了整个排序。只要排序的结果不同，这个数字就会有所不同。因此，这就避免了“精度”或“召回”对排序不敏感的问题。</p>
<p><strong>其次，每个位置上面的“获得”（Gain）是和这个文档原本定义的相关度相关的，但是，根据不同的位置，要打不同的“折扣”</strong>。位置越低（也就是位置数越大），折扣越大。这就是DCG名字的由来。</p>
<p>在原始的DCG定义中，“折扣”是文档的相关度除以位置的对数转换。这样，既保证了位置越低（位置数大），折扣越大，还表达了，高位置（位置数小）的差别要大于低位置之间的差别。这是什么意思呢？意思就是，如果某一个文档从位置1挪到了位置2，所受的折扣（或者说是损失）要大于从位置9挪到了位置10。在这样的定义下，DCG鼓励把相关的文档尽可能地排到序列的顶部。</p>
<p>事实上，假设我们有5个文档，假定他们的相关度分别是1、2、3、4、5，分别代表“最不相关”、“不相关”、“中性”、“相关”和“最相关”。那么，在DCG的定义下，最佳的排序就应该是把这5个文档按照相关度的顺序，也就是5、4、3、2、1来排定。任何其他的顺序因为根据位置所定义的“折扣获得”的缘故，都会取得相对较小的DCG，因此不是最优。DCG比“精度”和“召回”能够更好地表达对排序的评估。</p>
<p>但直接使用DCG也存在一个问题。如果我们有两个查询关键字，返回的文档数不一样，那么直接比较这两个查询关键字的DCG值是不“公平”的。原因在于DCG的“加和”特性，结果肯定是越加越大，因此不能直接比较两个不同查询关键字的DCG值。</p>
<p>有没有什么办法呢？把DCG加以“归一化”的指标叫做 <strong>nDCG</strong> （Normalized Discounted Cumulative Gain）。nDCG的思路是下面这样的。</p>
<p>首先，对某一个查询关键字的排序，根据相关信息，来计算一组“理想排序”所对应的DCG值。理想排序往往就是按照相关信息从大到小排序。然后，再按照当前算法排序所产生的DCG值，除以理想的DCG值，就产生了“归一化”后的DCG，也就是我们所说的nDCG值。简单来说，nDCG就是把DCG相对于理想状态进行归一化。经过nDCG归一化以后，我们就可以比较不同查询关键字之间的数值了。</p>
<p>这里需要说明的是，我们上面介绍的是DCG的原始定义。后来微软的学者们在2005年左右发明了另外一个变种的DCG，基本原理没有发生变化，只是分子分母有一些代数变形。这个新的版本后来在工业界得到了更加广泛的应用。如果你感兴趣，可以查看文末的参考文献[4]。</p>
<p><strong>直到今天，nDCG以及DCG依然是评价排序算法以及各种排序结果的标准指标。</strong></p>
<h2>比较两个不同的排序</h2>
<p>不管是我们之前谈到的“精度”和“召回”，还是今天介绍的nDCG，我们都是使用一个“数”来描述了相对于某个查询关键字，一组结果的好坏。当我们有多个查询关键字的时候，我们该如何比较两个不同排序的结果呢？</p>
<p>这里面的一个问题是，相对于两个不同的排序A和B来说，可能结果各有千秋，也许对于某一个关键字A比B的表现要好，但是另外一个关键字B就比A的结果更棒。这怎么办呢？</p>
<p>也许你会想到用平均值来描述A和B的表现。这的确是很好的第一步。于是，我们就计算A和B，两个排序的平均表现。这样对于这两个排序而言，我们就有了两个数值来表达这两个排序的好坏。</p>
<p>然而，很快我们就会遇到问题。假设A的nDCG平均值是0.781，B的nDCG平均值是0.789，我们可以下结论认为B是比A更好的排序算法吗？</p>
<p>答案当然是不一定。这种情况，我们就需要依赖统计工具“<strong>假设检验</strong>”来评价两个排序的好坏。</p>
<p>我这里就不去复习假设检验的细节了，简单说一个经常使用的工具。</p>
<p>如果我们比较A和B是在同一组查询关键字上的话，那我们常常可以使用“<strong>两个样本的配对T检验</strong>”（Two Sample Paired T-Test）。这里所谓的“配对”是指A和B的结果是可以一一比较的。这里的“T检验”其实就是说借助“T分布”或者我们通常所说的“学生分布”来进行假设检验。如果我们是在不同查询关键字集合中进行比较的话，还有其他的假设检验工具，这里就不展开了。</p>
<p>值得注意的是，假设检验本身也不是“万灵药”。第一，怎么最有效地在排序结果上进行假设检验还是一个研究话题，包括我们刚说的“两个样本的配对T检验”在内的所有方法都不是“金科玉律”。第二，依靠假设检验得出来的结论，仅仅是统计意义上的“好坏”，和这些系统在用户面前的表现可能依然会有很大差距。因此，<strong>对于假设检验的结果也要带有“批判”的眼光</strong>。</p>
<h2>小结</h2>
<p>今天我为你讲了现代搜索技术中如何评价我们构建的系统，特别是如何评价排序系统。</p>
<p>一起来回顾下要点：第一，简要讲解了基于“多程度相关”的评价体系，包括其由来和DCG以及nDCG的概念。第二，详细介绍了如何来比较两个排序的好坏。</p>
<p>最后，给你留一个思考题，如果我们只有“二元”相关信息，能不能用nDCG来评价好坏呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p><strong>参考文献</strong></p>
<ol>
<li>
<p>Ben Carterette and Rosie Jones. Evaluating search engines by modeling the relationship between relevance and clicks. <em>Proceedings of the 20th International Conference on Neural Information Processing Systems (NIPS’07)</em>, J. C. Platt, D. Koller, Y. Singer, and S. T. Roweis (Eds.). Curran Associates Inc., USA, 217-224,2007.</p>
</li>
<li>
<p>Scott B. Huffman and Michael Hochster. How well does result relevance predict session satisfaction? <em>Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval (SIGIR '07)</em>. ACM, New York, NY, USA, 567-574, 2007.</p>
</li>
<li>
<p>Kalervo Järvelin and Jaana Kekäläinen. IR evaluation methods for retrieving highly relevant documents. <em>Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval (SIGIR '00)</em>. ACM, New York, NY, USA, 41-48, 2000.</p>
</li>
<li>
<p>Chris Burges, Tal Shaked, Erin Renshaw, Ari Lazier, Matt Deeds, Nicole Hamilton, and Greg Hullender. Learning to rank using gradient descent. <em>Proceedings of the 22nd international conference on Machine learning (ICML '05)</em>. ACM, New York, NY, USA, 89-96, 2005.</p>
</li>
</ol>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor43">042 | 如何评测搜索系统的在线表现？<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>我在本周前面的两篇文章中为你讲解了基于“二元相关”和基于“多程度相关”原理的线下评测指标。利用这些指标，研发人员在半个世纪的时间里开发了一代又一代的搜索系统，这些指标和系统也都在不断演化。</p>
<p>虽然我们这周讲过的这些指标都很有指导意义，但大多数指标被提出来的时候都是基于线下的静态数据集，并不是真正去检测用户和系统的互动（虽然后期也有研发人员直接使用这些评测工具用于在线评测，但在使用上就产生了问题）。那有什么样的方法来评测搜索系统的在线表现呢？</p>
<p>为了回答这个问题，我们今天就来探讨一下进行在线评测的几个话题。</p>
<h2>在线可控实验</h2>
<p>我们先回到整个评测指标的初衷，为什么要进行线下测试呢？</p>
<p>第一个原因是在信息检索系统（也就是最早的搜索系统）的开发时期，还很难做在线可控实验（Controlled Experiments），研发人员还没有开发出值得依赖的手段来判断用户的行为。因此，在那个年代，比较可靠的方法就是调查问卷和后来开发出来的线下静态评测。可以说，这些手段都是真正了解用户行为的一个“代理”（Proxy）。</p>
<p>要进行评测，不管是线下还是线上，另外一个原因就是我们需要某种手段来分辨两个系统的好坏，从而能够不断地通过这种手段来改进系统，做到数据驱动。</p>
<p>那么，能够正确观测两个系统不同的工具，就是“在线可控实验”，有时候又称作“在线实验”，或者也叫作“在线A/B实验”。</p>
<p><strong>在线可控实验其实是建立“因果联系”（Causal Relationship）的重要工具，也可以说是唯一完全可靠的工具。这里面的基础是统计的假设检验</strong>。</p>
<p>具体来说，就是我们针对访问网站或者应用的人群，进行某种划分，一般情况下是平均随机划分，百分之五十的用户进入划定的一个群组，叫作“控制组”（Control Bucket），而另外百分之五十的用户进入另外一个群组，叫作“对照组”（Treatment Bucket）。“控制组”和“对照组”的唯一区别在于所面对的系统。</p>
<p>假设有一个搜索系统，我们想对其中的某个部分进行改进，那么，我们可以保持住其他的部分，让这个希望得到改进的部分成为唯一的“独立变量”（Independent Variable），也就是在整个实验设置中的变量。这样，我们就希望看到，能否通过在线实验以及假设检验的工具，来认定这个“独立变量”是否会带来系统性能上的提高，亦或是降低。</p>
<p>这里面还有一个需要提前确定的，那就是需要评测的指标，特别是用户指标，比如网站的点击率、搜索的数量等等。这些指标我们称之为“依赖变量”（Dependent Variable）。说白了，<strong>我们就是希望能够在“独立变量”和“依赖变量”之间通过假设检验建立联系</strong>。</p>
<p>虽然在概念上很容易理解在线可控实验，但在实际操作中会面临很多挑战。</p>
<!-- [[[read_end]]] -->
<p>虽然在理想状态下，我们可以把用户五五对分，让用户分别进入“控制组”和“对照组”。然而现实中，经过随机算法分流的用户群在这两个群组中很可能并不呈现完全一样的状态。什么意思呢？</p>
<p>举个例子，比如，在“控制组”中，相比于“对照组”而言，可能存在更多的女性用户；或者是在“对照组”中，可能存在更多来自北京的用户。在这样的情况下，“依赖变量”，比如网站点击率，在“控制组”和“对照组”的差别，就很难完全解释为“独立变量”之间的差别。</p>
<p>也就是说，如果“控制组”下的点击率比“对照组”高，是因为我们更改了系统的某部分产生了差别呢，还是因为这多出来的女性用户呢，又或者是因为女性用户和系统的某些部分的交互，产生了一定复杂的综合结果导致的呢？这就比较难说清楚了。对于刚才说的有更多来自北京的用户这个例子也是一样的。</p>
<p>当然，在现实中，如果说我们依然可以比较容易地通过算法来控制一两个额外的变量，使得在“控制组”和“对照组”里面这些变量的分布相当，那么，面对十几种（例如，年龄、性别、地域、收入层级等等）重要变量，要想完全做到两边的分布相当，难度很大。</p>
<p>即便我们能够做到通过随机算法使得已知变量在两个群组中的分布相当，我们依然不能对当前还未知的变量进行如此操作。因此，<strong>如何处理因人群特性所带来的对结论的影响是现实中在线实验的难点之一</strong>。</p>
<p><strong>在线实验的难点之二是，我们有可能很难做到如设想中的那样，让系统的某个部分成为“控制组”和“对照组”中唯一的“独立变量”</strong>，即便是除去了刚才所提到的人群差异。</p>
<p>在现代网站或者应用中，有很多服务、子系统、页面、模块同时在为整个网站服务。而这些服务、子系统、页面和模块，都有不同的前端系统和后端系统，很可能属于不同的产品和工程团队。每个部分都希望能够做自己的可控实验，希望自己改进的部分是唯一变化的“独立变量”。然而，我们从宏观的角度去看，如果每个部分都在做自己的实验，而我们做实验的基本单元依旧是每个用户的话，那这就很难保证用户之间的可比性。</p>
<p>举个例子，如果用户U1，进入了首页的“控制组”，然后访问了搜索页面的“对照组”继而离开了网站。而用户U2，直接访问了帮助页面的“对照组”，然后访问了搜索页面的“控制组”。那U1和U2两个用户最终产生的点击率的差别，就很难从他们访问网站页面的过程中得出结论。即便是在有大量数据的情况下，我们也很难真正去平衡用户在所有这些页面的组别之间的关系。</p>
<p><strong>实际上，如何能够有效地进行在线实验，包括实验设计、实验评测等，都是非常前沿的研究课题</strong>。每年在KDD、WSDM、ICML等学术会议上都有不少新的研究成果出炉。</p>
<h2>利用因果推论对实验结果进行分析</h2>
<p>今天的最后我想提一下因果推论（Causal Inference）。因果推论不是普通的统计教科书内容，也不在一般工程类学生接触到的统计内容之内。然而这个领域在最近几年受到了机器学习界越来越多的关注，因此了解因果推论对于学习机器学习的前沿知识来说很有必要。</p>
<p>像我们刚才提到的种种实验中产生的用户特征不平均、实验之间可能存在关系等，在这些方面我们都可以利用很多因果推论的工具进行分析。另外，对于工程产品而言，并不是所有的情况都能够通过A/B测试来对一个希望测试的内容、模型或者产品设计在一定时间内找到合理的结果，有很多情况下是不能进行测试的。因此，在不能进行测试的情况下还能通过数据研究得出期望的结果，也就是说，我们能否模拟在线实验，这就是因果推论的核心价值。</p>
<p>一般而言，在机器学习中需要因果推论的场景也很常见。比如，我们需要用数据来训练新的模型或者算法，这里面的数据采集自目前线上的系统。然而，现在的线上系统是有一定偏差的，那么，这个偏差就会被记录到数据里。在此，因果推论就为机器学习带来了一系列工具，使得在一个有偏差的数据中依然能够无偏差地进行训练以及评测模型和算法。</p>
<h2>小结</h2>
<p>今天我为你讲了在现代搜索技术中，如何利用在线实验，特别是可控实验来评价我们构建的系统。</p>
<p>一起来回顾下要点：第一，详细介绍了在线实验的一些因素，并分析了在线实验中可能产生的用户不平衡以及实验有相互作用的问题。第二，简短地提及了现在利用因果推论来进行在线实验数据分析以及“偏差”调整的一个思路。</p>
<p>最后，给你留一个思考题，如何建立在线实验评测结果和线下指标比如nDCG之间的关系呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor44">043 | 文档理解第一步：文档分类<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>我们在前几周的专栏里讲解了最经典的信息检索（Information Retrieval）技术以及基于机器学习的排序学习算法（Learning to Rank），并且花了一定的时间分享了查询关键字理解（Query Understanding）这一关键搜索组件的核心技术要点。上周，我们还详细讨论了如何从线上和线下两个层面来评价一个搜索系统。</p>
<p>这周我们的分享将转移到搜索的另外一个重要部件：<strong>文档理解</strong>（Document Understanding）。也就是从文档中抽取各种特性，来帮助检索算法找到更加相关的文档。</p>
<p>文档理解最基本的一个步骤就是给<strong>文档分类</strong>（Classification），看这些文档表达什么类别的信息。今天我就来和你聊一聊文档分类的一些基本概念和技术，让你对这方面的开发与研究有一个基本认识。</p>
<h2>文档分类的类型</h2>
<p>如果我们把文档分类看做一个监督学习任务的话，那么在各式应用中就经常使用以下几种类型的文档分类。</p>
<p>第一个类别就是<strong>二元分类</strong>，或者称为二分文档分类，目的就是把文档分成两种不同的类别。比如，把文档分成“商业类”或者“非商业类”。</p>
<p>第二个类别自然就是<strong>多类分类</strong>，也就是判断文档是否属于好几种不同类别中的某一个。比如，把文档划归为“艺术”、“商业”、“计算机”或者“运动”类别中的某一类。</p>
<p>当然，在多类分类的下面，我们还可以分三个小类别。</p>
<p>第一个小类别，是“<strong>多类-单标签-硬分类</strong>”（Multiclass，Single-Label，Hard Classification）。什么意思呢？就是说每一个文档只能在多类分类问题中被赋予唯一的标签，并且所有互相的类别是不兼容的。</p>
<p>第二个小类别，就是“<strong>多类-多标签-硬分类</strong>”（Multiclass，Multilabel，Hard Classification），也就是说每一个文档可以被认为属于多个类别，然而每个这样的分类都是唯一确定的。</p>
<p>最后一个小类别则是“<strong>多类-软分类</strong>”（Multiclass，Soft Classification），也就是认定每个文档以概率的形态属于多个类别。</p>
<p>在这个分类基础上，还有一种分类的方法，那就是可以把所有的类别看做一个平面的结构（Flat）或者是有组织结构的。通常情况下，如果把文档分类到一个层次组织（Hierarchical Structure）里就叫“<strong>层次分类</strong>”（Hierarchical Classification）。在这样的情况下，一个文档同时属于这个层次结构上从根节点到叶子节点的所有类别。一般来说，上层节点相对于下层节点更加抽象。</p>
<h2>文档分类经典特性</h2>
<p>了解了文档分类的基本类型之后，我们接着来讨论文档分类所用到的经典特性。</p>
<!-- [[[read_end]]] -->
<p><strong>我们最先会想到的当然是使用文档上原本的文字信息</strong>。最直接的文字特性可能就是每个英文单词，或者中文的词语。这种完全把文字顺序打乱的方式叫作“<strong>词袋模型</strong>”（Bag-of-words Model）。</p>
<p>从很多实践者的报告来看，“词袋模型”虽然不考虑文字的顺序，但是在实际使用中，依然不失为一种非常有效的特性表达方式。同时，在“词袋模型”中，每个词的权重其实可以用我们之前介绍过的TF-IDF或是语言模型（Language Model）对单词进行加权。关于TF-IDF以及语言模型，建议你回到我们前面讲过的内容去复习一下。</p>
<p>除了“词袋模型”以外，还有一些不同的尝试，是希望能够保留部分或者全部的词序。</p>
<p>比如，我们曾经讲过的“<strong>N元语法</strong>”（N-gram）对文字的表达方法，就是一种非常有效的保留部分词序的方法。不过，N元语法最大的问题就是极大地增大了特性空间，同时，每一个N元组被观测到的次数明显减少，这也就带来了数据的稀少（Sparsity）问题。</p>
<p>除了N元语法以外，近年来随着深度学习的推广，比较新的思路是用“<strong>递归神经网络</strong>”（RNN）来对序列，在这里也就是词句进行建模。有不少研究表明这样的效果要明显好于“词袋模型”。</p>
<p><strong>除了文档上的原始文字以外，文档上的排版格式其实也是很重要的</strong>。有些字段有很明显的特征，比如一个文档的标题显然占据了举足轻重的地位。有一些文档有“章节”、“段落”等结构，其中这些小标题对文章的主要内容有很大的指导意义。于是，对文章的不同“字段”（有时候也叫做“域”）进行建模，对文档分类的效果可能会有比较大的影响。</p>
<p>另外，针对某些特殊文档，仅仅考虑文字的基本信息可能是不够的。例如，现代网页的原始HTML表达和最终在浏览器中呈现出来的效果很可能会有较大区别。因此，针对网页，我们可能还需要采用浏览器中最终呈现出来的视觉效果来提取特性。</p>
<p>对于孤立的文档来说，单个文档的信息可能是比较有限的。但是在互联网上，很多文档都不是孤立存在的。就拿普通网页来说，互联网的一个特点就是很多网页都通过各种链接连到一起。这些和当前网页相连的其他页面很可能就会为当前页面提供一些额外信息。</p>
<p>在所有这些周围的页面中，有一类页面值得在这里提一下。那就是这些页面上会有链接指向当前我们需要分类的目标网页。这些链接往往有文字描述来叙述目标网页的一些特质，甚至有一些周围的文字描述也是有意义的。</p>
<p>比如，当前网页是微软公司的首页，上面也许因为有各种精美的图片而缺乏文字描述，而周围的页面上很可能就有“微软公司官方网站”等链接指向微软公司的首页。这样，我们就通过这些链接文字得出了“微软公司”的信息，然后如果我们又知道微软公司是软件公司，那么就比较容易对这个页面进行分类了。</p>
<p><strong>根据这个思路，我们就可以尝试去使用周围文档中更多的信息</strong>。不过，值得指出的是，周围文档信息所带的“噪声”也是比较多的。已经有各类研究尝试去理解周围文档中更多有价值的信息，这里就不赘述了。</p>
<h2>文档分类相关算法</h2>
<p>根据我们刚刚讲过的不同文档的分类类型，就可以直接借用已知的、熟悉的监督学习各种算法和模型。</p>
<p>假如是简单的二分文档分类问题，那“对数几率回归”（Logistic Regression）、“支持向量机”（SVM）、“朴素的贝叶斯分类器”（Naïve Bayes Classifier）就都能够胜任工作。而针对多类分类问题，也是标准的监督学习设置，刚才说到的这几类算法和模型在一定的改动下也能够做到。</p>
<p>近些年，深度学习席卷很多领域。在文档分类领域，各类深度学习模型也都展示出了一定的优势。</p>
<p>需要注意的是，并不是所有的分类算法都“天生”（Natively）支持“概率的输出结果”。也就是说，如果我们需要对“多类-软分类”文档问题进行建模，那就会有一些问题。比如支持向量机就是这么一种情况。在默认的状态下，支持向量机并不输出每一个数据样例属于每一个类别的概率。</p>
<p>因此，这里就需要用到一些技巧。在实际应用中，我们经常采用的是一种叫“<strong>普拉特调整</strong>”（Platt Scaling）的办法。简单来说，其实就是把支持向量机的输出结果再当做新的特性，学习一个对数几率回归。</p>
<p>除了我们刚刚讲的利用基本的监督学习手段进行文档分类以外，另外一种方法就是我们前面说的利用周围有关系的文档，也就是所谓的“<strong>关系学习</strong>”（Relational Learning）。关系学习是说，希望利用文档与文档之间的关系来提高文档的分类效果。这一方面的很多方法都会利用这样的思想：<strong>相似的页面很有可能是相同的类别</strong>。</p>
<p>如果是在“层次分类”的情况下，相似的页面就很有可能在层次结构上距离比较近。这里，“相似”有可能被定义成文字信息相似，也有可能是在文档与文档之间所组成的“图”（Graph）上位置类似。</p>
<p>比如，某一个公司的很多子页面，虽然上面的文字本身有差异，但因为都是这个公司的页面，从大的文档页面网络上看，他们都代表这个公司的信息，因此在进行文档分类的时候，也很有可能会把他们放到一起。</p>
<h2>小结</h2>
<p>今天我为你讲了现代搜索技术中又一个至关重要的环节，那就是文档理解中的文档分类问题。你可以看到文档分类所要了解的信息还是比较多的。</p>
<p>一起来回顾下要点：第一，简要介绍了文档分类的主要类型，包括二元分类、多类分类以及层次分类。第二，详细介绍了文档分类所可能用到的种种特性，比如文档上原本的文字信息、文档的排版格式以及周围有关系的文档。第三，介绍了如何利用监督学习以及其他的算法工具来完成文档分类的任务。</p>
<p>最后，给你留一个思考题，如果一个文档中既有图片也有文字，那我们该如何组织这些特性，然后放到我们的分类器中去学习呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor45">044 | 文档理解的关键步骤：文档聚类<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>周一我们分享了文档理解最基本的一个步骤，那就是给文档分类（Classification），主要是看不同文档表达什么类别的信息。今天我就来聊一聊文档理解的另外一个重要组件：<strong>文档聚类</strong>（Document Clustering）。</p>
<h2>文档聚类的类型</h2>
<p>和了解文档分类的思路相似，我们先来看看文档聚类的分类。一般来说，可以把文档聚类看作非监督学习的典型代表。</p>
<p>先说一种直观的分类方法。如果把文档分为“互不相关”的几个聚类，那就叫作“<strong>扁平聚类</strong>”（Flat Clustering）；如果这些聚类相互之间有一定的结构关系，那就叫作“<strong>层次聚类</strong>”（Hierarchical Clustering）。</p>
<p>“扁平聚类”中的“互不相关”是说文档所划分进去的聚类之间本身没有重合。而“层次聚类”的特点是，希望在聚类之间找到关系，从而把这些文档组织到一个有层次的结构中。在这种层级结构里，根节点所代表的内容往往比较抽象，而叶节点所表达的内容则比较具体。</p>
<p>值得注意的是，不管是“扁平聚类”还是“层次聚类”，相较于文档分类来说，这里最大的不同就是这些聚类以及它们之间的关系都不是事先定义好的，或者说研发人员事先并不知道这些聚类的存在。从这个角度来看，聚类的确是比分类要困难的任务，难在如何衡量聚类的好坏。</p>
<p>除了“扁平聚类”和“层次聚类”这种区分以外，聚类方法中还有一个类似的区分，那就是“<strong>硬聚类</strong>”（Hard Assignment）和“<strong>软聚类</strong>”（Soft Assignment）的区别。</p>
<p>顾名思义，“硬聚类”是说对于每一个文档，不管是“扁平聚类”还是“层次聚类”，都确定性地分配到一个或者一组聚类中。而“软聚类”则往往学习到文档分配到聚类的一个分布，也就是说所有的分配都是以某种概率存在的。</p>
<h2>文档聚类的应用</h2>
<p>在搜索系统为背景的场景中，我们为什么要强调文档聚类？</p>
<!-- [[[read_end]]] -->
<p><strong>首先，文档聚类可以帮助文档提取和排序</strong>。很多文档能够聚合到一个类别肯定是因为文档在某种情况下“相似”。相似的文档很可能都满足用户的某种“信息需求”（Information Needs）。实际上，在类似“语言模型”（Language Model）或者其他概率模型的场景中，对文档相关度的预测经常需要从相似文档群体中寻找额外信息。</p>
<p>举个例子，在“语言模型”中，我们需要估计文档相对于查询关键字的相关度。单独的某一个文档，数据信息可能比较匮乏，因此一个常用的策略就是从整个数据集中补充信息。如果我们已经有了文档的聚类，那自然就可以从这些聚类中补充，而不需要数据全集。</p>
<p><strong>其次，文档聚类能够帮助整理搜索结果</strong>。在最普通的搜索结果上，如果只是完全“平铺”所有的结果，用户很可能对成百上千的结果“不得要领”。因此，在这些结果上体现某种结构就成为了很多搜索引擎提升用户体验的一种方法。</p>
<p>当然，这里可以用我们之前提到的“文档分类”的方法，把返回的结果按照类别组织。这样，哪一个类别有什么结果就清清楚楚。在这里，文档聚类相比于文档分类的优势是，聚类更能反应文档之间更本质的联系，而不是类似于分类这样“先入为主”地对文档的关系有一个定义。</p>
<p>文档聚类不仅仅是搜索结果的展示利器，<strong>很多时候，文档聚类还可以帮助研究人员来浏览一个文档集合，而不需要太多的先期假设</strong>。在有“层次聚类”的帮助下，研发人员可以很容易地根据层次之间的关系来对一个文档集合进行分析。利用文档聚类来浏览文档集合常常是发现问题，并且进行下一步工作的有效步骤。</p>
<h2>文档聚类的基本模型</h2>
<p>最基础的文档“扁平聚类”方法当属“K均值算法”（K-Means）。</p>
<p><strong>首先，一个最基本的步骤就是要把文档表示成“特性向量”</strong>（Feature Vector）。具体的做法可以采用我们周一讲过的几个方式，比如最基本的“词袋模型”（Bag Of Word），这是一种把文字顺序完全打乱的方式。在“词袋模型”中，每个词的权重可以用我们之前介绍过的TF-IDF或是语言模型对单词进行加权。当然，还有“N元语法”（N-gram）和“递归神经网络”（RNN）两种思路，这一部分可以回到我们周一的内容再复习一下。</p>
<p><strong>把文档表达成为“特征向量”之后，就可以开始聚类了</strong>。“K均值算法”的基本思路是这样的。给定一个数据样本集，K均值算法尝试把所有的样本划分为K个聚类。每个聚类都是互斥的，也就是说样本都被有且唯一地分配到这些聚类中。K均值算法在优化一个目标函数，那就是每个样本到目标聚类中心的平均平方误差最小。</p>
<p>这里，目标聚类中心是指当前这个样本被分配到的聚类；而聚类中心则是所有被分配到这个聚类的样本的均值。很明显，根据不同的样本被分配到不同的聚类，聚类中心也会随之发生变化。通俗地说，K均值算法的目标函数要达到的目的是，让聚类内部的样本紧紧围绕在聚类的均值向量周围。整个目标函数的值越小，聚类内样本之间的相似度就越高。</p>
<p>和我们熟悉的线性回归模型（Linear Regression）以及对数几率回归（Logistic Regression）一样，目标函数本身仅仅描述了当最终的聚类分配最佳时的一种情况，并没有描述如何能够得到最佳聚类分配的情况。实际上，对于K均值算法而言，直接最小化这个目标函数并不容易，一般来说，找到它的最优解是一个NP难的问题。</p>
<p>不过幸运的是，<strong>贪心算法一般能够找到不错的近似解</strong>。下面我就介绍一个通过迭代优化来近似求解目标函数的算法。</p>
<p><strong>首先，我们对均值向量进行初始化</strong>。比较简单的初始化方法就是直接随机地选择某几个点来当做聚类均值。<strong>然后，我们依次对每一个样本点进行聚类划分</strong>。每个数据点被分配到距离某一个均值向量最近的那个聚类里。当我们进行了所有的分配之后再对均值向量更新。这就完成了一次迭代，整个算法需要进行多次迭代更新。<strong>若迭代更新后聚类结果保持不变，就将当前聚类划分结果返回</strong>。</p>
<h2>文档聚类的难点</h2>
<p>在今天分享的最后，我想来谈一谈文档聚类的一些难点。</p>
<p><strong>首先，怎样衡量聚类的质量好坏，也就是如何评价聚类算法以及比较不同的算法，一直都是聚类模型，甚至说是无监督机器学习算法的共同问题</strong>。有一些评价手段基于定义聚类内部数据的相似度，并且认为聚类内部数据应该比聚类之间的数据更加相似。然而，这样的定义并不能真正反映聚类的质量。</p>
<p><strong>其次，在聚类算法中，往往有一个参数非常难以决定，那就是聚类的个数</strong>。对于一个决定的数据集来说，我们不可能事先知道这个参数。当聚类的个数过少的时候，我们可能无法对数据集进行比较完备的K均值算法描述。而聚类的个数过多的时候，可能数据又被切割成过多的碎片。因此，要确定这个参数就成了聚类算法研究的一个核心难点。</p>
<h2>小结</h2>
<p>今天我为你讲了文档理解中的文档聚类问题。一起来回顾下要点：第一，简要介绍了文档聚类的类型。第二，详细介绍了文档聚类的应用场景。第三，讲解来一个基本的文档聚类K均值算法。第四，简要提及了文档聚类的一些难点。</p>
<p>最后，给你留一个思考题，当得到文档聚类的结果以后，能否把这些结果用在其他任务中呢？如果可以，如何利用？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor46">045 | 文档理解的重要特例：多模文档建模<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>本周我们重点分享搜索系统中的一个重要部件，那就是文档理解。周一我们首先分享了文档理解最基本的一个步骤，那就是给文档分类，主要是看不同文档表达什么类别的信息。然后，周三我们聊了聊另外一个重要的文档理解组件，也就是文档聚类的一些基本的概念和技术。今天我就来和你分享一个文档理解的重要特例：<strong>多模文档建模</strong>（Multimodal Modeling）。</p>
<h2>多模数据</h2>
<p>我们首先来了解一下，到底什么是多模数据。</p>
<p><strong>多模数据，其实就是说数据有多种模式（Modal）的表达途径。而这些多种不同的模式都共同参与描述同一个数据点的不同方面</strong>。</p>
<p>比如，有一张照片反映的是美国总统特朗普在华盛顿白宫的致辞。那么照片本身是对这个场景的一个描述，这是一个模式。然后，和照片相应的文字描述，说明这是特朗普在白宫的致辞，又是另外一个模式。这两个模式是相辅相成的，都是对这个场景的描述。很明显，针对这样多种数据模式的建模是多媒体时代、社交媒体时代非常重要的课题。</p>
<p>在文档领域，非常普遍的情况是文字和图片混搭。一般来说，新闻网站一般都有大量的图文信息。而有一些特殊场景，文字和图片则出现很不对称的混合情况。比如，一些社交媒体（例如Instagram、Pinterest甚至Twitter）上很多短文档都仅仅包含图片或者图片和很少的文字。在这些情况中，文字和图片就成了非常重要的互相补充的信息源。</p>
<p>另外，在电子商务网站中，商品的图片正在成为越来越重要的信息途径。用户经常依靠图片来判断是否要购买某个商品。在电子商务网站上已经很难看到只有文字描述的商品信息了。因此，对于文档的搜索来说，对图文信息的理解是一个核心的技术问题。</p>
<p>那么，多模数据的建模难点是什么呢？</p>
<!-- [[[read_end]]] -->
<p>不同模式的数据其实是有不同的特征，如何能够有效利用各自的特性来最优地反映到某一个任务中（比如分类或者聚类等），是多模数据建模的难点。</p>
<h2>多模数据建模基础</h2>
<p>那么，如何对多种模式的数据进行建模呢？</p>
<p><strong>多模数据建模的核心思路就是数据表征</strong>（Representation）。我们需要思考的是如何学习到文字的表征，以及图片的表征。然后，又如何把文字和图片的表征能够联系到一起。</p>
<p><strong>一个最直接的思路，应该是文字采用我们熟悉的各种文字特性，然后利用图片相关的特性提取技术来对图片进行表征</strong>。得到文字和图片各自的表征之后，直接把两个不同的特征向量（Feature Vector）连接到一起，就得到了一个“<strong>联合表征</strong>”（Joint Representation）。</p>
<p>比如，假设我们学习到了一个1000维度的文字特征向量，然后一个500维的图片特征向量，那么，联合特征向量就是1500维度。</p>
<p>一个相对比较现代的思路是利用两个不同的神经网络分别代表文字和图片。神经网络学习到“<strong>隐含单元</strong>”（Hidden Unit）来表达图片信息以及文字信息之后，我们再把这些“隐含单元”联结起来，组成整个文档的“<strong>联合隐含单元</strong>”。</p>
<p>另外一个思路，那就是并不把多种模式的数据表征合并，而是保持它们的独立。在文字图片这个例子中，那就是保持文字和图片各自的表征或者特征向量，然后通过某种关系来维持这两种表征之间的联系。</p>
<p>有一种假设就是，虽然各种数据模式的表象是不一样的，例如图片和文字的最终呈现不一样，但是内在都是这个核心内容的某种表述。因此，这些数据模式的内在表达很可能是相近的。</p>
<p>这个假设套用到这里，那就是我们假设文字和图片的各自的表征相近，而这个“相近”是依靠某种相似函数来描述，比如这里就经常使用“<strong>余弦相似函数</strong>”（Cosine Similarity）。</p>
<p><strong>有了上述两种思路之后，一种混合的思路就很自然地出现了</strong>。混合思路的基本想法是这样的。数据不同的模式肯定是某种内在表征的不同呈现，因此，需要一个统一的内在表征。但是，只采用一种表征来表达不同的数据源，又明显是不够灵活的。所以，在这种混合的思路里，我们依然需要两种不同的特征来表达文字和图片。</p>
<p>具体来说，混合思路是这样的。首先，我们从文字和图片的原始数据中学习到一个统一的联合表征。然后，我们认为文字和图片各自的表征都是从这个联合表征“发展”或者是“产生”的。很明显，在这样的架构中，我们必须要同时学习联合表征以及两个模式的、产生于联合表征的、单独的各自表征。</p>
<p>值得注意的是，不管是从原始数据到联合表征，还是从联合表征到各自表征，这些步骤都可以是简单的模型，不过通常是多层的神经网络模型。</p>
<p>值得一提的是，在需要多种不同的表征，不管是联合表征还是各自表征的情况中，文字和图片的原始输入甚至是最开始的表征，不一定非要“端到端”（End-to-End）地从目前的数据中学习到。实际上，利用提前从其他数据集中训练好的文字嵌入向量表达来作为文字的输入，是一个非常流行也是非常高效的做法。</p>
<p>有了数据表征之后，很自然地就是利用这些学习到的表征来进行下一步的任务。我们这里就拿文档分类为例。有了联合表征之后，下一步就是利用这个新的表征当做整个文档的特征，学习分类器来进行分类任务。而对于独立的数据表征来说，通常的方法是针对各自表征分别学习一个分类器。这样，我们就有了两个独立的分类器，一个用于文字信息，一个用于图片信息。</p>
<p>有了这两个分类器之后，我们再学习第三个分类器，根据前面两个分类器的分类结果，也就是说这个时候分类结果已经成为了新的特征，来进行第三个分类器的分类。很明显，这个过程需要训练多个不同的分类器，为整个流程增加了不少复杂度。</p>
<h2>其他多模数据建模应用</h2>
<p>除了我刚才所说的表征的学习以及如何构建分类器以外，多模数据还有一些其他的富有挑战性的任务。</p>
<p><strong>在有文字和图片的情况下，我们经常还需要在这两种模式之间进行转换，或者叫做“翻译”</strong>。比如，在已知图片的情况下，如何能够产生一段准确的文字来描述这个图片；或者是在已经有文字的情况下，如何找到甚至产生一张准确的图片。当然，这样的“翻译”并不仅仅局限于文字图片之间，在其他的数据模式中，例如文字和语音之间、语音和图像之间等等，也是普遍存在的。</p>
<p>在这种“翻译”的基础上，更进一步的则是把文字和图片等信息“对接”（Align）起来。比如，针对一组图片，我们能够根据图片的变化产生图片的描述信息。</p>
<p>还有一种应用叫做“<strong>可视化问答</strong>”（Visual Question &amp; Answering），是指利用图片和文字一起回答问题。很显然，要想能够回答好问题，我们需要同时对图片和文字信息进行建模。</p>
<p>不管是“翻译”还是“可视化问答”这些任务，都是近些年来大量利用深度学习所带来的<strong>序列模型</strong>（Sequential Modeling），特别是类似于RNN或者LSTM等模型的领域。</p>
<h2>小结</h2>
<p>今天我为你讲了文档理解中的多模数据建模问题。你可以看到这是一个非常火热的领域，如何理解多媒体数据是现代数据处理的一个重要问题 。</p>
<p>一起来回顾下要点：第一，简要介绍了什么是多模数据。第二，详细介绍了多模数据建模的一些基本思路，包括如何获取文档的表征、什么是联合表征和什么是独立表征。然后，我们还讲了如何构建不同的分类器。第三，简要地提及了其他的多模数据建模任务以及这些任务所依靠的基本的深度学习趋势。</p>
<p>最后，给你留一个思考题，多模建模带来了丰富的特性，由这些丰富特性所训练的分类器，就一定能比单一数据源所训练得到的分类器表现得更好吗？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor47">046 | 大型搜索框架宏观视角：发展、特点及趋势<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>我们在前几周的专栏里讲解了一系列最经典的信息检索（Information Retrieval）技术以及基于机器学习的排序学习算法（Learning to Rank）。然后我们花了一定的时间讨论了两个关键搜索组件的核心技术要点，包括查询关键字理解（Query Understanding）和文档理解（Document Understanding）。除此之外，我们还详细讨论了如何从线上和线下两个层面来评价一个搜索系统。相信你已经对搜索系统的各个基本组成部分有了一个比较基础的把握。</p>
<p>那么，今天我们就第一次从整体上来看看大型搜索系统框架的演变和历史发展，给你一个宏观的认识。相信有了之前的基础知识铺垫，我们今天的分享会让你感觉到水到渠成。</p>
<h2>基于文本匹配的信息检索系统</h2>
<p>我们在介绍TF-IDF和BM25这些经典信息检索系统的时候，其实就已经介绍了不少基于文本匹配的基本的信息检索系统的核心概念。</p>
<p>实际上，<strong>从20世纪50年代有信息检索系统开始一直到2000年前后，这种纯粹基于文本匹配的搜索系统一直都是主流搜索系统的基础所在</strong>。甚至当前的很多开源搜索框架也都是基于这种最基本的信息检索系统的。</p>
<p>总结一下，这种信息检索系统有这么几个特点。</p>
<p><strong>首先，文本匹配系统的基础是一个倒排索引</strong>（Inverted Index）。索引中的“字段”是某一个查询关键字。而每个字段所对应的则是包含这个查询关键字的文档列表。这个文档列表大多按照某种重要的顺序排列。</p>
<!-- [[[read_end]]] -->
<p>比如，某个文档整体和查询关键字的相关度大，那么就会排列到这个列表的前面。当然，也并不一定所有包含这个查询关键字的文档都会包含到这个列表中。另外，之所以叫做“索引”，也是因为这个列表中并不实际存储整个文档，往往只是存储文档的编号。</p>
<p>从这个基本的索引结构其实衍生出了很多值得研究而且在实际应用中也很有必要考虑的问题。</p>
<p>比如如何进一步优化构建这个索引。特别是当列表中的文档数目过多的时候，或者当查询关键字也很多的时候，采用某种编码的模式来压缩索引就变得很关键。</p>
<p>同时，索引过大也会带来很多性能上的问题。比如，当索引过大的时候，某一部分索引或者很大部分就无法存放在内存中，这个时候，整个搜索系统的性能就受到了很大的威胁。因为在对查询关键字进行处理的时候，就需要反复在内存和硬盘上切换内容。因此，对于索引进行创新，使得索引能够在内存中使用并且快速查询是一个非常重要的课题。</p>
<p><strong>文本匹配系统的另外一个特点就是对传统的检索方法，例如TF-IDF或BM25以及它们变种的依赖</strong>。这些方法在查询关键字和索引之间架起一座桥梁，使得搜索引擎能够针对每一个查询关键字文档对赋予一个数值。然后我们可以利用这个数值进行排序。</p>
<p>然而，这些方法本质上的最大问题就是，他们都不是基于机器学习的方法。也就是说，这些方法本身都是基于一些研究人员的假设和经验，往往无法针对现有的数据进行适应。也正是因为如此，这种方法的研发工作往往让人感到缺乏理论基础。</p>
<p><strong>最后，传统的文本匹配系统还存在一个问题，那就是很难比较自然地处理多模数据</strong>。也就是我们之前说过的，如果数据中有文字、图像、图（Graph）信息等综合数据信息，文本匹配的方法在这方面并没有提供什么理论指导。</p>
<p><strong>那么，文本匹配系统有哪些优势呢？</strong>其实，即便是在今天，<strong>文本匹配系统的最大劣势也是其最大优势：不依靠机器学习</strong>。也就是说，如果你要构建一个新的搜索系统或者是某个App中有搜索功能，最开始的版本最容易依靠文本匹配系统，因为这时候并不需要依靠任何数据，并且文本匹配系统不需要太多调优就能上线。但是，文本匹配系统的这一优势今天往往被很多人忽视。</p>
<h2>基于机器学习的信息检索系统</h2>
<p><strong>从2000年开始，基于机器学习的信息检索系统思潮逐渐变成了构建搜索系统的主流</strong>。在这种框架下的信息检索系统主要有以下这些特点。</p>
<p><strong>第一，基于机器学习的系统开始有了一整套的理论支持</strong>。比如我们之前讲过的单点法（Pointwise）排序、配对法（Pairwise）排序和列表法（Listwise）排序等方法，都明确地使用通用的机器学习语言来描述搜索问题。</p>
<p><strong>什么叫做通用的机器学习语言？</strong>那就是，有一个明确的目标函数，有明确特性（Feature），有明确的算法来求解在这些框架下的机器学习问题。同时，机器学习的一系列基本的方法论，比如训练数据、测试数据、评测方法等等都可以应用到信息检索的场景中来。这对于搜索系统的性能以及整体搜索系统的研发都有了非常重要的指导意义。</p>
<p>同时，这也开启了一个非常便利的提高搜索系统效果的大门。那就是任何机器学习领域内部的发展，很多都可以被借鉴到搜索系统中。比如，最近几年深度学习的大力发展，就可以在已经铺就的基于机器学习的搜索系统框架下很容易地进行尝试。</p>
<p><strong>第二，基于机器学习的搜索系统能够很容易地利用多模数据</strong>。对于机器学习而言，多模数据，或者说是多种类型的数据的融合，可以很自然地通过特性以及不同类型的特性来表达。因此，对于多模数据，机器学习有天然的优势。<strong>通过学习这些特性之间的联系从而预测相关度，是机器学习的强项</strong>。</p>
<p>因此，理解搜索系统各个部分的数据并把这些信息用在排序算法中，这样的方式就如雨后春笋般大量地出现了。比如，我们之前提到过的查询关键字理解中的查询关键字分类和查询关键字解析，以及文档理解中的文档分类所产生的特性，很难想象这些内容在传统的文本匹配系统中得以应用。但在基于机器学习的搜索系统中，这些信息则往往成为提高相关度建模的重要工具。</p>
<p>同时，我们也在之前的分享中介绍了，针对多模数据，机器学习中专门有相关的研究，思考如何把不同类型的数据能够更好地融合在一起来建模。这类研究在传统的文本匹配搜索系统中根本不存在。</p>
<p><strong>基于机器学习的搜索系统也不是完美无瑕</strong>。实际上，如果没有各种保证，机器学习并不一定能在实际中获得满意的效果，因为基于机器学习的搜索系统对整个系统而言有了较高的要求。</p>
<p>机器学习往往需要大量的数据，而在一个现实的软件产品中，如何能够构建可靠并且干净的数据就是一个不简单的任务。如果没有可靠的数据，对于一般的机器学习算法而言，就是“垃圾进入，垃圾出来”，实际效果往往比不使用机器学习还要糟糕。</p>
<p>同时，机器学习系统可能会有特性异常、模型异常、数据异常等等其他软件系统所不具备的各种问题。如果在生产系统中对这些情况没有一个估计和处理，机器学习搜索系统往往也会不尽人意。</p>
<h2>更加智能的搜索系统</h2>
<p>很明显，搜索系统不会仅仅停留在应用普通的机器学习算法。近几年，搜索系统的发展有两个方面。</p>
<p><strong>一方面，当然就是依靠深度学习发展的春风，不少学者和研究人员都在思考，如何能够利用深度学习技术让搜索系统更上一层楼</strong>。在这方面的研发中，不仅仅是针对普通的深度学习算法，而是看如何应用深度学习所特有的一些模式，比如<strong>深度强化学习</strong>等方式来重新思考搜索问题。</p>
<p><strong>另一方面，就是从用户的角度来说，研究更加有意义的评测方式</strong>。也就是说，如何能够真正抓住用户对这个系统的偏好，并且能够进一步地去优化这个系统的性能。</p>
<h2>小结</h2>
<p>今天我为你讲了现代搜索技术框架的发展，并简单提及了搜索系统目前发展的趋势 。 一起来回顾下要点：第一，我们讲了基于文本匹配的经典搜索系统的特点；第二，我们讲了基于机器学习的搜索系统的特点。</p>
<p>最后，给你留一个思考题，在机器学习和深度学习的思潮中，传统搜索系统的核心，也就是我们说过的索引，能否依靠机器学习来生成呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor48">047 | 多轮打分系统概述<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>周一我为你介绍了搜索系统的一个宏观分类，包括传统的文本匹配信息检索系统和机器学习信息检索系统。这个分类可以让你非常清晰地了解信息搜索系统的历史进程，并对这两种搜索系统的特点有所了解。</p>
<p>今天我们就来剖析搜索系统的另一个框架体系：<strong>多轮打分（Scoring）系统</strong>。</p>
<h2>多轮打分系统综述</h2>
<p>什么是多轮打分系统？为什么搜索系统需要多轮打分？</p>
<p>我们拿上次介绍的机器学习搜索系统为例。从整体来说，机器学习搜索系统的目的是利用机器学习模型来预测文档和搜索关键字之间的相关性。那么，在理想状态下，针对每一个查询关键字，我们需要对数据集中的每一个文档进行打分。</p>
<p>如果是一个类似互联网搜索引擎的应用场景，那么理论上，每一个查询关键字都需要对几亿甚至十几亿的网页进行打分。显然，仅仅从这个数量级上来说，这样做都是不现实的。</p>
<p>从另一个方面来讲，目前比较通用的机器学习模型，特别是在排序问题上有强劲表现的树模型（Tree Model），比如GBDT（Gradient Boosted Decision Trees）或者神经网络，都有较高的计算时间复杂度。要想在实时响应的反应时间内（例如几百毫秒内）对相对比较多（我们这里说的是几千甚至上万）的文档进行打分是很困难的，我们刚才提到的整个数据集中是有几亿甚至十几亿的文档，那就更加困难了。</p>
<p>于是在这样的情况下，我们就需要有这么一种机制：对于每个查询关键字而言，能够先有一个方法在整个数据集上快速评价出几百到几千不等（视具体应用）的文档，然后在这个几百到几千不等的集合上运用复杂的模型进行计算并且排序。 <strong>这种需要对文档进行两轮打分的流程叫做“两轮打分框架”</strong>（见参考文献[3]）。</p>
<!-- [[[read_end]]] -->
<p><strong>第一轮打分又常常被称作“顶部K”（Top-K）提取</strong>。你可以看到，在这样的机制下，相对比较简单的模型和方法可以用于第一轮打分，因为这一轮是有可能在全部的数据集上进行操作的。这一轮也是被优化得最彻底的一轮，毕竟需要在海量的数据集中快速找到几百或者几千个合适文档。</p>
<p><strong>然后在第二轮，当文档的数目已经降到了几千甚至几百的时候，我们就可以使用比较复杂的模型了</strong>。这其实也是整个多轮打分的一个目的，那就是可以在一个比较适量的数据集上应用复杂模型。</p>
<p>实际上我们不仅可以对文档进行两轮打分，甚至可以扩展到多轮打分，比如雅虎搜索引擎的“三轮打分机制”（见参考文献[1]）。第三轮根据第二轮打分所产生的文档“上下文特征“（Contextual Feature），从而可以进一步精准地提高搜索结果的质量。类似的思想也可以借鉴参考文献[2]。</p>
<p>一般来说，<strong>多轮打分系统有两个明显的特点</strong>。一个特点是每一轮都比上一轮使用的文档数目要少。也就是说，多轮打分的目的是每经过一轮都筛选出更少的文档。另外一个特点是每一轮使用的特性数目都比上一轮更加复杂，模型也更加复杂。</p>
<h2>第一轮“顶部K提取”</h2>
<p>我刚才说了一下多轮打分系统的机理。现在我们来看一看第一轮打分，也就是俗称的“顶部K提取”都有什么技术特点。</p>
<p><strong>“顶部K提取”的一个核心问题就是，如何快速地从非常巨大的数据集中返回有价值的几百到几千的文档</strong>。这就需要对获取文档的数据结构以及使用的模型有一定的要求。</p>
<p>首先，“<strong>倒排索引</strong>”（Inverted Index）是一个非常重要的机制。是否能够建立有效的索引是第一轮打分能否达到目的的关键。</p>
<p>传统的倒排索引已经可以在很大程度上有效地“削减”没必要的文档。我再简要地讲解一下这个基本的数据结构，我们一起来复习一下倒排索引的内容。索引中的“字段”是某一个查询关键字，而每个字段所对应的则是包含这个查询关键字的文档列表。</p>
<p>这个文档列表大多按照某种重要的顺序排列。比如，某个文档整体和查询关键字的相关度大，那么就会排列到这个列表的前面。当然，也并不是所有包含这个查询关键字的文档一定都会包含到这个列表中。另外，之所以叫做“索引”，也是因为这个列表中并不实际存储整个文档，而往往是只存储文档的编号。</p>
<p>除了最基本的通过索引来提取文档以外，我们还可以通过一些简单的模型来提取文档，比如<strong>线性模型</strong>。一个经典的方法叫做“<strong>WAND操作符</strong>”（WAND Operator，参见参考资料[4]）。</p>
<p>当然，严格来讲，WAND操作符并不是把一个通用的、普遍的线性模型应用到文档索引上，而是说，如果我们能够把模型给简化为只有正系数的线性模型，那么，整个模型其实可以看做是两个向量的点积，而WAND则是对点积在索引上的一种优化。</p>
<p>当然，研发人员不仅想把线性模型直接使用到倒排索引上。实际上，这么多年来也有不少的尝试，希望能够把树模型直接应用到倒排搜索上。但是，因为我们之前提到的性能因素，通常情况下树模型都没法直接应用（这里提供一个参考文档[5]供你阅读）。应该说，树模型的优化还处在一个研究的阶段。</p>
<h2>第二轮或以后轮数的重排</h2>
<p>当我们结束了第一轮之后，就来到了第二个阶段，也是经常所说的<strong>“重排”（Re-rank）阶段</strong>。在这个阶段，文档已经从索引中到达了内存。一般来说，在比较普通的架构下，所有的几百到几千不等的文档在这个时候已经整合到了某一台机器的内存中。</p>
<p>我们在思考第一轮和第二轮的时候，需要先理解这两轮的一个重要区别，才能知道什么样的模型能够比较好地应用在这两个不同的场景中。</p>
<p>首先，第一轮必须能够应用在搜索倒排索引上。现代的索引模式，往往是部署在很多的节点（机器）上的。也就是说，每一个节点都拥有一部分，但不是完整的文档集合。这也就导致了我们之前介绍过的单点法（Pointwise）、配对法（Pairwise）和列表法（Listwise）这些机器学习方法很难在索引的这个级别直接使用，因为每一个节点为了计算效率问题，只能访问到一部分的文档并且进行打分。</p>
<p>因此，<strong>两轮的最大区别就是，第一轮一般都是针对单一文档的打分，而只有第二轮才能利用上配对法或者列表法针对文档打分</strong>。我们之前曾经提过，配对法或者列表法都比单点法的效果要好，因此如何平衡这两者在两轮中的表现差异就变得越来越重要了。</p>
<p>这里我简单提一下第二轮之后的其他轮数。当我们应用了第二轮之后，其实基本上就已经产生了最后的结果集合。为什么还需要其他轮数呢？</p>
<p><strong>我们可能还需要其他轮数至少有两个原因</strong>。</p>
<p>第一，很多搜索系统中，相关排序只是搜索系统的一个方面。搜索系统还可能引入“多元化”或者其他的“商业规则”。这些规则或者进一步的重新排序很难完整地在前面的轮数中进行。</p>
<p>第二，当最后文档集合生成之后，有证据表明（参考文献[1]），我们还可以生成一些更加精细的特性来进一步提高排序的精度。因此，多轮打分是值得探索的。</p>
<h2>小结</h2>
<p>今天我为你讲了现代搜索技术中一个很重要的思路，多轮打分系统 。 一起来回顾下要点：第一，我们讲了为什么需要多轮打分，多轮打分的核心思路是什么。第二，我们分别讲了第一轮和第二轮以及后面轮数的一些特点。</p>
<p>最后，给你留一个思考题，在多轮打分系统的情况下，如何评测第一轮模型的好坏呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p><strong>参考文献</strong></p>
<ol>
<li>
<p>Dawei Yin, Yuening Hu, Jiliang Tang, Tim Daly, Mianwei Zhou, Hua Ouyang, Jianhui Chen, Changsung Kang, Hongbo Deng, Chikashi Nobata, Jean-Marc Langlois, and Yi Chang. Ranking Relevance in Yahoo Search. <em>Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD '16)</em>. ACM, New York, NY, USA, 323-332, 2016.</p>
</li>
<li>
<p>Ruey-Cheng Chen, Luke Gallagher, Roi Blanco, and J. Shane Culpepper. Efficient Cost-Aware Cascade Ranking in Multi-Stage Retrieval. <em>Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '17)</em>. ACM, New York, NY, USA, 445-454, 2017.</p>
</li>
<li>
<p>Van Dang, Michael Bendersky, and W. Bruce Croft. Two-Stage learning to rank for information retrieval. <em>Proceedings of the 35th European conference on Advances in Information Retrieval (ECIR’13)</em>, Pavel Serdyukov, Pavel Braslavski, Sergei O. Kuznetsov, Jaap Kamps, and Stefan Rüger (Eds.). Springer-Verlag, Berlin, Heidelberg, 423-434, 2013.</p>
</li>
<li>
<p>Andrei Z. Broder, David Carmel, Michael Herscovici, Aya Soffer, and Jason Zien. Efficient query evaluation using a two-level retrieval process. <em>Proceedings of the twelfth international conference on Information and knowledge management (CIKM '03)</em>. ACM, New York, NY, USA, 426-434, 2003.</p>
</li>
<li>
<p>N. Asadi, J. Lin and A. P. de Vries. Runtime Optimizations for Tree-Based Machine Learning Models. <em>In IEEE Transactions on Knowledge and Data Engineering</em>, vol. 26, no. 9, 2281-2292, 2014.</p>
</li>
</ol>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor49">048 | 搜索索引及其相关技术概述<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>本周我们分享的主题是从宏观上来剖析现代搜索架构。周一我介绍了搜索系统的一个大的分类，一类是从20世纪50年代开始研发并使用的传统文本匹配信息检索系统，一类是从2000年开始发展并逐渐成熟的机器学习信息检索系统。周三我们剖析了搜索系统的另一个框架体系，多轮打分系统，阐述了为什么需要多轮打分，以及每一轮打分又有什么特性。</p>
<p>今天，我们来看一个在本周已经反复涉及到的话题：<strong>倒排索引</strong>（Inverted Index）。一起来聊聊它的核心技术。值得注意的是，关于索引的很多话题其实都会牵涉到搜索中的“查询关键字处理”（Query Processing），我们今天的分享就主要来谈谈索引及相关技术在“查询关键字处理”这个场景下的应用。</p>
<h2>经典的索引结构</h2>
<p><strong>经典的索引结构由“字段”（Field）和对应的列表组成</strong>。一般来说，“字段”就是某一个查询关键字。在英文里，这就是一个单独的单词；在中文里，这也许就是一个词或者短语。每个字段所对应的列表就是包含这个查询关键字的文档列表。</p>
<p><strong>有两点值得注意</strong>。</p>
<!-- [[[read_end]]] -->
<p>第一，在文档列表里的文档，大多按照某种重要的顺序排列，这方便我们首先提取重要性高的文档。比如，某个文档整体和查询关键字的相关度大，那么就会排列到这个列表的前面。</p>
<p>第二，对于每个字段，也就是查询关键字而言，所有包含这个查询关键字的文档并不一定都会包含到这个列表中，这个列表可以是一个节选。</p>
<p>另外，我们前面已经讲过了，之所以叫做“索引”，也是因为这个列表中并不实际存储整个文档，往往是只存储文档的编号。</p>
<p>如果用户输入的查询关键字包含多个词组，根据这个最基础的结构，我们可以很容易地获取包含所有关键字的文档集合。这个操作仅仅相当于在多个列表中做“<strong>归并排序</strong>”（Merge Sort）。</p>
<p>除了在索引中仅仅保存最基本的文档标号信息以外，另外一些文档的基础信息也可以一并存放在索引中。比如，<strong>经常存放的信息还有文档包含某个查询关键字的次数</strong>。保存次数信息本质上是在保存“词频”（Term Frequency）这个文档特性。</p>
<p>我们前面分享经典的信息检索模型的时候，介绍过很多模型，例如TF-IDF、BM25或者语言模型，都对词频的计算有很强的依赖。<strong>在索引中存放词频信息有助于近似计算这些基础的检索模型</strong>。</p>
<p><strong>另外一个经常存放的信息就是查询关键字在文档中出现的位置</strong>（Position）。位置信息对于有多个查询关键字的时候尤为重要。比如，我们要搜索的词组是“五道口电影院”。在这样的情况下，我们非常希望“五道口”在某个文档中出现的位置和“电影院”在文档中出现的位置相邻。这样，我们可以确认这个文档的确是关于“五道口电影院”的，而不是恰好含有“五道口”和“电影院”这两个词。</p>
<p><strong>同时，位置信息还可以帮助搜索引擎生成搜索结果界面上的“结果摘要”信息</strong>。我们经常看到搜索结果页面上有几句话的摘要信息，这个信息就需要查询关键字的位置来生成。</p>
<h2>索引技术</h2>
<p>除了最基础的索引技术以外，研发人员开发了多种技术让索引更加高效。</p>
<p><strong>第一个技术当然就是希望对索引进行压缩</strong>。索引信息很快就会随着可能的关键字数目的膨胀而扩展。索引中每一个关键字所对应的文档列表也会越来越庞大。因此，能否快速处理索引信息并为后续的计算节约时间就变得非常关键。本周三我们分享了多轮打分系统。多轮打分系统的的一个重要思想就是整个流程必须在几百毫秒的响应时间内完成。因此，每一个步骤，包括从索引中提取“顶部K个文档”的过程都需要很快捷。</p>
<p>压缩技术博大精深，我们在今天的分享中就不展开讨论这部分的内容了。在这里，我们只需要从高维度上把握这个问题的一个基本思路。索引的一个基本信息就是相对于某个查询关键字的文档列表。而存储在文档列表里的并不是文档本身的数据，而是文档的某种信息，比如文档本身的编号。而编号就是数字，文档列表最终就是一个数字序列。压缩技术中有很多算法就是对一个数字序列进行压缩。</p>
<p>那么，到底怎样才能起到压缩的作用呢？我们这里举一个例子。比方说，有一种压缩算法是基于一种叫“<strong>差值编码</strong>”（Delta Encoding）的技术。简单来说，就是不直接记录文档编号本身，而是按照文档编号的顺序，记录文档编号之间的差值。</p>
<p>对于某些非常频繁的查询关键字而言，这些词汇有可能会出现在非常多、甚至是绝大多数的文档中。而采用这种“差值编码”来对文档列表进行重新编排，我们就可以用一组很小的数（这些数表达两个相邻文档编号的差值）来代表文档列表。当然，这种方法对于文档很少的查询关键字效果肯定不明显。同时，这种技术也要求文档列表不按照相关度排序，而要按照文档的编号排序。</p>
<p><strong>在索引的发展过程中也开发出了一些很细小的技术，比如“略过”</strong>（Skipping）。简单来说，这个技术就是，当我们有多个查询关键字的时候，而且这些关键字之间的频率有非常大的差距，我们可以略过一些文档。</p>
<p>例如在“北京，地铁出行”这个组合中，“北京”有可能在整个数据集中出现的频率是“地铁出行”的几倍甚至十几倍、上百倍，因此我们其实并不需要搜索所有包含“北京”的文档，因为最终需要的仅仅是同时包含两个关键字的这样一个交集。因此，在处理“北京”的文档序列的时候，我们可以“略过”K个文档，然后看有没有到达下一个包含“地铁出行”的文档。这里的K当然是一个参数，需要尝试。有了这样的思路，处理多个查询关键字时就可以很显著地提升效果。</p>
<h2>查询关键字处理</h2>
<p>最后我们来谈一谈查询关键字处理。说得通俗易懂一点，就是如何从索引中提取出相关的文档并计算分数。这里有两种基本思路。</p>
<p><strong>第一种思路叫作“文档优先”（Document-at-a-Time）计算策略</strong>。简单来说，就是我们首先从索引中找到所有查询关键字所对应的文档集合。比如我们处理“北京，地铁出行”这一查询关键字组合，我们先取出所有包含这些关键字的文档；然后保持一个“优先队列”（Priority Queue）来保存分数最高的K个文档；再针对取出来的文档分别计算分数，这里的分数有可能就是词频的某种简化检索模型；计算完分数之后，我们把分数压入优先队列中。</p>
<p><strong>第二种思路和“文档优先”思路相对应，叫作“词优先”（Term-at-a-Time）计算策略</strong>。在这种思路下，我们对所有查询关键字词组中的每一个字一一进行处理。请注意，这里的第一个步骤其实是一样的，我们依然要先取出所有的文档集合。但是这一步之后，我们先处理包含“北京”的文档，得到所有文档分数的一个部分值，然后再处理“地铁出行”，在刚才计算的部分值上进行更新，取得最后的分数。</p>
<p>在实际应用中，这两种策略是更加复杂的优化查询关键字处理的基础，在这两种思路的基础上演化出了很多高级算法，不仅能快速地处理文字特性，还包括我们讲过的类似WAND操作符这样能够模拟线性模型的算法。</p>
<h2>小结</h2>
<p>今天我为你讲了现代搜索技术的一个核心组成部分，那就是倒排索引系统。 一起来回顾下要点：第一，我们讲了索引系统的基本组成和原理。第二，我们讲了索引相关技术的一个概况，重点介绍了压缩以及“略过”的含义。第三，简要讲解了查询关键字处理的两种最基础的策略。</p>
<p>最后，给你留一个思考题，如果我们既有图像信息又有文字信息，那该如何构建我们的索引呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor50">049 | PageRank算法的核心思想是什么？<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>上周我们介绍了信息搜索系统的历史进程，剖析了搜索系统的多轮打分系统，还深入探讨了倒排索引，聊了聊它的核心技术。</p>
<p>这周我要和你分享的是在互联网搜索引擎兴起之后的一个研发需要，那就是如何理解网页和网页之间的关系，特别是怎么从这些关系中提取网页中除文字以外的其他特性。这部分的一些核心算法曾是提高搜索引擎质量的重要推进力量。另外，我们这周要分享的算法也适用于其他能够把信息用结点与结点关系来表达的信息网络。</p>
<p>今天，我们先看一看用图来表达网页与网页之间的关系，并且计算网页重要性的经典算法：<strong>PageRank</strong>。</p>
<h2>PageRank的简要历史</h2>
<p>时至今日，谢尔盖·布林（Sergey Brin）和拉里·佩奇（Larry Page）作为Google这一雄厚科技帝国的创始人，已经耳熟能详。但在1995年，他们两人还都是在斯坦福大学计算机系苦读的博士生。那个年代，互联网方兴未艾。雅虎作为信息时代的第一代巨人诞生了，布林和佩奇都希望能够创立属于自己的搜索引擎。1998年夏天，两个人都暂时离开斯坦福大学的博士生项目，转而全职投入到Google的研发工作中。他们把整个项目的一个总结发表在了1998年的万维网国际会议上（ WWW7，the seventh international conference on World Wide Web）（见参考文献[1]）。<strong>这是PageRank算法的第一次完整表述</strong>。</p>
<p>PageRank一经提出就在学术界引起了很大反响，各类变形以及对PageRank的各种解释和分析层出不穷。在这之后很长的一段时间里，PageRank几乎成了网页链接分析的代名词。给你推荐一篇参考文献[2]，作为进一步深入了解的阅读资料。</p>
<h2>PageRank的基本原理</h2>
<p>我在这里先介绍一下PageRank的最基本形式，这也是布林和佩奇最早发表PageRank时的思路。</p>
<p>首先，我们来看一下每一个网页的周边结构。<strong>每一个网页都有一个“输出链接”（Outlink）的集合</strong>。这里，输出链接指的是从当前网页出发所指向的其他页面。比如，从页面A有一个链接到页面B。那么B就是A的输出链接。根据这个定义，可以同样定义“<strong>输入链接</strong>”（Inlink），指的就是指向当前页面的其他页面。比如，页面C指向页面A，那么C就是A的输入链接。</p>
<p>有了输入链接和输出链接的概念后，下面我们来定义一个页面的PageRank。我们假定每一个页面都有一个值，叫作PageRank，来衡量这个页面的重要程度。这个值是这么定义的，<strong>当前页面I的PageRank值，是I的所有输入链接PageRank值的加权和</strong>。</p>
<p>那么，权重是多少呢？对于I的某一个输入链接J，假设其有N个输出链接，那么这个权重就是N分之一。也就是说，J把自己的PageRank的N分之一分给I。从这个意义上来看，I的PageRank，就是其所有输入链接把他们自身的PageRank按照他们各自输出链接的比例分配给I。谁的输出链接多，谁分配的就少一些；反之，谁的输出链接少，谁分配的就多一些。这是一个非常形象直观的定义。</p>
<p>然而，有了这个定义还是远远不够的，因为在这个定义下，页面I和页面J，以及其他任何页面的PageRank值是事先不知道的。也就是等式两边都有未知数，这看上去是个无解的问题。</p>
<!-- [[[read_end]]] -->
<p>布林和佩奇在他们的论文中采用了一种迭代算法。<strong>这个算法很直观，那就是既然不知道这些PageRank的值，那我们就给他们一组初始值，这个初始值可以是这样的情形，所有页面有相同的PageRank值</strong>。然后，根据我们上面所说的这个定义，更新所有页面的PageRank值。就这么一遍一遍地更新下去，直到所有页面的PageRank不再发生很大变化，或者说最后收敛到一个固定值为止。他们在文章中展示了实际计算的情况，往往是在比较少的迭代次数后，PageRank值就能够收敛。</p>
<p>以上就是整个PageRank算法的基本思想和一种迭代算法。</p>
<h2>PageRank算法的改进</h2>
<p>完全按照我们上面介绍的这个最原始的PageRank算法，布林和佩奇很快就遇到了麻烦。</p>
<p><strong>第一个麻烦就是有一些页面并没有输出链接，比如某些PDF文件，或者一些图片文件</strong>。由于没有输出链接，这些页面只能聚集从上游输入链接散发过来的PageRank值，而不能把自己的PageRank值分发出去。这样的结果就是，这些页面成为一些“悬空”（Dangling）结点。<strong>悬空结点存在的最大问题就是会使得PageRank的计算变得不收敛</strong>。这些结点成了PageRank值的“黑洞”，导致悬空结点的PageRank值越来越大，直至“吸干”其他所有输入链接的值。</p>
<p>要解决这个问题，就要为悬空结点“引流”，能够把这些点的值分发出去、引出去。<strong>谢尔盖和拉里找到的一个方法是，对于每一个悬空结点，都认为这个结点能够随机到达整个网络上的其他任意一个结点</strong>。也就相当于人工地从这个结点连接到所有页面的一个结点，让当前悬空结点的PageRank能够“均匀”地分散出去到其他所有的结点，这就解决了悬空结点的问题。</p>
<p>然而原始的PageRank还存在其他问题。要想保证PageRank的收敛性，并且能够收敛到唯一解，我们还需要第二个改进。<strong>第二个改进就是，即便一个页面有自然的输出链接，我们也需要一个机制，能够从这个页面跳转到其他任何一个页面</strong>。这也就是模拟假设一个用户已经浏览到了某个页面，一方面用户可以顺着这个页面提供的输出链接继续浏览下去，另一方面，这个用户可以随机跳转到其他任何一个页面。</p>
<p>有了这个机制以后，对于所有的结点来说，PageRank的分配也就自然地产生了变化。在之前的定义中，每个页面仅仅把自己的PageRank值输送给自己原生的所有输出链接中。而现在，这是一部分的“分享”，另外一部分还包括把自己的PageRank值分享到所有的页面。当然，后者的总量应该比前者要少。于是，<strong>这里可以引入一个参数，来控制有多大的比例我们是顺着输出链接走，而多大的比例跳转其他页面</strong>。通常情况下，这个参数的取值范围大约是60%~85%。</p>
<p>有了这两个改进之后，整个网络上的每个页面实际上已经可以到达其他任何页面。也就是说，<strong>整个页面网络成了一个完全联通的图，PageRank算法就有了唯一的收敛的解</strong>。</p>
<h2>PageRank分析</h2>
<p>PageRank被提出后不久，就有学者开始针对PageRank模型和算法的性质进行分析。大家很快发现，还有一些其他的方法可以对PageRank进行解释。</p>
<p><strong>第一种比较流行的，也是更加正规的解释PageRank的方法，是把我们刚才说的这个分配等式写成矩阵的形式</strong>。那么，整个算法就变成了一个标准的求解一个随机矩阵的“左特征向量”的过程。这个随机矩阵就是我们刚才讲的经过了两次修改后的跳转规律的矩阵形式。而刚才所说的迭代方法正好就是求解特征向量的“<strong>乘幂法</strong>”（Power Method）。在一定条件下的随机矩阵，经过乘幂法就一定能够得到一个唯一解。</p>
<p><strong>另外一种解释，是把刚才我们说的这个矩阵形式进行一次代数变形，也就是把等式两边的各项都移动到等式的一边，而另一边自然就是0</strong>。那么，整个式子就变了一个“线性系统”的求解过程。也就是说从代数的角度来解释整个PageRank的求解过程。</p>
<h2>小结</h2>
<p>今天我为你讲了现代搜索技术中的一个重要分支，链接分析中最重要的算法PageRank的核心思想 。 一起来回顾下要点：第一，我们讲了PageRank的一些简明历史和算法最原始的定义和思路 。第二，我们讲了PageRank的两种改进。第三，我们简要地介绍了针对PageRank的两种解释方法。</p>
<p>最后，给你留一个思考题，除了乘幂法，你觉得还有什么方法可以用来求解PageRank值？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p><strong>参考文献</strong></p>
<ol>
<li>
<p>Sergey Brin and Lawrence Page. The anatomy of a large-scale hypertextual Web search engine. <em>Proceedings of the seventh international conference on World Wide Web 7 (WWW7)</em>, Philip H. Enslow, Jr. and Allen Ellis (Eds.). Elsevier Science Publishers B. V., Amsterdam, The Netherlands, The Netherlands, 107-117, 1998.</p>
</li>
<li>
<p>Langville, Amy N.; Meyer, Carl D. Deeper Inside PageRank. <em>Internet Math</em>. no. 3, 335-380, 2003.</p>
</li>
</ol>
<p><strong>论文链接</strong></p>
<ul>
<li>
<p><a href="http://infolab.stanford.edu/~backrub/google.html">The anatomy of a large-scale hypertextual Web search engine</a></p>
</li>
<li>
<p><a href="http://meyer.math.ncsu.edu/Meyer/PS_Files/DeeperInsidePR.pdf">Deeper Inside PageRank</a></p>
</li>
</ul>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor51">050 | 经典图算法之HITS<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>这周我们分享的内容是如何理解网页和网页之间的关系。周一我们介绍了用图（Graph）来表达网页与网页之间的关系并计算网页的重要性，就是经典算法PageRank。今天我来介绍一下PageRank的姊妹算法：<strong>HITS算法</strong>。</p>
<h2>HITS的简要历史</h2>
<p>HITS是Hypertext-Induced Topic Search算法的简称。这个算法是由康奈尔大学计算机科学教授乔·克莱恩堡（Jon Kleinberg）于1998年发明的，正好和我们周一讲的布林和佩奇发表PageRank算法是同一年。</p>
<p>这里有必要简单介绍一下乔这个人。乔于1971年出生在马萨诸塞州波士顿。1993年他毕业于康奈尔大学获得计算机科学学士学位，并于1996年从麻省理工大学获得计算机博士学位。1998的时候，乔正在位于美国西海岸硅谷地区的IBM阿尔玛登（Almaden）研究院做博士后研究。HITS的工作最早发表于1998年在旧金山举办的第九届ACM-SIAM离散算法年会上（详细论述可参阅参考文献）。</p>
<p>乔目前是美国国家工程院（National Academy of Engineering）和美国自然与人文科学院（American Academy of Arts and Sciences）院士。顺便提一下，乔的弟弟罗伯特·克莱恩堡也在康奈尔大学计算机系任教职。</p>
<h2>HITS的基本原理</h2>
<p>在介绍HITS算法的基本原理之前，我们首先来复习一下网页的网络结构。每一个网页都有一个“输出链接”（Outlink）的集合。输出链接指的是从当前网页出发所指向的其他页面，比如从页面A有一个链接到页面B，那么B就是A的输出链接。根据这个定义，我们来看“输入链接”（Inlink），指的就是指向当前页面的其他页面，比如页面C指向页面A，那么C就是A的输入链接。</p>
<p>要理解HITS算法，我们还需要引入一组概念：<strong>“权威”（Authority）结点</strong>和<strong>“枢纽”（Hub）结点</strong>。这两类结点到底是什么意思呢？</p>
<!-- [[[read_end]]] -->
<p>HITS给出了一种“循环”的定义：<strong>好的“权威”结点是很多“枢纽”结点的输出链接，好的“枢纽”结点则指向很多好的“权威”结点</strong>。这种循环定义我们在PageRank的定义中已经见识过了。</p>
<p>很明显，要用数学的方法来表述权威结点和枢纽结点之间的关系就必须要为每一个页面准备两个值。因为从直觉上来说，不可能有一个页面完全是权威，也不可能有一个页面完全是枢纽。绝大多数页面都在这两种角色中转换，或者说同时扮演这两类角色。</p>
<p>数学上，对于每一个页面I，<strong>我们用X来表达这个页面的“权威值”，用Y来表达这个页面的“枢纽值”</strong>。那么，一个最直观的定义，对于I的权威值X来说，它是所有I页面的输入链接的枢纽值的总和。同理，I的枢纽值是所有I页面输出链接的权威值的总和。这就是HITS算法的原始定义。</p>
<p>我们可以看到，如果I页面的输入链接的枢纽值大，说明I页面经常被一些好的“枢纽”结点链接到，那么I自身的权威性自然也就增加了。反之，如果I能够经常指向好的“权威”结点，那I自身的“枢纽”性质也就显得重要了。</p>
<p>当然，和PageRank值一样，X和Y在HITS算法里也都是事先不可知的。因此，<strong>HITS算法的重点就是要求解X和Y</strong>。如果把所有页面的X和Y都表达成向量的形式，那么HITS算法可以写成X是矩阵L的转置和Y的乘积，而Y是矩阵L和X的乘积，这里的矩阵L就是一个邻接矩阵，每一行列表达某两个页面是否相连。进行一下代数变形，我们就可以得到X其实是一个矩阵A乘以X，这里的A是L的转置乘以L。Y其实是一个矩阵B乘以Y，这里的B是L乘以L的转置。</p>
<p>于是，惊人的一点出现了，那就是HITS算法其实是需要求解矩阵A或者矩阵B的主特征向量，也就是特征值最大所对应的特征向量，用于求解X或者Y。这一点和PageRank用矩阵表达的形式不谋而和。也就是说，尽管PageRank和HITS在思路和概念上完全不同，并且在最初的定义式上南辕北辙，但是经过一番变形之后，我们能够把两者都划归为<strong>某种形式的矩阵求解特征向量的问题</strong>。</p>
<p>实际上，<strong>把图表达为矩阵，并且通过特征向量对图的一些特性进行分析是图算法中的一个重要分支</strong>（当然，我们这里说的主要是最大的值对应的特征向量，还有其他的特征向量也有含义）。既然我们已经知道了需要计算最大的特征向量，那么之前计算PageRank所使用的“乘幂法”（Power Method）在这里也是可以使用的，我们在这里就不展开了。</p>
<p>如何把HITS算法用于搜索中呢？最开始提出HITS的时候是这么使用的。</p>
<p><strong>首先，我们根据某个查询关键字构建一个“相邻图”</strong>（Neighborhood Graph）。这个图包括所有和这个查询关键字相关的页面。这里，我们可以简化为所有包含查询关键字的页面。这一步在现代搜索引擎中通过“倒排索引”（Inverted Index）就可以很容易地得到。</p>
<p><strong>有了这个相邻图以后，我们根据这个图建立邻接矩阵，然后就可以通过邻接矩阵计算这些结点的权威值和枢纽值</strong>。当计算出这两组值之后，我们就可以根据这两组值给用户展现两种网页排序的结果，分别是根据不同的假设。</p>
<p>值得注意的是，PageRank是“查询关键字无关”（Query-Independent）的算法，也就是说每个页面的PageRank值并不随着查询关键字的不同而产生不同。而HITS算法是“查询关键字相关”（Query-Dependent）的算法。从这一点来说，HITS就和PageRank有本质的不同。</p>
<h2>HITS算法的一些特点</h2>
<p>HITS算法依靠这种迭代的方法来计算权威值和枢纽值，你一定很好奇，这样的计算究竟收敛吗？是不是也需要像PageRank一样来进行特别的处理呢？</p>
<p><strong>答案是HITS一定是收敛的</strong>。这点比原始的PageRank情况要好。然而，HITS在原始的情况下，不一定收敛到唯一一组权威值和枢纽值，也就是说，解是不唯一的。因此，我们其实需要对HITS进行一部分类似于PageRank的处理，那就是让HITS的邻接矩阵里面所有的结点都能够达到其他任何结点，只是以比较小的概率。经过这样修改，HITS就能够收敛到唯一的权威值和枢纽值了。</p>
<p><strong>HITS算法的好处是为用户提供了一种全新的视角，对于同一个查询关键字，HITS提供的权威排序和枢纽排序能够帮助用户理解自己的需求</strong>。</p>
<p>当然，<strong>HITS的弱点也来自于这个依赖于查询关键字的问题</strong>。如果把所有的计算都留在用户输入查询关键字以后，并且需要在响应时间内计算出所有的权威值和枢纽值然后进行排序，这里面的计算量是很大的。所以，后来有研究者开始使用全局的网页图，提前来计算所有页面的权威值和枢纽值，然而这样做就失去了对某一个关键字的相关信息。</p>
<h2>小结</h2>
<p>今天我为你讲了HITS算法的核心思想 。 一起来回顾下要点：第一，我们讲了HITS的一些简明历史。第二，我们讲了HITS最原始的定义和算法，并且联系PageRank，讲了两者的异同之处。第三，我们分析了HITS的一些特点。</p>
<p>最后，给你留一个思考题，有没有办法把权威值和枢纽值所对应的两个排序合并成为一个排序呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p><strong>参考文献</strong></p>
<ol>
<li>Jon M. Kleinberg. <em>Authoritative sources in a hyperlinked environment</em>. J. ACM 46, 5 (September 1999), 604-632，1999.</li>
</ol>
<p><strong>论文链接</strong></p>
<ul>
<li><a href="http://www.woodmann.com/searchlores/library/authoratitativesources.pdf">Authoritative sources in a hyperlinked environment</a></li>
</ul>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor52">051 | 社区检测算法之“模块最大化 ”<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>一起来回顾下本周的内容。周一我们介绍了用图（Graph）来表达网页与网页之间的关系并计算网页的重要性，就是经典的PageRank算法。周三我们介绍了PageRank的一个姊妹算法，HITS算法，并且分析了这两种算法的内在联系，这两类算法都希望给网页赋予一个权重来表达网页的重要性。</p>
<p>今天，我们来看一类完全不一样的网页分析工具，那就是希望把网页所代表的图分割成小块的图，或者叫图聚类，每个小聚类代表一个“社区”。这类分析有时候被称作图上面的“<strong>社区检测</strong>”（Community Detection），意思就是从一个图上挖掘出潜在的社区结构。</p>
<h2>社区检测的简要历史</h2>
<p>提到社区检测就不得不提到这么一位学者，他与我们今天要介绍的算法有非常紧密的联系，而且他的研究在2000年~2010年间成了社区检测研究的标杆，影响了后续的大量研究工作。这位学者就是密歇根大学（University of Michigan）的物理学教授马克·纽曼（Mark Newman）。</p>
<p>1991年，纽曼从牛津大学获得理论物理博士学位。在接下来的10年里，他在康奈尔大学和圣塔菲学院（Santa Fe Institute）分别担任博士后研究员和研究教授。2002年，纽曼来到密歇根大学物理系担任教授，并且一直在这里进行网络科学（Network Science）的基础研究。</p>
<p>2006年，纽曼在《物理评论》杂志上发表了一个叫“<strong>模块最大化</strong>”（Modularity Maximization）的社区检测算法。从某种程度上来说，这个算法很快就成了社区检测的标准算法，吸引了研究领域的广泛关注，激发了大量的针对这个算法的分析和研究。对这个算法的最原始论述，请参阅参考文献[1]和[2]。</p>
<p>今天我们就来讲一讲这个“模块最大化”算法的基本原理。</p>
<!-- [[[read_end]]] -->
<h2>模块最大化的基本原理</h2>
<p>在我们讲解模块最大化算法之前，我们先来看一看“社区”的含义。在图分析以及网络科学中，<strong>“社区”定义为一组结点，它们互相之间的联系比它们跟社区之外结点的联系要更加紧密</strong>。你可以注意到，在这个定义中，什么叫紧密，怎么来衡量“更紧密”这个关系都是没有说明的，这就为各类社区检测算法或模型带来了很大的发挥空间。</p>
<p>社区检测（有时候也说社区发掘）算法的核心就是要<strong>根据给定的一组结点和它们之间的关系，在无监督的情况找到这些社区，并分配哪些结点属于哪个社区</strong>。</p>
<p>我们先来谈一谈<strong>“模块最大化”的一个整体思路</strong>。这里，我们讨论一种简化的情况，那就是如何把一个网络分割成两个社区。首先，算法按照某种随机的初始化条件，把网络分成两个社区。然后，算法逐一检查每一个结点，看如果把这个点划归到另外一个社区的话，会不会增加“模块化”这个目标函数。最终，算法决定改变那些能够最大化模块化目标的结点的社区赋值。然后整个算法不断重复这个过程，直到社区的赋值不再发生变化。</p>
<p>现在我们来讨论一下模块化这个目标函数。根据上面提到的社区含义，我们希望社区里结点之间的联系紧密。<strong>在模块化目标函数里，就表达为两个结点的连接数目减去这两个结点之间的“期望连接数”</strong>。模块化最大化说的就是，对于同一个社区中的所有结点，我们希望这个差值的和最大化。什么意思呢？就是说，如果我们把两个结点放到一个社区中，那它们的连接数（其实就是1或者0）要足够大于它们之间的连接数的期望值，这就解决了我们刚才所说的如何来衡量“更加紧密”的难题。</p>
<p>那么，怎么来定义两个结点之间的“期望连接数”呢？最初纽曼在介绍模块最大化的时候，他给出了这么一个计算方法。那就是，用两个结点各自的总连接数相乘，除以整个网络的总连接数的2倍。直观上说，这是在衡量这两个结点之间出现任何连接的可能性。</p>
<p>那么，整个模块最大化的目标函数就是，针对现在网络中的所有结点，根据它们是否在同一个社区，我们计算他们两两之间的模块化数值，也就是它们之间的连接减去“期望连接数”，最后对所有的两两配对进行加和。我们希望这个目标函数最大化，这个目标函数中的未知数，就是社区的分配，也就是哪个结点属于哪个社区。一旦社区的分配已知，整个模块最大化这个目标函数的数值就可以很容易地计算出来。</p>
<p>那么如何得到这些社区的分配呢？和我们之前介绍的PageRank以及HITS的思路类似，纽曼使用了矩阵的表达方法对整个模块最大化进行了一个重构，经过一系列代数变形之后[1]，纽曼得到了一个新的目标函数，那就是一个向量s的转置，乘以一个矩阵B，然后再乘以向量s，最后除以4倍的网络连接总数。这里，向量s代表了一个结点是否属于两个社区中的一个，矩阵B中的每一个元素表示了横纵坐标所代表的两个结点的模块化值。问题就是求解s的值。请注意，s中的值是离散的，要么是正1（代表属于两个社区中的一个）要么是负1（代表属于两个社区中的另一个）。很明显，这是一个困难的离散优化问题。</p>
<p><strong>纽曼对这个复杂的离散优化问题进行了近似处理的方法</strong>。具体来说，那就是允许s的值不仅仅是正负1而是实数，这样就大大简化了优化问题的难度。在设置好最优化这个新的目标函数之后，经过代数变形，我们得到了一个惊人的结论，那就是最优情况下的s，实际就是矩阵B最大的特征值所对应的特征向量。这又和PageRank以及HITS有着极其相似的最优结构。在找最大特征向量的过程中找到s以后，我们就根据s里元素的正负号，正的属于一个社区，负的属于另外一个社区，来对整个网络中的结点进行划分。</p>
<p>当然，我们这里讲的仅仅是把整个网络进行二分的情况。在实际应用中，我们往往需要把整个网络划分成多个社区。纽曼在论文中[1]也讲解了<strong>如何把二分法推广到多个社区的情景</strong>。具体来说，就是先把一个网络分成两份，然后再不断地二分下去。不过，每次进行二分的时候，我们都需要检查是否对模块化目标函数起了正向的帮助，而不只是机械地进行二分。</p>
<h2>小结</h2>
<p>今天我为你讲了社区检测中一个有代表性的算法：模块最大化 。 一起来回顾下要点：第一，我们讲了什么是社区检测以及社区检测的一些简明历史。第二，我们讲了模块最大化的的基本思想，比如模块最大化是如何定义的，又是如何把一个困难的离散优化问题转换成类似HITS和PageRank的寻找最大特征向量的问题 。</p>
<p>最后，给你留一个思考题，如何把网页的社区信息利用到学习网页的相关度里面去呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p><strong>参考文献</strong></p>
<ol>
<li>M. E. J. Newman. <em>Modularity and community structure in networks</em>. Proc. Natl. Acad. Sci. USA 103, 8577–8582 , 2006.</li>
<li>M. E. J. Newman. <em>Finding community structure in networks using the eigenvectors of matrices</em>. Phys. Rev. E 74, 036104 , 2006.</li>
</ol>
<p><strong>论文链接</strong></p>
<ol>
<li><a href="http://www.pnas.org/content/103/23/8577.full.pdf">Modularity and community structure in networks</a></li>
<li><a href="https://arxiv.org/pdf/physics/0605087.pdf">Finding community structure in networks using the eigenvectors of matrices</a></li>
</ol>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor53">052 | 机器学习排序算法经典模型：RankSVM<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>到目前为止，我们在专栏里已经讨论了关于搜索引擎方方面面的很多话题，包括经典的信息检索技术、查询关键字理解、文档理解以及现代搜索引擎的架构等等 。同时，我们也从机器学习角度出发对搜索引擎的最核心部分，也就是排序算法进行了最基本的分享，囊括了单点法排序学习（Pointwise Learning to Rank）、配对法排序学习（Pairwise Learning to Rank）以及列表法排序学习（Listwise Learning to Rank），相信你应该对这类算法的大概内容有所掌握。</p>
<p>那么，这周我们就来看看机器学习排序算法中几个经典的模型，希望能够通过这几个经典的算法为你深入学习和研究排序算法指明方向。</p>
<p>今天，我就来分享配对法排序中最有价值一个算法，<strong>排序支持向量机</strong>（RankSVM）。这个算法的核心思想是<strong>应用支持向量机到序列数据中，试图对数据间的顺序直接进行建模</strong>。</p>
<h2>排序支持向量机的历史</h2>
<p>20世纪90年代中后期，受统计学习理论（Statistical Learning Theory ）思想和风险最小化框架（Risk Minimization Framework）趋于成熟的影响，支持向量机逐渐成为当时机器学习界的主流模型。一时间，各个应用领域的学者和工程师都在思考如何把支持向量机利用到自己的问题领域上，从而获得更好的效果。</p>
<p>拉夫⋅赫博里奇（Ralf Herbrich）发表于1999年[1]和2000年[2]的论文中讨论了如何把支持向量机和有序回归（Ordinal Regression）结合起来。赫博里奇当时在柏林科技大学（Technical University of Berlin）攻读博士学位。2000年到2011年，他在微软研究院和Bing任职，从事机器学习，特别是贝叶斯方法（Bayesian method）的研究。2011年到2012年，他在Facebook短暂任职后，于2012年加入了亚马逊负责机器学习的研发工作，并且担任在柏林的研发中心主管经理（Managing Director）。尽管赫博里奇很早提出了把有序回归和支持向量机结合的思路，但是当时的论文并没有真正地把这个新模型用于大规模搜索系统的验证。</p>
<p>更加完整地对排序支持向量机在搜索中的应用进行论述来自于康奈尔大学教授索斯腾⋅乔基姆斯（Thorsten Joachims）以及他和合作者们发表的一系列论文（见参考文献[3]、[4]、[5]和[6]）。索斯滕我们前面介绍过，他是机器学习界享有盛誉的学者，是ACM和AAAI的双料院士；他所有论文的引用数超过4万次；他获得过一系列奖项，包括我们前面讲的2017年ACM KDD的时间检验奖等等。</p>
<h2>排序支持向量机模型</h2>
<p>在说明排序支持向量机之前，我们先来简要地回顾一下支持向量机的基本思想。</p>
<!-- [[[read_end]]] -->
<p>在二分分类问题中（Binary Classification），线性支持向量机的核心思想是找到一个“超平面”（Hyperplane）把正例和负例完美分割开。在诸多可能的超平面中，支持向量机尝试找到距离两部分数据点边界距离最远的那一个。这也就是为什么有时候支持向量机又被称作是<strong>“边界最大化”（Large Margin）分类器</strong>。</p>
<p>如果问题并不是线性可分的情况，支持向量机还可以借助“<strong>核技巧</strong>”（Kernel Trick）来把输入特性通过非线性变换转化到一个线性可分的情况。关于支持向量机的具体内容你可以参考各类机器学习教科书的论述。</p>
<p><strong>要把支持向量机运用到排序场景下，必须改变一下原来的问题设置</strong>。我们假设每个数据点由特性X和标签Y组成。这里的X代表当前文档的信息、文档与查询关键字的相关度、查询关键字的信息等方方面面关于文档以及查询关键字的属性。Y是一个代表相关度的整数，通常情况下大于1。</p>
<p>那么，在这样的设置下，我们针对不同的X，需要学习到一个模型能够准确地预测出Y的顺序。意思是说，如果有两个数据点$X_1$和$X_2$，他们对应的$Y_1$是3，$Y_2$是5。因为$Y_2$大于$Y_1$（在这里，“大于”表明一个顺序），因此，一个合理的排序模型需要把$X_1$通过某种转换，使得到的结果小于同样的转换作用于$X_2$上。这里的转换，就是排序支持向量机需要学习到的模型。</p>
<p>具体说来，在线性假设下，排序支持向量机就是要学习到一组线性系数W，使得在上面这个例子中，$X_2$点积W之后的结果要大于$X_1$点积W的结果。当然，对于整个数据集而言，我们不仅仅需要对$X_1$和$X_2$这两个数据点进行合理预测，还需要对所有的点，以及他们之间所有的顺序关系进行建模。也就是说，模型的参数W需要使得数据集上所有数据点的顺序关系的预测都准确。</p>
<p>很明显，上述模型是非常严格的。而实际中，很可能并不存在这样的W可以完全使得所有的X都满足这样的条件。这也就是我们之前说的线性不可分在排序中的情况。那么，更加现实的一个定义是，<strong>在允许有一定误差的情况下，如何使得W可以准确预测所有数据之间的顺序关系，并且W所确定的超平面到达两边数据的边界最大化</strong>，这就是线性排序向量机的定义。</p>
<p>实际上，在线性分类器的情境下，线性排序向量机是针对数据配对（Pair）的差值进行建模的。回到刚才我们所说的例子，线性排序向量机是把$X_2$减去$X_1$的差值当做新的特性向量，然后学习W。也就是说，原理上说，整个支持向量机的所有理论和方法都可以不加改变地应用到这个新的特征向量空间中。当然，这个情况仅仅针对线性分类器。</p>
<p><strong>因为是针对两个数据点之间的关系进行建模，排序支持向量机也就成为配对法排序学习的一个经典模型</strong>。</p>
<h2>排序支持向量机的难点</h2>
<p>我们刚刚提到的排序支持向量机的定义方法虽然很直观，但是有一个非常大的问题，那就是<strong>复杂度是N的平方级，这里的N是数据点的数目</strong>。原因是我们需要对数据点与点之间的所有配对进行建模。 当我们要对上万，甚至上百万的文档建模的时候，直接利用排序支持向量机的定义来求解模型参数显然是不可行的。</p>
<p>于是，针对排序支持向量机的研究和应用就集中在了<strong>如何能够降低计算复杂度</strong>这一难点上，使得算法可以在大规模数据上得以使用。</p>
<p>比较实用的算法是索斯腾在2006年发表的论文[6]中提出的，这篇论文就是我们前面讲的2017年KDD时间检验奖，建议你回去复习一下。这里，我再简要地梳理一下要点。</p>
<p>这个算法的核心是重新思考了对排序支持向量机整个问题的设置，把解决结构化向量机（Structural SVM）的一种算法，CP算法（Cutting-Plane），使用到了排序支持向量机上。简单来说，这个算法就是保持一个工作集合（Working Set）来存放当前循环时依然被违反的约束条件（Constraints），然后在下一轮中集中优化这部分工作集合的约束条件。整个流程开始于一个空的工作集合，每一轮优化的是一个基于当前工作集合的支持向量机子问题。算法直到所有约束条件的误差小于一个全局的参数误差为止。</p>
<p>索斯腾在文章中详细证明了该算法的有效性和时间复杂度。相同的方法也使得排序支持向量机的算法能够转换成为更加计算有效的优化过程，在线性计算复杂度的情况下完成。</p>
<h2>小结</h2>
<p>今天我为你讲了利用机器学习技术来学习排序算法的一个基础的算法，排序支持向量机的基本原理。作为配对法排序学习的一个经典算法，排序支持向量机有着广泛的应用 。 一起来回顾下要点：第一，我们简要介绍了排序支持向量机提出的历史背景。第二，我们详细介绍了排序支持向量机的问题设置。第三，我们简要提及了排序支持向量机的难点和一个实用的算法。</p>
<p>最后，给你留一个思考题，排序支持向量机是否给了你一些启发，让你可以把更加简单的对数几率分类器（Logistic Regression）应用到排序问题上呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p><strong>参考文献</strong></p>
<ol>
<li>Herbrich, R.; Graepel, T. &amp; Obermayer, K. Support vector learning for ordinal regression. <em>The Ninth International Conference on Artificial Neural Networks</em> (ICANN 99), 1, 97-102 vol.1, 1999.</li>
<li>Herbrich, R.; Graepel, T. &amp; Obermayer, K. Smola; Bartlett; Schoelkopf &amp; Schuurmans (Eds.). Large margin rank boundaries for ordinal regression. <em>Advances in Large Margin Classifiers</em>, MIT Press, Cambridge, MA, 2000.</li>
<li>Tsochantaridis, I.; Hofmann, T.; Joachims, T. &amp; Altun, Y. Support Vector Machine Learning for Interdependent and Structured Output Spaces. <em>Proceedings of the Twenty-first International Conference on Machine Learning</em>, ACM, 2004.</li>
<li>Joachims, T. A Support Vector Method for Multivariate Performance Measures. <em>Proceedings of the 22Nd International Conference on Machine Learning</em>, ACM, 377-384, 2005.</li>
<li>Tsochantaridis, I.; Joachims, T.; Hofmann, T. &amp; Altun, Y. Large Margin Methods for Structured and Interdependent Output Variables. <em>The Journal of Machine Learning Research</em>, 6, 1453-1484, 2005.</li>
<li>Joachims, T. Training Linear SVMs in Linear Time. <em>Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em>, ACM,  217-226, 2006.</li>
</ol>
<p><strong>论文链接</strong></p>
<ul>
<li>
<p><a href="hhttp://www.herbrich.me/papers/icann99_ordinal.pdf">Support vector learning for ordinal regression</a></p>
</li>
<li>
<p><a href="http://www.machinelearning.org/proceedings/icml2004/papers/76.pdf">Support Vector Machine Learning for Interdependent and Structured Output Spaces</a></p>
</li>
<li>
<p><a href="https://www.cs.cornell.edu/people/tj/publications/joachims_05a.pdf">A Support Vector Method for Multivariate Performance Measures</a></p>
</li>
<li>
<p><a href="http://www.jmlr.org/papers/volume6/tsochantaridis05a/tsochantaridis05a.pdf">Large Margin Methods for Structured and Interdependent Output Variables</a></p>
</li>
<li>
<p><a href="https://www.cs.cornell.edu/people/tj/publications/joachims_06a.pdf">Training Linear SVMs in Linear Time</a></p>
</li>
</ul>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor54">053 | 机器学习排序算法经典模型：GBDT<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>这周我们讨论机器学习排序算法中几个经典的模型，周一分享了配对法排序中的一个经典算法，即排序支持向量机（RankSVM），这个算法的核心思想是把支持向量机应用到有序数据中，试图对数据间的顺序进行直接建模。</p>
<p>今天，我们来聊一聊利用机器学习进行排序的一个重要算法：<strong>“梯度增强决策树”（Gradient Boosted Decision Tree）</strong>。长期以来，包括雅虎在内的很多商业搜索引擎都利用这种算法作为排序算法。</p>
<h2>梯度增强决策树的历史</h2>
<p>梯度回归决策树的思想来源于两个地方。首先是“<strong>增强算法</strong>”（Boosting），一种试图用弱学习器提升为强学习器的算法。这种算法中比较成熟的、有代表性的算法是由罗伯特⋅施派尔（Robert Schapire）和约阿夫⋅福伦德（Yoav Freund）所提出的<strong>AdaBoost算法</strong>[1]。因为这个算法两人于2003年获得理论计算机界的重要奖项“哥德尔奖”（Gödel Prize）。罗伯特之前在普林斯顿大学任计算机系教授，目前在微软研究院的纽约实验室工作。约阿夫一直在加州大学圣地亚哥分校任计算机系教授。</p>
<p>增强算法的工作机制都比较类似，那就是先从初始训练集训练出一个基学习器，再根据基学习器的表现对训练样本分布进行调整，使得先前基学习器做错的训练样本在后续受到更多关注，然后基于调整后的样本分布来训练下一个基学习器。如此重复进行，直到基学习器数目达到事先制定的值，最终将所有的基学习器进行加权结合。如果你对“偏差-方差分解”（Bias-Variance Decomposition）有耳闻的话，那么，Boosting主要关注降低偏差。<strong>在实际效果中，增强算法往往能基于泛化性能相当弱的学习器构建出很强的集成结果</strong>。</p>
<p>AdaBoost提出后不久，机器学习学者和统计学家杰罗姆⋅弗赖德曼（Jerome H. Friedman）等人发表了一篇论文[2]，<strong>从“统计视角”解释AdaBoost实质上是基于加性模型（Additive Model）以类似牛顿迭代法来优化指数损失函数（Loss Function）</strong>。于是受此启发，杰米姆提出了“<strong>梯度增强</strong>”（Gradient Boosting）的想法。这也就是梯度回归决策树思想来源的第二个地方，也是直接根源。如果你希望对“梯度增强”有进一步的了解，可以见参考文献[3]。</p>
<p>最早把“梯度增强”的想法应用到搜索中，是雅虎研究院的学者于2007年左右提出的[4]&amp;[5]。之后，Facebook把梯度增强决策树应用于新闻推荐中[6]。</p>
<h2>梯度增强的思想核心</h2>
<p>我们刚才简单讲了增强算法的思路，那么要想理解梯度增强决策树，就必须理解梯度增强的想法。</p>
<p><strong>梯度增强首先还是增强算法的一个扩展，也是希望能用一系列的弱学习器来达到一个强学习器的效果，从而逼近目标变量的值，也就是我们常说的标签值</strong>。而根据加性模型的假设，这种逼近效果是这些弱学习器的一个加权平均。也就是说，最终的预测效果，是所有单个弱学习器的一个平均效果，只不过这个平均不是简单的平均，而是一个加权的效果。</p>
<p>那么如何来构造这些弱学习器和加权平均的权重呢？</p>
<!-- [[[read_end]]] -->
<p><strong>梯度增强采用了一个统计学或者说是优化理论的视角，使得构造这些部分变得更加直观</strong>。</p>
<p>梯度增强的作者们意识到，如果使用“梯度下降”（Gradient Descent）来优化一个目标函数，最后的预测式可以写成一个加和的形式。也就是，每一轮梯度的值和一个叫“学习速率”（Learning Rate）的参数共同叠加起来形成了最后的预测结果。这个观察非常重要，如果把这个观察和我们的目标，也就是构造弱学习器的加权平均联系起来看，我们就会发现，<strong>其实每个梯度的值就可以认为是一个弱学习器，而学习速率就可以看作是某种意义上的权重</strong>。</p>
<p>有了这个思路，梯度增强的算法就很容易构造了。</p>
<p><strong>首先，这是一个迭代算法</strong>。每一轮迭代，我们把当前所有学习器的加权平均结果当作这一轮的函数值，然后求得针对某一个损失函数对于当前所有学习器的参数的一个梯度。<strong>然后，我们利用某一个弱学习器算法，可以是线性回归模型（Linear Regression）、对数几率模型（Logistic Regression）等来拟合这个梯度</strong>。<strong>最后，我们利用“线查找”（Line Search）的方式找到权重</strong>。说得更直白一些，那就是我们尝试利用一些简单的模型来拟合不同迭代轮数的梯度。</p>
<p>梯度增强的一个特点就是梯度下降本身带来的，那就是每一轮迭代一定是去拟合比上一轮小的一个梯度，函数对目标的整体拟合也是越来越好的。这其实也就是增强算法和梯度下降的一个完美结合。</p>
<h2>梯度增强决策树以及在搜索的应用</h2>
<p>理解了梯度增强，那么梯度增强决策树也就容易理解了。简单来说，<strong>梯度增强决策树就是利用决策树，这种最基本的学习器来当作弱学习器，去拟合梯度增强过程中的梯度</strong>。然后融合到整个梯度增强的过程中，最终，梯度增强决策树其实就是每一轮迭代都拟合一个新的决策树用来表达当前的梯度，然后跟前面已经有的决策树进行叠加。在整个过程中，决策树的形状，比如有多少层、总共有多少节点等，都是可以调整的或者学习的<strong>超参数</strong>。而总共有多少棵决策树，也就是有多少轮迭代是重要的<strong>调节参数</strong>，也是防止整个学习过程过拟合的重要手段。</p>
<p>参考文献[5]和[6]，就是雅虎的科学家第一次把刚才提到的这个思路用于搜索问题中，训练排序算法。在应用的时候，有一些细节的调整，比如<strong>损失函数的设定</strong>。这里，作者们采用了配对法排序学习方法，那就是不直接去拟合相关度，而是拟合两个不同文档相关度的差值。具体来说，就是针对某一个查询关键字，我们利用算法来最小化对文档相关度差值的预测，也就是说我们不希望把相关度高的文档放到相关度低的后面。</p>
<p>在这些论文中，还有后续的很多研究中，利用梯度增强决策树算法进行排序训练得到的效果比当时的其他算法都有大幅度的提升。因此，这也就慢慢地奠定了<strong>梯度增强决策树作为一种普适的机器学习排序算法</strong>的地位。值得说明的是，梯度增强决策树的成功，一部分来自于增强算法，另一部分来自于把很多决策树堆积起来的想法。这两个思路都是在机器学习中被反复验证、行之有效的“模式”。</p>
<h2>小结</h2>
<p>今天我为你讲了梯度增强决策树算法的基本原理，这是一个利用机器学习技术来学习排序的基础算法。作为配对法排序学习的一个经典算法，梯度增强决策树算法有着广泛的应用 。 一起来回顾下要点：第一，我们简要介绍了梯度增强决策树提出的历史。第二，我们详细介绍了增强算法的核心以及梯度增强的思路。第三，我们简要介绍了梯度增强决策树的核心以及如何利用这个算法来训练排序问题。</p>
<p>最后，给你留一个思考题，梯度增强的思路能和神经网络模型结合吗？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p><strong>参考文献</strong></p>
<ol>
<li>Yoav Freund and Robert E Schapire.  A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting. J. Comput. Syst. Sci. 55, 1 (August 1997), 119-139, 1997.</li>
<li>Friedman, Jerome; Hastie, Trevor; Tibshirani, Robert. Additive logistic regression: a statistical view of boosting (With discussion and a rejoinder by the authors). Ann. Statist. 28 (2000), no. 2, 337–407, 2000.</li>
<li>Friedman, Jerome H. Greedy function approximation: a gradient boosting machine. Annals of Statistics (2001): 1189–1232, 2001.</li>
<li>Zhaohui Zheng, Hongyuan Zha, Tong Zhang, Olivier Chapelle, Keke Chen, and Gordon Sun. A general boosting method and its application to learning ranking functions for web search. Proceedings of the 20th International Conference on Neural Information Processing Systems (NIPS’07), J. C. Platt, D. Koller, Y. Singer, and S. T. Roweis (Eds.). Curran Associates Inc., USA, 1697-1704, 2007.</li>
<li>Zhaohui Zheng, Keke Chen, Gordon Sun, and Hongyuan Zha. A regression framework for learning ranking functions using relative relevance judgments. Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval (SIGIR '07). ACM, New York, NY, USA, 287-294, 2007.</li>
<li>Xinran He, Junfeng Pan, Ou Jin, Tianbing Xu, Bo Liu, Tao Xu, Yanxin Shi, Antoine Atallah, Ralf Herbrich, Stuart Bowers, and Joaquin Quiñonero Candela. Practical Lessons from Predicting Clicks on Ads at Facebook. Proceedings of the Eighth International Workshop on Data Mining for Online Advertising (ADKDD’14). ACM, New York, NY, USA, , Article 5 , 9 pages, 2014.</li>
</ol>
<p><strong>论文链接</strong></p>
<ul>
<li>
<p><a href="http://www.face-rec.org/algorithms/Boosting-Ensemble/decision-theoretic_generalization.pdf">A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting</a></p>
</li>
<li>
<p><a href="https://web.stanford.edu/~hastie/Papers/AdditiveLogisticRegression/alr.pdf">Additive logistic regression: a statistical view of boosting</a></p>
</li>
<li>
<p><a href="https://statweb.stanford.edu/~jhf/ftp/trebst.pdf">Greedy function approximation: a gradient boosting machine</a></p>
</li>
<li>
<p><a href="https://corescholar.libraries.wright.edu/cgi/viewcontent.cgi?referer=https://www.google.com.hk/&amp;httpsredir=1&amp;article=1314&amp;context=knoesis">A general boosting method and its application to learning ranking functions for web search</a></p>
</li>
<li>
<p><a href="https://www.cc.gatech.edu/~zha/papers/fp086-zheng.pdf">A regression framework for learning ranking functions using relative relevance judgments</a></p>
</li>
<li>
<p><a href="http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=A54CCA7D4A8F05B6636C9D64316BCF96?doi=10.1.1.718.9050&amp;rep=rep1&amp;type=pdf">Practical Lessons from Predicting Clicks on Ads at Facebook</a></p>
</li>
</ul>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor55">054 | 机器学习排序算法经典模型：LambdaMART<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>在这周的时间里，我们讨论机器学习排序算法中几个经典的模型。周一我们分享了排序支持向量机（RankSVM），这个算法的好处是模型是线性的，容易理解。周三我们聊了梯度增强决策树（Gradient Boosted Decision Tree），长期以来，这种算法被用在很多商业搜索引擎当中来作为排序算法。</p>
<p>今天，我们来分享这一部分的最后一个经典模型：<strong>LambdaMART</strong>。这是微软在Bing中使用了较长时间的模型，也在机器学习排序这个领域享有盛誉。</p>
<h2>LambdaMART的历史</h2>
<p>LambdaMART的提出可以说是一个“三步曲”。</p>
<p>这里有一个核心人物，叫克里斯多夫⋅博格斯（Christopher J.C. Burges）。博格斯早年从牛津大学物理学毕业之后，又于布兰戴斯大学（Brandeis University）获得物理学博士学位，他曾在麻省理工大学做过短暂的博士后研究，之后来到贝尔实验室，一待14年。2000年，他来到微软研究院，并一直在微软研究院从事机器学习和人工智能的研究工作，直到2016年退休。可以说，是博格斯领导的团队发明了微软搜索引擎Bing的算法。</p>
<p><strong>LambdaMART的第一步来自于一个叫RankNet的思想</strong>[1]。这个模型发表于ICML 2005，并且在10年之后获得ICML的时间检验奖。这也算是在深度学习火热之前，利用神经网络进行大规模商业应用的经典案例。</p>
<p>RankNet之后，博格斯的团队很快意识到了RankNet并不能直接优化搜索的评价指标。因此他们根据一个惊人的发现，<strong>提出了LambdaRank这一重要方法</strong>[2]。LambdaRank的进步在于算法开始和搜索的评价指标，也就是NDCG挂钩，也就能够大幅度提高算法的精度。</p>
<p>LambdaRank之后，博格斯的团队也认识到了当时从雅虎开始流行的使用“梯度增强”（Gradient Boosting），特别是“梯度增强决策树”（GBDT）的思路来进行排序算法的训练，于是他们就把LambdaRank和GBDT的思想结合起来，<strong>开发出了更加具有模型表现力的LambdaMART</strong>[3]。LambdaMART在之后的雅虎排序学习比赛中获得了最佳成绩。</p>
<h2>RankNet的思想核心</h2>
<p>要理解LambdaMART，我们首先要从RankNet说起。其实，有了排序支持向量机RankSVM的理论基础，要理解RankNet就非常容易。RankNet是一个和排序支持向量机非常类似的配对法排序模型。也就是说，RankNet尝试正确学习每组两两文档的顺序。那么，怎么来定义这个所谓的两两文档的顺序呢？</p>
<!-- [[[read_end]]] -->
<p>其实，我们需要做的就是<strong>定义一个损失函数（Loss Function）来描述如何引导模型学习正确的两两关系</strong>。我们可以假设能够有文档两两关系的标签，也就是某一个文档比另外一个文档更加相关的信息。这个信息可以是二元的，比如+1代表更加相关，-1代表更加不相关，注意这里的“更加”表达了次序关系。</p>
<p>那么，在理想状态下，不管我们使用什么模型，都希望模型的输出和这个标签信息是匹配的，也就是说模型对于更加相关的文档应该输出更加高的预测值，反之亦然。很自然，<strong>我们能够使用一个二元分类器的办法来处理这样的关系</strong>。RankNet在这里使用了“对数几率损失函数”（Logistic Loss），其实就是希望能够利用“对数几率回归”（Logistic Regression）这一思想来处理这个二元关系。唯一的区别是，这里的正例是两个文档的相对关系。</p>
<p>有了损失函数之后，我们使用什么模型来最小化这个损失函数呢？在RankNet中，作者们使用了神经网络模型，这也就是Net部分的由来。那么，整个模型在这里就变得异常清晰，那就是<strong>使用神经网络模型来对文档与文档之间的相对相关度进行建模，而损失函数选用了“对数几率损失函数”</strong>。</p>
<h2>LambdaRank和LambdaMART</h2>
<p>尽管RankNet取得了一些成功，但是，文档的两两相对关系并不和搜索评价指标直接相关。我们之前讲过，搜索评价指标，例如NDCG或者MAP等，都是直接建立在对于某一个查询关键字的相关文档的整个序列上，或者至少是序列的头部（Top-K）的整个关系上的。因此，RankNet并不能保证在NDCG这些指标上能够达到很好的效果，因为毕竟没有直接或者间接优化这样的指标。</p>
<p>要想认识这一点其实很容易，比如你可以设想对于某一个查询关键字，有10个文档，其中有两个相关的文档，一个相关度是5，另外一个相关度是3。那么，很明显，在一个理想的排序下，这两个文档应该排在所有10个文档的头部。</p>
<p>现在我们假定相关度5的排在第4的位置，而相关度3的排在第7的位置。RankNet会更愿意去调整相关度3的，并且试图把其从第7往前挪，因为这样就可以把其他不相关的挤下去，然而更优化的办法应该是尝试先把相关度5的往更前面排。也就是说，从NDCG的角度来说，相关度高的文档没有排在前面受到的损失要大于相关度比较低的文档排在了下面。</p>
<p>NDCG和其他一系列搜索评价指标都是更加注重头部的相关度。关于这一点，RankNet以及我们之前介绍的GBDT或者排序支持向量机都忽视了。</p>
<p>既然我们找到了问题，那么如何进行补救呢？</p>
<p>之前说到博格斯的团队有一个惊人的发现，其实就在这里。他们发现，RankNet的优化过程中使用到的梯度下降（Gradient Descent）算法需要求解损失函数针对模型的参数的梯度，可以写成<strong>两个部分</strong>的乘积。在这里，模型的参数其实就是神经网络中的各类系数。第一部分，是损失函数针对模型的输出值的，第二部分是模型输出值针对模型的参数的。第二个部分跟具体的模型有关系，但是第一个部分没有。第一个部分跟怎么来定一个损失函数有关系。</p>
<p>在原始的RankNet定义中，这当然就是“对数几率函数”定义下的损失函数的梯度。这个数值就是提醒RankNet还需要针对这个损失做多少修正。其实，这个损失梯度不一定非得对应一个损失函数。这是博格斯的团队的一个重大发现，只要这个损失的梯度能够表示指引函数的方向就行了。</p>
<p>那既然是这样，能不能让这个损失的梯度和NDCG扯上边呢？答案是可以的。也就是说，我们只要定义两个文档之间的差距是这两个文档互换之后NDCG的变化量，同时这个变化量等于之前所说的损失的梯度，那么我们<strong>就可以指导RankNet去优化NDCG</strong>。在这里，博格斯和其他作者把这个损失的梯度定义为Lambda，因为整个过程是在优化一个排序，所以新的方法叫作LambdaRank。</p>
<p>有了LambdaRank之后，LambdaMART就变得水到渠成。Lambda是被定义为两个文档NDCG的变化量（在实际运作中，是用这个变化量乘以之前的对数几率所带来的梯度）。那么，只要这个Lambda可以计算，模型就可以嫁接别的算法。于是，博格斯的团队使用了在当时比神经网络更加流行的“梯度增强决策树”（GBDT）来作为学习器。不过，梯度增强决策树在计算的时候需要计算一个梯度，在这里就被直接接入Lambda的概念，使得GBDT并不是直接优化二分分类问题，而是一个改装了的二分分类问题，也就是在优化的时候优先考虑能够进一步改进NDCG的方向。</p>
<h2>小结</h2>
<p>今天我为你讲了LambdaMART算法的基本原理。作为配对法和列表排序学习的一个混合经典算法，LambdaMART在实际运用中有着强劲的表现 。 一起来回顾下要点：第一，我们简要介绍了LambdaMART提出的历史。第二，我们详细介绍了LambdaMART的核心思路。</p>
<p>最后，给你留一个思考题，采用Lambda这样更改优化过程中的梯度计算，虽然很形象，但是有没有什么坏处？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p><strong>参考文献</strong></p>
<ol>
<li>
<p>Burges, C.; Shaked, T.; Renshaw, E.; Lazier, A.; Deeds, M.; Hamilton, N. &amp; Hullender, G. Learning to Rank Using Gradient Descent. <em>Proceedings of the 22nd International Conference on Machine Learning</em>, ACM, 89-96, 2005.</p>
</li>
<li>
<p>Burges, C. J.; Ragno, R. &amp; Le, Q. V. Schölkopf, B.; Platt, J. C. &amp; Hoffman, T. (Eds.). Learning to Rank with Nonsmooth Cost Functions. <em>Advances in Neural Information Processing Systems 19</em>, MIT Press, 193-200,  2007.</p>
</li>
<li>
<p>Wu, Q.; Burges, C. J.; Svore, K. M. &amp; Gao, J. Adapting Boosting for Information Retrieval Measures. <em>Information Retrieval</em>, Kluwer Academic Publishers, 13, 254-270, 2010.</p>
</li>
<li>
<p>Chapelle, O. &amp; Chang, Y.Chapelle, O.; Chang, Y. &amp; Liu, T.-Y. (Eds.). Yahoo! Learning to Rank Challenge Overview. <em>Proceedings of the Learning to Rank Challenge</em>, PMLR, 14, 1-24, 2011.</p>
</li>
</ol>
<p><strong>论文链接</strong></p>
<ul>
<li>
<p><a href="https://icml.cc/2015/wp-content/uploads/2015/06/icml_ranking.pdf">Learning to Rank Using Gradient Descent</a></p>
</li>
<li>
<p><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.62.1530&amp;rep=rep1&amp;type=pdf">Learning to Rank with Nonsmooth Cost Functions</a></p>
</li>
<li>
<p><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.157.5117&amp;rep=rep1&amp;type=pdf">Adapting Boosting for Information Retrieval Measures</a></p>
</li>
<li>
<p><a href="http://proceedings.mlr.press/v14/chapelle11a/chapelle11a.pdf">Yahoo! Learning to Rank Challenge Overview</a></p>
</li>
</ul>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor56">055 | 基于深度学习的搜索算法：深度结构化语义模型<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>近两个月，我们集中系统地分享了搜索核心技术模块。做一个简单的内容梳理，我们讲解了搜索引擎方方面面的话题，从经典的信息检索技术、查询关键字理解、文档理解到现代搜索引擎的架构和索引的核心技术；还从机器学习角度出发分享了搜索引擎的最核心部分，也就是排序算法，深入排序算法的细节讲解了排序支持向量机（RankSVM）、梯度增强决策树（GBDT）以及经典模型LambdaMART。至此，整个人工智能领域关于搜索的经典话题也就告一段落了。</p>
<p>那么，这个星期，我们来看一些关于搜索算法的前沿思考。火热的深度学习不仅对图像、视频和音频这些领域产生了巨大的冲击，也对自然语言处理、甚至搜索领域有不小的影响。<strong>深度学习带给传统的模型和算法以新的建模能力和新的视角，为以前所不能完成的应用打下了基础</strong>。</p>
<p>今天，我们来看一篇较早利用深度学习技术来进行搜索建模的论文：《使用点击数据学习深度结构化的网络搜索语义模型》（Learning deep structured semantic models for web search using clickthrough data）。这篇论文阐述了一个<strong>深度结构化语义模型</strong>，发表在第22届世界信息和知识管理大会CIKM 2013上。</p>
<h2>论文背景介绍</h2>
<p>发表于2013年的这篇论文应该算是比较早的直接使用深度学习中经验的论文。其主要目的是探索一些经典的深度学习方法能否在搜索的应用中得到合适的效果。</p>
<p>下面我们来了解一下这篇论文的作者群信息。</p>
<p>第一作者黄博森（Po-Sen Huang）是一名来自台湾的学者。在发表论文的时候，他在伊利诺伊大学香槟分校攻读电子工程和计算机博士学位，师从马克·约翰森（Mark Hasegawa-Johnson）。论文是黄博森在微软实习时的工作总结。2015年黄博森博士毕业，然后于2016年加入了微软研究院。到目前为止，他发表了30多篇人工智能相关的论文，论文引用次数已经超过1千多次。</p>
<p>其他作者均来自当时在微软研究院工作的学者。其中不乏著名学者，比如何晓冬（Xiaodong He）、邓力（Li Deng）、亚历克斯·阿西罗（Alex Acero）和拉里·赫克（Larry Heck）等。下面聊聊比较少被提及的阿西罗和赫克。阿西罗曾长期在微软研究院担任语音相关研究组的经理职位，2013年之后，他到苹果公司担任Siri的资深总监。赫克曾经在雅虎担任搜索和广告业务副总裁，然后到微软研究院担任语音组的首席科学家。文章发表之后，赫克到了谷歌，在一个人工智能组担任总监，并于最近加入三星北美研究院担任资深副总裁。这些学者主要是为这个工作提供支持和指导工作。</p>
<p>这篇论文自2013年发表后已经有超过390多次的引用，是深度学习在搜索领域应用中被引用次数最多的论文之一。</p>
<h2>深度结构化语义模型详解</h2>
<p>下面详细讲讲这篇论文的核心思想。要想理解这篇论文提出的思路，我们首先要简单回顾一下经典的搜索模型构建。</p>
<!-- [[[read_end]]] -->
<p>在经典的搜索模型里，不管是TF-IDF、BM25、语言模型，还是基于机器学习的排序算法模型，整体来说，一个共通的想法就是争取用某种表示（Representation）来表达查询关键字，然后用相同的、或者类似的表示来表达文档，再通过某种程度的匹配函数来计算查询关键字表示和文档表示之间的距离，然后进行排序。</p>
<p>那么，从深度学习的角度来说，要想针对这个传统的模式进行革新，当然就可以从最主要的三个方面入手：<strong>查询关键字的表达、文档的表达和匹配函数</strong>。</p>
<p>这篇文章也正是沿着这个思路，提出了深度结构化语义模型。</p>
<p>首先，深度结构化语义模型对查询关键字和文档进行了相似的处理。具体来说，就是先把查询关键字或者文档转换为<strong>词向量</strong>（Term Vector），这个词向量可以是最简单的“<strong>词袋</strong>”的表达方式，这也就是最基本的模型的输入。从词向量出发，模型首先学习一个“<strong>词哈希</strong>”（Word Hashing），也就是把0或1的稀疏词向量转换成为一个稠密（Dense）的向量表达。这一步是<strong>把深度学习方法应用在自然语言处理中所通用的办法，目的就是把稀疏的输入转换为稠密的输入，降低输入的数据维度</strong>。</p>
<p>当查询关键字和文档都转换成稠密数组以后，深度结构化语义模型利用了深度学习中的重要经验，那就是通过“<strong>非线性转换</strong>”（Non-Linear Projection）来获取数据深层次的语义信息，而不仅仅只是传统方法中字面上的匹配。这里，查询关键字和文档都使用了简单的“<strong>前馈神经网络</strong>”（Feedforward Neural Network）的方法，对输入向量进行了多层的非线性转换。非线性转换本身通过“<strong>双曲正切函数</strong>”（tanh函数）实现，这应该算是最传统的深度学习模型的实现方法了。</p>
<p>经过多层转换之后，查询关键字和文档都变成了新的某种表达之后，如何来计算两者间的距离（或者远近）呢？这篇文章采用了非常直接的形式，那就是利用“<strong>余弦函数</strong>”（Cosine）来作为距离函数，描述两个向量之间的距离。在传统信息检索的语境中，也经常用余弦函数来计算向量的距离，所以在这里应该说并没有太多创新的地方。</p>
<p>总体来说，<strong>深度学习在这里的主要应用，就是成为查询关键字和文档的表达的提取器</strong>。和传统方法中人工提取各种类型的文字特性相比，在深度结构化语义模型中，基于前馈神经网络的特征提取器自动提取了文字的深层语义信息。</p>
<p>提出了模型之后，我们来看这个模型是如何被训练出来的。作者们首先利用了用户的点击信息，也就是针对某一个查询关键字，有哪些文档被点击过，作为<strong>正例数据</strong>，其他文档作为<strong>负例数据</strong>，然后把整个建模问题看作一个<strong>多类分类问题</strong>。这样就可以利用标签信息对整个模型进行学习了。</p>
<p>整体来说，这个深度学习模型是可以利用“端到端”（End-to-End）的方式进行训练的，并且采用了随机梯度下降（SGD）这样的优化算法，这里就不复述了。</p>
<h2>深度结构化语义模型的实验效果</h2>
<p>因为深度结构化语义模型仅仅使用了查询关键字和文档之间的文字信息，因此提出的模型就无法和完整的、利用很多特性的机器学习排序算法进行比较，只能和文字型的排序算法例如TF-IDF、BM25和语言模型进行比较，这也是文章并没有采用一些更为通用的数据集的原因。最终文章在数据集上采用了Bing的搜索数据，有1万6千多的查询关键字以及每个查询关键字所对应的15个文档，每个文档又有4级相关标签，这样可以用来计算诸如NDCG这样的指标。</p>
<p>在这篇文章里，作者们比较了一系列的方法，比如TF-IDF、BM25，以及一些传统的降维方法如LSA和PLSA。简单来说，深度结构化语义模型在最后的比较中取得了不错的结果，NDCG在第10位的表现是接近0.5。不过，TF-IDF的表现也有0.46，而传统的PLSA和LSA也有0.45左右的表现。所以，可以说深度结构化语义模型的效果虽然很明显但并不是特别惊人。</p>
<h2>小结</h2>
<p>今天我为你讲了深度结构化语义模型的一些基本原理，这是利用深度学习技术对搜索算法进行改进的一个经典尝试。我们在上面的实验结果总结中已经说到，虽然文章仅仅谈到了文本信息的匹配，并没有作为完整的排序算法进行比较，但是也揭开了用深度模型来表征查询关键字和文档的研发序幕 。</p>
<p>一起来回顾下要点：第一，我们简要介绍了提出深度结构化语义模型的历史。第二，我们详细介绍了深度结构化语义模型的核心思路以及实验结果。</p>
<p>给你留一个思考题，除了文章中提到的余弦函数可以作为一个距离函数，还有没有其他的函数选择来表达两个向量之间的距离？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p>最后，预告一个小活动，本周六（1月13日）晚8:30我会在极客时间做一场直播，欢迎你参加。主题是“人工智能20问”，如果你有想交流的问题，欢迎给我留言，我们周六直播见！</p>
<p><img src="https://static001.geekbang.org/resource/image/03/a4/036075efeb9f168a768b32cd178ce9a4.jpg" alt="" /></p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor57">056 | 基于深度学习的搜索算法：卷积结构下的隐含语义模型<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>这个星期，也是我们整个搜索领域分享的最后一周内容，来看一些搜索算法的前沿思考，特别是深度学习对搜索领域的影响。周一我们分享了一篇较早利用深度学习技术来进行搜索建模的论文，论文提出如何使用前馈神经网络来对查询关键字和文档进行信息提取，从而能够学习更有意义的语义信息。</p>
<p>今天我们来看一篇文章《信息检索中结合卷积池化结构的隐含语义模型》（<a href="http://www.iro.umontreal.ca/~lisa/pointeurs/ir0895-he-2.pdf">A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval</a>），可以说这是我们周一分享论文的一个后续工作。这篇论文发表在第23届世界信息和知识管理大会CIKM 2014上。</p>
<h2>论文背景介绍</h2>
<p>这篇论文的主要目的是探讨深度学习中的卷积神经网络能否应用在搜索中，并取得较好的效果。</p>
<p>下面我们先来了解一下这篇论文作者群的信息。</p>
<p>第一作者Yelong Shen是微软研究院的一名资深研究员。</p>
<p>第二作者是何晓冬（Xiaodong He）是微软研究院深度学习组的主任研究员兼经理，发表过一百多篇学术论文，在人工智能领域，特别是近年来在深度学习领域有很突出的贡献。</p>
<p>第三作者高剑峰（Jianfeng Gao）是一名长期在微软研究院工作的研究员和经理。</p>
<p>第四作者邓力（Li Deng）是微软研究院的人工智能学者，曾担任微软的首席人工智能科学家并且领导深度学习中心。2017年5月，邓力离开微软加入Citadel，美国著名的金融机构，担任首席人工智能官的职位。</p>
<p>最后一位作者格雷古瓦·梅尼尔（Grégoire Mesnil）是来自蒙特利尔大学的一名博士学生。</p>
<p>这篇论文自2014年发表后已被引用180多次，是探讨深度学习在搜索领域中应用的主要论文之一。</p>
<h2>卷积结构下的隐含语义模型详解</h2>
<p>我们周一介绍的深度结构化语义模型，其主要思想是希望能够利用前馈神经网络来对查询关键字和文档进行信息提取。这个模型有一个很明显的问题，那就是在第一步对查询关键字或文档进行特征提取时所形成的词向量（Term Vector）是忽略了文字原本的顺序信息的，也就是依然是一个“词袋模型”（Bag of Words）假设，这显然是丢失了很多信息的。</p>
<p>当然，我们今天要分享的卷积结构下的隐含语义模型，也并不是第一个想要解决这个问题的模型。在经典的信息检索领域的研究中，已经有不少这方面的尝试了。那么对于深度学习来说，又有什么优势呢？</p>
<!-- [[[read_end]]] -->
<p>近些年来深度学习模型兴起的一个重要动力就是在图像、音频、视频领域的技术突破。而这些突破离不开一个重要的基础模型，<strong>卷积神经网络</strong>的成熟。这个模型对有空间位置结构性的数据，比如图像中每一个像素，有较强的建模能力，成为了探索结构信息建模的一个利器。那么，能不能把在这些领域中已经成熟的经验借鉴到搜索领域呢？</p>
<p>如果把文本的词与词，句子与句子之间的关系看作是一种空间位置关系的话，那么从假设上来看，就很符合卷积神经网络模型的基本设置。接下来，我们就来看看这个模型具体是怎么应用到搜索中的。</p>
<p>首先，模型对查询关键字或者文档的文字进行“<strong>移动窗口</strong>”式（Sliding Window）的扫描。这第一步就和之前的深度结构化语义模型有了本质区别。然后，模型进一步把“移动窗口”下的词转换成为<strong>字母级别的表征向量</strong>（Representation Vector）。这个步骤之后，模型采用了<strong>卷积层</strong>来提取空间位置的特征，也是把数据的维度大幅度降低。卷积层之后就是基本的“<strong>池化层</strong>”（Pooling Layer），这里的模型采用了<strong>最大池化</strong>（Max Pooling），也就是从多个卷积层的结果中，每一个层对应元素中的最大元素。在池化层之后，就是进行一个全部展开的语义层。</p>
<p>更加直白地说，<strong>整个模型就是希望先从原始的文字信息中，利用保留顺序的一个移动窗口提取最基本的特征；然后利用卷积神经网络的标配，卷积层加池化层，来提取空间位置信息；最后利用一个全部的展开层来学习下一步的系数</strong>。卷积层主要抓住的是单词这个级别的特征；而池化层则是希望抓住句子这个层面的语义信息；最后利用句子这个层面的语义信息形成整个文字的内在语义表达。</p>
<p>这个模型是如何被训练出来的呢？事实上，可以说整个模型的训练过程和我们周一分享的深度结构化语义模型的训练过程一模一样。首先，同样是利用用户的点击信息，也就是针对某一个查询关键字，有哪些文档被点击过，作为正例数据，其他文档作为负例数据；然后把整个建模问题看做是一个多类分类问题；这样就可以利用标签信息对整个模型进行学习。</p>
<h2>隐含语义模型的实验效果</h2>
<p>和深度结构化语义模型一样，隐含语义模型也仅仅使用了查询关键字和文档之间的文字信息，所以也只能和文字型的排序算法进行比较。最终文章在数据集上采用了Bing的搜索数据，有1万2千多的查询关键字以及每个查询关键字所对应的74个文档，每个文档又有4级的相关标签，用来计算NDCG这样的指标。数据虽然和之前一篇不完全一样，但是在数量级上是差不多的。</p>
<p>在这篇文章里，作者们也比较了一系列的方法，比如TF-IDF、BM25，以及传统的PLSA和LDA。简单来说，隐含语义模型在最后的比较中取得了不错的结果，NDCG在第10位的表现是接近0.45，而之前提出的深度结构化语义模型达到了差不多0.44。虽然利用卷积的效果要好一些，但是差距并不大。在这个数据集上，传统方法要差很多，比如BM25的表现仅有0.38左右，而传统的PLSA和LDA也只有0.40左右的表现。应该说在这篇文章中展示出来的效果还是有比较大的差距的。</p>
<h2>小结</h2>
<p>今天我为你讲了卷积结构下的隐含语义模型的一些基本原理，这个模型是利用深度学习技术对搜索算法进行改进的另一个很有价值的尝试，揭开了用深度学习模型，特别是用在图像处理中非常成功的卷积神经网络技术来表征查询关键字和文档会达到的效果。</p>
<p>一起来回顾下要点：第一，我们简要介绍了隐含语义模型提出的历史。第二，我们详细介绍了隐含语义模型的核心思路以及实验结果。</p>
<p>给你留一个思考题，为什么顺序信息并没有像我们想象中的那样，给文档搜索提升带来很大的效果呢？有没有什么解释？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p>最后，预告一个小活动，本周六（1月13日）晚8:30我会在极客时间做一场直播，欢迎你参加。主题是“人工智能20问”，如果你有想交流的问题，欢迎给我留言，我们周六直播见！</p>
<p><img src="https://static001.geekbang.org/resource/image/03/a4/036075efeb9f168a768b32cd178ce9a4.jpg" alt="" /></p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor58">057 | 基于深度学习的搜索算法：局部和分布表征下的搜索模型<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>周一我们分享了一篇较早利用深度学习技术来进行搜索建模的论文，利用前馈神经网络来对查询关键字和文档进行信息提取，从而学习到更有意义的语义信息。周三我们分享了另外一篇论文，可以说是周一分享文章的一个后续工作，探讨了如何利用卷积神经网络来对搜索表征进行进一步提升。这两篇论文呈现了一个统一的套路，那就是尝试把深度学习的一些经验直接应用到传统的搜索建模上。这些尝试，也都取得了一些初步成绩。</p>
<p>今天我们来聊一篇2017年刚刚发表的论文《网页搜索中利用文本的局部和分布表征学习匹配》（Learning to Match Using Local and Distributed Representations of Text for Web Search），这是近期将深度学习模型应用在搜索领域的一个创新。这篇论文发表在世界万维网大会WWW 2017上。</p>
<h2>论文背景介绍</h2>
<p>下面我们来了解一下这篇论文的作者群信息。</p>
<p>第一作者巴斯卡⋅米特拉（Bhaskar Mitra）是微软研究院在剑桥实验室的一名研究员。他已经发表了多篇利用深度学习技术解决搜索问题的论文。目前，米特拉在伦敦大学学院攻读博士学位。</p>
<p>第二作者是费尔南多⋅迪亚兹（Fernando Diaz）在文章发表的时候是微软研究院的一名研究员，目前则在Spotify工作。迪亚兹长期从事搜索以及信息检索的工作，发表多篇论文，文章总引用数超过三千次。加入微软之前，他曾经在雅虎研究院从事过研究工作。</p>
<p>文章的第三作者尼克⋅克拉维尔（Nick Craswell）在微软研究院工作，目前是主任级研发经理，长期从事搜索和信息检索的研究，发表多篇论文，文章总引用数达8千多次。</p>
<h2>局部和分布表征下的搜索模型详解</h2>
<p>我们详细讲讲这篇论文的核心思想。要想理解这篇论文提出的思路，我们首先要简单回顾一下这周讲的前两篇文章内容。</p>
<p>本周第一篇介绍的深度结构化语义模型主要是希望利用前馈神经网络来对查询关键字和文档进行信息提取。第二篇文章尝试用卷积神经网络来提取查询关键字和文档的信息。</p>
<p>不论是前馈网络，还是卷积网络， 这些尝试都是想从文本中提取高层次的语义信息。那么今天这篇文章说得是，并不是所有的相关信息都是高层次的语义信息。这是什么意思呢？</p>
<!-- [[[read_end]]] -->
<p>作者们提出了这样一个观点，那就是在搜索的时候，一个非常关键的需求就是被搜索到的文档应该包含查询关键字；或者反过来说，拥有查询关键字的文档有很大可能是相关的。也就是说，<strong>如果一个模型不能去进行绝对的关键字匹配，那很有可能就无法真正抓住所有的相关信息</strong>。</p>
<p>另一方面，相关信息的提取也需要高层次的语义，比如同义词，或者同一个主题。设想我们需要查找汽车相关的信息，而一个最新品牌的汽车页面也许并不直接包含“汽车”关键字，但很明显是一个相关的页面。因此，<strong>利用同义词或者整个主题的相关性，通常可以提高搜索效果，特别是“召回”（Recall）的效果</strong>。</p>
<p>那么，很显然，一个好的搜索模型应该兼顾这两个方面，也就是说<strong>既能够做到关键字的直接匹配，也能做到在高层次的语义上进行模糊匹配</strong>。</p>
<p>之前讲到的比如利用前馈网络或者卷积网络主要是针对后者，也就是模糊匹配，文章中提到叫做“分布表征”的匹配。那么，这篇文章的新意就是提出一种捕捉直接匹配的方式，文章叫做“<strong>局部表征</strong>”，并且和模糊匹配的分布表征结合在一起，形成一个统一的模型，从而提高搜索的效果。</p>
<p>具体来说，文章提出的模型是这样的。首先，从整体的网络框架来说，整个网络分成两个部分：一部分来学习查询关键字和文档的局部表征，也就是完全匹配；另一部分来学习查询关键字和文档的分布表征，也就是模糊匹配。最后，两个部分分别学习出一个向量，然后两个向量加和就形成了最后的表征。</p>
<p>完全匹配的局部表征技巧来自于数据的输入。和之前介绍的模型不同，因为我们需要学习查询关键字和文档之间的匹配信息，因此，网络的输入信息就不单单是查询关键字和文档本身，而是两者的一个“<strong>点积</strong>”（Dot-Product），也就是说，网络的输入信息就是两者是否有匹配。把这个信息作为输入向量之后，这篇文章采用了我们分享过的卷积神经网络的结构，来进一步提取点积过后的输入向量。</p>
<p>在模糊匹配的分布表征部分，整体的框架和上次分享的模型很类似，也就是对查询关键字和文档分别进行建模，分别利用卷积神经网络提取高层次的语义信息。然后在高层次的语义信息上再进行查询关键字和文档表征的乘积（这里是矩阵相对应元素相乘）。最后，在经过基层的隐含转换（其实就是前馈网络），形成分布表征的最后唯一结果。</p>
<p><strong>从整个模型来看，局部表征和分布表征的主要区别在于如何处理查询关键字和文档的匹配信息</strong>。如果是在原始数据上直接匹配，然后学习匹配后的高层语义，这就是局部表征。如果是先学习高层语义然后再匹配，这就是分布表征。</p>
<p>整个模型利用相关标签，进行的是监督学习流程，并且采用了SGD来优化。</p>
<h2>局部和分布表征的搜索模型实验效果</h2>
<p>这篇论文提出的模型还是仅仅使用了查询关键字和文档之间的文字信息，因此和上两篇分享一样，提出的模型就只能和文字型的排序算法例如TF-IDF、BM25和语言模型进行比较。文章在数据集上采用了Bing的搜索数据，有19万多的查询关键字，总共有将近百万的文档数。这比之前两个分享里的数据都要大。不过遗憾的是，这三篇文章都是不同的数据集 。每个文档又有4级的相关标签，可以用来计算诸如NDCG这样的指标。</p>
<p>在这篇文章里，作者们比较了一系列的方法，比如TF-IDF、BM25，以及一些传统的降维方法比如LSA，然后还比较了之前两个分享中提到的模型。简单来说，本文模型在最后的比较中取得了非常不错的成绩，NDCG在第10位的表现接近0.53，而之前提出的一系列深度搜索模型，包括我们分享的两个模型达到了差不多0.45~0.48左右。看来，既需要完全匹配还需要模糊匹配的确能够带来性能上的提升。在这个数据集上，传统方法其实也不差，比如BM25的表现有0.45左右，而传统的LSA也有0.44左右的表现。</p>
<h2>小结</h2>
<p>今天我为你分享了搜索专题的最后一篇内容，那就是利用深度学习技术对搜索算法进行改进的又一个尝试：一个结合了学习完全匹配的局部表征和模糊匹配的分布表征的统一的搜索模型。</p>
<p>一起来回顾下要点：第一，我们简要介绍了局部和分布表征搜索模型提出的历史。第二，我们详细介绍了局部和分布表征搜索模型的核心思路以及实验结果。</p>
<p>给你留一个思考题，我们这周分享了三个经典的深度学习和搜索相结合的尝试，你觉得目前深度学习在搜索领域取得的成果，有让你感到特别惊讶的结果吗？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p>最后，预告一个小活动，明晚（1月13日）8:30我会在极客时间做一场直播，欢迎你参加。主题是“人工智能20问”，如果你有想交流的问题，欢迎给我留言，我们周六直播见！</p>
<p><img src="https://static001.geekbang.org/resource/image/03/a4/036075efeb9f168a768b32cd178ce9a4.jpg" alt="" /></p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor59">复盘 1 | 搜索核心技术模块<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>到目前为止，我们讲完了人工智能核心技术的第一个模块——<em><span class="orange">搜索</span></em>。我们从搜索的核心算法入手，进而讨论了搜索的两个关键组件，分别是查询关键字理解和文档理解，并落实到对搜索系统的评价，然后从宏观视角介绍了搜索框架的历史和发展，最后又从深度学习技术在搜索领域的应用角度，对分享做了一个延伸。</p>
<p>整个模块<span class="orange">共27期</span>，<span class="orange">9大主题</span>，希望通过这些内容，能让你对搜索技术有一个系统的认识和理解，为自己进一步学习和提升打下基础。今天我们就来对这一模块的内容做一个复盘。</p>
<p><span class="reference">提示：点击知识卡跳转到你最想看的那篇文章，温故而知新。如不能正常跳转，请先将App更新到最新版本。</span></p>
<h2>1.现代搜索架构剖析</h2>
<p>从20世纪50年代有信息检索系统开始，搜索系统大致经历了三个发展阶段。从最开始的“基于文本匹配的信息检索系统”到“基于机器学习的信息检索系统”，再到近几年受深度学习影响的“更加智能的搜索系统”。</p>
<p><a href="https://time.geekbang.org/column/article/1702"><img src="https://static001.geekbang.org/resource/image/7b/07/7b421403d2398604e4115bee4df25707.png" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/1762"><img src="https://static001.geekbang.org/resource/image/45/0d/458e60fc7255a359bc31a73a0f70b30d.png" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/1821"><img src="https://static001.geekbang.org/resource/image/db/a4/dbc32bbdc558aac10c40144f318a9ba4.png" alt="" /></a></p>
<h2>2.经典搜索核心算法</h2>
<p><a href="https://time.geekbang.org/column/article/822"><img src="https://static001.geekbang.org/resource/image/f4/5e/f489afcf01a5ffb8aeb801899436325e.png" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/828"><img src="https://static001.geekbang.org/resource/image/01/98/01a7ce8bc679bc75e414b3a5c8e04698.png" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/830"><img src="https://static001.geekbang.org/resource/image/21/b6/218e2118d860c7b342076e5fda049cb6.png" alt="" /></a></p>
<h2>3.基于机器学习的排序算法</h2>
<p>问题设置：把一个排序问题转换成一个机器学习的问题设置，特别是监督学习的设置。</p>
<p><a href="https://time.geekbang.org/column/article/949"><img src="https://static001.geekbang.org/resource/image/e4/b9/e48e5413055da8fd441d7781ff9801b9.png" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/950"><img src="https://static001.geekbang.org/resource/image/fe/74/fe1844e1de5f9f34af2e4a842ac3aa74.png" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/952"><img src="https://static001.geekbang.org/resource/image/9b/00/9b087c4f672314639e1bcd572f8c4000.png" alt="" /></a></p>
<h2>4.基于机器学习的高级排序算法</h2>
<p><a href="https://time.geekbang.org/column/article/2026"><img src="https://static001.geekbang.org/resource/image/70/91/70d53c45a87711e1b1b441bec1753591.png" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/2052"><img src="https://static001.geekbang.org/resource/image/0c/32/0cfd58acbe692fc437f6ce3a35092e32.png" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/2099"><img src="https://static001.geekbang.org/resource/image/51/6b/517840c53b3d0e7cd2abc487da578d6b.png" alt="" /></a></p>
<h2>5.查询关键字理解</h2>
<p><a href="https://time.geekbang.org/column/article/1077"><img src="https://static001.geekbang.org/resource/image/fb/43/fb7cbfccb622be4515e7450b182a3443.png" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/1079"><img src="https://static001.geekbang.org/resource/image/5c/03/5c14df7301b5e41186ec4a469b670c03.png" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/1081"><img src="https://static001.geekbang.org/resource/image/1a/10/1a6766670e0a62feb367f285afaebc10.png" alt="" /></a></p>
<h2>6.文档理解</h2>
<p><a href="https://time.geekbang.org/column/article/1448"><img src="https://static001.geekbang.org/resource/image/0a/44/0a290fe14835b5873e9c96f97c4bd944.png" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/1449"><img src="https://static001.geekbang.org/resource/image/e6/52/e6cee91bb08cd53231417fb31ab2a252.png" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/1450"><img src="https://static001.geekbang.org/resource/image/bc/0f/bc47227d10463309cf61c49d1bf9e20f.png" alt="" /></a></p>
<h2>7.经典图算法</h2>
<p><a href="https://time.geekbang.org/column/article/1883"><img src="https://static001.geekbang.org/resource/image/b8/0e/b82b17813fabd3f5f4122cd28f90fc0e.png" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/1938"><img src="https://static001.geekbang.org/resource/image/3c/75/3c7b084e04691a127d3ccbb6e44d3a75.png" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/1940"><img src="https://static001.geekbang.org/resource/image/37/63/37c944d1604e9fc3403af4d6b1e1da63.png" alt="" /></a></p>
<h2>8.基于深度学习的搜索算法</h2>
<p><a href="https://time.geekbang.org/column/article/2297"><img src="https://static001.geekbang.org/resource/image/7b/79/7bf8ff71d180de4f595492d4814f1b79.png" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/2298"><img src="https://static001.geekbang.org/resource/image/ff/0a/ff66c775018198c8dbf53522b2cfd00a.png" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/2332"><img src="https://static001.geekbang.org/resource/image/51/e7/51e5337043a69b3cdfe3a19eba2466e7.png" alt="" /></a></p>
<h2>9.搜索系统的评价</h2>
<p>If You Can’t Measure It, You Can’t Improve It.</p>
<p><a href="https://time.geekbang.org/column/article/1296"><img src="https://static001.geekbang.org/resource/image/3f/d3/3f60f5a72923c2ac414952330be920d3.png" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/1299"><img src="https://static001.geekbang.org/resource/image/5a/54/5a3beafeeaae0b85ab37188763349e54.png" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/1300"><img src="https://static001.geekbang.org/resource/image/82/3a/827f32f8bfed0874f9cb12775e6c193a.png" alt="" /></a></p>
<h2>积跬步以至千里</h2>
<p>最后，<em>恭喜你在这个模块中已经阅读了<span class="orange">70047字</span>，听了<span class="orange">220分钟</span>的音频，这是一个不小的成就</em>。在人工智能领域的千里之行，我们已经迈出了扎实的第一步。</p>
<p><img src="https://static001.geekbang.org/resource/image/fe/d1/fef59e0cf354d51287e3b3d5d360c0d1.png" alt="" /></p>
<p>感谢你在专栏里的每一个留言，给了我很多思考和启发。期待能够听到你更多的声音，我们一起交流讨论。</p>
<!-- [[[read_end]]] -->
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor60">058 | 简单推荐模型之一：基于流行度的推荐模型<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>今天，我们正式进入专栏的另一个比较大的模块，那就是<strong><span class="orange">推荐系统</span></strong>。之前我们详细且全面地介绍了搜索系统的各个组成部分。在接下来的几周时间里，我们一起来看推荐系统的技术要点又有哪些。</p>
<p>我们还是从简单推荐系统聊起，由易到难，逐步为你讲述一些经典的推荐模型。</p>
<p>推荐系统目前已经深入到了互联网的各类产品中。不管是到电子商务网站购物，还是到新闻阅读网站获取信息，甚至是在出行的时候希望听到不同的音乐，不同种类的推荐系统都在我们的生活中发挥着举足轻重的作用。</p>
<p>那么，搭建一个最简单的推荐系统，应该如何入手呢？今天我们就来聊一个最基本的推荐模型：<strong>基于流行度的推荐模型</strong>。</p>
<h2>最简单的流行度估计</h2>
<p>什么是基于流行度（Popularity-based）？通俗地说，就是什么内容吸引用户，就给用户推荐什么内容。</p>
<p>这里面其实有一个隐含的假设，那就是物品本身的质量好坏和流行度有一定的正比关系。什么意思呢？就是说好的东西，关注的人自然就多，自然就会有更多的谈论。当然，这是一个主观的假设，并不是所有质量高的物品都会有很高的流行度。然而，在不需要过多其他信息和假设的情况下，流行度可以算是衡量物品质量好坏的一个最简单的测度。</p>
<p>那么，如果我们能够在每一个时间点上准确地估计到一个物品的流行度，就只需要按照流行度的数值从高到低排序显示所有的物品就可以了。</p>
<p>然而，这里牵涉到一个问题，那就是如何判断一个物品在任何时间点上的流行度呢？有两个重要的因素影响着物品流行度的估计，那就是<strong>时间和位置</strong>。</p>
<p>我们先来说一下时间因素。很显然，用户访问每一个应用或者服务都有一定的规律，这种规律导致每一个应用的<strong>流量规律</strong>也不一样。比如，人们可能更倾向于在早上或者傍晚打开新闻网站，看一看一天都发生了什么事情。因此，任何文章投放到这两个时段自然就会有比较高的关注度。这并不代表这些文章就要好于其他的文章，可能仅仅是由于时间的关系。因此，我们在对流行度建模的时候就需要考虑时间的因素。</p>
<p>另外一个重要的因素是位置。这个“位置”并不是真正的地理位置，而是在一个服务或者网站的什么位置显示你的物品。因为用户心理对于不同位置的感受，在很多类型的服务中常常都有隐含的“<strong>位置偏差</strong>”（Position Bias）。</p>
<!-- [[[read_end]]] -->
<p>这些偏差给我们估计某个物品的流行度带来了很大的困难。比如说，在绝大多数的搜索引擎服务中，排名第一的物品所受到的关注度很可能大大高于排名第二和之后的物品。因此，一个物品只要放到第一的位置，关注度自然就会升高。当然，这并不能完全代表这个物品本身的属性。</p>
<p>因此，我们在估计物品的流行度时就需要考虑上面所说的这两个重要因素。</p>
<p>要解决刚才说的两个问题，我们就<strong>不能使用绝对数值来对流行度建模</strong>。比如我们使用在单位时间内点击的数目，购买的数目，或者点赞的数目，都会受到刚才所说的两种偏差的影响。假设一篇文章在9点到10点这个时段被点击了100次，在10点到11点这个时段被点击了50次，这并不能代表这个文章在10点到11点这个时段就变得不受欢迎了，很可能是这个时段的总的用户量比较多。</p>
<p>因此，<strong>对于流行度的衡量，我们往往使用的是一个“比值”（Ratio），或者是计算某种“可能性”（Probability）</strong>。也就是说，我们计算在总的用户数是N的情况下，点击了某个文章的人数。这个比值，取决于不同的含义，如果是点击，往往叫作点击率；如果是购买，叫作购买率。为了方便讨论，我们在下面的例子中都使用点击率。</p>
<p>然而，点击率本身虽然解决了一部分时间和位置偏差所带来的影响，但是点击率的估计所需要的数据依然会受到偏差的影响。因此，我们往往希望能够建立无偏差的数据。</p>
<p>关于如何能够无偏差地估计，这是一个研究课题，我们今天不详细展开。不过，有一种比较经济的方法可以收集没有偏差的数据，那就是把服务的流量分成两个部分。</p>
<p>一个部分，利用现在已有的对物品流行度的估计来显示推荐结果。另外一个部分，则随机显示物品。这种方法是一种特殊的<strong>EE算法</strong>（Exploitation &amp; Exploration），叫“<strong>epsilon贪心</strong>”（epsilon-Greedy）。</p>
<p>我们之后还会聊到这个话题。根据这样的方式搜集的数据可以认为是没有位置偏差的。我们从随机显示物品的这部分流量中去估计流行度，然后在另外一个部分的流量里去显示物品。</p>
<p>如果从数学上对点击率建模，其实可以把一个物品在显示之后是否被点击看成是一个“<strong>伯努利随机变量</strong>”，于是对点击率的估计，就变成了对一个伯努利分布参数估计的过程。</p>
<p>有一种参数估计的方法叫作“<strong>最大似然估计法</strong>”（Maximum Likelihood Estimation）。简而言之，就是说，希望找到参数的取值可以最大限度地解释当前的数据。我们利用最大似然法就可以求出在某一段时间内的点击率所代表的伯努利分布的参数估计。这个估计的数值就是某个物品当前的点击总数除以被显示的次数。通俗地讲，如果我们显示某个物品10次，被点击了5次，那么在最大似然估计的情况下，点击率的估计值就是0.5。</p>
<p>很显然，这样的估计有一定的局限性。如果我们并没有显示当前的物品，那么，最大似然估计的分母就是0；如果当前的物品没有被点击过，那么分子就是0。在这两种情况下，最大似然估计都无法真正体现出物品的流行度。</p>
<h2>高级流行度估计</h2>
<p>我们从统计学的角度来讲了讲，如何利用最大似然估计法来对一个伯努利分布所代表的点击率的参数进行估计。</p>
<p>这里面的第一个问题就是刚才我们提到的分子或者分母为0的情况。显然，这种情况下并不能很好地反应这些物品的真实属性。</p>
<p><strong>一种解决方案是对分子和分母设置“先验信息”</strong>。就是说，虽然我们现在没有显示这个物品或者这个物品没有被点击，但是，我们“主观”地认为，比如说在显示100次的情况下，会有60次的点击。注意，这些显示次数和点击次数都还没有发生。在这样的先验概率的影响下，点击率的估计，或者说得更加精确一些，点击率的后验概率分布的均值，就成为了实际的点击加上先验的点击，除以实际的显示次数加上先验的显示次数。你可以看到，在有先验分布的情况下，这个比值永远不可能为0。当然，这也就避免了我们之前所说的用最大似然估计所带来的问题。</p>
<p><strong>利用先验信息来“平滑”（Smooth）概率的估计，是贝叶斯统计（Bayesian Statistics）中经常使用的方法</strong>。如果用更加精准的数学语言来表述这个过程，我们其实是为这个伯努利分布加上了一个Beta分布的先验概率，并且推导出了后验概率也是一个Beta分布。这个Beta分布参数的均值，就是我们刚才所说的均值。</p>
<p>在实际操作中，并不是所有的分布都能够找到这样方便的先验分布，使得后验概率有一个解析解的形式。我们在这里就不展开讨论了。</p>
<p><strong>另外一个可以扩展的地方就是，到目前为止，我们对于流行度的估计都是针对某一个特定的时段</strong>。很明显，每个时段的估计和前面的时间是有一定关联的。这也就提醒我们是不是可以用之前的点击信息，来更加准确地估计现在这个时段的点击率。</p>
<p>答案是可以的。当然，这里会有不同的方法。</p>
<p>一种最简单的方法还是利用我们刚才所说的先验概率的思想。那就是，当前T时刻的点击和显示的先验数值是T-1时刻的某种变换。什么意思呢？比如早上9点到10点，某个物品有40次点击，100次显示。那么10点到11点，我们在还没有显示的情况下，就可以认为这个物品会有20次点击，50次显示。注意，我们把9点到10点的真实数据乘以0.5用于10点到11点的先验数据，这种做法是一种主观的做法。而且是否乘以0.5还是其他数值需要取决于测试。但是这种思想，有时候叫作“<strong>时间折扣</strong>”（Temporal Discount），是一种非常普遍的时序信息处理的手法。</p>
<h2>小结</h2>
<p>今天我为你讲了基于流行度的推荐系统的基本原理。一起来回顾下要点：第一，我们简要介绍了为什么需要基于流行度进行推荐；第二，我们详细介绍了如何对流行度进行估计以及从统计角度看其含义；第三，我们简要地提及了一些更加高级的流行度估计的方法。</p>
<p>最后，给你留一个思考题，我们介绍了如何使用先验信息来对参数进行平滑，如何能够更加准确地确定先验概率中的数字呢？具体到我们的例子就是，如何来设置先验的点击和显示次数呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor61">059 | 简单推荐模型之二：基于相似信息的推荐模型<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>这周我们开始讲推荐系统。周一的文章中，我们聊了一个最基本的推荐模型：基于流行度的推荐模型。这是一种简单且实用的推荐系统搭建方式，那就是需要对每一个物品的流行度进行估计。</p>
<p>今天，我们来看另外一种简单但很有效果的推荐模型：<strong>基于相似信息的推荐模型</strong>。</p>
<h2>什么是相似信息的推荐模型</h2>
<p>相似信息的推荐模型又叫<strong>“临近”（Neighborhood）模型</strong>。顾名思义，就是我们希望利用临近、或者相似的数据点来为用户推荐。</p>
<p>临近模型的内在假设是推荐系统中著名的“<strong>协同过滤</strong>”（Collaborative Filtering）。什么意思呢？就是说，我们认为，<strong>相似的用户可能会有相似的喜好，相似的物品可能会被相似的人所偏好</strong>。于是，如果我们能够定义怎么寻找相似的用户或者相似的物品，那么我们就可以利用这些类别的人群或者物品来给用户进行推荐。</p>
<p>例如，对于一个电影推荐的场景来说，有一个用户A观看了电影《战狼2》，我们希望根据这个信息来为用户进行推荐。很显然，如果我们仅仅知道用户A观看过《战狼2》，这个信息是非常有限的。但是，假设有一个用户B也观看过《战狼2》，并且最近还观看过《红海行动》。那么， 我们可以根据B的信息来对A进行推荐，也就是说，我们认为用户A也有可能喜欢《红海行动》。</p>
<p>这里面，我们其实经历了这么两个步骤。</p>
<!-- [[[read_end]]] -->
<p>第一，联系用户A和用户B的是他们都看过《战狼2》。这就帮助我们定义了A和B是相似用户。</p>
<p>第二，我们的假定是，相似的用户有相似的观影偏好，于是我们就直接把B的另外一个观看过的电影《红海行动》拿来推荐给了A。</p>
<p>这两个步骤其实就很好地解释了“协同过滤”中“协同”的概念，意思就是相似的用户互相协同，互相过滤信息。</p>
<p><strong>“协同过滤”从统计模型的意义上来讲，其实就是“借用数据”，在数据稀缺的情况下帮助建模</strong>。掌握这个思路是非常重要的建模手段。</p>
<p>在用户A数据不足的情况下，我们挖掘到可以借鉴用户B的数据。因此，我们其实是把用户A和用户B“聚类”到了一起，认为他们代表了一个类型的用户。当我们把对单个用户的建模抽象上升到某一个类型的用户的时候，这就把更多的数据放到了一起。</p>
<h2>基于相似用户的协同过滤</h2>
<p>刚才我们简单聊了聊什么是基于相似信息的推荐系统。相信到现在，你已经对这个概念有了一个最基本的认识。</p>
<p>那么，如何才能够比较系统地定义这样的流程呢？</p>
<p>首先，问题被抽象为我们需要估计用户I针对一个没有“触碰过”（这里指点击、购买、或者评分等行为）的物品J的偏好。</p>
<p>第一步，我们需要构建一个用户集合，这个用户集合得满足两个标准：第一，这些用户需要已经触碰过物品J，这是与用户I的一大区别；第二，这些用户在其他的行为方面需要与用户I类似。</p>
<p>现在我们假设这个集合已经构造好了。那么，接下来的一个步骤，就是根据这个相似的用户集，我们可以对物品J进行一个打分。这个打分的逻辑是这样的。首先，我们已经得到了所有和I相似的用户对J的打分。那么，一种办法就是，直接用这些打分的平均值来预估J的评分。也就是说，如果我们认为这个相似集合都是和用户I相似的用户，那么他们对J的偏好，我们就认为是I的偏好。显然这是一个很粗糙的做法。</p>
<p>我们可以针对这个直接平均的做法进行两个改动。</p>
<p>第一，采用加权平均的做法。也就是说，和用户I越相似的用户，我们越倚重这些人对J的偏好。</p>
<p>第二，我们也需要对整个评分进行一个修正。虽然这个相似集合的人都对J进行过触碰，但是每个人的喜好毕竟还是不一样的。比如有的用户可能习惯性地会对很多物品有很强的偏好。因此，仅仅是借鉴每个人的偏好，而忽略了这些用户的偏差，这显然是不够的。所以，我们需要对这些评分做这样的修正，那就是减去这些相似用户对所有东西的平均打分，也就是说，我们需要把这些用户本人的偏差给去除掉。</p>
<p>综合刚才说的两个因素，可以得到一个更加合适的打分算法，那就是，用户I对物品J的打分来自两个部分：一部分是I的平均打分，另外一部分是I对于J的一个在平均打分之上的补充打分。这个补充打分来自于刚才我们建立的相似用户集，是这个相似用户集里每个用户对于J的补充打分的一个加权平均。权重依赖于这个用户和I的相似度。每个用户对于J的补充打分是他们对于J的直接打分减去他们自己的平均打分。</p>
<h2>相似信息的构建</h2>
<p>我们刚才讲了一下相似用户协同过滤的一个基本思路。那么，这里面有几个要素需要确定。</p>
<p><strong>第一，我们怎么来定义两个用户是相似的？</strong>一种最简单的办法，就是计算两个用户对于他们都偏好物品的“<strong>皮尔森相关度</strong>”（Pearson Correlation）。这里当然可以换做是其他相关信息的计算。</p>
<p>具体来说，皮尔森相关度是针对每一个“两个用户”都同时偏好过的物品，看他们的偏好是否相似，这里的相似是用乘积的形式出现的。当两个偏好的值都比较大的时候，乘积也就比较大；而只有其中一个比较大的时候，乘积就会比较小。然后，皮尔森相关度对所有的乘积结果进行“加和”并且“归一化”。</p>
<p><strong>第二，当有了用户之间的相关度信息后，我们可以设定一些“阈值”来筛选刚才所说的相关用户集合</strong>。对于每个目标用户，我们可以设置最多达到前K个相似用户（比如K等于100或者200），这也是有效构造相似集合的办法。</p>
<p><strong>最后，我们来谈一下刚才所说的加权平均里面的权重问题</strong>。一种权重，就是直接使用两个用户的相似度，也就是我们刚计算的皮尔森相关度。当然，这里有一个问题，如果直接使用，我们可能会过分“相信”有一些相关度高但自身数据也不多的用户。什么意思呢？比如有一个用户M，可能和目标用户I很相似，但是M自己可能也就偏好过一两件物品，因此我们可能还需要对相关度进行一个“<strong>重新加权</strong>”（Re-Weighting）的过程。具体来说，我们可以把皮尔森相关度乘以一个系数，这个系数是根据自身的偏好数量来定的。</p>
<h2>基于相似物品的协同过滤</h2>
<p>在协同过滤的历史上，人们很快就意识到在进行构建推荐的过程中，用户和物品的“对称性”。什么意思？也就是说，我们刚才对于用户的讨论其实完全可以变换到物品中。</p>
<p>具体说来，那就是我们不去构造和用户I相似的用户，而是去构造所有和物品J相似的物品。这些相似物品集合必须要满足两点：第一，和J相似；第二，已经被用户I触碰了。这里的一个基本的假设类似于，虽然我不知道用户I对于《红海行动》的偏好，但我可以去看一看用户过去看的电影里有哪些和《红海行动》是类似的，我们就可以从那些类似的电影中进行加权平均，取得对《红海行动》的预测。</p>
<h2>小结</h2>
<p>今天，我为你讲了推荐系统的另外一个基本的形式：基于相似度的协同过滤推荐系统。</p>
<p>一起来回顾下要点：第一，我们简要介绍了整个基于相似度协同过滤的内涵以及我们这么做的基本假设；第二，我们详细介绍了如何构造一个基于用户相似度的协同过滤系统；第三，我们简要地提及了如何构造物品相似的协同过滤系统。</p>
<p>最后，给你留一个思考题，协同过滤的一个致命问题是什么？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor62">060 | 简单推荐模型之三：基于内容信息的推荐模型<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>周一的文章中，我们聊了一个最基本的基于流行度的推荐模型。周三我们讨论了基于相似信息的推荐模型。基于相似信息的推荐模型，其核心就是协同过滤的思想，希望能够通过相似的用户或者相似的物品来对当前的场景进行推荐。</p>
<p>然而，不管是基于流行度的推荐，还是协同过滤，这些方法都有一些根本的问题。比如，对于基于流行度预测的推荐来说，推荐结果不是个性化的。因为流行度预测是一种全局的预测，每个人得到的推荐结果是一样的。而协同过滤的问题是强烈依赖相似用户以及相似物品的定义，而且对于新用户或者新物品来说有数据稀缺的问题。因此，在实际应用中，往往不能在整个系统中单独使用协同过滤。</p>
<p>今天，我们来分享一个更加普遍的方法，那就是<strong>基于内容信息的推荐系统</strong>。这种系统在实践中往往更能适应各种不同的推荐场景。</p>
<h2>什么是基于内容信息的推荐系统</h2>
<p>所谓基于内容信息的推荐系统，其实就是<strong>用特征（Feature）来表示用户、物品以及用户和物品的交互，从而能够把推荐问题转换成为监督学习任务</strong>。</p>
<p>把推荐系统完全定义为监督学习任务，需要有这么几个步骤。</p>
<p>第一，就是我们已经提到的，需要把所有用户、物品的各种信号用特征来表示。这里面往往牵涉非常复杂和繁琐的<strong>特征工程</strong>，也就是看如何能够把不同的信息通过特征表达出来。</p>
<p>第二，就是每一个监督任务都需要面临的问题，如何构造一个<strong>目标函数</strong>，来描述当前的场景。可以说，这是最难的一个部分，也是和基于流行度和基于相似度的推荐系统的最大区别。</p>
<h2>内容信息的各类特性</h2>
<p>那么，对于物品特性来说，有哪些是比较重要的呢？这里我们肯定没法提供一个完备的列表，那我就来谈一些主要的特性，起到一个抛砖引玉的作用。</p>
<!-- [[[read_end]]] -->
<p>第一，<strong>物品的文本信息</strong>。比如商品的名字和描述。这些文字信息可以使用很多文本挖掘（Text Mining）的方式来组成有效的特征。</p>
<p>我们在讲搜索模块的时候，其实就已经提到了一些，比如用TF-IDF的方法来形成文本向量。当然，因为文本信息的噪声相对比较大，并且数据维度也比较大（维度等于文本所对应语言的词汇量），很多时候我们都寻求降低这部分数据的维度，降低到一个固定的维度。这种时候，很多所谓“降维”的工具就很有必要了。</p>
<p>传统上，有用“<strong>话题模型</strong>”（Topic Model）对文本进行降维的。也就是说，我们针对每一个文字描述都可以学习到一个话题的分布，这个分布向量可能是50维、100维等等，但是肯定要比原始的词汇向量要小。</p>
<p>近些年，很多人又开始使用各种“<strong>词嵌入向量</strong>”（Word Embedding）的方法来为文字信息降维，从而能够使用一个固定的维度来表达文字信息。</p>
<p>第二，<strong>物品的类别信息（或者物品的知识信息）</strong>。对于新闻文章来说，类别信息是新闻的话题类别，像娱乐新闻、财经新闻或者时政新闻等。而对于商品来说，类别信息是商品的品类，像电器、床上用品或者生活用品等。这些类别信息往往能够非常有效地抓住物品的整体属性。通常情况下，这样的属性比直接使用文字信息更加直接。</p>
<p>如何能够得到这样的类别信息呢？在有些情况下，这些类别信息是在数据输入的时候获取的。比如通过合作渠道取得新闻文章的时候，类别往往是编辑加上去的。再比如，商品的类别很多时候也是卖家在输入商品的时候加上去的。</p>
<p>当然，也有一些情况，这些类别信息并不是直接获得的；或者是在数据中有很多缺失的情况下，就需要利用机器学习的手段，来构造分类器以获取这些类别信息。我们在这里就不展开讨论这些分类器该如何构建了。</p>
<p>最后需要说明的一点是，除了最基本的类别信息，最近一段时间比较火热的研发领域，就是<strong>利用知识图谱（Knowledge Graph）来对物品的各种信息进行深入挖掘</strong>。很多信息是通过知识图谱推断出来的。</p>
<p>举个例子，某一篇新闻文章是关于美国总统特朗普的，于是这篇文章可能就会自动被打上美国总统、美国政治等其他标签。这种通过一些原始的信息来进一步推断更加丰富的知识信息，也是重要的物品类别特征的处理工作。</p>
<p>最后需要提及的是图像或者其他多媒体的信息。在信息如此丰富的今天，很多物品都有多样的表现形式，比如比较常见的图像、视频等。</p>
<p>那么，如何从这些媒介中提取信息也是非常关键的物品特征工程。和文字信息正好相反，很多多媒体的信息都是稠密（Dense）的向量，因此需要对这些向量进行特殊处理，比如我们首先学习一个分类器，然后再和其他特征的不同分类器组合。</p>
<p>前面我们简单谈了谈物品的特征，下面我们再来看看用户的特征。</p>
<p>对于用户来说，最基础、最首要的肯定是用户的基本特性，包括性别、年龄、地理位置。这三大信息其实可以涵盖用户特性工程中非常大的一块内容。</p>
<p>这里不仅是最基本的这三个特性的值，还有围绕这三个特性发展出来的三大种类的特性。比如，不同性别在文章点击率上的差异，不同年龄层在商品购买上的差异，不同地理位置对不同影视作品的喜好等，这些都是根据这三个特性发展出来的更多的特性。</p>
<p>然后，我们可以为用户进行画像（Profiling）。有显式的用户画像，比如用户自己定义的喜好，或者用户自己认为不愿意看到的物品或者类别。</p>
<p>但是在大多数情况下，用户都不会为我们提供那么精准的回馈信息，甚至完全不会有任何直接的反馈。在这样的情况下，绝大多数的用户画像工作，其实是通过用户的“隐反馈”（Implicit Feedback），来对用户的喜好进行建模。关于如何进行用户画像，我们今天就不在这里展开了。</p>
<h2>目标函数</h2>
<p>讨论了物品和用户特征的一些基本情况后，我们再来简单聊聊另外一个话题，那就是<strong>目标函数</strong>。我们前面提到，整个基于内容信息的推荐系统就是把所有的信号都当做特征，然后构建一个监督学习任务。</p>
<p>监督学习的一个关键的就是目标函数。对于一个推荐系统来说，都有什么样的目标函数呢？</p>
<p>和纯粹的基于评分（Rating）的协同过滤推荐系统一样，我们可以设置监督学习的目标函数是<strong>拟合评分</strong>。当然，已经有很多学者指出评分并不是推荐系统的真正目标。</p>
<p>那么，在实际系统中比较常见的目标函数有点击率和购买率，也有一些相对比较复杂的目标函数，比如预测用户在某一个物品上的停留时长。</p>
<p>对于究竟在哪种场景中使用什么样的目标函数，这依然是当前的一个主要研究方向。</p>
<h2>小结</h2>
<p>今天我为你讲了基于内容信息的推荐系统。通俗地说，就是如何把推荐系统当做监督学习任务来看待。</p>
<p>一起来回顾下要点：第一，我们简要介绍了整个基于内容推荐的内涵以及我们这么做的基本假设；第二，我们详细介绍了如何构造一个基于内容的推荐系统，特别是如何构造物品和用户的特征；第三，我们简要地介绍了目标函数的重要性。</p>
<p>最后，给你留一个思考题，如何把我们前面介绍的两种推荐系统模式，也就是基于流行度和协同过滤，也融进基于内容的推荐系统中去呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor63">061 | 基于隐变量的模型之一：矩阵分解<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>上周我们聊了三个简单的推荐模型，分别是基于流行度的推荐模型，基于相似信息的推荐模型和基于内容特征的推荐模型。</p>
<p>这周，我们来看一类非常重要的推荐模型：<strong>基于隐变量的推荐模型</strong>。这类模型的优势是对用户和物品信息中的隐含结构进行建模，从而能够挖掘更加深层次的用户和物品关系。</p>
<h2>什么是隐变量</h2>
<p>在解释如何用隐变量来生成推荐结果之前，我们先来说一下什么是隐变量。</p>
<p><strong>隐变量</strong>（Latent Variable），顾名思义，就是“隐藏的变量”或者叫“隐藏的参数”，这里主要是指我们假定实际的数据是由一系列的隐含变量产生的。我们通过模型的假设，知道隐变量之间的关系，但暂时并不知道隐变量的取值。因此需要通过“推断”（Inference）过程来确定隐变量的实际取值。当我们知道了这些隐变量的取值之后，就可以根据这些取值来对未来的数据进行预测和分析。</p>
<p>隐变量往往还带有“统计分布”（Distribution）的假设。什么意思呢？就是隐变量之间，或者隐变量和显式变量之间的关系，我们往往认为是由某种分布产生的。</p>
<p>举一个最简单的隐变量模型的例子，那就是“<strong>高斯混合模型</strong>”（Mixture of Gaussian）。</p>
<p>高斯混合模型假设数据是由多个不同的高斯分布产生的，每一个高斯分布有自己的均值和方差。在最简单的两个高斯的情况下，每一个数据点，都有可能是由这两个高斯分布中的一个产生的，但是，究竟是哪一个我们并不知道。于是，对于每一个数据点，我们就有一个隐含的变量，来表达当前这个数据点究竟来自哪一个高斯分布。</p>
<p>很明显，这个隐含变量的取值事先并不知道。除了这个隐含变量我们不知道以外，两个高斯分布的均值和方法其实也不知道。于是，对于高斯混合模型来说，整个学习的过程就需要估计每个数据点的来源以及多个高斯分布的均值和方差。<strong>高斯混合模型，几乎是最简单的隐变量模型，但也给我们了展示了使用隐变量模型对数据建模的灵活性以及训练的复杂性</strong>。</p>
<h2>矩阵分解作为隐变量模型</h2>
<p>了解了隐变量模型的基本的概念以后，我们还是回到推荐的场景。</p>
<!-- [[[read_end]]] -->
<p>在推荐系统中，有一种最普遍的数据表达，那就是用户和物品的交互，比如评分、点击等等。这里我们用评分作为一般性的讨论。对于每一个用户，如果我们用一个向量来表达其对所有可能物品的评分，那么把所有用户的向量堆积起来，就可以得到一个矩阵。这个矩阵的每一行代表一个用户，每一列代表一个物品，每一个交叉的元素代表某一个用户对于某一个商品的评分。</p>
<p>那么这个矩阵有什么特点呢？最大的特点就是，这个矩阵的数据其实非常稀少。因为在一个现实的系统中，一个用户不可能对所有的物品都进行评分。实际上，一个用户仅仅对非常少的物品进行过评分，而对绝大多数物品并不会评分，甚至连评分的打算都没有。因此，这个矩阵的绝大多数元素其实是0。当然，实际上这些元素也不是0，而是未知，因为用户并不是觉得这些物品的评分是0，而是压根没有对这些物品进行打分，也就是说评分信息不完备。</p>
<p>对于这样一个矩阵，我们的任务其实就是根据有评分的用户物品交互，对那些还没有评分信息的物品进行预测。如果我们能够“补全”（Complete）整个矩阵里的其他元素，那么就可以根据预测的评分从大到小给用户进行推荐。</p>
<p>怎么来补全这个矩阵的信息呢？</p>
<p>这里，我们假设，矩阵的每一个元素都是经过这样一个过程产生的。</p>
<p>首先，我们假设每一个用户和每一个物品都对应一个隐向量（Latent Factor）。比如，我们用100维的向量来表达一个用户，用另外一个100维的向量来表达一个物品。如果我们有1百万个用户和1万个物品，那么我们就需要1百万个100维的用户向量，和1万个100维的物品向量。</p>
<p>然后，我们假设矩阵的每一个元素是由所对应的用户和物品的隐向量点积得到的。也就是说，矩阵里的每一个元素，都是一个100维的用户向量和一个100维的物品向量对应元素相乘相加而得。</p>
<p>在这样的一个假设下，一个原本1百万乘以1万的矩阵就可以被分解为1百万乘以100的用户矩阵和100乘以1万的物品矩阵的乘积。这也就是为什么在这样的模型下，我们会称这个方法为“<strong>矩阵分解</strong>”（Matrix Factorization）的原因。</p>
<p>在矩阵分解这个假设下，我们可以看到，原本是需要对整个矩阵，也就是1百万乘以1万个数据进行建模，而现在缩减到了两个小一些的矩阵1百万乘以100和100乘以1万。对比来看，之前对于每一个用户，我们需要一万个元素来表达用户对于这一万个物品的评分喜好；现在，对每个用于仅仅需要保存100个元素。</p>
<p>只不过，这一百个元素的数值并不代表任何意义。从这个层面上理解矩阵分解，也就能够帮助我们知道，这个方法其实是一种“<strong>降维</strong>”（Dimension Reduction），也就是把一个比较大的矩阵分解成两个小矩阵来表达。</p>
<p>我们可以看到，矩阵分解的核心其实就是刚才的假设，用隐向量来表达用户和物品，他们的乘积关系就成为了原始的元素。不同的假设可以得到不同的矩阵分解模型。</p>
<h2>学习矩阵分解模型</h2>
<p>很明显，矩阵分解仅仅告诉了我们这个模型的表达，但并没有告诉我们怎么去获得整个模型的最核心内容，那就是用户矩阵和物品矩阵里每一个元素的数值。也就是我们所说的，用户隐向量和物品隐向量都是事先不知道的。</p>
<p>那有什么办法能够得到这些向量的取值呢？</p>
<p>这里介绍一种常用的方法，就是利用<strong>最小二乘法</strong>的原理（Least Square）来拟合求解这些隐向量。</p>
<p>前面讲到，矩阵里的每一个元素来自于两个隐向量的点积，我们就可以利用这一点来构造一个目标函数。这个目标函数其实就是说，这两个隐向量的点积一定要与我们观测到的矩阵数值相近。这里的“相近”是用这两个数值的误差，在这里也就是<strong>平方差</strong>（Square Error）来衡量的。误差越小，说明数据拟合得越好，隐向量也就更能表达用户和物品。</p>
<p>构造好了这个目标函数以后，我们就可以利用<strong>优化算法</strong>来求解这个目标函数。因为两个未知数点积的原因，这个目标函数没有一个全局的最优解，但是我们可以通过“<strong>梯度下降</strong>”（Gradient Descent）的方法找到一个不错的局部解（Local Minima）。</p>
<h2>小结</h2>
<p>今天我为你讲了推荐系统的一个重要分支，隐变量模型。我们讲了其中最重要的一个基本模型，矩阵分解。</p>
<p>一起来回顾下要点：第一，我们简要介绍了隐变量模型的基本原理；第二，我们详细介绍了矩阵分解作为隐变量模型的假设和原理；第三，我们简要地讨论了如何求解矩阵分解里的隐变量。</p>
<p>最后，给你留一个思考题，矩阵分解模型最大的问题是什么？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor64">062 | 基于隐变量的模型之二：基于回归的矩阵分解<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>本周我们主要来分享“矩阵分解”的点点滴滴，这是过去10年里推荐系统中最流行的一类模型。周一我们讨论了这类方法中最基础的基于隐变量的矩阵分解。这类模型的优势是显式地对用户和物品信息中的隐含结构进行建模，从而能够挖掘更加深层次的用户和物品关系。矩阵分解的流行起源于10年前的Netflix大赛，当时各类矩阵分解模型都在实际数据中起到了很好的效果。</p>
<p>今天我们要分享的模型，叫作“<strong>基于回归的隐变量模型</strong>”（Regression-based Latent Factor Model）。这是在基本矩阵分解的基础上衍生出来的一类模型。</p>
<h2>基本矩阵分解的问题</h2>
<p>我们先来看看基本矩阵分解模型的潜在问题。</p>
<p>首先，我们来回顾一下矩阵分解的基本表达。假设我们在对用户和物品的评分进行建模。对于每一个用户，用一个向量来表达其对于所有可能物品的评分，把所有用户的向量堆积起来，就可以得到一个矩阵。这个矩阵的每一行代表一个用户，每一列代表一个物品，每一个交叉的元素代表某一个用户对于某一个商品的评分。对于每一个用户和物品的隐向量都要少于原有的物品数目，因此，我们也说矩阵分解的模型实现了“降维”（降低建模维度）的目的。</p>
<p>虽然矩阵分解的模型对于挖掘用户和物品的内在联系有比较强的作用，但是这类模型的劣势也十分明显。</p>
<p><strong>第一，矩阵分解的矩阵仅仅是对用户和物品的喜好进行了“编码”</strong>（Encode）。我们之前在解释基于内容的推荐系统时说过，对于一个复杂的工业级推荐系统来说，有很多灵感或者直觉，都很难仅仅依赖用户和物品的喜好来捕捉到。有大量的信号，无法很好地被融合到这个矩阵分解的模式里。因此，矩阵分解虽然是不错的“独立”模型（Standalone），但在融合多种不同的推荐元素方面，表现却很一般。</p>
<!-- [[[read_end]]] -->
<p><strong>第二，矩阵分解的核心是学习用户的隐向量和物品的隐向量</strong>。原则上，这两类隐向量的学习仅能通过训练过程获得。</p>
<p>什么意思呢？就是说，如果在训练集合中有100个用户，200个物品，那么通过训练，我们可以学习到这100个用户和200个物品对应的隐向量，用于以后的预测或者排序。但我们无法获得新来用户或者新来物品的隐向量了，因为这些用户和物品并不在训练集里。</p>
<p>在推荐系统中，这种情况就叫作不能处理“冷启动”（Cold Start）问题，也就是不能处理“冷”用户和“冷”物品。这个特点是好是坏取决于具体的应用。但是，在有些应用的场景下，这是灾难性的一种特性。比如，新闻网站推荐文章，一般来说新闻文章滚动得都很快，随时随地都可能有新文章涌入，每过几天，整个网站的文章可能都被换掉，在这样的场景下，直接使用矩阵分解就会有问题。</p>
<p>矩阵分解的基本模型存在这两个问题，那有没有什么办法可以扩展矩阵分解的形式，改善在这两种情况下的处理呢？</p>
<h2>基于回归的矩阵分解</h2>
<p>基于回归的矩阵分解，其核心思路其实非常简单直观。矩阵分解不过是定义了一种从用户隐变量和物品隐变量到可以观测到的评分，这一显变量的产生过程。如果我们掌握了这么一个思路，那么，基于回归的矩阵分解就很容易理解了。</p>
<p><strong>首先，有一组用户特性和物品特性来表述每一个用户和物品</strong>。这些特性不是隐变量，是显式表达的特性。用户特性比如用户的年龄、性别、经常出现的地区、已经表达了喜好的类别等；物品特性比如物品的种类、描述等等。这两组显式的特性就是为了解决我们刚才说的第一个问题，矩阵分解无法抓住更多的信号。而在这里，我们明确定义这两组信号，一组来自于用户，一组来自于物品，希望能够通过这些信号抓住更多有价值的信息。</p>
<p>解决了这一步后，现在我们有两个独立的，看上去不相关的部分。一个是基于矩阵分解的部分，这一部分是分解一个已知的评分矩阵，从而学习到用户和物品的隐向量。另外一个部分，就是用户特性和物品特性，暂时还不知道如何与矩阵分解关联上。</p>
<p>基于回归的矩阵分解假定，用户的隐向量，其实是从用户的显式特性变换而来的。同理，物品的隐向量，其实是从物品的显式特性变换而来的。而这两种变换，本质上就是两个回归模型（Regression Model）。就是说，<strong>我们建立一个从显式特性到隐向量的回归模型，使得隐向量受到两方面的制约：从评分矩阵的分解得来的信息和从显式特性回归得来的信息</strong>。这样，我们就把这两部分信息嫁接到了一起。</p>
<p><strong>把这两部分信息嫁接到一起的好处就是，我们不再怕“冷启动”了</strong>。或者说，在有一部分“冷启动”的情况下，这样的模型可以处理得更好。原因就是我们使用了显示特性来回归隐向量。对于新用户和新物品而言，我们虽然没有直接得到他们的隐向量，但是有这些用户或者物品的显式特性，而这些显式特性可以帮助我们估计到新用户和新物品的隐向量，即使我们并没有它们的交互信息。这就是基于回归的矩阵分解的强大之处。</p>
<p><strong>我们还可以从贝叶斯的角度来理解基于回归的矩阵分解</strong>。把用户的隐向量和物品的隐向量看作是两个随机变量。我们可以认为这些随机变量加上了先验概率分布。只不过，这个先验概率分布的均值不是我们经常使用的0，而是一个以回归函数的结果为均值的高斯分布，这个回归函数就是我们由显式特性得到的。本质上，我们认为显示特性的某种变换成为了隐向量的先验信息。</p>
<h2>学习基于回归的矩阵分解</h2>
<p>基于回归的矩阵分解，其实就相当于我们定义了“<strong>层次的贝叶斯模型</strong>”（Hierarchical Bayesian Model）。模型的求解就变得更加复杂。</p>
<p>有一种学习这个模型的简单思路。第一，针对已知的用户和物品，先通过简单的矩阵分解学习到用户和物品的隐变量。在这个部分里，用户的显式信息并不参与学习。第二，学习好了这部分变量以后，再来学习从显式信息到隐变量的回归部分。这部分基本上可以当作线性回归。当然，用这种两个阶段的学习流程，并不能保证学习到的参数是最优的，这仅仅是一种简化的学习方法。</p>
<p>如果走比较正统的学习过程，这样的模型需要采用“<strong>期望最大化</strong>”（Expectation Maximization）的流程。也就是说，我们先用一组随机的参数来决定回归的部分，学习到最佳的隐向量，然后再根据隐向量更新回归部分的参数。因篇幅的原因我们就不展开细节了。不过，即便如此，我们也仅仅能够学习到一个局部解。</p>
<h2>小结</h2>
<p>今天我为你讲了隐变量模型中基于回归的矩阵分解。</p>
<p>一起来回顾下要点：第一，我们简要介绍了矩阵分解的一些问题；第二，我们详细介绍了基于回归的矩阵分解的基本思路，以及这样的模型如何解决了传统矩阵分解关于“冷启动”的难题；第三，我们简要地讲解了如何求解基于回归的矩阵分解里的参数。</p>
<p>最后，给你留一个思考题，基于回归的矩阵分解的短板是什么？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor65">063 | 基于隐变量的模型之三：分解机<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>周三我们分享了“基于回归的隐变量模型”，这是在基本的矩阵分解基础上衍生出来的一类模型。这种模型把显式特性和隐变量结合起来，对解决“冷启动”问题有一定作用。</p>
<p>今天，我们来介绍一种叫作“<strong><span class="orange">分解机</span></strong>”（Factorization Machines）的推荐技术。这个模型是从基于回归的隐变量模型中衍生出来的，已成为了主流的推荐模型。</p>
<h2>矩阵分解和基于回归的隐变量模型存在哪些问题？</h2>
<p>在介绍分解机的基本原理之前，我们先来回顾一下从“矩阵分解”到“基于回归的隐变量模型”的一个发展脉络。</p>
<p>首先，矩阵分解主要解决了两个问题，那就是从一个大矩阵降维到两个小矩阵，并且寄希望这两个小矩阵能够抓住用户和物品的相关度。</p>
<p>然而，单纯的矩阵分解无法融入很多用户和物品的特性，这就引导我们开发出了基于回归的矩阵分解。所谓的回归部分，也就是从显式特性出发，建立从显式特性到隐变量之间关系的流程，从而使我们能够把更多的信号放进模型中。</p>
<p>在一定程度上，基于回归的隐变量模型实现了把显式变量和隐变量结合的目的，但是这类模型的学习过程非常麻烦。实际上，因为这类模型复杂的训练流程，其在实际应用中并不常见。</p>
<p>那么，有没有其他思路来统一显式变量和隐变量的处理方式呢？</p>
<!-- [[[read_end]]] -->
<h2>分解机的基本原理</h2>
<p>分解机[1]是学者斯特芬·润顿（Steffen Rendle）在德国康斯坦扎大学任教期间开发出来的推荐模型。斯特芬后来加入谷歌，分解机是他的代表作品。</p>
<p>分解机结合了“基于内容的推荐系统”和“基于回归的隐变量模型”的一些基本思想。</p>
<p>基于内容的推荐系统，其核心就是认为需要预测的变量（这里我们依然讨论评分）是所有显式变量的一个回归结果。分解机直接借鉴了这一点，也就是说，分解机的输入是所有的显式变量。</p>
<p>实际上，分解机在对待显式变量的手法上更进了一步，那就是不仅直接对显式变量进行建模，还对显示变量的两两关系进行建模。当然，在原始的论文中，分解机其实还可以对更加高维的关系进行建模，我们这里局限在两两关系上。</p>
<p>什么意思呢？比如说我们有一个用户特性，是用户的年龄；我们有一个物品特性，是物品的种类。那么，普通的回归模型，就是把用户的年龄和物品的种类直接当作特性输入到模型中。而对于分解机来说，这只是第一步。</p>
<p><strong>第二步，分解机是把这两个特性的数值进行乘积，当作一个新的特性，然后进一步处理这种两两配对的关系</strong>。把原始特性进行两两配对是构建模型的一种重要的方法，特别是对于非深度学习模型，需要自己做特征工程的模型。</p>
<p>两两配对的特征有什么好处呢？好处就是可以对两种特性的交互信息进行建模。举个例子，如果我们特别在意某个年龄段的用户在某种商品类别中的评分，那么，把这两个特性相乘，从而抓取到这个交互信息，是一个非常有效的手段。</p>
<p>但是，两两配对存在什么问题吗？一个问题就是<strong>特性空间会急速增长</strong>。如果我们有一个100维的用户特性向量，然后有一个100维的物品特性向量，那对于两两配对的特征，就是100乘100这个数量级的。另一个更严重的问题就是，如果我们的单独特性中，有一些是“类别特性”（Categorical Feature），那么在两两配对之后就会产生大量的0，从而变成一个巨大的稀疏矩阵。</p>
<p>如何解决这个问题呢？<strong>分解机利用了矩阵分解的降维思路</strong>。就是说，我们不对一个稀疏矩阵直接建模，而是把这个稀疏矩阵分解之后再进行建模。具体到上面这个例子，就是先假定，所有特性都对应一个隐变量向量，两个显式特性的乘积是两个特性的隐变量的点积。也就是说，我们把两个显式特性的乘积分解为了两个向量的乘积。这样，我们就不需要直接表示原来的稀疏矩阵。</p>
<p>在这样的思路下，分解机成功地把隐变量和显式变量结合到了一起。当我们的显式特性仅仅是用户ID和物品ID的时候，分解机的表达退回了最原始的矩阵分解。也就是说，矩阵分解其实可以表达成为特性的两两作用矩阵的分解。</p>
<p>在原始的论文中，作者还用分解机模拟了好几种流行的模型，我们这里就不复述了。</p>
<p>虽然也是为了建立从显式特性到隐变量的关系，但是对比基于回归的矩阵分解而言，分解机的训练过程大大简化了。在实际应用中，我们经常使用“<strong>随机梯度下降</strong>”（SGD, Stochastic Gradient Descent）来对分解机直接进行求解。</p>
<p>在最近几年的Kaggle比赛中以及一些工业级的应用中，分解机凭借其简单易用的特点，成为了很多产品的核心算法。</p>
<h2>小结</h2>
<p>今天我为你讲了隐变量模型中分解机的基本原理。</p>
<p>一起来回顾下要点：第一，我们简要介绍了矩阵分解的一些问题；第二，我们详细介绍了分解机的基本原理；第三，我们简要讲了如何求解分解机。</p>
<p>最后，给你留一个思考题，分解机能够解决“冷启动”的问题吗？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p><span class="reference"><strong>参考文献</strong></span></p>
<p><span class="reference">1.  Steffen Rendle. Factorization Machines with libFM. ACM Trans. Intell. Syst. Technol. 3, 3, Article 57 (May 2012), 22 pages, 2012.</span></p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor66">064 | 高级推荐模型之一：张量分解模型<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>上周我们分享了推荐系统中矩阵分解的点点滴滴，简单复习一下讨论过的三个模型。</p>
<p>第一，“基于隐变量的矩阵分解”，其优势是显式地对用户和物品信息中的隐含结构进行建模，从而能够挖掘更加深层次的用户和物品关系。</p>
<p>第二，“基于回归的隐变量模型”，这是在基本的矩阵分解基础上衍生出来的一类模型。这种基于回归的矩阵分解模型把显式特性和隐变量结合起来，对解决“冷启动”问题有一定作用。</p>
<p>第三，“分解机”是由基于回归的隐变量模型衍生出来的，并且吸纳了基于信息的推荐系统的一些观点，成为了一种可以融合多种信息的强有力的工具。</p>
<p>这周，我们跟随着这个脚步，进一步来讨论一些比较高级的模型，看这些模型如何抓住更多的用户和物品之间的关系。</p>
<p>今天，我们先来聊一种叫作“<strong><span class="orange">张量分解</span></strong>”（Tensor Factorization）的模型。</p>
<h2>为什么需要张量分解</h2>
<p>在我们探讨张量分解的一些基本思想之前，先来看一看，推荐系统在什么场景下需要张量分解。</p>
<p>我们还是要从矩阵分解说起。矩阵分解的核心思想，是用矩阵这种数据结构来表达用户和物品的相互关系。这里，我们一般谈论的都是一些最简单的关系，例如评分、点击、购买等（本文我们依然只是讨论评分）。在这种二元的模式下，矩阵就是最好的表达用户和物品之间关系的数据结构。</p>
<p>然而，在真实的场景中，用户和物品的关系以及产生这种关系的周围环境是复杂的。一个矩阵并不能完全描述所有的变量。例如，用户对于某个物品的评分是发生在某个地点、某个时间段内的。这种所谓的“上下文关系”（Context）往往会对评分产生很大影响。遗憾的是，一个矩阵无法捕捉这样的上下文关系。</p>
<p>我们之前讨论过的“基于回归的矩阵分解”和“分解机”，本质上都是在某种程度上绕开这个问题。采用的方法就是，依然用矩阵来表达二元关系，但是把其他信息放进隐变量中，或者是采用基于信息的推荐系统的思路来得到相关信息的建模。</p>
<p>除了这种思路，还有没有别的方法，可以把上下文关系融入到对用户和物品的建模中去呢？</p>
<p>这时“张量”就该上场了。</p>
<p>从本质上来说，<strong>张量就是矩阵的推广</strong>。我们可以这么理解，<strong>矩阵是对二维关系建模的一种工具；而张量，就是对N维关系的一种建模</strong>。在二维关系中，用户和物品的评分是唯一能够被建模的变量；而到了N维关系中，理论上，我们可以对任意多种上下文关系进行建模。</p>
<p>比如，我们刚才提到的时间，就可以组成一个三维的张量，分别为用户、物品和时间。然后，在这个三维的张量中，每一个单元代表着某一个用户对于某一个物品在某一个时间段的评分。</p>
<h2>基于张量分解的推荐模型</h2>
<p>我们已经讲了张量的作用。那么，如何使用张量来进行推荐模型的建模呢？</p>
<p>我们还是用刚才所说的“用户、物品和时间”作为例子。在这个三维的张量里，每一个元素代表的是用户对于物品在某个时间段上的评分。那么，根据矩阵分解的思路，我们怎么来对这个张量进行分解呢？</p>
<p>遗憾的是，张量的分解要比矩阵分解更为复杂。与矩阵分解不同，张量分解至少有两种不同的形式，这两种形式会引导出不同的分解模型和算法。</p>
<p><strong>第一种分解模式叫 <span class="orange">CP分解</span></strong>（CANDECOMP/PARAFAC）。</p>
<p>拿我们刚才所说的三维张量来讲，CP分解是把一个三维张量分解为三个矩阵。具体来说，比如我们的三维张量是N维用户乘以M维的物品乘以R维的时间段。那么，分解出来的三个矩阵就分别为N维乘以K维的用户矩阵，M维乘以K维的物品矩阵，以及R维乘以K维的时间矩阵。这三个矩阵中的每一个向量都代表某一个用户、某一个物品和某一个时间段。K在这里是一个参数，类似于矩阵分解中的隐变量的维度，我们也就可以把这个K理解成为隐变量的维度。</p>
<p>那么在原始的三维张量中，某一个元素就是这三个矩阵的某三个向量对应元素乘积相加的结果。CP分解的一大好处就是，分解出来的三个矩阵的隐变量维度是一样的，这也就减少了需要调整的参数的个数。</p>
<p><strong>第二种分解模式叫作 <span class="orange">HOSVD分解</span></strong>（High Order Singular Value decomposition）。</p>
<!-- [[[read_end]]] -->
<p>这种分解和CP分解最大的不同就是分解出来的三个矩阵的维度不再一样。也就是说，在我们之前的例子中，用户矩阵的维度可以是N乘以A，物品矩阵的维度是M乘以B，时间段矩阵的维度是R乘以C。当然，这样就无法还原之前的N乘以M乘以R的三维张量了。</p>
<p>于是在技术上，还需要乘以一个A乘以B乘以C的小张量才能对原始数据进行复原。所以，通俗地讲，HOSVD分解就是把一个三维的张量，分解成为三个矩阵和一个更小的张量的乘积。</p>
<p>那HOSVD相比CP分解有什么好处呢？好处自然就是给不同的数据以不同的自由度，因为不再限制用户、物品和时间段都必须有一样的维度。但同时也带来了难点，那就是有了更多的“超参数”需要调整。</p>
<p>值得一提的是，我们仅仅是讲了讲张量分解的一个基本思路。在实际的运作中，还有一个重要的步骤，那就是<strong>设计目标函数</strong>，或者说是<strong>定义损失函数</strong>。在一般的分解过程中，我们可以定义“<strong>平方差</strong>”（Squared Loss），也就是原始数值和预测数值之间的平方差来作为损失函数，当然也可以使用其他的损失函数，这一点和矩阵分解是一样的。</p>
<h2>求解张量分解</h2>
<p>虽然张量是对矩阵的自然延伸，张量分解是矩阵分解的某种延伸，但是求解张量分解则是一个相对比较难的问题。</p>
<p>一种比较简单的模式依然是使用“<strong>随机梯度下降</strong>”法（<span class="orange">SGD</span>, Stochastic Gradient Descent），也就是把张量的分解问题看作是一个一般的优化问题。关于这种方法的细节我在这里不详细讲解了，感兴趣的话，建议阅读参考文献[1]，这是一篇很经典的论文，是第一次把张量分解使用在推荐系统中。</p>
<p>另外一种方法，也是在矩阵分解中可以使用的，叫作 <strong><span class="orange">ALS</span></strong>（Alternating Least Square）方法。这种方法则是在优化每一轮的时候，按住所有其他的矩阵变量不动，单独优化一个变量。举例来说，如果我们要优化用户矩阵，那么我们就按住物品矩阵和时间段矩阵不动，不去更新里面的参数，而仅仅更新用户矩阵里面的参数。同理，在下一轮的优化中，可以仅仅更新物品矩阵里的参数。这种方法也是行之有效的一种优化方法。</p>
<h2>小结</h2>
<p>今天我为你讲了推荐系统的一个高级模型：张量分解。张量分解模型主要用来对上下文的信息进行建模。</p>
<p>一起来回顾下要点：第一，我们简要介绍了为什么需要张量分解；第二，我们详细介绍了张量分解的基本原理；第三，我们简要地讨论了如果求解张量分解。</p>
<p>最后，给你留一个思考题，从概念上来看，用张量分解对上下文信息进行建模的最大问题是什么？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p><strong><span class="reference">参考文献</span></strong></p>
<p><span class="reference">1. Alexandros Karatzoglou, Xavier Amatriain, Linas Baltrunas, and Nuria Oliver. <a href="https://xamat.github.io/pubs/karatzoglu-recsys-2010.pdf">Multiverse recommendation: n-dimensional tensor factorization for context-aware collaborative filtering</a>. Proceedings of the fourth ACM conference on Recommender systems (RecSys '10). ACM, New York, NY, USA, 79-86, 2010.</span></p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor67">065 | 高级推荐模型之二：协同矩阵分解<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>周一我们讨论了“张量分解”模型。这种模型的特点是能够把不同的上下文当作新的维度，放进一个张量中进行建模。虽然张量分解是矩阵分解在概念上的一种直觉扩展，但其在现实建模的过程中有很大难度，最大的问题就是张量分解的求解过程相对比较复杂，不同的分解方法又带来不同的建模选择。</p>
<p>今天，我们来看另外一种思路，来解决融合多种渠道信息的问题，这就是<strong><span class="orange">协同矩阵分解</span></strong>（Collective Matrix Factorization）。</p>
<h2>为什么需要协同矩阵分解</h2>
<p>在解释什么是协同矩阵分解之前，我们先来看一看为什么需要这样一种思路。我们还是需要回到矩阵分解本身。</p>
<p>矩阵分解的核心就是通过矩阵，这个二维的数据结构，来对用户和物品的交互信息进行建模。因为其二维的属性，矩阵往往只能对用户的某一种交互信息直接进行建模，这就带来很大的局限性。</p>
<p>在之前的讨论中，我们看到了一系列不同的思路来对这样的基本结构进行扩展。</p>
<p><strong>思路一</strong>，就是通过建立显式变量和隐变量之间的回归关系，从而让矩阵分解的核心结构可以获得更多信息的帮助。</p>
<p><strong>思路二</strong>，则是采用分解机这样的集大成模型，从而把所有的特性，都融入到一个统一的模型中去。</p>
<p><strong>思路三</strong>，就是我们这周已经讲到的，利用张量，把二维的信息扩展到N维进行建模。</p>
<p>这些已有的思路都各有利弊，需要针对具体的情况来分析究竟什么样的模型最有效果。</p>
<p>然而在有一些应用中，除了用户和物品这样很明显的二元关系以外，还有其他也很明显的二元关系，如何把这些二元关系有效地组织起来，就变成了一个有挑战的任务。</p>
<p>什么意思呢？比如，我们是一个社交媒体的网站，既有用户对于物品（比如帖子）的交互信息，又有用户之间的互相连接信息（谁与谁是好友等）。那么，如何来显式地表达这两类不同的二元关系呢？</p>
<!-- [[[read_end]]] -->
<p>在前面的思路里面可以看到，我们似乎需要选择一个主要的关系来作为这个模型的基础框架，然后把其他的信息作为补充。在这样两类关系中，选择哪一个作为主要关系，哪一个作为补充关系，就显得有一点困难了。</p>
<p>更进一步说，对于用户与用户之间的建模，以及用户与物品之间的建模，我们其实会有不同的模型去构造。例如，用户与物品之间的评分，往往用整数来代表评分的数值，或者是用实数来代表喜好度。而用户与用户之间的友好关系，则往往是0或者1，象征是否有连接。因此，我们可能需要不同的模型对这些不同的数值进行建模。</p>
<p>这也就让研究人员想出了协同矩阵分解的思路。</p>
<h2>协同矩阵分解的基本思路</h2>
<p>协同矩阵分解的基本思路其实非常直观，那就是<strong>有多少种二元关系，就用多少个矩阵分解去建模这些关系</strong>。</p>
<p>用我们刚才所说的社交媒体的例子。如果我们有用户与用户的关系，用户与物品的关系，那我们就组织两个矩阵分解，分别来对这两种关系进行建模。最早对这个思想进行得比较完整的表述，我在文末列出了参考文献[1]。</p>
<p>这里的一个核心就是，如果两个没有关系的矩阵，各自做矩阵分解，那么分解出来的信息，一般来说，是没有任何关联的。</p>
<p>再来看刚才的例子，如果有一个用户与用户的矩阵需要分解，然后有一个用户与物品的矩阵需要分解。那从这两个矩阵分解中，我们分别可以得到至少两组不同的<strong>用户隐变量</strong>。一组是从用户与用户的关系而来，一组是从用户与物品的关系而来。这两组用户的隐变量是不一样的。同时，因为两个矩阵没有关联，所以无法达到我们希望这两种关系互相影响的效果。</p>
<p>要想在两个矩阵分解之间建立联系，我们必须有其他的<strong>假设</strong>。这里的其他假设就是，两组不同的用户隐变量其实是一样的。也就是说，我们假设，或者认定，<strong>用户隐变量在用户与用户的关系中，以及在用户与物品的关系中，是同一组用户隐变量在起作用</strong>。</p>
<p>这样，虽然表面上还是两个矩阵分解，但其实我们限定了其中某一部分参数的取值范围。说得直白一些，我们认定从两个矩阵分解出来的两组来自同一个因素（这里是用户）的隐变量是完全一样的。用更加学术的语言来说，这就是<strong>将两组矩阵分别投影到了相同的用户空间和物品空间</strong>。</p>
<p>这样做的好处，自然就是对于多种不同的关系来说，我们使用“<strong><span class="orange">相同隐变量</span></strong>”这样的假设，可以把这些关系都串联起来，然后减少了总的变量数目，同时也让各种关系互相影响。</p>
<p>那么，这样的假设有没有潜在的问题呢？</p>
<p>一个比较大的潜在问题就是，使用同样的一组隐变量去表达所有的同类关系，这样的假设存在一定的局限性。比如上面的例子，用同样一组用户隐变量去解释用户和用户之间的关系，同时也需要去解释用户和物品之间的关系，能够找到这样一组用户隐变量其实是有一定难度的。</p>
<p>而在实际应用中，不同关系的数据量会有很大的差距。比如，用户和物品关系的数据总量可能要比用户与用户的多。所以，由于用户和物品关系的数据多，两个矩阵分解用的同一组用户隐变量，很可能会更多地解释用户和物品的部分，从而造成了学到的隐变量未必能够真正表达所有的关系。</p>
<p>对于这样的情况，自然已经有一些学者想到了对策，我们今天就不在这里展开了。</p>
<p>最后，需要提一下，在协同矩阵分解的场景中，学习各个隐变量的参数的过程，和一般的单个矩阵分解相比，没有太多本质性的变化。最简单的学习过程，依然是利用<strong>随机梯度下降法</strong>（SGD, Stochastic Gradient Descent）去学习。只不过，每一个隐变量会存在于多个矩阵分解中，这在更新变量时增加了所需的计算量。</p>
<h2>小结</h2>
<p>今天我为你讲了推荐系统的另一个高级模型，协同矩阵分解，用来对不同类型的二元信息进行建模。</p>
<p>一起来回顾下要点：第一，我们简要介绍了为什么需要协同矩阵分解；第二，我们详细介绍了协同矩阵分解的原理、潜在问题和解法。</p>
<p>最后，给你留一个思考题，从概念上来看，协同矩阵分解和张量分解之间有怎样的关系？是不是所有的张量分解都可以化为多个协同矩阵分解呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p><strong><span class="reference">参考文献</span></strong></p>
<p><span class="reference">1.  Ajit P. Singh and Geoffrey J. Gordon. <a href="http://www.cs.cmu.edu/~ggordon/singh-gordon-kdd-factorization.pdf">Relational learning via collective matrix factorization</a>. Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining (KDD '08). ACM, New York, NY, USA, 650-658, 2008.</span></p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor68">066 | 高级推荐模型之三：优化复杂目标函数<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p><span class="orange"></span>周三我们讨论了协同矩阵分解，其主要思想就是解决多个两两关系的矩阵分解，并且希望能够建立隐变量之间的共享。</p>
<p>今天，我们来看一个稍微不一样的话题，那就是<strong><span class="orange">如何优化更加复杂的目标函数</span></strong>。</p>
<h2>为什么需要复杂的目标函数</h2>
<p>在介绍更复杂的目标函数之前，我们首先来回想一下，在之前的分享中，都接触到了哪些目标函数。</p>
<p>对于基于流行度或者相似度的推荐系统来说，其实并没有真正的目标函数的概念。这些推荐模型都是某种直观的“翻译”，这也导致了这些推荐系统很难直接使用在真实的应用中，往往是被当作特性用在其他模型中。</p>
<p>基于信息的推荐系统，本质上就是监督学习在推荐系统中的应用。因为是监督学习，那自然就需要目标函数。这里，经常是对点击率或者购买率进行建模，也就是说，经常使用<strong>二分分类的目标函数</strong>。</p>
<p>当我们使用矩阵分解的架构来对用户和物品的关系进行建模时，绝大多数情况下我们是在讨论<strong>评分</strong>。对于评分信息，常用的其实是<strong>线性回归</strong>（Linear Regression），也有学者使用<strong>泊松回归</strong>，因为泊松回归对于整数变量的建模要好于线性回归。当然了，矩阵分解也可以扩展到对点击率或者购买率的建模。</p>
<p>当年Netflix竞赛之后，Netflix公司把获奖的矩阵分解拿来进行实现，放入线上系统中，结果发现并没有本质性地提高推荐效果，这其实就和目标函数有关。虽然Netflix竞赛造就了矩阵分解等类似模型的流行，但是逐渐地，研究人员和工业界从业人员也意识到，<strong>用户对物品的评分，并不是推荐系统需要优化的目标，也就是说目标函数“选错了”</strong>。</p>
<p>那么，我们需要什么样的目标函数呢？</p>
<!-- [[[read_end]]] -->
<h2>高级目标函数</h2>
<p>直接对评分进行建模的最大问题，就是这和真实的推荐场景并不相符。不管是电商平台，还是新闻系统，我们并不是只在意用户对于某一些物品的评分。</p>
<p>真实的应用场景往往是这样的，用户打开应用，然后浏览一系列物品，由上往下进行翻阅，然后从中找到喜欢的物品。</p>
<p>这是不是很像我们在讨论搜索的时候，用户对于搜索结果的浏览？回忆一下，在搜索的场景中，我们首先输入关键字，然后搜索算法会返回一系列的结果。大多数情况下，我们会对返回的结果逐一检查。</p>
<p>在推荐场景下，我们虽然没有搜索关键词，但是整个从上往下的场景是类似的。</p>
<p>于是，我们就可以从搜索排序中得到启发，尝试对推荐结果进行排序。换句话说，我们并不在意用户的真实评分，或者我们是否能对用户和物品的喜好度进行完美估计，我们在意的是，<strong>能否把用户可能喜欢的物品排到前面去</strong>。</p>
<p><strong><span class="orange">把搜索系统中的排序思想利用到推荐系统中，是推荐系统的一个重大进步，这也让推荐系统和真实场景逐渐挂钩。</span></strong></p>
<p>那么，很直观的，要想更改推荐系统的行为，从评分的预测到排序学习，我们需要更改目标函数。</p>
<p>参考文献[1]中提出了一种叫<strong>BPR</strong>的方法，是把<strong>配对法</strong>引入到推荐系统中的一个重要工作。我们快速回忆一下已经在搜索系统中介绍过的“配对排序学习”。简单说来，配对法就是希望，对于某一个查询关键词来说，学习到每一对文档之间的关系，然后通过把所有的两两关系都预测正确，从而建立一个完整的排序结果。</p>
<p>很明显，在推荐系统的场景下，没有查询关键词，但是我们依然可以通过构造“<strong>会话</strong>”（Session）来学习排序。</p>
<p>简单来说，我们针对用户来到应用后产生的会话，对用户交互过的物品进行建模训练。我们期望能把有“正交互信息”的物品排到“负交互信息”的物品之前。</p>
<p>值得注意的是，和搜索不一样，推荐系统往往没有明确的反馈信息。意思就是，在搜索系统中，我们有已知的标签信息，也就是哪一个文档是“相关”的，哪一个是“不相关”的。然而，在推荐系统中我们并没有这样的信息。</p>
<p>因此，所有用户和物品的交互都是“<strong>隐回馈</strong>”（Implicit Feedback）。我们必须<strong>依靠假设来找到相关的物品</strong>。在这里，我们假定有正交互信息的物品是比其他物品更加相关。于是，正交互的物品的预测值要高。这里的“正交互”可以是点击、购买或者其他信息。这就是BPR的基本思路。</p>
<p>需要强调的一点是，BPR仅仅是一种思路框架，我们可以应用到矩阵分解中，以及基于信息的推荐系统等不同的模型中。我们可以把矩阵分解中的对于评分的目标函数换成基于BPR的目标函数，也就是进行配对法训练，得到的推荐系统能够更好地对物品进行排序。</p>
<p>有了这个思路，我们就可以打开一系列的想法了。比如，我们在前面的搜索模块中讲过，其实还可以直接优化类似NDCG、MAP这样的指标。那能不能把这些想法也搬运到推荐系统中去呢？</p>
<p>简单的回答是，能。但是这个流程也不是那么显然易见的，毕竟我们没有直接的标签信息，而且一般来说，这些目标函数本身就已经很难优化了，我们还要嫁接到矩阵分解或者是分解机等模型上，这就会让优化的难度继续攀升。今天我们就不展开讨论这部分内容了。</p>
<h2>小结</h2>
<p>今天我为你讲了推荐系统的另外一个问题，那就是目标函数。</p>
<p>一起来回顾下要点：第一，我们分析了为什么要关注目标函数，以评分为基础的目标函数的问题；第二，我们详细介绍了BPR这种非常经典的配对法的目标函数。</p>
<p>最后，给你留一个思考题，如果我们能够对所有物品的喜好度进行精准预测，是不是就不需要BPR了呢？学习排序和对物品喜好度的预测是完全不同的两件事，还是相互之间有联系呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p><strong><span class="reference">参考文献</span></strong></p>
<p><span class="reference">1.  Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. BPR: Bayesian personalized ranking from implicit feedback. Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence (UAI '09). AUAI Press, Arlington, Virginia, United States, 452-461, 2009.</span></p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor69">067 | 推荐的Exploit和Explore算法之一：EE算法综述<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>上周，我们聊了一些比较高级的模型，包括张量分解和协同矩阵分解，讨论这些模型如何能够抓住更多的用户和物品之间的关系。最后，我们还讨论了如何优化更加复杂的目标函数。</p>
<p>这周，我们来看一个完全不同的话题，那就是 <span class="orange">Exploitation</span>（利用）和 <span class="orange">Exploration</span>（探索）的策略，俗称“<strong><span class="orange">EE策略</span></strong>”。</p>
<p>一个推荐系统，如果片面优化用户的喜好，很可能导致千篇一律的推荐结果。其实，EE策略是推荐系统里很有意思，但也非常有争议的一个话题。一方面，大家都明白这类算法的目的，每年有很多相关论文发表。但另一方面，工业界对于部署这类算法非常谨慎，有的产品经理甚至视之为“洪水猛兽”。我们今天就来分析一下导致这个现象的一些因素。</p>
<h2>走一步看一步的策略</h2>
<p>这里再简单阐述一下什么是EE。简单来说，就是我们在优化某些目标函数的时候，从一个时间维度来看，当信息不足或者决策不确定性（Uncertainty）很大的时候，我们需要平衡两类决策：</p>
<ul>
<li>选择现在可能是最佳的方案；</li>
<li>选择现在不确定，但未来可能会有高收益的方案。</li>
</ul>
<p>在做这两类决策的过程中，我们也逐渐更新对所有决策不确定性的认识。最终，从时间的维度上来看，我们在不确定性的干扰下，依然能够去优化目标函数。</p>
<p>也就是说，<strong>EE可以看作是一个优化过程，需要多次迭代才能找到比较好的方案</strong>。</p>
<h2>EE的应用历史</h2>
<p>早期把EE应用于新闻推荐系统的文章，主要关注在雅虎的今日新闻（Today Module）这一产品上，这也基本上是EE最早在互联网应用的尝试，目的是为了优化点击率（CTR）。而更早的一些奠基性的文章，则是在广告的数据集上展示实验结果。</p>
<p>雅虎的今日新闻其实为EE提供了一些被很多学者和工业界人士忽视了的条件和成功因素。如果不考虑这些因素，鲁莽地在其他场景中使用这些文献中相似的算法，很可能会产生相当差的效果。那么是哪些因素呢？主要有两点。</p>
<!-- [[[read_end]]] -->
<ol>
<li>
<p><strong>相对少量的优质资源</strong>。今日新闻每天的内容池（Content Pool）其实并不大。这里面都是网站编辑精选了的大概100篇文章。这些文章原本的质量就非常高，无论是这里面的任何一组，用户体验都没有明显变差。内容池每天都人为更换。</p>
</li>
<li>
<p><strong>非常大的用户量</strong>。有亿万级的用户，最终可能是从算法随机产生的文章排序中选择了阅读的文章。因为用户数量巨大，所以算法就相对比较容易收敛（Converge）到稳定的方案，也就是前面讲的，优化CTR的状态。</p>
</li>
</ol>
<p>正因为有了以上两个因素，在这个模块上，工程师和科学家们享受了后来学者们所无法想象的“奢侈”，比如运行Epsilon-Greedy这种简单粗暴的EE算法；甚至是完全随机显示新闻，收集到了大量无偏（Unbiased）的数据，都为很多学术工作奠定了数据基础。时至今日，依然有不少后续学者，在今日新闻随机数据的基础上进行算法改进。</p>
<p>如果没有了这两条因素，最早的解决方案可能都没法在当时的雅虎施行。原因很简单，如果资源良莠不齐，资源数量非常大，那么在仅有的几个展示位置，优质资源显示的可能性在短期内就会比较小（因为系统对于大多数的资源还有很高的不确定性，需要Explore）。</p>
<p>由于优质资源显示得少了，用户就会明显感受到体验下降，最直接的可能就是倾向于不点击甚至放弃使用产品。用户不和系统交互这样的行为，又进一步减缓了系统学习资源不确定性的速度。这时，也许亿万级用户数都没法满足学习所有资源的用户数量（毕竟所有用户只有一部分会落入Exploration）。</p>
<p>关于这个解决方案有一个很有意思的点值得一提，在雅虎的研究人员跳槽到了LinkedIn以后，LinkedIn也推了相似的方案。为了模拟雅虎今日新闻的这些条件，就对用户内容流里的数据进行了大规模的过滤。这样就有少数的信息符合高质量的要求，并且能够在用户数允许的情况下探索到合适的解决方案。</p>
<h2>EE的产品部署难点</h2>
<p>我们来讲一下EE的产品部署难点，这些难点普遍高于具体的EE算法选择（比如选某一个UCB或者某一个Thompson Sampling）在产品工程解决方案上的抉择。</p>
<p>为了便于讨论，我们把所有EE算法整体叫作“Random”，简称“<strong>R算法</strong>”，而把不做EE的算法叫作“Deterministic”，简称“<strong>D算法</strong>”。这里面的假设是，D算法比较静态，能够产生高质量、一致性的内容。这里的一致性是指用户在短时间内的体验比较稳定，不会有大幅度的界面和内容变化。相反，整体来说，R算法的不确定性比较大，用户体验和产生的内容可能会有比较大的波动。</p>
<p><strong>第一个难点是如何上线测试</strong>。这看上去不应该是难点，但实际上需要格外小心。传统EE文献，只是把问题抽象为每一次访问需要做一个决策的选择。然而，文献却没有说，这些访问是否来自同一个用户。</p>
<p>那么，理论上，EE应该对所有的访问不加区别，不管其是否来自同一个用户。用我们这篇文章的术语来说，就是所有的流量都做R算法。虽然从理论上讲这样没有问题，但实际上，用户体验会有很大的差别。特别是一些推荐网站，用户希望自己前后两次对网站的访问保持一致性。如果不加区分地做R，对于同一个用户来说，很可能两次看见的内容完全迥异。这对用户熟悉产品界面，寻找喜爱的内容会产生非常大的障碍。</p>
<p>那么，我们对绝大部分用户做D，对另外一小部分用户做R，这样会好一些吗？这其实就是“牺牲”少部分用户体验，来换取绝大多数用户体验的一致性。这样实现也是最直观的，因为很多在线系统的A/B测试系统是根据用户来进行逻辑分割的。也就是说，某一部分用户会进入一个Bucket，而另一批用户会进入另外一个Bucket。按用户来做D &amp; R可以很容易和Bucket System一致起来，方便部署。当然，这样做也是有潜在风险的。那就是，这部分老做R的用户，在当了别人的小白鼠以后，很可能永远放弃使用产品。</p>
<p><strong>另外一个难点就是如何平衡产品</strong>。EE几乎是一定会导致用户对产品的体验下降，至少是在短期内会这样。如何弥补这一点，技术上其实比较困难。比如做过滤是一种思路，那就是只在优质内容里探索。当然，有人会说，这样其实也没有多大的意义。然而，一旦把质量的闸门打开了，那就会对用户体验带来很大的影响。</p>
<p>这也是很多产品经理对于EE非常谨慎的原因，能不做就不做。而且，牺牲了用户体验后，EE所带来的好处其实是很难评测的，这主要是由线上产品的评测机制和评测原理决定的。目前还没有比较统一的解决方案。</p>
<p>如何能够做到“用户友好型”的EE呢？这里面可以有两种思路。</p>
<p><strong>思路一，不是所有人群的所有访问都适合做R</strong>。和传统EE不同的是，做“<strong>反向EE</strong>”。也就是说，我们只针对常用产品的用户做探索，而并不是针对新用户或者是还没有那么熟悉系统的人群。这个思路和EE完全相反，但是更加人性化。</p>
<p><strong>思路二，夹带“私货”</strong>。也就是更改EE的算法，使得高质量的内容和低质量的内容能够相伴产生，并且高质量的内容更有几率排在前面。这样用户体验的损失是可控的。</p>
<p>其实，EE和产品的结合点应该是工程和研究的重点，但遗憾的是，碍于数据和其他方面的因素，这方面的研究工作几乎没有。</p>
<h2>小结</h2>
<p>今天我为你讲了推荐系统的一个重要的问题，就是如何持续挖掘用户可能的喜好，也就是做EE。</p>
<p>一起来回顾下要点：第一，我们讲解了什么是EE；第二，我们介绍了EE的一些简要历史；第三，我们讨论了EE的部署难点。</p>
<p>最后，给你留一个思考题，EE策略是不是一定会导致用户看到多样不同的东西呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor70">068 | 推荐的Exploit和Explore算法之二：UCB算法<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>这周，我们来讨论EE策略，周一介绍了EE的综合情况。今天来看一种最基本的思路，叫作 <strong><span class="orange">UCB（Upper Confidence Bound）算法</span></strong>。</p>
<h2>EG算法</h2>
<p>在介绍UCB算法之前，我们先来看一种更加简单的EE算法，叫 <strong>EG（Epsilon-Greedy）算法</strong>。</p>
<p>我们先来回顾一下EE的主要目的。EE的核心思想是说，我们对当前物品的估计往往是有限的、不准确的，需要不断尝试来增强对整个环境的了解，进而能够更加准确地对每个物品进行估计。</p>
<p>可以说，<strong>EG算法是最简单也是最基本的EE算法</strong>。EG算法的基本思路是这样的：既然我们当前对所有物品的估计是不完整的，那就可以随机地显示所有物品来获取数据。假设我们现在有一千个物品，我们对每个物品都需要估计一个数值，比如点击率。很显然，这个点击率的估计受以下两个因素的影响：已经显示了什么样的物品和显示的次数。那么，要想进一步提高这个估计值的准确度，EG算法认为我们必须对所有物品进行“探索”（Explore）。</p>
<p>具体来说，<strong>EG算法的流程是这样的：对于所有的物品，在概率P的情况下，按照当前的估计值来显示物品</strong>。回到刚才点击率的例子，那就是在概率P的情况下，谁的点击率高就显示谁。然后在概率1-P的情况下，随机地在所有物品中选择显示对象。如果我们从所有用户的角度来看，也就是说，P%的用户看到的是根据点击率排序的物品，而(1-P)%的用户看到的是随机的物品。</p>
<p>EG的想法是，虽然在最开始的时候，这种随机性可能会带来用户体验的下降，也就是那(1-P)%的用户会持续看到随机的内容，但是在牺牲这部分用户体验的情况下，随着时间的推移，慢慢地从整体上来看，对所有物品的估计会更加准确，P%的那部分用户的体验会增加。这也就是一种牺牲小部分用户体验来换取大部分用户体验的思路。</p>
<h2>UCB算法的核心思路</h2>
<p>我们刚才讲了EG算法的基本思路。很显然，<strong>EG有一个很大的问题，那就是有一个固定百分比的用户持续看到的都是随机的内容，这就太过于局限</strong>。</p>
<p>那么，我们能不能根据对物品的估计，来动态地调整显示物品的可能性呢？</p>
<!-- [[[read_end]]] -->
<p>回到我们刚才说的物品点击率预测的例子。一般来说，我们可以根据每个物品的显示记录来预测点击率。这个数值，其实是一个估计的“均值”。然而，这个估计可能是很不准确的，或者说，估计的置信度不高。</p>
<p>那么，<strong>如何来衡量一个物品的置信度呢</strong>？在统计中，一个比较好的方法，就是利用“<strong>标准差</strong>”（Standard Deviation）。从感性上来理解，标准差描述了数据的离散程度，也就是说，标准差其实是量化了数据在均值周围的分布情况。标准差小说明我们对这个数值的估计比较有信心，而标准差大则说明了不确定性大。</p>
<p>有了标准差的思路之后，我们再回到最初的问题，怎样才能动态地调整显示物品的可能性呢？我们沿着这个思路再稍微展开一下。很显然，我们需要考虑物品的当前估计，但同时也需要考虑这个估计的置信度。这个置信度告诉我们是不是需要更多地去“探索”这个物品。那么，很自然地，<strong>我们就可以同时用均值和标准差来表达对一个物品的整体估计</strong>，然后根据这个估计来排序显示物品。因为标准差已经表达了这种不确定因素，因此，我们的结果里面，不确定性特别大的物品，会被显示到前面来。</p>
<p>具体来说，<strong>UCB采用的数值是均值加上两倍的标准差来作为最终排序的实用数值</strong>。当然，不同类型的UCB算法在最终的数值上会有所偏差，但是大体思路基本相同。在这样的思路下，每一轮计算，我们都根据当前的数据计算出物品点击率的均值和当前的标准差，然后根据UCB的计算，我们再基于物品的数值，也就是刚才提到的均值加上两倍的标准差来排序。</p>
<p>在这样的一个机制下，经过多轮显示，当某个物品的数据越来越多的时候，标准差也会慢慢减小，最终UCB的数值会收敛到均值上。因此，<strong>这个算法本身其实是同时考虑了物品现在的情况以及在这种情况下的置信度，并且寄希望通过多次迭代来达到减小标准差，提高置信度的目的。</strong></p>
<h2>UCB算法的讨论</h2>
<p>UCB的方法一经提出，因为它的简单，并且有数学基础，马上备受学术界的关注。另外从概念上来说，UCB的确要比EG要好。EG有一个固定的群体需要忍受“探索”的不确定性结果；而UCB，这部分“牺牲”消失了。不仅如此，我们之前提到EG中有一个概率P，这个参数在UCB中也完全消失了。这个概率P是一个需要调整的参数，而且没人知道这个参数该怎么设置才是最优的。而在UCB中，每一个物品的“随机度”是不一样的，并没有一个全局的类似P这样的参数。</p>
<p>那是不是UCB就没有问题了呢？</p>
<p><strong>UCB的最大问题在于其对物品打分的机制，也就是均值加上两倍的标准差</strong>。这个机制听上去很合理，但在实际中，比如一些大型网站，会有上百上千甚至几百万的物品，那么，在没有任何特殊处理的情况下，对绝大多数物品的打分数值是相同的。什么意思？比如，很多物品从来没有被显示过，估计的均值就可能是0，或者是一个默认的初始值，在这样的情况下，物品的标准差自然也是一样的。那对于所有这些一样的物品，UCB本身并没有设计任何机制来加以区分。</p>
<p>这其实说明了一个问题，UCB算法本质上还是“确定性”（Deterministic）算法，也就是说并没有随机性。表面上通过标准差引入的不确定性其实是一种假象，这个算法从根本上还并不能真正做到随机探索。</p>
<h2>小结</h2>
<p>今天我们继续讨论推荐系统的一个重要问题，EE策略。我们介绍了一个很重要的算法，UCB算法。</p>
<p>一起来回顾下要点：第一，我们首先介绍了比UCB算法更加简单的EG算法；第二，我们介绍了UCB的核心思想；第三，我们讨论了UCB存在的一些问题。</p>
<p>最后，给你留一个思考题，如果有一大堆物品的UCB打分值是一样的，我们该如何解决这个问题呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor71">069 | 推荐的Exploit和Explore算法之三：汤普森采样算法<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>周三的分享里，我们讨论了一种叫作UCB（Upper Confidence Bound）的算法。这种算法的核心是使用均值和标准差组成对物品的估计，并且利用这种估计达到EE的效果。同时，我们也提到，UCB的最大问题就是并没有真正达到随机的效果。</p>
<p>今天，我们来看一种不太一样的算法，叫“<strong><span class="orange">汤普森采样</span></strong>”（Thompson Sampling）。</p>
<h2>为什么需要随机采样？</h2>
<p>在讨论汤普森采样之前，我们先来看一看什么是<strong>随机采样</strong>。随机采样的技术和概率分布密不可分，也和计算机产生随机数有很大的联系。</p>
<!-- [[[read_end]]] -->
<p>我们这里主要是关心如何从一个概率分布中产生一个随机变量的样本。因为是随机变量的样本，因此不可能每一次产生的结果都一样。然而，对于大量的样本来说，其均值往往是对概率分布均值的一个比较好的估计。因此，样本其实可以用来刻画一个概率分布。</p>
<p>比如，我们用参数是0.5的伯努利分布来表达抛硬币这个事件。那么，从这个伯努利分布中产生的样本，也就是0和1，象征了硬币是正面还是反面这两个事件。很显然，因为是随机样本，所以如果我们的抽样次数足够多，每个事件发生的概率会趋向于0.5。</p>
<p>然而，有一点需要注意，并不是所有的分布都能够这样容易地抽取样本。实际上，即便是伯努利分布，也是因为有一定的程序，才能够确定从中抽样。而能够抽样的，往往是标准的分布，诸如伯努利分布、高斯分布或者其他简单分布。从抽样的角度来说，对于绝大多数的模型，从中抽取样本都不是一件完全直观自然的事情。</p>
<p>回到我们讨论的场景。在进行EE策略中，为什么需要引入随机采样呢？</p>
<p>我们之前介绍过EG算法。EG算法在实施过程中，P%的人群看到按照点击率排序的物品。这一部分，是没有随机性的。也就是说这些人会“确定性”地看见按照点击率排序的物品，每一次都会看见一模一样的东西。而在(1-P)%的人群中，每一次看到的又完全是随机的内容，一点都没有规律。很明显，EG算法的缺点是，有一部分过于确定，而有一部分过于随机。</p>
<p>再来说一说我们上一次分享的UCB算法。这个算法最大的问题在于它是一个“确定”的算法。也就是说，在参数已经确定了的情况下，UCB展示给用户看的内容也是一样的。</p>
<p>这里面的一个核心问题是，如果展示给用户的内容是一样的，也就是我们说的确定性算法，那么，也就丧失了“探索”（Explore）的机会。试想，一个用户在同一天内访问一个网站多次，看到的结果都是一样的，而用户一定不希望每次访问都看到同样的内容。这对于用户体验来说很不友好。</p>
<p>那怎么才能带来随机性呢？</p>
<p>我们刚才谈了抛硬币的例子，很显然，如果能够通过采样来对物品进行排序或者展示，那就能够解决随机性的问题，也就能够每次都给用户不一样的体验。</p>
<h2>汤普森采样基本原理</h2>
<p>有了希望通过采样来获得结果这个思路以后，下面的事情就变得慢慢清晰起来。</p>
<p>首先，我们提到了，采样需要对应的概率分布。因此，<strong>第一步就是要构建场景的概率分布，来描绘我们的应用</strong>。</p>
<p>回到物品点击率的场景下，和抛硬币类似，物品的点击其实可以用<strong>伯努利分布</strong>来进行建模。这里需要注意的是，我们究竟应该从什么分布中去采样呢？汤普森采样的原理是，从模型的<strong>后验分布</strong>中去采样。什么意思？这其实是借用了贝叶斯统计的思路，也就是说，我们希望对参数的后验概率分布进行建模。关于贝叶斯统计的思路，这里限于篇幅不做展开。大体上来说，后验概率分布是在已经有了数据的情况下，结合我们的先验概率，对参数的一种估计。</p>
<p>再回到用伯努利分布来对点击进行建模的例子中，如果我们希望得到后验概率分布，需要设置怎样的先验概率分布呢？如果我们希望后验概率分布是一个相对比较简单的分布，那我们可以设置所谓的“<strong>共轭先验</strong>”（Conjugate Prior）。对于伯努利分布来说，共轭先验就是<strong>Beta分布</strong>。在设置了Beta分布这个先验之后，我们其实就可以解析得到后验概率的分布，也是一个Beta分布，只不过后验概率分布的参数与先验的参数不同。</p>
<p><strong>在构造好后验概率分布之后，我们就可以选择从中进行抽样了</strong>。注意，在当前的情况下，已经不是从伯努利分布中抽样，而是从Beta分布中抽样了。关于如何从Beta分布中抽样，这不在今天讨论的范畴。很多通用的数值计算库，比如MATLAB、NumPy等都有这方面的过程可以直接使用。</p>
<p>汤普森采样的流程是这样的，从后验分布中抽取一个参数的样本，然后选取所有物品中参数数值最大的那个，进行展示。</p>
<p>我们来分析一下汤普森采样的整体情况。</p>
<ol>
<li>
<p>每一轮，汤普森采样都有一个<strong>参数采样</strong>的动作。这个流程决定了汤普森采样本质上是一个随机的流程，不是一个确定的流程。</p>
</li>
<li>
<p>汤普森是从后验概率分布中进行抽样的。这有什么好处呢？后验概率分布中抽样，当样本数足够大的时候，样本的均值也是趋近于分布的均值的。什么意思？如果某一个物品的点击率高，那么其后验概率的均值也就大，反复从中抽样，平均下来，基本上还是在这个点击率的数值范围周边，不会偏离很远。也就是说，我们从后验概率分布中抽样的结果，当样本比较多的时候，是会尊重点击率的数值大小的。这其实就是EG中P%的用户，以及UCB中为什么要使用均值这些步骤的核心所在。我们并不希望让物品最后显示的结果与真正的估计值偏离太远。</p>
</li>
<li>
<p>汤普森采样因为使用了贝叶斯统计，我们对参数有先验的设置，因此针对当前点击率估计还不准确甚至还没有数据的物品来说，有天然的优势。</p>
</li>
<li>
<p>因为是采样，即便是在参数一样的情况下，两个物品的采样数值都有很大可能是不一样的，一举解决了我们之前提到的UCB的问题。</p>
</li>
</ol>
<h2>小结</h2>
<p>今天我为你介绍了一个很重要的算法叫作汤普森采样，可以解决UCB的“确定性”问题，真正实现随机的效果。结束了我们今天的分享，EE这个话题也就告一段落了。</p>
<p>一起来回顾下要点：第一，我们聊了聊为什么需要引入采样的机制；第二，我们介绍了汤普森采样的基本原理。</p>
<p>最后，给你留一个思考题，汤普森采样有没有什么问题，或者说有没有什么劣势呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor72">070 | 推荐系统评测之一：传统线下评测<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>上周我们讨论了EE算法，介绍了UCB（Upper Confidence Bound）算法和“汤普森采样”（Thompson Sampling）。</p>
<p>这周，我们回归到一个更加传统的话题，那就是<strong>如何评测推荐系统</strong>。这个话题非常重要，牵涉到如何持续对一个推荐系统进行评价，从而能够提高推荐系统的精度。</p>
<p>今天，我们先来看一看<strong><span class="orange">推荐系统的线下评测</span></strong>。</p>
<h2>基于评分的线下评测</h2>
<p>在过去10年里，随着Netflix大奖赛的举行，很多研究人员和工程人员往往把推荐系统的模型学习简化为对用户评分的一种估计。同时，在模型上面来说，对用户物品评分矩阵进行分解成为了一种主流的方法。</p>
<p>在这样的场景下，如何对模型进行评测呢？</p>
<p>一种简单且直观的办法，就是<strong>衡量评分的准确性</strong>，换句话说，也就是看我们预测的评分和真实评分之间有多大的差距。</p>
<p>那么，有哪些方法可以用来衡量两个数值之间的差异呢？</p>
<p>在机器学习中，一个经常使用的测度叫“<strong>均方差</strong>”（Mean Square Error），或<strong>MSE</strong>。有时候，我们也会使用它的根号后的结果，叫作“<strong>方差</strong>”（Rooted Mean Square Error），或<strong>RMSE</strong>。</p>
<p>MSE是这么定义的。首先，如果我们知道一个用户i和物品j的真实评分，假设叫$ Y_{ij} $ ，那么我们的一个估计值是$ Z_{ij} $，MSE计算的就是$ Y_{ij} $ 和$ Z_{ij} $的差值，然后取平方。平方以后的结果肯定是一个正数，也就是说这样做的好处是整个计算不会出现负数，我们的估计值比真实值小了或者大了，MSE都可以处理。当我们对于每一个用户和物品都计算了这个差值以后，再对所有的差值的平方取一个平均值，就得到了我们所要的MSE。</p>
<p>从计算上来讲，RMSE就是在MSE的基础上再取一个根号。我们在很多实际应用中，往往使用RMSE来汇报模型的评测结果。同时，RMSE也经常用在大多数的学术论文中，但这个评测有没有什么问题呢？</p>
<!-- [[[read_end]]] -->
<p>答案是，RMSE其实存在很多问题。</p>
<p>首先，我们从刚才描述的计算过程中就可以看到，RMSE需要取一个平均值。这是对所有用户在所有物品上评分误差的估计的平均。那么，如果一个用户在数据集里面对很多物品进行了评分，这个用户误差的贡献就会在最后的平均值里占很大一部分。也就是说，最后的差值大部分都用于描述这些评分比较多的用户了。</p>
<p>上述情况存在一个弊端，如果我们得到了一个比较好的RMSE数值，往往很可能是牺牲了大部分用户的评分结果，而对于少部分的高频用户的评分结果有提高。说得更加直白一些，<strong>那就是RMSE小的模型，并不代表整个推荐系统的质量得到了提高</strong>。这是RMSE很容易带来困惑的地方。</p>
<p><strong>RMSE的另外一个问题就是，这个指标并没有反应真实的应用场景</strong>。什么意思呢？真实的应用场景，我们往往是从一大堆物品中，选择出一个物品，然后进行交互。在这样的流程下，物品单独的评分其实并不是最重要的。更进一步说，就算一个推荐系统能够比较准确地预测评分，也不能证明这个推荐系统能够在真实的场景中表现优异。</p>
<h2>基于排序的线下评测</h2>
<p>当研究人员意识到RMSE的问题后，不少人就开始回归到问题的本质，<strong>究竟什么样的评测更能反应推荐系统在真实场景中的表现呢？</strong></p>
<p>很多人很自然地就想到了搜索。</p>
<p>我们来回忆一下，搜索的结果是根据某个查询关键字，然后搜索引擎返回一系列文档结果。在这样的场景中，如果我们来和推荐进行对比，就会发现，这里面最大的区别仅仅是有没有一个查询关键词。</p>
<p>所以，我们其实<strong>可以把搜索的一些指标“移植”到推荐中来使用</strong>。比如，我们在搜索中讲过的<strong>基于二元相关度的指标</strong>。下面简单回顾一下这个指标。</p>
<p>什么叫“二元相关度”呢？简单说来，就是指针对某一个查询关键字而言，整个测试集里的每一个文档都有一个要么“相关”，要么“不相关”的标签。在这样的情况下，不存在百分比的相关度。而每个文档针对不同的关键字，有不同的相关信息。假定某个系统针对某个关键字，从测试数据集中提取一定量的文档而不是返回所有文档，我们就可以根据这个提取的文档子集来定义一系列的指标。</p>
<p>有两个定义在“二元相关度”上的指标，成为了很多其他重要指标的基石。一个叫“<strong>精度</strong>”（Precision），也就是说，在提取了的文档中，究竟有多少是相关的。另一个叫“<strong>召回</strong>”（Recall），也就是说， 在所有相关的文档中，有多少是提取出来了的。</p>
<p>“精度”和“召回”的相同点在于，分子都是“既被提取出来又相关的文档数目”。这两个指标的不同之处则是他们的分母。“精度”的分母是所有提取了的文档数目，而“召回”的分母则是所有相关的文档数目。如果我们返回所有的文档，“精度”和“召回”都将成为1（也就是说，在这样的情况下是没有意义的）。因此，我们注意到，这两个指标其实都假定，提取的文档数目相比于全集而言是相对比较小的子集。</p>
<p>我们其实就<strong>可以利用“精度”和“召回”来评测推荐系统</strong>。</p>
<p>然而，这有一个问题，那就是对于搜索而言，相关度大多数时候是通过人工标注的，但这个对于推荐系统来说是不可能的。因为推荐的结果对于每个人来说都是不一样的，所以，没法针对所有人来进行统一的人工标注。</p>
<p>一种折中的办法，就是使用用户的回馈信息。在这里，因为我们需要二元信息，所以可以使用像用户的点击信息或者购买信息来作为二元的相关度。也就是说，如果用户点击了某个物品，那我们就认为是相关的，反之则是不相关。</p>
<p>顺着这个思路下去，其实我们就可以计算类似于<strong>NDCG</strong>等更加复杂的指标，只不过我们需要自己去定义相关信息。</p>
<p><strong>利用排序的思路来评测推荐系统，已经成为了目前推荐系统线下评测的一个标准指标</strong>。</p>
<h2>小结</h2>
<p>今天我为你讲了如何评测推荐系统的好坏，今天的重点是线下评测的两类指标。</p>
<p>一起来回顾下要点：第一，我们聊了聊非常通用的RMSE的评测方法，并且指出这类方法的缺陷；第二，我们介绍了怎么把搜索里的评测方法给移植到推荐中。</p>
<p>最后，给你留一个思考题，基于排序的评测有什么致命的问题吗？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor73">071 | 推荐系统评测之二：线上评测<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>周一，我们聊了推荐系统的线下评测。线下评测是任何系统能够不断演化的最直接的要求。在线下的环境中，我们能够开发出系统的种种改进，并且希望能够通过这些线下评测的手段来选择下一个更好的版本。</p>
<p>今天，我们来讨论<span class="orange">推荐系统的线上评测</span>。任何系统在开发之后最终都要放到线上拿给用户使用。那么，在线上评测的时候需要注意什么呢？</p>
<h2>线上评测的基础</h2>
<p>推荐系统线上评测的基础和我们之前讲过的搜索系统有很多类似的地方。</p>
<p>线上评测的核心就是<strong>在线可控实验</strong>，有时候又称作是在线实验，或者叫作在线A/B实验。我们希望能够利用在线实验来对推荐系统的某一个部分进行检验，看是否对用户和系统的交互产生影响。</p>
<p>在线可控实验其实是建立“<strong>因果联系</strong>”（Causal Relationship）的重要工具，也可以说是唯一完全可靠的工具。这里面的基础是统计的<strong>假设检验</strong>。</p>
<!-- [[[read_end]]] -->
<p>具体来说，就是我们针对访问网站或者应用的人群，进行某种划分，一般情况下是平均随机划分。50%的用户进入被划定的一个群组，叫作“控制组”（Control Bucket），而另外50%的用户进入另一个群组，叫作“对照组”（Treatment Bucket）。“控制组”和“对照组”的唯一区别在于所面对的系统。</p>
<p>假设我们有一个推荐系统，想对其中的某个部分进行改进。那么，可以保持住其他的部分，让这个希望得到改进的部分成为唯一的“<strong>独立变量</strong>”（Independent Variable），也就是在整个实验设置中的变量。这样，我们就希望通过在线实验以及假设检验的工具，来认定这个“独立变量”是否会带来系统性能上的提高或是降低。</p>
<p>这里面还有一个需要提前确定的，就是需要评测的指标，特别是用户指标，比如网站的点击率、搜索的数量等。这些指标我们称之为“<strong>依赖变量</strong>”（Dependent Variable）。说白了，<strong>我们就是希望能够在“独立变量”和“依赖变量”之间通过假设检验建立联系</strong>。今天在这里，我们就不重复假设检验的基础知识了，如果有兴趣深入了解，可以参考任意一本基础的统计教程。</p>
<p>对于在线可控实验，在概念上很容易理解，但在现实操作中有很多挑战。</p>
<p>首先，我们可以想一想，虽然理想状态下，我们可以把用户五五平分，进入“控制组”和“对照组”。然而，现实中，经过随机算法分流的用户群，在这两个群组中很可能并不呈现完全一样的状态。什么意思呢？举个通俗的例子，相比于“对照组”而言，“控制组”中可能存在更多的女性用户；或者是“对照组”中，可能存在更多来自北京的用户。</p>
<p>而在这样的情况下，“依赖变量”，比如网站点击率，在“控制组”和“对照组”的差别，就很难完全解释为“独立变量”之间的差别。也就是说，如果“控制组”下的点击率比“对照组”高，是因为我们更改系统的某部分的差别呢？还是因为这多出来的女性用户呢？还是女性用户和系统某些部分的交互产生一定复杂的综合结果导致的呢？这就比较难说清楚了。</p>
<p>当然，在现实中，如果说我们依然可以比较容易地通过算法来控制一两个额外的变量，使得在“控制组”和“对照组”里面这些变量的分布相当，那么，面对十几种重要变量（例如，年龄、性别、地域、收入层级等），要想完全做到两边的分布相当，难度很大。</p>
<p>另外一个难点是，即便能够做到对已知的变量通过随机算法，使得在两个群组中的分布相当，我们依然不能对当前还未知的变量进行上述操作。因此，现实中因为人群特性所带来的对结论的影响，是在线实验的难点之一。</p>
<p>在线实验的难点之二是，即便刨除刚才所提到的人群的差异以外，我们可能也很难在设想中的某个系统“控制组”和“对照组”中，确定唯一的“独立变量”。</p>
<p>在现代网站或者应用中，有很多服务、子系统、页面、模块在同时为整个网站服务。而这些服务、子系统、页面和模块，还有不同的前端系统和后端系统，很可能属于不同的产品以及工程团队。每个部分都希望能够做自己的可控实验，都希望自己改进的部分是唯一变化的“独立变量”。然而，我们从宏观的角度去看，如果每个部分都在做自己的实验，而我们做实验的基本单元依旧是每个用户的话，那这就很难保证用户之间的可比较性。</p>
<p>举个例子，如果用户U<sub>1</sub>，进入了首页的“控制组”，然后访问了购物篮推荐模块的“对照组”后离开了网站。而用户U<sub>2</sub>，直接访问了帮助页面的“对照组”，然后访问了购物篮推荐模块的“控制组”。那U<sub>1</sub>和U<sub>2</sub>两个用户最终产生的点击率的差别，就很难从他们访问网站页面的过程中得出结论。即便是在有大量数据的情况下，我们也很难真正去平衡用户在所有这些页面组别之间的关系。</p>
<p>实际上，如何能够有效地进行在线实验，包括实验设计、实验的评测等，都是非常前沿的研究课题。</p>
<h2>推荐系统线上评测</h2>
<p>在上次的分享中，我讲了过去比较流行的推荐系统线下评测的方法，比如利用MSE以及在此之上衍生出的RMSE。然后，我又讲了如何从排序的角度来对一个推荐系统进行衡量。</p>
<p>到线上评测以后，很明显，RMSE以及排序的一些相关指标，都不能完全反映用户是否对一个推荐系统产生好感。我这里讲几个通用的指标。</p>
<p><strong>第一，用户的驻留或者停留时间（Dwell Time）</strong>。这个指标主要是衡量用户在某一个物品上的停留时间。用户总的停留时间往往和用户对网站的黏稠度有很强的关系。总体说来，如果用户会长期反复访问网站，用户在网站平均驻留时间往往是比较多的。</p>
<p><strong>第二，用户在相邻两次访问中的间隔时间，有时叫作“空缺时间”（Absence Time）</strong>。这个指标是越短越好。当用户反复访问你的网站，并且空缺时间越来越短，证明用户越来越依赖你网站提供的服务。</p>
<p>停留时间和空缺时间都是很好的推荐系统线上评测的指标。</p>
<h2>小结</h2>
<p>今天我为你讲了推荐系统评测的线上评测。</p>
<p>一起来回顾下要点：第一，我们聊了聊推荐系统的在线实验；第二，我们介绍了几个推荐系统线上评测的通用指标。</p>
<p>最后，给你留一个思考题，如何知道用户对于推荐的内容已经越来越不满意了呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor74">072 | 推荐系统评测之三：无偏差估计<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>周三，我讲了推荐系统的线上评测，我们讨论了如何做在线评测，以及推荐系统在线评测可能遇到的一系列问题。</p>
<p>今天，我们来看一个比较高级的话题，那就是<span class="orange">如何做到推荐系统的无偏差估计</span>。</p>
<h2>推荐系统的偏差性</h2>
<p>在理解为什么需要无偏差估计之前，我们先来看一看现在系统为什么会存在偏差性，以及这种偏差性会对推荐系统的学习造成什么样的影响。</p>
<p>先假定我们讨论的是一个新闻推荐系统。为了方便，假设我们的系统中仅有两类文章，体育新闻和财经新闻。我们先来看一个极端情况，假设系统因为种种原因，只给用户推荐体育新闻，会出现什么样的情况呢？</p>
<!-- [[[read_end]]] -->
<p>很明显，如果我们只给用户看体育新闻，那么，用户只可能在这些体育新闻里面选择点击，压根不知道财经新闻的存在。因为用户只在体育新闻里面通过点击浏览表达了喜好，任何一个机器学习系统，只能在这些新闻里面学习到用户的喜好。</p>
<p>具体来说，用户已点击的新闻可以认为是正例，没有点击的可以认为是负例。这样可以对用户在体育新闻上面的喜好加以建模。但是很明显，系统在用户对财经新闻喜好的学习上是一筹莫展的，因为我们根本没有任何用户对于财经新闻的回馈数据。</p>
<p>这就是系统的偏差性。在这样的设置下，系统存在的偏差是无法修正的。通俗地讲，我们压根没有给财经新闻任何机会，所以没有数据可以供系统学习。</p>
<p>其实还有更加严重的情况。因为我们当前的系统仅仅学习到了用户对于体育新闻的喜好，然后如果把这个系统部署到生产中，系统又会进一步选择体育新闻给用户看，如此循环下去。这其实就是说，系统的偏差性会随着机器学习系统而反复循环，甚至有逐渐放大的可能性。</p>
<p>当然在现实的应用中，我们不可能有这么极端的情况。但可能面临更加复杂的情况，比如，我们压根不知道系统存在什么样的偏差，或者说，我们该如何面对各种不同的偏差。</p>
<p>在有偏差的系统中，先通过数据学习得到模型，然后再部署到系统中去，这个流程其实严重阻碍了我们对用户真实喜好的检测。因此，这也是线下表现和线上表现不一致的一个原因。长期以来，偏差性都是困扰研究者的一个非常重要的问题。</p>
<h2>无偏差估计</h2>
<p>当我们知道系统有偏差以后，怎么来解决这个问题呢？</p>
<p>一个很容易想到的策略是，如果我们知道系统的某种偏差，那能不能在后面的评测过程中矫正这种偏差呢？</p>
<p>这就涉及“<strong>矫正</strong>”的思路。回到我们所说的体育新闻和财经新闻的例子。假设我们的系统在80%的情况下会显示体育新闻，20%的情况下显示财经新闻。那么，当用户面对一篇体育新闻点击浏览，或者面对一篇财经新闻点击浏览，我们的系统该如何应对呢？</p>
<p>在我们已经提到过的传统评测手段中，例如计算MAP或者NDCG的时候，这两种点击是一样的。或者说，权重是一样的。然而，在这样的情况下，机器学习系统其实还是会更加偏重于学习到用户对于体育新闻的偏好，因为毕竟80%的情况下都是体育新闻。相对于财经新闻而言，这种情况就是处于劣势的，可能我们没有给财经新闻足够的机会。</p>
<p>所以，从矫正的角度来说，我们认为如果用户点击浏览了原本出现概率较低的文章，这个时候，我们反要给这类文章更大的权重。什么意思呢？也就是说，我们认为财经新闻出现的概率比较低，如果在这种情况下，用户点击浏览了财经新闻，那应该是真正的偏好。而相同的情况下，因为80%的新闻都是体育新闻，因此用户点击了其中的一篇也就不足为奇。</p>
<p>把这种思维放入到一种数学的表达中，也就是，我们希望用户的回馈按照出现的概率进行<strong>反比矫正</strong>，出现概率越大的物品，正样本权重越小；反之，出现概率越小的物品，正样本权重越大。具体来说，也就是正样本除以出现的概率，然后我们计算平均的加权点击率。这样加权平均后的结果，就是矫正后无偏差的点击率的计算结果。</p>
<p>很明显，无偏差估计是有一定假设的。首先，我们就需要假设收集的数据涵盖了整个数据集。什么意思？就是刚才我们说的极端情况，比如我们只显示体育新闻而压根一点都不显示财经新闻，这种情况是无法进行矫正的，因为在这种情况下，财经新闻的概率是0。也就是说，无论什么类别的新闻，都需要有非零的概率出现。这是进行无偏差估计的一个基本假设和要求。</p>
<p>遗憾的是，虽然这个要求看似容易，但其实在现实中很难真正做到。</p>
<p>试想一个有百万文章量的新闻网站，要确保所有的新闻都有一定概率显示给用户是有挑战的。在实际的应用中，大量的新闻质量是呈指数下降的。也就是说，虽然有百万甚至更多的文章量，但是很有可能只有几百几千的文章相对比较有质量，而剩下的大量文章是低质量的文章。</p>
<p>然而，我们并不能完全确定哪些是低质量文章。如果我们真的需要做无偏差的估计，就需要针对所有的文章进行显示，也就是说，我们需要冒着给用户显示低质量文章的风险，显然这并不是很好的策略。</p>
<p>在如何收集数据这一方面，无偏差估计其实和我们之前提到过的EE策略又结合在了一起。也就是说，如何既能够让我们尽可能地把所有数据都呈现给用户，使得我们可以进行无偏差估计，又能够照顾到用户的体验，这是目前非常热门的研究领域。</p>
<h2>小结</h2>
<p>今天我为你重点讲了什么是系统的偏差以及如何处理偏差的思路。</p>
<p>一起来回顾下要点：第一，我们聊了聊在线系统的偏差出现的场景以及机器学习为什么会让这样的情况恶化；第二，我介绍了如何进行无偏差估计以及无偏差估计所需的条件。</p>
<p>最后，给你留一个思考题，假如一个系统，你不知道每一种新闻出现的概率，你该如何做无偏差估计呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor75">073 | 现代推荐架构剖析之一：基于线下离线计算的推荐架构<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>上周，我们讨论了推荐系统的评测，聊了推荐系统的线下评测、线上评测和无偏差估计。至此，我们已经聊了推荐系统的一些基本技术和评测体系，相信你已对推荐系统有了一个基本的认识。</p>
<p>那么，到底该如何搭建一个工业级的推荐系统呢？这周，我们就来谈一谈<strong>现代推荐系统的架构体系</strong>，帮助你从宏观上对推荐系统的构建有一个更加完整的认识。</p>
<p>今天，我们先来看一看，<strong><span class="orange">基于线下离线计算的推荐架构</span></strong>。</p>
<h2>推荐架构需要解决的问题</h2>
<p>在讨论任何一种架构之前，我们首先来看一下这个架构需要解决什么样的问题。然后在这些问题的指引下，我们就可以来分析不同架构在解决这些问题上的优劣。</p>
<p>那么，对于一个推荐架构来说，我们需要解决什么样的问题呢？</p>
<p>首先，从大的角度来说，一个用户来到我们的网站或者服务，<strong>推荐系统最重要的一个任务就是，能够在一两百毫秒内给用户提供当前的推荐结果</strong>。也就是说，从用户的角度来看，<strong>推荐结果的呈现必须是实时的</strong>。这一条就是把工业级应用和学术模型区分开的一个重要指标。</p>
<p>在过去十多年里，学术界的推荐系统，或者是Kaggle竞赛的推荐系统，往往是一个使用了很多不同模型的<strong>集成模型</strong>（Ensemble Model），这种方式虽然在比赛和论文发表中能够取得较高的精度，但是在现实的系统中，如果不加修改直接使用，必然无法在规定的时间内，也就是一两百毫秒内产生所有的推荐结果。同样的，很多非常复杂的深度学习模型，也无法在规定的时间内产生所有的推荐结果。由此可见，很多推荐架构的核心就是在解决这些问题。</p>
<p>其次，<strong>推荐系统架构需要对用户和系统的交互结果做出响应</strong>。什么意思呢？如果用户看了推荐结果，并且点击了一些推荐结果，或者明确表达了对推荐结果的不喜爱，那么推荐模块需要对这些互动的结果给予回馈。试想，如果一个用户已经明确表示了对某些结果的不喜欢，然后在下一次访问的时候，用户又看到同样的推荐，那一定是一个非常不好的体验。</p>
<p>最后，<strong>推荐系统架构需要考虑用户群体的覆盖率的问题</strong>。如果一个系统架构只能为部分用户服务，这想必无法真正做到对一个网站或者服务产生影响力。因此，在模型以及其他的技术选择上面，如何能够做到“为更广阔的用户群体服务”，就是一个非常关键的因素。</p>
<h2>基于线下离线计算的架构</h2>
<p>刚才我们简单讨论了一个现代推荐系统架构需要满足的一些需求。那么，在这些需求的驱动下，一种简单易行的架构就诞生了，那就是“<strong>基于线下离线计算的架构</strong>”。</p>
<p>什么叫基于线下离线计算的架构呢？</p>
<!-- [[[read_end]]] -->
<p>试想一下，我们有一个推荐模块，是在一个网站首页为用户推荐新闻。现在假设，我们有M个用户，N个新闻文章。M的数量级可能是几千万，N的数量级可能是几百万。那么，理想状态下，需要用我们的模型，对每一个用户，以及每一个新闻进行打分。具体地，对于某一个用户来说，当这个用户访问网站的那一瞬间，我们需要对几百万的新闻进行打分，并且在一两百毫秒内返回结果，这很有可能是不现实的。</p>
<p>既然我们无法<strong>实时</strong>对所有的新闻打分，那么，退一步讲，我们能不能事先把这些打分的工作都做了，然后当用户来到网站的时候，我们仅仅是显示结果呢？答案是，可以的，并且<strong>这就是线下离线计算的核心思想</strong>。</p>
<p>通俗地说，<strong>线下离线计算的一个主要想法</strong>就是：把计算中复杂的步骤尽量提前做好，然后当用户来到网站需要呈现结果的时候，我们要么已经完成了所有的计算，要么还剩非常少的步骤，可以在很快的时间内，也就是所说的一两百毫秒内完成剩下的计算。</p>
<p>回到我们刚才的新闻推荐的例子。我们可以把针对每一个用户的所有新闻的打分，在线下都提前计算好，然后存放在一个数据库或者数据存储的地方，当用户来到网站的时候，我们只需要展示已经完全计算好的推荐结果。</p>
<p>完全线下离线计算的最大好处就是，当用户来临的时候，基本没有任何的计算成本。系统唯一需要做的就是从一个数据存储的地方直接取得当前的推荐结果。</p>
<p>也就是说，线下离线计算的最大好处，就是解决我们刚才说的在规定的时间内计算出推荐结果的需求。然而，线下离线计算对其他两个需求则无法很好地处理。</p>
<p>第一，因为我们是完全提前计算好了所有的结果，并且存储在数据库中。那么，假设用户和推荐结果进行了交互，希望更新推荐结果，离线计算的模式就无法支持这样的操作，或者是非常困难。</p>
<p>我们可以试想一下，如果一个用户不喜欢某一个新闻推荐结果，那么在当前的框架下，我们应该如何应对呢？首先，我们需要启用线下的计算流程，重新计算这个用户所有的推荐结果，然后把这个推荐结果存储到刚才说的数据库里，这样用户下一次来到网站的时候，就会看到更新的结果了。</p>
<p>因为刚才我们已经假设模型的复杂度导致无法很快地进行运算，因此，这个更新的流程可能会比较耗时。同时，这只是一个用户的情况，如果我们要针对大量用户进行这样的处理，那最省力的就是隔一段时间，比如说几个小时就针对那些和系统有交互的用户重新计算一次结果，然后再把更新的结果存入数据库。很明显，在这几个小时的间隙里，用户看到的依然是旧的推荐结果。</p>
<p>第二，完全提前计算好所有结果的情况下，针对新的用户，新的新闻文章就无法进行推荐了。针对这些新用户和新文章来说，完全离线计算这种架构就有一个致命的缺陷。当然，我们也可以依照刚才的思路，也就是说隔一段时间，比如几个小时，就针对当前所有用户和所有新闻，重新计算结果，然后把结果存放到数据库中，但是很明显，这也会导致在这个间歇期内，我们无法对新用户和新文章进行推荐。</p>
<p><strong>完全离线计算的推荐架构适用于一些简单的场景和一些应用的初期架构</strong>。很明显，在复杂的网站需求下，单靠提前把所有结果都计算好是不能满足动态的用户需求的。</p>
<p>然而，理解离线计算的需求对于构建复杂架构很有帮助。<strong>我们在设计一个更加复杂的架构时，依然会依靠很多离线计算，用线下时间来换取线上时间。这个思路是现代推荐系统架构中非常重要的一个想法。</strong></p>
<h2>小结</h2>
<p>今天我为你讲了一种简单的现代推荐系统的构建思路，那就是基于线下离线计算的推荐架构。</p>
<p>一起来回顾下要点：第一，我们聊了聊推荐架构的需求；第二，我们介绍了什么是离线计算架构，以及这种架构的优缺点是什么。</p>
<p>最后，给你留一个思考题，如果我们的用户数量和物品数量实在是太大，线下计算无法满足每天全部更新一次推荐，这种情况下，我们又该怎么办呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor76">074 | 现代推荐架构剖析之二：基于多层搜索架构的推荐系统<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>周一，我们讨论了基于线下离线计算的推荐架构，这也是最简单的一种推荐架构。我们了解了这种架构的优劣势，以及能够做的一些方案。</p>
<p>今天，我们来看另外一种也很常见的推荐系统架构，那就是<strong><span class="orange">基于多层搜索架构的推荐系统</span></strong>。</p>
<h2>推荐架构需要解决的问题</h2>
<p>周一我们详细讨论了推荐架构需要解决的问题，今天做一个简单的回顾。</p>
<p>推荐系统解决三个需求。</p>
<p>第一，推荐系统架构能够在一两百毫秒内给用户提供当前的推荐结果，即实时呈现推荐结果。</p>
<p>第二，推荐系统架构需要对用户和系统的交互结果做出响应。</p>
<p>第三，推荐系统架构需要考虑用户群体的覆盖率问题。</p>
<p>我们周一次讲到的基于离线计算的推荐架构，可以很好地解决第一个问题。解决思路就是先计算好所有的结果，然后存在某种存储空间里，当用户来到网站的时候，再直接显示事先已经计算好的结果。然而，这样的架构在第二和第三个需求面前，就显得有些捉襟见肘了。</p>
<h2>基于多层搜索架构的推荐系统</h2>
<p>我们前面在介绍搜索系统的时候，多次提到了<strong>多层搜索架构</strong>。一起来回顾一下这种架构。</p>
<p>首先，我们有一个索引，能够根据某些特性（比如关键字）来把所有的文档存储到里面，方便随时检索。</p>
<p>第一层或者叫第一轮打分，是发生在索引这个层面，我们通过一些简单的流程或者函数，往往是<strong>线性函数</strong>或者<strong>布尔值函数</strong>，来获取最相关的几百最多几千个文档。</p>
<p>紧接着，第二层或者叫第二轮打分，就是一个重排序的过程。这个时候，我们往往只需要针对几百个文档进行打分，所以可以使用相对比较复杂的函数，比如<strong>基于决策树的模型</strong>或者<strong>深度模型</strong>，以得到最终的结果。</p>
<p>有些时候，在第二轮打分之后，还有后面的轮数，主要是针对一些不同的商业规则，比如结果的多样性等等。</p>
<p>多层搜索架构可以支持搜索结果，自然地，对第一个需求，也就是在规定的时间内返回结果，有很好的支持。在搜索里面，用户输入查询关键词以后，大多数情况都希望能够快速得到结果。一般来说，我们把在所有文档里查找相关信息分解为两个步骤，先查找一个大概相关的集合，然后再在这个集合里进行重排序。特别是第一个步骤，往往是在索引上并行进行的，因此速度也相对比较快。</p>
<p>那么，多层搜索架构如何来解决第二和第三个需求呢？</p>
<!-- [[[read_end]]] -->
<p>我们先来看第二个需求，也就是说如何针对用户的反馈对结果进行更新。所谓进行更新，其实就是说，给用户的推荐结果，需要有一些不一样的地方。但是，如果我们仔细想一下这个需求，就会发现，第二个需求的核心是<strong>需要对用户的反馈进行更新</strong>，但也不能走向另外一个极端，那就是用户点击或者浏览了一两个物品后，整个推荐结果就全部发生了改变。因此，如果我们在这种<strong>需要变化但又不是大变的假设</strong>之下，多层搜索架构就能相对容易地解决这个问题。</p>
<p>例如，我们可以根据索引返回用户可能喜欢的一千个物品。假定用户的喜好不会在每一天内发生巨大变化。这个索引本身可以每天更新，但不需要更新得特别频繁。因为用户点击了一些物品，之后需要产生的更新变化，我们可以寄希望在重排序这个环节发生。也就是说，<strong>我们在每一天中，从索引中提取出来的内容都可以是一模一样的，但是我们可以根据重排序的部分产生不一样的结果，这样也就满足了用户的需求。</strong></p>
<p>具体来说，在重排序的阶段，有两种方法可以根据用户的反馈进行更新。</p>
<p><strong>一种方法，就是更新重排序阶段的模型</strong>。如果重排序阶段是一个决策树模型，那我们就对这个决策树进行重新训练。这里主要取决于重排序阶段是一个什么样的模型。如果这个模型需要所有用户的信息，那重新训练的计算量，无疑是非常大的，而且往往还无法在线完成。在这样的情况下，重新训练可能并不是最优的解决方案。</p>
<p><strong>另外一种方法，就是更新重排序的模型的某些特性</strong>。如果重排序模型使用了一些特性，其中包含记录了用户的一些行为。那么，我们其实可以在不更改模型的情况下，通过更新特性的数值来达到更新结果的目的。比如，可能有这么一个特性，记录用户在某个物品上点击了多少次，那么我们单单刷新这个特性的数值就可以了。</p>
<p>对于第三个需求，也就是说如何针对新用户和新物品进行支持。可以说，<strong>搜索架构对于新用户是天然支持的</strong>。因为索引里面是物品，而并不是特定的用户信息，所以新老用户对于这个以索引为基础的架构来说是一样的。不太相同的自然是新老用户的特性值是不一样的，因此取决于重排序的模型，很有可能是针对老用户有比较强的效果，而针对新用户则可能会有一些捉襟见肘。</p>
<p>相对来说，<strong>搜索架构的短板在于对新物品的支持</strong>。因为整个索引机制是基于物品的，因此当我们已经建立了一个当前的索引后，新的物品不在索引里面，因而无法在提取阶段被取出来。一个比较直接的方法自然是重新建立索引，然而如果我们有上百万的物品，重建索引并不是一个简单容易的步骤。关于如何支持这样一个功能，我们留到下一次分享中探讨。</p>
<h2>小结</h2>
<p>今天我为你讲了基于多层搜索架构的推荐系统。</p>
<p>一起来回顾下要点：第一，我们回顾了推荐架构的需求；第二，我们介绍了什么是多层搜索架构，以及这个架构是如何利用到推荐场景的，同时还聊了聊这种架构的优缺点是什么。</p>
<p>最后，给你留一个思考题，我们谈到了用索引来帮助推荐系统的构建，那么在搜索里面索引可以根据关键字来建立，在推荐系统中，我们怎么构建索引呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor77">075 | 现代推荐架构剖析之三：复杂现代推荐架构漫谈<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>本周我们讨论现代推荐系统的架构体系。周一我们看了最简单的基于线下离线计算的推荐架构，周三我们聊了基于多层搜索架构的推荐系统。</p>
<p>今天，我们来谈一谈如何从这两种架构的思路出发，来满足更加复杂多变的实际情况。</p>
<h2>推荐架构需要解决的问题</h2>
<p>这周我反复强调推荐系统的几个基本需求点。第一，能够在一两百毫秒内给用户提供当前的推荐结果；第二，需要对用户和系统的交互结果做出响应；第三，需要考虑用户群体的覆盖率问题。</p>
<p>接下来我们就聊一些经常考虑的场景，起到一个抛砖引玉的作用，供你参考。</p>
<h2>新用户的问题</h2>
<p>如果你要搭建的系统面临的情况是新用户多，比如一个新上线的快速增长的产品，那么我们需要怎么考虑架构呢？</p>
<!-- [[[read_end]]] -->
<p>这里面有<strong>两个基本思路</strong>。第一，我们要更加快速地抓住这些新用户和系统的交互信息，从而更好地为他们推荐信息。第二，在我们还没有足够多的信息的时候，如何为这些用户提供推荐结果。</p>
<p>我们先从第一点说起，如果希望能够更加快速地抓住用户的交互信息，从而很好地为他们推荐内容，有两种做法：要么能够快速更新模型从而更新推荐结果，要么快速更新特性从而更新推荐结果。</p>
<p>如果我们整个产品只有一个全局的排序模型的话，不管是基于线下的静态架构还是基于搜索的架构，基本上都不可能很快地去更新这个全局模型。因此，在这种情况下就需要去思考如何更新特性。</p>
<p>对于搜索的框架，也许我们可以通过更新特性，从而达到在重排序的这个阶段，因特性改变而带来不同的结果。但是对于线下的静态架构，因为所有推荐结果都是事先处理好的，因此改变特性也不能改变结果，除非针对这个用户，对所有的推荐结果重新进行线下计算。这样做是可行的，但是计算成本还是相对比较高。因此，综合来看，如果在新用户比较多的情况下，并且我们还希望抓住用户的交互，静态架构可能就会显得有一些心有余而力不足了。</p>
<p>第二点则是新用户的交互信息一开始会比较少，如何处理冷启动呢？我们前面提到过，其实冷启动可以利用一些用户的其他信息，比如年龄、性别、地理信息来产生推荐结果。我们可以为用户显示当前比较流行的在某个年龄段、某个性别、某个地理区域的信息。</p>
<p>一个简单的思路是，这些年龄、性别、地域的信息，可以每个小时或者每天更新一次，单独存放在一个数据库里。当用户来网站的时候，我们可以尝试从搜索的架构里提取信息，也从这个单独的数据库里提取信息，然后在这个基础上进行全部重新排序。这样我们就能够保证架构的统一性，同时也解决了冷启动的问题。</p>
<h2>新物品的问题</h2>
<p>和大量新用户问题不同的是，大量新物品的问题则更加棘手一些。</p>
<p>在静态框架下，新物品意味着对于所有的用户，我们之前都没有考虑过这些物品，因此如果不进行特殊处理，我们是绝对没法把这些物品展示给用户看的。</p>
<p>这里有两种思路。<strong>一种思路</strong>，就是把新物品加入到内容池里，对于所有用户，全部重新生成推荐结果。这当然是最简单的想法，但是很显然，这样做是非常耗时的。<strong>另外一种思路</strong>，我们把当天产生的新物品单独存储在一个数据库，针对这些物品给出一些预估计的分数。这里当然可以针对物品的特性打分，也可以随机给定一些分数。然后我们在显示推荐的时候，可以混合之前线下已经产生的推荐结果和当天的新物品结果，这样从用户的角度来看，我们是可以对新物品进行推荐的。</p>
<p>在搜索的架构下，也有<strong>两个类似的思路</strong>。第一，那就是我们对索引进行重索引，但这个过程相对比较耗时。第二，那就是对新物品构建一个临时索引或者数据库，最后的结果是从索引和当天的临时存储中共同获取，然后进行重新排序。</p>
<p>在新物品比较多，并且很快就会过时的情况下，另外一个需要注意的棘手问题就是，推荐的模型一定不能仅仅抓住用户喜爱的某一个物品。比如新闻推荐，用户喜欢某一个新闻，但是这个新闻很快就会过时。这就和商品推荐有很大不同，对于商品来说，用户可以反复购买同一件日用品。</p>
<h2>小结</h2>
<p>今天我为你讲了利用推荐系统的一个重要问题，就是如何构架一个现代推荐系统。我们聊了两个场景下的一些更加细致的取舍，分别是新用户多的情况和新物品多的情况。</p>
<p>其实，所有的这些思路都不是“死规矩”，但是有一些基本的规则你可以去琢磨。</p>
<p><strong>比如，我们尽可能把复杂的运算放在线下，因为毕竟需要在规定的时间内返回结果。在一切有可能的情况下，尽可能使用搜索引擎来减少需要对大量物品进行打分的步骤。再比如，对于活跃的用户，我们可以使用多层搜索架构；但是对于不活跃用户，我们可以依赖线下，提前产生所有的推荐结果。</strong></p>
<p>一起来回顾下要点：第一，我们再次回顾了推荐架构的需求；第二，我们通过两个场景，新用户多和新物品多，分析了架构里面的一些取舍。</p>
<p>最后，给你留一个思考题，假设我们的推荐系统需要给一个手机客户端的产品进行推荐，有什么和桌面端不一样的，需要在架构上额外注意的地方呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor78">076 | 基于深度学习的推荐模型之一：受限波兹曼机<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>这几周我们进入专栏里一个比较大的模块，那就是推荐系统。</p>
<p>上周，我们谈了现代推荐系统的架构体系，帮助你在宏观上对推荐系统的构建有一个更加完整的认识。这周，我们主要来看在推荐系统研究领域里一个比较前沿的话题，那就是<strong>如何利用深度学习来提升推荐系统的精度</strong>。</p>
<p>今天，我们首先来看一篇经典的文章《受限波兹曼机进行协同过滤》（<a href="https://www.cs.toronto.edu/~rsalakhu/papers/rbmcf.pdf">Restricted Boltzmann machines for collaborative filtering</a>）[1]，这篇文章尝试使用<strong><span class="orange">受限波兹曼机</span></strong>（Restricted Boltzmann Machines），简称 <strong><span class="orange">RBM</span></strong>，来对推荐系统进行建模。这应该是最早把深度学习应用到推荐建模的典范。</p>
<h2>受限波兹曼机（RBM）</h2>
<p>从严格意义上讲，RBM自身并不是深度模型，在早期对于RBM的使用上，也并没有将其“累加”到很多层从而形成“深度RBM”（Deep RBM）。但是从建模思路上来说，由一层RBM到多层RBM的扩展其实是非常直接的，因此了解RBM的基本思路，对后面理解推荐系统中如何利用深度学习模型进行建模是很有帮助的。</p>
<p>今天我们要介绍的文章发表于2007年的ICML（International Conference on Machine Learning，国际机器学习大会）上。作者群是鲁斯兰·萨拉胡特蒂诺夫（Ruslan Salakhutdinov）、安德烈·尼哈（ Andriy Mnih）以及杰弗里·辛顿（Geoffrey Hinton）。</p>
<p>辛顿在近日常常被称作深度学习之父。他不仅算是波兹曼机（Boltzmann Machines）的重要发明人和推动者之一，也和其学生一起把RBM应用到各类数据上，比如RBM在推荐领域的尝试。</p>
<p>2007年的时候，Netflix大赛如火如荼，很多学者都希望把各种模型和思路应用到这个比赛中。而在这个大赛中，有三个重要的思想脱颖而出，影响了后来推荐系统的研究发展。这三个思想分别是：</p>
<ol>
<li>
<p>基于矩阵分解的模型；</p>
</li>
<li>
<p>基于RBM的模型；</p>
</li>
<li>
<p>利用集成学习（Ensemble Learning）把大量不同的模型整合起来。</p>
</li>
</ol>
<p>由此可见，RBM对于推荐系统的尝试在当时是非常有新意的。</p>
<p>第一作者鲁斯兰当时在多伦多大学攻读计算机博士，跟随辛顿研究深度学习模型。另外一篇他当时做的工作，是把贝叶斯矩阵分解利用到Netflix大赛中，和我们今天讨论的这篇论文一起，都是他在博士阶段对于推荐系统这个领域所做的重要贡献。目前鲁斯兰在卡内基梅隆大学任教，并兼任苹果公司的人工智能总监一职。</p>
<p>那什么是RBM呢？简单说来，RBM就是由一层<strong>隐单元</strong>（Hidden Unit）和一层<strong>显单元</strong>（Visible Unit）组成的神经网络结构。通常情况下，显单元和隐单元这两层之间是完全连通的。也就是说，对于每一个显单元来说，它都和所有的隐单元联系到一起。</p>
<p><strong>每个隐单元和显单元自身都有一个权重（Weight），并且在每对隐单元和显单元之间的连接上还有一个权重</strong>。所有这些权重都是需要通过训练学习的未知参数。举例来说，如果我们有3个显单元（用于描述3个数据点），5个隐单元。那么我们就有3个权重对应3个显单元，有5个权重对应5个隐单元，然后有15（3*5）个连接权重，这样算下来一共是23个权重。RBM可以针对高斯信号，也就是实数信息，以及伯努利或者二项分布（Binomial Distribution）信号，也就是离散信息，进行建模。</p>
<h2>受限波兹曼机在推荐上的应用</h2>
<p>当我们对RBM有了一个基本的了解之后，我们来看RBM是怎么应用到推荐系统上的。为了讲解方便，我们这里使用Netflix的例子，也就是对“用户为电影打分”进行建模。</p>
<!-- [[[read_end]]] -->
<p>首先，对于每一个用户，我们使用一个单独的RBM来对这个用户进行建模，只不过，每一个RBM都有一样的隐单元数量。在建模的时候，每一个RBM仅仅对当前这个用户曾经打过分的数据进行建模。也就是说，每一个RBM需要建模的数据是不一样的，有的用户对三个电影打过分，有的对十个电影打过分。你可以设想一下，在这样的情况下，整个模型是什么意思。</p>
<p>每个用户有一个独立的RBM，这个RBM负责对这个用户的电影集合进行建模。很显然，这些RBM互相没有关联。那怎么把每个用户的RBM给联系起来呢？作者们做了这样的假设，也就是每个RBM的隐单元是不一样的，这其实可以代表学习到的“用户的偏好”。但是，如果两个用户都对同一个电影打过分，那么，针对这个电影，两个不同的RBM会共享一样的权重。这就是联系两个RBM的核心思想，也就是说，<strong>利用RBM对用户电影推荐的核心是“共享相同电影的权重”</strong>。</p>
<p>具体说来，每一个显单元都是用户对于某个电影的评价。这里每个显单元都是一个K维的数组，其中只有一个元素是1，其他都是0。这种<strong>二元的数组表达</strong>，帮助模型来对“用户对于有K种可能的输出”进行建模。隐单元在这篇论文中，也是二元的，只不过，我们事先并不知道隐单元的取值。和刚才介绍的一样，在这样的模型里，需要学习的参数包括显单元的权重、隐单元的权重以及他们之间关系的权重，同一个电影的权重是共享的。</p>
<p>每一个用户都有一个单独的RBM，并且我们在RBM里只对已经评过分的电影进行了建模，因此这个模型并不能直接对未知的电影评分进行预测。需要预测的时候，我们其实是先拿到这个电影的权重，然后看，我们把那个K维的评分数组设置成哪种情况的时候，产生的概率是最大的。也就是说，我们尝试把对于未知的电影评分设置成不同情况，取出现可能性最大的那种评分作为预测结果。很明显，这样做的计算效率并不高。文章中也介绍了如何加速，我们这里就不复述了。</p>
<p><strong>RBM对于推荐系统的建模看上去很简单，但是难点却是如何学习这些未知的权重</strong>。总体说来，RBM无法直接使用类似“最大似然法”或者“递归下降”的方法来对参数进行学习。这其实也是阻碍这类方法广泛使用的一个重要障碍。在最初的论文里，作者们提出了一种CD（Contrastive Divergence，对比散度）方法，这种方法其实是一种简化的MCMC（Markov chain Monte Carlo，马尔科夫蒙特卡洛）方法，用于对RBM进行采样。CD方法具体是如何实现的，我们这里就不展开了。</p>
<p>在Netflix的数据集上，RBM展现了惊人的效果，不仅能够很轻松地击败Netflix自身的算法基线，还比当时提出的单纯的矩阵分解方法要更加优秀。基于此，后来就有了很多RBM的扩展工作。</p>
<h2>小结</h2>
<p>这周我来为你讲解利用推荐系统的一个重要的问题，就是如何利用深度学习模型来对推荐系统进行建模。今天我们聊了一个最基本的深度学习模型，受限波兹曼机，讨论了如何将其应用在推荐系统中。</p>
<p>一起来回顾下要点：第一，我们介绍了什么是受限波兹曼机；第二，我们讨论了如何把受限波兹曼机应用到推荐场景中。</p>
<p>最后，给你留一个思考题，如果希望在受限波兹曼机里增加其他信息，比如各种用户信息或者电影信息，我们该如何做呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p><strong><span class="reference">参考文献</span></strong></p>
<p><span class="reference">1. Ruslan Salakhutdinov, Andriy Mnih, and Geoffrey Hinton. <em>Restricted Boltzmann machines for collaborative filtering</em>. Proceedings of the 24th international conference on Machine learning (ICML '07), Zoubin Ghahramani (Ed.). ACM, New York, NY, USA, 791-798, 2007.</span></p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor79">077 | 基于深度学习的推荐模型之二：基于RNN的推荐系统<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>周一我们看了一篇经典的文章，那就是尝试使用受限波兹曼机（RBM）来对推荐系统建模。这应该是最早把深度学习应用到推荐建模的典范。当然，RBM虽然算是相对比较早的深度学习模型，但其本质上并没有很多后来提出的深度模型的特质，也没有真正发挥出深度学习模型的特有优势。</p>
<p>今天，我们结合几篇论文来看一类深度学习模型，那就是“<strong><span class="orange">递归神经网络</span></strong>”（Recurrent Neural Network），简称 <strong><span class="orange">RNN</span></strong>，在推荐系统中的应用。这类模型可以解决传统推荐模型中难以对时序信息进行建模的问题，扩宽了推荐系统的应用边界。</p>
<h2>时序信息建模</h2>
<p>要想说清楚RNN对于推荐系统的贡献，我们首先要来看一看为什么需要对时序信息进行建模。</p>
<p>在我们前面介绍的诸多推荐模型中，不管是矩阵分解，还是简单的基于流行度的推荐模型，或是其他更加复杂的张量分解等模型，其实都没有内置“时间”这个概念。</p>
<p>比方说，我们通过矩阵分解来对用户和物品的评分进行建模。在这个建模的场景里，用户物品评分矩阵是针对所有数据的，不管是用户昨天对某个物品进行评分还是今天，甚至是一年以前，所有数据都是在唯一一个矩阵里面加以表示。这么做的好处是，极大地简化了真实情况，不好的地方则是完全忽略了所有评分在时间上的发展。</p>
<p>其实早在Netflix大赛中，一些学者就在Netflix公布的数据集上发现，用户对于电影的喜爱程度，或者说评分数值，有非常明显的随时间变化而变化的趋势。文末我列的参考文献[1]，这篇论文就是充分挖掘了时间信息从而带来了性能上的提升，如果你有兴趣的话，建议读一读这篇文章。</p>
<p>在深度学习模型，特别是RNN之前，如果我们希望对时间进行建模，从模型工具的角度上来说，我们都有哪些选择呢？</p>
<p><strong>一种办法是可以尝试使用传统的“时序模型”（Time Series Models）</strong>。这一类模型在统计领域已经使用了较长时间，然而最大的问题就是，很多工具很难直接和我们提到的这些推荐模型进行嫁接。另外一个难点是在嫁接之后，模型的训练算法往往会变得异常复杂，这也给模型的普及和使用带来了很多障碍。</p>
<p><strong>另外一种办法，就是尝试在现有的模型里通过特性（Feature）或者其他的方法，来让当前的模型能够对时间信息进行建模</strong>。这个思路其实是对矩阵分解进行了修改。这样做的好处就是可以根据自己的需要在某一个模型上进行必要的更改，然而这么做的先天性缺陷就在于提出来的修改往往只能针对某一个模型，而没有办法扩展到其他模型。</p>
<p><strong>第三种做法是可以利用张量分解（Tensor Factorization）</strong>。我们直接把时间作为一个新的维度，因此可以对用户在某一个时间段对某个物品的评分进行建模，有一些工作是基于这个假设的。</p>
<p>不过，直接利用张量分解的最大问题是，张量本身并不是时序模型，利用张量对时序信息进行建模仅仅是因为时序信息大多时候可以被表达成为离散的数据，因此张量才在这里有了用武之地。然而，因为张量无法直接对离散时序的两位数据点之间进行约束建模，比如时间点“昨天”和时间点“今天”可能在张量中占据两个不同的数据点，但是张量本身并不能把这两个数据点联系起来。也就是说，张量在“语义”（Semantics）上其实并不支持时序数据。</p>
<p>基于以上这些原因，我们需要有新的工具来对时序信息进行比较直接的建模，同时也能有相对容易的学习算法。</p>
<!-- [[[read_end]]] -->
<h2>基于RNN的推荐模型</h2>
<p>RNN作为深度学习中有力的时序信息建模工具，随着深度学习的火热，被越来越多的学者用来解决我们刚才所说的这些问题。我们一起来看两篇论文，可以说这两篇文章是RNN在推荐领域应用的重要参考。</p>
<p>除了从工具的角度来讲为什么需要RNN以外，还有一个是从实际的场景出发，也就是在同一个“<strong>会话</strong>”（Session）中的推荐结果，这是一个比较突出的需要时序信息的场景，且传统的方法无法很好地解决。</p>
<p>在这方面比较早的尝试，来自于在ICLR2016上发表的一篇论文《使用递归神经网络的基于会话的推荐》（Session-based recommendations with recurrent neural networks）[2]。这里面的基本思路其实很直观，就是在推荐系统中使用某种RNN模型，在这篇论文里使用的是 <strong>GRU</strong>（Gated Recurrent Unit）。我们在这里不展开RNN或者GRU的定义细节以及这些模型里面的特征。我们从比较高的维度来讲一讲RNN的建模思路。</p>
<p>RNN的输入是当前的一个物品，然后RNN需要输出的是对于下一个物品的预测，同时为了能够对这些在时间序列上的物品进行建模，RNN内部也要维持一个隐含的状态序列，这个状态序列会随着时间的变化而变化。不同的RNN模型在以下内容的实现上有所不同，包括如何实现这个隐含的状态序列，以及如何对从状态序列到输入和输出物品的建模。</p>
<p>总的来说，这篇论文就是直接把目前在自然语言处理中经常使用的GRU拿到了推荐领域，并且做了一些微小的修改。从实验结果来看，如果我们对会话进行建模的话，效果要明显好于没有对会话进行建模。</p>
<p>再介绍一个比单对会话进行建模更进一步的工作，是发表于WSDM2017上的一篇论文《递归推荐网络》（Recurrent Recommender Networks）[3]。我们前面提到了，矩阵分解的最大问题就是学习到的用户以及物品向量无法囊括时间的信息。在这篇论文里，作者们假定用户的隐向量，物品的隐向量都会随着时间的变化而变化，而在某一个时刻的物品评分仅仅是那一个时刻的用户隐向量和物品隐向量的一个结合。在传统的模型里，要描述这种隐向量随着时间的变化而变化的思路就会充满难度。</p>
<p>在这篇论文里，一个重要的贡献就是使用了一种叫 <strong>LSTM</strong>（Long Short-Term Memory）的RNN模型，来对这些用户的隐变量随着时间的变化而变化进行建模。我们在这里也不展开LSTM的基本定义。总体来说，LSTM也是对某一组输入变量和输出变量在时间上的关系进行建模，同时利用内部隐状态序列来对输入和输出变量进行建模。</p>
<h2>小结</h2>
<p>今天我们聊了如何利用RNN对推荐系统中的时序信息进行建模。</p>
<p>一起来回顾下要点：第一，我们讨论了为什么对时序信息建模是非常必要的；第二，我们结合两篇论文，聊了利用RNN对时序信息建模的例子。</p>
<p>最后，给你留一个思考题，除了会话信息或者用户的喜好是比较明显的时序信息以外，推荐系统中还有哪些时序信息的应用呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p><strong><span class="reference">参考文献</span></strong></p>
<p><span class="reference">1. Yehuda Koren. <em><a href="http://courses.ischool.berkeley.edu/i290-dm/s11/SECURE/a1-koren.pdf">Factor in the neighbors: Scalable and accurate collaborative filtering</a></em>. ACM Trans. Knowl. Discov. Data 4, 1, Article 1 (January 2010), 24 pages, 2010.</span></p>
<p><span class="reference">2. Bal´azs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. <em><a href="https://arxiv.org/pdf/1511.06939.pdf">Session-based recommendations with recurrent neural networks</a></em>. International Conference on Learning Representations (2016), 2016.</span></p>
<p><span class="reference">3. Chao-Yuan Wu, Amr Ahmed, Alex Beutel, Alexander J. Smola, and How Jing. <em><a href="http://alexbeutel.com/papers/rrn_wsdm2017.pdf">Recurrent Recommender Networks</a></em>. Proceedings of the Tenth ACM International Conference on Web Search and Data Mining (WSDM '17). ACM, New York, NY, USA, 495-503, 2017.</span></p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor80">078 | 基于深度学习的推荐模型之三：利用深度学习来扩展推荐系统<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>这周，我们主要讨论如何利用深度学习来提升推荐系统的精度。我们分别介绍了使用RBM（Restricted Boltzmann Machines，受限波兹曼机）来对推荐系统建模，和RNN（Recurrent Neural Network，递归神经网络）在推荐系统中的应用。</p>
<p>今天，我们最后再来看一看，还有哪些深度学习的思潮在影响着推荐系统。这些思想都是一些值得关注和学习的方向，虽然这些方法能否在短时间内成为主流还有待检验。</p>
<h2>多层神经网络</h2>
<p>深度学习开始从计算机视觉这一人工智能子领域慢慢向其他领域扩展，在这个大背景下，很多学者和实践者总结出了深度学习获得成功的一大法宝，那就是<strong>能够从众多的信息中学习到高维度的特性</strong>（Feature）。比如，在计算机视觉里，通过多层神经网络建立的深度学习模型往往能够识别出类似“边”、“角”、“形状”等视觉概念。于是，大家就形成了这样一个普遍认识：<strong>多层神经网络是一种提取特性的利器</strong>。</p>
<p>和很多其他领域的思路一样，在推荐领域的学者也开始尝试利用多层神经网络对用户和物品的信息进行提取。这里面比较经典的思路是：直接利用<strong><span class="orange">多层神经网络</span></strong>，来尝试我们之前已经讲过的基于矩阵分解的推荐模型。</p>
<p>在矩阵分解的例子里，我们学习到的是用户的隐变量和物品的隐变量。这两者的点积成为评分的预测结果。在这个模型框架里可以认为，用户的隐变量和物品的隐变量是我们从数据中提取的特性信息。只不过，这种特性的提取是一种<strong>线性变换</strong>，而深度学习模型寻求的是<strong>多层次的非线性变换</strong>。</p>
<p>利用多层神经网络提取用户和物品特性的基本思路是这样的。</p>
<!-- [[[read_end]]] -->
<p>首先，我们的输入信息是用户的ID以及物品的ID。这里我们可以认为 <strong>ID是高维的离散输入</strong>。那么，根据这个输入信息，我们分别对用户和物品构建多层神经网络。这里比较常见的是至少有一层的神经网络，可以把离散的输入转换成为<strong>连续的数据层</strong>。</p>
<p>通常我们把这一层叫作“<strong>嵌入层</strong>”（Embedding）。嵌入层的基本思想是希望能够把离散信息转换成为连续信息，并且这些连续信息携带着“语义”（Semantic）上面的相似。什么意思呢？就是说如果两个用户是相似的，或者两个物品是相似的，那么我们就会寄希望于他们的嵌入层在数值上相近，这样嵌入层就能够很好地捕捉到用户和物品的相似度。</p>
<p>当用户和物品两边分别得到了嵌入层以后，输入信息已经完全变成了连续数据信息，通常的做法是把两边的嵌入层拼接在一起（也有把两个嵌入层取加权平均的做法），形成一个大的嵌入层。这个新的拼接层就成为连结了用户信息和物品信息的输入。</p>
<p>然后，接下来要做的，就是对这个新的输入进行多层的神经网络变换，最后输出我们对评分的预测。</p>
<p>总而言之，<strong>直接利用多层神经网络对用户和物品的建模可以简单归纳为两步</strong>：首先，把离散的ID信息转换成为连续的信息，形成嵌入层；然后，利用多层神经网络对嵌入层进行变换，并最后输出预测结果。</p>
<p>虽然利用多层神经网络在推荐系统上可以算是非常直观，然而在实际的效果中，我们其实并没有发现利用多层神经网络比矩阵分解要更好。如何能够更加有效地利用多层神经网络目前还是一个研究方向。</p>
<h2>其他深度学习模型</h2>
<p>除了直接利用多层神经网络来对推荐系统进行建模以外，最近也有不少把深度学习中其他思潮应用到推荐系统中的尝试。这里我也简单提及一些。</p>
<p>首先，在深度学习领域有一个技术叫作“<strong><span class="orange">自动编码器</span></strong>”（Autoencoder）。这个方法的核心思想就是希望能够无监督化地学习到某种信号的编码后的信息，并且编码后的信息能够再次通过解码尽可能地还原最初的信号。如果我们能够找到这样完美的过程，那么，在这个方法的假设里，我们就获取了更有价值的特性信息。</p>
<p>于是，把自动编码器思想应用到推荐系统的尝试，主要就是对用户以及物品进行编码。需要指出的是，我们刚才提到的直接使用多层神经网络的方法，其实也是某种意义上的编码，但我们这里提到的自动编码器的思想，还强调能够从学习到的隐含信息中还原最初的信息，也就是尽可能保持学习到的隐含变量的<strong>可还原性</strong>。这一点是多层神经网络所不具备的。</p>
<p>另外一个就是 <strong><span class="orange">CNN（卷积神经网络）</span></strong>的应用，学者和工程人员希望借助CNN来对用户和物品进行建模，从而扩展推荐系统的表现力。目前CNN在计算机视觉领域占据着举足轻重的地位，因此，很多人都希望能够直接把CNN的成功借鉴到推荐系统中。</p>
<p>和刚才我们介绍的直接使用多层神经网络建模的思路非常类似。一种常见的做法也是<strong>直接利用CNN来提取用户和物品的信息</strong>。通常的做法就是在我们刚才所说的嵌入层之后，不直接使用多层神经网络了，而是使用CNN来对嵌入层之后的信息进行变换。这里其实并没有太多创新的地方，基本上就是把视觉里面的模型拿来直接使用。</p>
<p>关于其他深度学习模型我们就说到这里，不做太多的介绍。原因是从总体上来看，深度学习在推荐系统上的应用，还是技术大于实际效果，目前并没有在太多的应用上有真正令人说服的成功案例。大多数情况是技术人员希望尝鲜，然后把一些成功的模型照搬到推荐任务上，虽然效果也不差，但从大的贡献来说，并没有太大的创新。</p>
<h2>小结</h2>
<p>今天我们继续讨论了如何利用深度学习模型来对推荐系统进行建模，我们聊了如何把深度学习的思路嫁接到推荐系统的开发中来。</p>
<p>一起来回顾下要点：第一，我们聊了一种最简单的应用，就是直接利用多层神经网络来对推荐系统进行扩展；第二，我们聊了一些其他的深度学习的思路，包括自动编码器和CNN，简单讨论了如何把这些深度学习模型应用到推荐系统中。</p>
<p>最后，给你留一个思考题，深度学习模型在推荐领域应用的最大问题，或者说最大挑战是什么？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p><strong><span class="reference">推荐阅读</span></strong></p>
<ul>
<li><a href="https://time.geekbang.org/column/article/3287"><span class="reference">深度学习 | 空竹里的秘密：自编码器</span></a></li>
</ul>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor81">复盘 2 | 推荐系统核心技术模块<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>到目前为止，我们讲完了人工智能核心技术的第二个模块——<span class="orange">推荐系统</span>。</p>
<p>整个模块共<strong><span class="orange">21</span>期</strong>，<strong><span class="orange">7</span>大主题</strong>，希望通过这些内容，能让你对推荐系统核心技术有一个全面系统的认识和理解，为自己进一步学习和提升打下基础。今天我准备了21张知识卡，和你一起来对这一模块的内容做一个复盘。</p>
<p><span class="reference">提示：点击知识卡跳转到你最想看的那篇文章，温故而知新。如不能正常跳转，请先将App更新到最新版本。</span></p>
<h2>现代推荐架构剖析</h2>
<p>推荐架构需要解决的问题：</p>
<ul>
<li>能够在一两百毫秒内给用户提供当前的推荐结果；</li>
<li>对用户和系统的交互结果做出响应；</li>
<li>考虑用户群体的覆盖率的问题。</li>
</ul>
<p><a href="https://time.geekbang.org/column/article/5434"><img src="https://static001.geekbang.org/resource/image/e0/c1/e02b1934236066a97ae36aef92c3bdc1.png" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/5519"><img src="https://static001.geekbang.org/resource/image/80/a7/807324f8294f096b4a65ae70186286a7.png" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/5571"><img src="https://static001.geekbang.org/resource/image/3e/ce/3e34f33d9a47d4038806f0c8bd701fce.png" alt="" /></a></p>
<h2>简单推荐模型</h2>
<p><a href="https://time.geekbang.org/column/article/4090"><img src="https://static001.geekbang.org/resource/image/37/2e/374e49076df0afa906a16e9f1a358b2e.png" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/4212"><img src="https://static001.geekbang.org/resource/image/98/86/98450431d48596f62cc1c60d3ee46c86.png" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/4278"><img src="https://static001.geekbang.org/resource/image/1b/e0/1b653031c07f82369df5d908d0f283e0.png" alt="" /></a></p>
<h2>基于隐变量的模型</h2>
<p>我们通过模型的假设，知道隐变量之间的关系，但暂时并不知道隐变量的取值。因此需要通过“推断”过程来确定隐变量的实际取值。当我们知道了这些隐变量的取值之后，就可以根据这些取值来对未来的数据进行预测和分析。</p>
<p>隐变量往往还带有“统计分布”的假设。最简单的隐变量模型是高斯混合模型。</p>
<!-- [[[read_end]]] -->
<p><a href="https://time.geekbang.org/column/article/4421"><img src="https://static001.geekbang.org/resource/image/56/24/569b83b19411ec553caab72f0345ea24.png" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/4484"><img src="https://static001.geekbang.org/resource/image/d2/20/d2a7fe56f96a98d3d5273eb6bdb81a20.png" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/4569"><img src="https://static001.geekbang.org/resource/image/5f/a3/5fb61d3a9985ad47cf788b1e8e9527a3.png" alt="" /></a></p>
<h2>高阶推荐模型</h2>
<p><a href="https://time.geekbang.org/column/article/4680"><img src="https://static001.geekbang.org/resource/image/d5/d4/d533bf563525a8fc26bdb961f77e29d4.png" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/4764"><img src="https://static001.geekbang.org/resource/image/90/86/90272a06f9d37b463bbe82ff8d857986.png" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/4784"><img src="https://static001.geekbang.org/resource/image/9f/0d/9fedf4ca01b38e5b3ca3e0f7c0e6e60d.png" alt="" /></a></p>
<h2>推荐的Exploit和Explore算法</h2>
<p><a href="https://time.geekbang.org/column/article/4881"><img src="https://static001.geekbang.org/resource/image/22/e0/2250834bcf534dc767c780b8a891cae0.png" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/4903"><img src="https://static001.geekbang.org/resource/image/27/6c/27273671a15d93715327d8a20845e06c.png" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/4915"><img src="https://static001.geekbang.org/resource/image/c2/c7/c288afc7d0e523ca292b9ba99b565ec7.png" alt="" /></a></p>
<h2>基于深度学习的推荐模型</h2>
<p><a href="https://time.geekbang.org/column/article/5624"><img src="https://static001.geekbang.org/resource/image/ef/83/ef58f8151d6e56e3b21fcc0405d24683.png" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/5646"><img src="https://static001.geekbang.org/resource/image/33/45/3348cdce4fe739403ff5b35fbc9da345.png" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/5709"><img src="https://static001.geekbang.org/resource/image/cc/51/cc0b8806fa5afd1cb7d4c36b25586951.png" alt="" /></a></p>
<h2>推荐系统的评价</h2>
<p><a href="https://time.geekbang.org/column/article/5075"><img src="https://static001.geekbang.org/resource/image/f2/76/f24271c6d95c4281e8ee67c79a46ec76.png" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/5117"><img src="https://static001.geekbang.org/resource/image/9e/08/9e1d29327ee87f7e45950aafcdcbc908.png" alt="" /></a></p>
<p><a href="https://time.geekbang.org/column/article/5221"><img src="https://static001.geekbang.org/resource/image/f6/58/f6cf7cb2162520ccd2fb3f092cb37158.png" alt="" /></a></p>
<h2>积跬步以至千里</h2>
<p>最后，恭喜你在这个模块中已经阅读了<strong>45397字</strong>，听了<strong>138分钟</strong>的音频，获得一张新的<strong>通关卡</strong>，这是一个不小的成就。在人工智能领域的千里之行，我们又往前迈出了一步。</p>
<p><img src="https://static001.geekbang.org/resource/image/68/09/68086c922fbc5bd91dafc37811aef009.png" alt="" /></p>
<p>感谢你在专栏里的每一个留言，给了我很多思考和启发。期待能够听到你更多的声音，我们一起交流讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor82">079 | 广告系统概述<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>在之前的分享里，我们已经介绍了搜索、推荐系统以及文本分析这三个重要的机器学习、人工智能领域。从基本的思想、算法以及架构说起，我们针对这几个领域要解决的问题和在解决这些问题的过程中出现的经典思路都做了比较详细的讲解。</p>
<p>可以说，搜索是最早利用机器学习以及人工智能思想和技术的应用领域。不管是从最初的图书馆信息检索系统还是到最近二十年年兴起的大规模现代搜索引擎，围绕搜索系统所产生的诸多方法论、算法和模型都影响着很多相关领域。<strong>特别是基于排序学习（Learning To Rank）的搜索排序算法的提出和成熟，让机器学习的一大批技术和搜索的现实问题得以结合，成为了机器学习和某个应用领域相互发展的一大典范</strong>。类似的，对于推荐系统来说，也在过去十几年间，通过机器学习技术和推荐问题的结合，迸发出了一系列经典方法，这些方法也影响了其他应用领域的发展。</p>
<p>从今天起，我们就来看另一个重要的应用领域：<strong><span class="orange">计算广告</span></strong>。计算广告这个领域深受搜索系统和推荐系统的影响，可以说有很多技术都是从这两个领域直接借鉴过来的。然而，因为其应用对象的不同和场景的不同，计算广告又有很多自己独特的问题，以及解决这些问题需要注意的限制条件。因此，在过去十多年间，计算广告慢慢发展出了一条独特的道路。</p>
<p>那么，我们首先来聊一聊广告系统的概述，看一下这个领域要解决的主要问题以及发展的简要历史。</p>
<h2>计算广告的主要场景</h2>
<p>为了给你建立一个感性的认识，我们先来讲一下计算广告的主要场景，了解这个领域需要解决什么样的问题。我们还会在后面的讲解中逐一展开这些场景下的问题设置，因此，这里主要是从大方向上来对这些场景进行一个把握。</p>
<p>互联网的应用和内容服务商慢慢意识到，提供广告可以作为一种重要的盈利手段，这以后，一个新兴的行业就此诞生了。</p>
<p>从最简单的场景来说，一个互联网内容服务商，例如一个新闻网站或者一个社交媒体网站，希望在自己的服务里插入广告，这基本上就是一个内容的匹配问题。我们把<strong>在自己的服务里提供广告的内容服务商叫作“发布商”</strong>（Publisher）。</p>
<p>发布商的目的是匹配广告和目标人群，有时候又叫“受众”（Audience），使得目标人群能够对广告产生兴趣并且点击，然后最终产生行动。这里的行动，可以是购买了广告里的商品，订阅了广告里的服务，也可以是非常广义下的行动，比如对某个品牌有了更加深刻的好印象等。</p>
<p>在这个最简单的场景里，有两种最基本的广告模式，一种叫作“<strong>搜索广告</strong>”，一种叫作“<strong>展示广告</strong>”。搜索广告是说发布商提供某种形式的搜索服务，然后将广告显示在搜索结果页面上。在这样的情况下，广告需要和查询关键词的语义有关系。从本质上说，这种情况下的广告是搜索结果的自然延伸。而对于展示广告来说，往往就是显示在发布商的普通页面上，一般并不直接和任何查询关键词相关。这又和经典的推荐系统的场景非常类似，也可以看做是推荐的一个自然延伸。</p>
<p>如果仅从这样的角度来看广告系统，那么我们基本上可以认定，广告就是特殊的搜索或者特殊的推荐。但其实广告系统还有另外一个和搜索以及推荐非常不一样的方面，最终决定了广告系统的特殊性，那就是“<strong>广告商</strong>”（Advertiser）。</p>
<!-- [[[read_end]]] -->
<p><strong>广告商是那些愿意把自己的广告放到发布商上来显示给受众观看的服务提供商</strong>。广告商对于自己的目标往往有明确的定位，比如希望能够通过广告来增加销售，提高服务订阅数量，提高自己的品牌效应等等。因此，广告商自然希望能够在以下这一系列的决策上有更多的发言权，比如发布商究竟如何显示广告，在什么情况下显示广告，针对什么人群显示广告等，从而能够让自己的利益最大化。</p>
<p>也正是因为这个原因，为了满足广告商的需求，从而能够吸引更多的广告商来自己的服务打广告，发布商往往提供各种工具，帮助广告商了解自己的用户群体以及广告的效果，使得广告商认为这个发布商是一个可以值得依赖的合作伙伴。</p>
<p>然而，即便如此，发布商和广告商的利益往往是不完全一致的。发布商，作为一个内容的提供平台或是一个社交媒体平台，需要照顾自己用户群的感受。例如，一个医院希望在一个新闻网站上投放自己的广告，即便可以为新闻网站带来丰厚的广告收益，新闻网站也需要考虑，从长远来看，这些广告内容和自己的新闻内容是否和谐，是否慢慢地会让用户产生厌烦情绪等。从这个角度来看，发布商不仅仅是简单地进行广告和受众的匹配，还有一个最重要的工作，是从宏观上平衡广告投放效果和内容服务效果，从而达到自己价值的最大化。</p>
<p>随着发布商和广告商数目的增多，众多的发布商发现，如果都需要依靠自己的力量来构建大型广告管理系统，那无疑是非常耗时也是很多中小发布商所不具备的能力。同样，对于广告商来说，如果希望自己的广告能够投放到众多发布商中，逐一研究发布商的工具以及各个发布商用户的区别，就会为广告投放增加不小的难度。因此，针对发布商以及针对广告商的中间平台很快就应运而生。</p>
<p>对于发布商的中间平台而言，整合众多发布机会，从而能够让发布商接触到更多的机会，成为了“<strong>供应侧平台</strong>”（Supply Side Platform）。而对于广告商的中间平台而言，整合众多广告商机会，从而能够让广告商接触更广的发布机会，成为了“<strong>需求侧平台</strong>”（Demand-side Platform）。而连接这两大平台的则是“<strong>广告交换平台</strong>”（Ads Exchange Platform）。关于这些平台的具体功效，我们后面会慢慢接触到。</p>
<p>总之，现在你可以了解到，<strong>广告系统的重要场景是涉及广告商、发布商以及受众“三种角色”的复杂系统之间的平衡以及利益的最大化</strong>。</p>
<h2>计算广告的简要历史</h2>
<p>当我们熟悉了广告系统的一些经典场景之后，我们现在来回顾一下计算广告系统的一个发展简史。</p>
<p>最早的互联网广告出现在1994年11月27日。AT &amp; T这个电信运营商在当时展现了一个叫HotWired的广告商的广告。那个时候，整个互联网只有三千多万用户。</p>
<p>1998年的时候，Goto.com的比尔⋅格罗斯（Bill Gross）发明了“搜索广告”（Sponsored Search），或者有些搜索引擎也把它叫作“竞价排名”。Goto.com后来在2001年成为了Overtune，并最终在2003年被雅虎公司收购。</p>
<p>2002年，谷歌也开始了自己的搜索广告产品AdWords并且很快引入了Generalized Second-Price-Auction，或者简称<strong>GSP</strong>的机制来对广告进行投标竞价。2007年，雅虎也跟进了这种方式来管理所有的广告投标。值得一提的是，当时的谷歌还针对一个广告专利技术纠纷，支付了240万股股票给雅虎。</p>
<p>另一方面，1998年已经有公司开始尝试利用自己的内容页面展示广告。2003年，谷歌收购了一家叫Oingo的公司并且将其业务更名为AdSense，从而开始了其展示广告服务。其后，雅虎和微软等服务商也相继效仿，扩展了自己的广告业务线。</p>
<p>早在2005年前后，各种广告交换平台也纷纷出现。这些交换平台的出现为“<strong>实时竞价</strong>”（Real-Time-Bidding），或叫<strong>RTB</strong>提供了可能性。今天，绝大多数广告平台都支持RTB来为广告商以及内容发布商提供服务。</p>
<h2>总结</h2>
<p>今天我为你简单介绍了广告系统的概况。一起来回顾下要点：第一，我们讲了广告系统的基本应用场景以及其中的重要角色；第二，我们回顾了计算广告在过去发展的一个简单历史。</p>
<p>最后，给你留一个思考题，除了我们所说的搜索广告和展示广告，你还见过什么其他类型的互联网广告呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor83">080 | 广告系统架构<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>从本周开始，我们就进入了计算广告这个重要的应用领域。周一我们首先介绍了广告系统的概述，了解了这个领域要解决的主要问题以及发展的简要历史。我们知道了广告系统中有发布商、广告商、受众群这些实体，还有应运而生的各类中间平台。</p>
<p>今天，我们就更加细致地来看一下<strong><span class="orange">广告系统的架构</span></strong>，熟悉各个组件都是怎么运作的。</p>
<h2>实时广告竞标的重要生态圈</h2>
<p>在前一篇分享里，我们提到了“<strong>实时竞标</strong>”广告系统（简称为<strong>RTB</strong>）这个概念。现在，我们首先来回顾一下这个系统的重要生态圈。</p>
<p>实时竞标系统的生态圈里有四个重要的“角色”：广告商、发布商、广告交换商和用户。在此基础上，这个生态圈产生了一些重要的新的中间平台。</p>
<ul>
<li>
<p><strong>供应侧平台</strong>，简称SSP，负责管理众多发布商的展示机会，接受来自需求侧平台的竞价（简称Bid），同时自动地展示广告。</p>
</li>
<li>
<p><strong>广告交易平台</strong>，简称ADX，是负责多个SSP和需求侧平台进行匹配的中间平台。</p>
</li>
<li>
<p><strong>需求侧平台</strong>，简称DSP，是负责管理众多广告商诸多广告的平台。</p>
</li>
<li>
<p><strong>数据处理平台</strong>，简称DMP，是为SSP、ADX、DSP提供数据服务的中间商。</p>
</li>
</ul>
<!-- [[[read_end]]] -->
<p>值得注意的是，以上的这种区别仅仅是一种概念上的区分，目的是为了让从业人员能够更加清晰地理解各个系统的目标和作用。在实际的运作中，不少平台都充当了多个角色，甚至有比较大的互联网广告平台在这几个子系统中都有所涉及。</p>
<h2>用户行为定向</h2>
<p>了解了实时竞价系统的生态环境之后，我们来看在一次广告显示的流程中，这些生态伙伴都参与了什么样的动作。</p>
<p>第一步，用户来到某个网站，网站产生了一个对实时竞价系统广告网络的请求。</p>
<p>第二步，实时竞价系统广告网络向某个DSP发送请求，这个请求里包含了用户是谁，当前页面是什么，以及一些上下文的数据。</p>
<p>第三步，DSP收到请求以后，就向DMP发送一个数据请求，用于收集用户更多的信息，包括用户的年龄、性别以及喜好。</p>
<p>第四步，DSP收到DMP的信息以后，会向实时竞价系统发出一个自己认为合适的广告以及竞价的价格。</p>
<p>第五步，实时竞价系统广告网络收集到所有的广告竞价以后，会举行一个拍卖（Auction）。每个实时竞价系统的拍卖规则可以不同。</p>
<p>第六步，实时竞价系统会向赢得广告位的DSP发送最后的收款价格，这个价格是根据某种拍卖规则决定的。</p>
<p>第七步，广告显示给了用户。</p>
<p>第八步，用户对广告的反馈，例如是否点击，是否购买广告相应的产品，是否订阅广告对应的服务等，这些信息会返回给DSP。</p>
<p>注意，这里提到的实时竞价系统广告网络既可以是一个SSP，也可以是一个ADX。</p>
<p>我们通过这个流程可以看出，在广告生态系统中，几乎所有的角色，都要在每一个广告请求中参与其中。每一个流程的不精确都有可能让最后现实的广告不符合用户的喜好。</p>
<h2>用户追踪</h2>
<p>从上面这个广告请求的流程中，我们可以看到，在整个广告生态系统中，<strong>对用户的追踪是一种非常重要的能力</strong>。如果广告平台的任何一个部件无法对用户信息进行有效的管理，那么，我们就无法显示相关的广告。</p>
<p>广告生态群对用户信息的追踪有一个基本的技术，那就是<strong>存储用户的Cookie</strong>。实际上，在广告生态圈里，就是用Cookie来对用户的身份进行识别的。当用户第一次访问一个网站的时候，一段Cookie就会被建立并且存储在用户的浏览器里。当用户下一次再访问的时候，这段Cookie就会被重新访问并且可能被更改。</p>
<p>需要注意的是，Cookie是和某一个域名（Domain）相关联的。比如，在通常情况下，你访问了A网站，B网站就无法访问你在A网站的Cookie。这样做的初衷是在互联网上可以做到保护用户的隐私以及有限制的信息共享。但作为广告平台来说，这样做当然是无助于平台对于用户信息的访问。</p>
<p>那么，一种方法就是B网站直接得到A网站的允许，到A网址植入脚本从而来收取用户的Cookie信息。例如，在某个时期内，纽约时报的网站就有多达17个合作方在对用户的数据进行收集。然而，即便是这样，每个单独的数据收集方都只能对用户在互联网上的行为进行局部的数据采集。也就是说，这些收集方很难对用户在互联网上的全部行为进行建模。很明显，这是不利于展示最有价值的广告信息的。</p>
<p>在这样的情况下，也就慢慢催生了一个新的技术——<strong>Cookie的整合</strong>。简单说来，Cookie整合要做的事情就是把多个由不同的数据收集方收集的Cookie进行匹配，从而能够在逻辑上把这些Cookie都当做同一个人处理。据统计，一个用户在30次点击内，就有99%的概率会被互联网上前10大“数据追踪机构”所追踪，而至少有40%的Cookie可以得到有效的整合。</p>
<p>当然，用Cookie来追踪用户并不是万能的。用户可以删除Cookie信息甚至在浏览器的层面禁止Cookie信息。这就给广告平台提出了不小的挑战。最近几年，基于其他存储技术的用户追踪手段，例如Canvas API或者Flash Cookie等也慢慢流行起来。</p>
<h2>总结</h2>
<p>今天我为你介绍了广告系统的基本架构。一起来回顾下要点：第一，我们分享了广告系统中各个系统的角色；第二，我们聊了各个子系统在一个广告显示请求中都干了什么事情，从感性上为你建立一个整体的观念；第三，我们简单提及了用户追踪的概念以及现在最常见的用户追踪技术的一些基本思路。</p>
<p>最后，给你留一个思考题，对于一个电子商务网站来说，卖家希望通过在站内显示的广告来扩大收益，这种情况下，谁是DSP、SSP和ADX呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor84">081 | 广告回馈预估综述<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>在上一篇的分享里，我们详细地讨论了广告系统的架构，熟悉了各个组件都是怎么运作的，特别是我们重点剖析了对于每一个广告请求，供应侧平台（SSP）、广告交易平台（ADX）、需求侧平台（DSP）以及数据处理平台（DMP）都扮演了什么样的角色。同时，我们介绍了对于用户信息的追踪和整合，业界的基本技术就是存储用户的Cookie，以及慢慢催生的Cookie的整合技术。</p>
<p>今天，我们就来看一看整个计算广告领域最核心的一个问题：<strong><span class="orange">广告回馈预估</span></strong>。</p>
<h2>什么是广告回馈预估</h2>
<p>什么是广告回馈预估？广告回馈预估要解决什么问题？我们先来弄明白这个问题。</p>
<p>我们说过计算广告有两大应用领域：搜索广告和展示广告，以及围绕这些广告的生态系统。这些系统或者领域都希望达到一个最终的目的，那就是用户和广告进行<strong>交互</strong>，并且能够对广告所代表的服务或者产品产生印象，从而达成某种程度的<strong>交易</strong>。</p>
<p>这里的“交互”包括对传统广告的点击，也包括对视频广告的观看。而在和广告交互之后，用户对于广告所代表的服务或商品达成的“交易”，包括购买、订阅甚至是改变印象等等。那么，这一切和广告本身的交互以及和广告所代表的服务或者商品达成的交易，我们都通通称为“<strong>回馈</strong>”（Feedback）。</p>
<!-- [[[read_end]]] -->
<p>而我们所说的“<strong>回馈预估</strong>”，<strong>就是要预测用户这种行为的可能性，或者说是概率</strong>。也就是说，我们希望了解用户是不是有可能点击这个广告；有多大概率观看完这段视频广告；有多大可能去购买这个广告所代表的商品。</p>
<p><strong>对广告的回馈概率进行有效估计是很多广告生态系统组件的一个核心需求</strong>。对于发布商来说，显示广告，不管是通过搜索结果还是通常的页面，都希望能够有用户交互从而带来收入。很多广告系统的收入模式就是依靠用户的点击从而让广告商为此支付一定费用给发布商。</p>
<p>因此，对于发布商来说，越是能准确估计这部分的点击率，就越能保证自己的收入。相应地，对于广告商来说，很有必要知道某一种类型的广告在哪个发布商能够带来更多的点击，从而能够有针对性地对于某个发布商进行投放。由此看来，广告回馈预估是一个非常重要的有待解决的技术问题。</p>
<h2>广告回馈预估的普遍挑战和技术难点</h2>
<p>既然广告回馈预估很重要，我们是不是可以直接用现成的机器学习工具就可以解决这个问题呢？这个问题有什么自身的特点，又有哪些挑战和技术难点呢？</p>
<p>在比较简单的设定下，广告回馈预估可以看做是某种<strong>监督学习的任务</strong>。在这类监督学习任务里，标签是用户的动作，例如点击或者观看，或者购买等。我们需要建立的是一个用户在某种上下文中对广告标签的一个模型。这里的上下文包括查询关键词、用户信息、广告信息以及一切其他有用的信息。</p>
<p>那么，在这样的设定下，广告回馈预估的核心挑战是什么呢？</p>
<p><strong>核心挑战其实来自于稀疏的数据</strong>。</p>
<p>不管是在搜索广告中也好，还是在展示广告中也好，从平均的角度来说，相比于用户和正常的搜索结果或者展示结果（比如新闻内容等）的互动，用户与广告的互动要成倍地减少。有一项研究表明，在同样一个位置，广告的点击率可以是正常内容的十分之一、百分之一甚至是千分之一。也就是说，从概率的角度来看，用户普遍是不点击广告的。这个观察基本上是符合我们对用户的普遍理解的。但是，较少的点击数据造成的结果就是，从监督学习的角度来说，大量的数据点都是未交互的数据，只能当做<strong>负例</strong>来处理。</p>
<p>实际上，<strong>在广告点击率预估的问题中，正例的数目常常是负例的百分之一或者千分之一</strong>。这样造成的就是非常“<strong>不均衡</strong>”的数据集。而要想在不均衡的数据里中进行概率估计，往往都是一件困难的事情。</p>
<p>而购买事件相对于广告点击来说就更加稀少，这一点其实也很正常。在点击了广告之后，又有多少人真正会去购买这些产品呢？因此，提高广告的转化率，也就是交易发生的概率，往往就是更富有挑战的任务。</p>
<p>值得一提的是，在监督学习的框架中，除了数据问题以外，广告回馈预估还有<strong>目标函数的挑战</strong>。具体是什么情况呢？</p>
<p>在真实的系统中，我们需要在很多候选可能的广告中，选出最优的一个或者几个显示在页面上。从某种程度上来说，这更像是一个<strong>排序问题</strong>。同时，对于不少DSP（需求侧平台）来说，广告排序的最终目的是进行“竞拍”（Auction）。因此，最后估算广告的点击率以后，还需要看广告的竞价，由此来对广告是否会赢得竞拍从而被显示在页面上进行一个更加全面的估计。很显然，和传统的推荐或者搜索比较，这些问题都要复杂许多。</p>
<h2>广告回馈预估的算法和模型</h2>
<p>广告回馈预估的难点和挑战来自两方面，一方面是稀疏的数据，会造成不均衡的数据集；一方面是目标函数的挑战。那么，广告回馈预估有哪些比较常见的算法或者模型呢？</p>
<p>我们接下来会对这一系列有关的算法和模型进行详细讨论。今天，我会带你从宏观上进行一下总结。</p>
<p>从最直接的监督学习的角度来看，广告回馈预估的一个常见算法就是把这个问题当做<strong>二元分类问题</strong>，并且直接利用“<strong>对数几率回归</strong>”（Logistic Regression）来对这个问题建模。实际上，直到今天，对数几率回归依然是广告回馈预估领域的重要方法。</p>
<p>第二类经常使用的就是<strong>树模型</strong>，特别是 <strong>GBDT</strong> 这个通常在搜索中使用的模型。我们前面已经提到了这类模型对于排序学习的作用。</p>
<p>第三类目前比较火热的领域就是<strong>如何利用深度学习来对回馈预估进行建模</strong>。这一类模型在最近几年有了比较大的进展。</p>
<h2>总结</h2>
<p>今天我为你介绍了广告系统中最核心的一个问题：广告回馈预估。一起来回顾下要点：第一，广告回馈预估就是预测“用户与广告的交互以及达成交易这种行为”的概率；第二，广告回馈预估有两方面的难点和挑战，分别来自数据和目标函数；第三，在这个领域有一些流行的模型，比如对数几率回归和数模型等。</p>
<p>最后，给你留一个思考题，当我们有不均衡数据集的时候，我们一般都有哪些解决方案？针对广告预估，是否需要对这些方案进行额外的处理呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor85">082 | Google的点击率系统模型<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>广告是很多互联网公司的重要收入来源，比如Google、Facebook、微软、阿里巴巴、百度、腾讯等。以Facebook为例，它的2017年第一季度财报显示，公司总营收为78.4亿美元，这其中98%的收入来自广告。同样，在这些公司内部，都有着完善的广告系统来支撑其广告业务。</p>
<p>当然，大型广告系统的成功需要依靠很多相互协调的子系统和组件。今天我要和你聊的是广告系统里最基础的一个子系统，也是整个广告系统的核心功能之一——<strong>点击率预估系统</strong>。点击率预估，顾名思义就是根据环境和广告的类型，来估计用户有多大的可能性点击当前的广告。这个预估值会用于广告系统的其他组件，比如对广告主（投放广告的客户）的计费模块。因此，点击率预估的准确性和实时性就变得十分重要。</p>
<p>今天和你分享一篇广告点击率预估文献史上非常重要的论文，它来自Google广告团队，标题是《工程实践视角下的广告点击率预估》（“Ad Click Prediction: a View from the Trenches”）。</p>
<h2>论文背景</h2>
<p>这篇论文发表于KDD 2013年的工业论文组，在短短几年时间里就获得了近200次的文章引用数，不少公司争相研究其中的内容，希望能够复制类似的算法和技术。</p>
<p>这篇文章的作者群多达16人，他们都是来自Google西雅图、匹兹堡、硅谷以及剑桥等地办公室的研究人员和工程师，文章的致谢部分也有9人。可见整个论文以及里面的技术的确是团队协作的结果。</p>
<p>这里面有两位作者值得介绍一下。第一位是论文的第一作者布兰登（H. Brendan McMahan）。布兰登早年在卡内基梅隆大学计算机系获得博士学位。他的博士生导师是戈登（Geoff Gordon）以及布卢姆（Avrim Blum），这两位都是卡内基梅隆大学机器学习界的权威教授。布兰登本人长期对优化算法有深入的研究，这篇论文的重要核心算法就来自于他的研究成果。</p>
<p>文章的另外一位作者斯卡利（D. Sculley）从塔夫茨大学（Tufts University）博士毕业之后，一直在Google的匹兹堡分部工作，并着手研究大规模机器学习系统，其中重要的代表性研究成果是如何把回归问题和排序问题结合起来（发表于KDD 2010年）。斯卡利曾经是一个著名的开源大规模机器学习软件包sofia-ml的作者，里面实现了一个大规模版本的RankSVM，一度受到关注。</p>
<h2>在线逻辑回归（Logistic Regression）</h2>
<p>文章首先讲解的是点击率预估的核心算法。因为Google要处理的数据集非常庞大，不管是样本数量还是样本的特征数都是百亿级别的，所以选用什么样的算法至关重要。2013年，也就是这篇论文发表的时候，当时大规模深度学习的环境还没有完全成熟起来，Google的科学家和工程师选择了<strong>逻辑回归</strong>，这是一个非常传统但也非常强大的线性分类工具。</p>
<p>我们这里简单回顾一下逻辑回归模型。</p>
<!-- [[[read_end]]] -->
<p>逻辑回归是要对二元分类问题进行建模，模型的核心是通过一组（有可能是非常巨大规模的）特征以及所对应的参数来对目标的标签进行拟合。这个拟合的过程是通过一个叫逻辑转换或函数来完成的，使得线性的特征以及参数的拟合能够非线性转换为二元标签。</p>
<p>普通的逻辑回归并不适应大规模的广告点击率预估。有两个原因，第一，数据量太大。传统的逻辑回归参数训练过程都依靠牛顿法（Newton’s Method）或者L-BFGS等算法。这些算法并不太容易在大规模数据上得以处理。第二，不太容易得到比较稀疏（Sparse）的答案（Solution）。也就是说，虽然数据中特征的总数很多，但是对于单个数据点来说，有效特征是有限而且稀疏的。</p>
<p>我们希望最终学习到的模型也是稀疏的，也就是对于单个数据点来说，仅有少量特征是被激活的。传统的解法，甚至包括一些传统的在线逻辑回归，都不能很好地解决答案的稀疏性问题。</p>
<p>这篇文章提出了用一种叫<strong>FTRL</strong>（Follow The Regularized Leader）的在线逻辑回归算法来解决上述问题。FTRL是一种在线算法，因此算法的核心就是模型的参数会在每一个数据点进行更新。FTRL把传统的逻辑回归的目标函数进行了改写。</p>
<p>新的目标函数分为三个部分：第一部分是一个用过去所有的梯度值（Gradients）来重权（Re-Weight）所有的参数值；第二部分是当前最新的参数值尽可能不偏差之前所有的参数值；第三个部分则是希望当前的参数值能够有稀疏的解（通过L1来直接约束）。从这三个部分的目标函数来看，这个算法既能让参数的变化符合数据规律（从梯度来控制），也能让参数不至于偏离过去已有的数值，从而整个参数不会随着一些异常的数据点而发生剧烈变化。</p>
<p>在算法上另外一个比较新颖的地方，就是对每一个特征维度的学习速率都有一个动态的自动调整。传统的随机梯度下降（Stochastic Gradient Descent）算法或是简单的在线逻辑回归都没有这样的能力，造成了传统的算法需要花很长时间来手工调学习速率等参数。</p>
<p>同时，因为每一个特征维度上特征数值的差异，造成了没法对所有特征选取统一的学习速率。而FTRL带来的则是对每一个维度特征的动态学习速率，一举解决了手动调整学习算法的学习速率问题。简单说来，学习速率就是根据每一个维度目前所有梯度的平方和的倒数进行调整，这个平方和越大，则学习速率越慢。</p>
<h2>系统调优工程</h2>
<p>很明显，光有一个比较优化的在线逻辑回归算法，依然很难得到最好的效果，还会有很多细小的系统调优过程。</p>
<p>比如文章介绍了利用<strong>布隆过滤器</strong>（Bloom Filter）的方法，来动态决定某一个特征是否需要加入到模型中。虽然这样的方法是概率性的，意思是说，某一个特征即便可能小于某一个值，也有可能被错误加入，但是发生这样事件的概率是比较小的。通过布隆过滤器调优之后，模型的AUC仅仅降低了0.008%，但是内存的消耗却减少了60%之多，可见很多特征仅仅存在于少量的数据中。</p>
<p>文章还介绍了一系列的方法来减少内存的消耗。比如利用更加紧凑的存储格式，而不是简单的32位或者64位的浮点数存储。作者们利用了一种叫q2.13的格式，更加紧凑地存储节省了另外75%的内存空间。</p>
<p>此外，前面我们提到的计算每一步FTRL更新的时候，原则上都需要存储过去所有的梯度信息以及梯度的平方和的信息。文章介绍了一种非常粗略的估计形式，使得这些信息可以不必完全存储，让内存的消耗进一步降低。这部分内容可能并非对所有读者都有益处，然而我们可以看到的是，Google的工程师为了把一种算法应用到实际中做出了非常多的努力。</p>
<p>另外，文章也特别提出，虽然大家都知道在点击率预估这样非常不对称的问题上（也就是正例会远远少于负例）需要对负样本进行采样，但是这里面需要注意的是直接采样会对参数的估计带来偏差。同时文章也提出了需要对模型的最后预测进行调整（Calibration），使得模型的输出可以和历史的真实点击率分布相近。这一点对于利用点击率来进行计费显得尤为重要，因为有可能因为系统性的偏差，预测的数值整体高出或者整体低于历史观测值，从而对广告主过多计费或者过少计费。</p>
<h2>失败的实验</h2>
<p>这篇文章难能宝贵之处是不仅介绍了成功的经验，还介绍了一些失败的或者是不怎么成功的实验结果，让后来的学者和工程师能够少走弯路。</p>
<p>比如著名的<strong>Hashing Trick</strong>，在这篇文章里，Google的工程师们经过实验发现，特征经过哈希之后并没有显著降低内存而且模型的精准度有所下降，同时哈希也让模型变得不可解释，于是Google的工程师觉得没有必要对特征进行哈希。</p>
<p>另外一个热门的技术<strong>Dropout</strong>也被作者们尝试了，在Google的实验数据上并没有显著的效果。还有一个经常见到的技术，那就是对学到的参数进行归一化（Normalization），这是让参数能够在一定的范围内不随便波动。遗憾的是，Google的作者们也发现这个技术没有太大作用，模型的效果经常还会降低。</p>
<h2>小结</h2>
<p>今天我为你分享了这篇关于广告点击率预估的重要论文，你需要理解的核心要点有几个，一是FTRL模型的创新；二是这个模型如何应用到工业界的环境中特别是如何对内存的消耗进行调优；三是Google一系列失败尝试的总结。</p>
<p>总之，这篇论文是难得一见的工业界级别的科技论文分享。从KDD工业组的角度来说，很有借鉴意义；从业界贡献来说，除了广告之外，FTRL也被广泛应用到推荐系统等领域。</p>
<p>最后，我们再来探讨个问题。假设你在负责公司的广告系统，那你应该如何判断自己的场景是不是应该使用FTRL呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor86">083 | Facebook的广告点击率预估模型<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>上一篇文章我们讲了整个计算广告领域最核心的一个问题：广告回馈预估。广告回馈预估，就是预测“用户与广告的交互以及达成交易这种行为”的概率，也就是点击率预估和转化率预估。广告回馈预估存在着数据稀疏等难点和挑战，目前在这个领域比较流行的模型有对数几率回归和数模型等。</p>
<p>今天，我们就来看一个广告回馈预估的实例：<strong><span class="orange">Facebook的广告点击率预估</span></strong>。我们会结合2014年发表的一篇论文《Facebook的广告点击率预估实践经验》（Practical Lessons from Predicting Clicks on Ads at Facebook）来进行分析[1]。</p>
<h2>Facebook广告预估</h2>
<p>Facebook的广告不是我们之前介绍过的搜索广告或者展示广告的简单应用，而是<strong>社交广告</strong>。可以说，社交广告是最近10年慢慢崛起的一种新的广告类型。在论文发表的时候，也就是2014年，Facebook有7.5亿“日活跃用户”（Daily Active Users）和超过1百万的广告商，这个数字在当时是相当惊人的。而今天，在Facebook上活跃的大约有14.5亿用户和5百万广告商。因此，广告系统所需要应对的规模是成倍增加的。</p>
<p>我们说Facebook的广告是社交广告，也就是说，这些广告不依赖于用户输入的搜索关键词。从Facebook的角度来说，广告商在其平台上投放广告的巨大优势，在于能够精准地根据用户的地理位置、年龄、性别等重要信息进行有针对性的投放，因此这些信息能够帮助平台选择什么样的广告适合什么样的人群。那这里的难点就是，对于某一个人群来说，可能符合的广告数量是巨大的，这对广告的回馈预估以及整个系统都是一个不小的挑战。</p>
<h2>广告点击率的评估</h2>
<p>在我们详细解释Facebook点击率系统的一些核心组件之前，我们首先来看一看Facebook的研究人员是怎么评测他们的系统的。</p>
<!-- [[[read_end]]] -->
<p>我们之前提到过，广告系统中的一个巨大挑战就是数据的不均衡。负例，也就是用户没有点击过的广告非常多；而正例，也就是点击过的广告相对比较少。这个比例，根据不同的广告系统会不太一样，但是大体说来，负例与正例的比大概是10:1、100:1甚至1000:1。</p>
<p>在这样的情况下，如果把点击率预估当做是一个分类问题，按照一般分类问题的评价标准，例如准确率，我们只要预测绝大多数，甚至是全部的实例为负例，那么就可以取得很高的准确率。因此，单独看准确率并不是一个很好的评测标准。</p>
<p>这个时候，一个比较通行的评测不均衡数据分类问题的指标是“<strong>曲线下面积</strong>”，或者简称为 <strong>AUC</strong>，这个评测办法可以算是一种替代方法。简单来说，AUC就是看我们是不是能够把正例给排序到负例上面。也就是说，如果每一个正例和负例都有一个预测数值，那么我们按照这个数值排序，去数每一个正例下面有多少负例，然后对所有正例所对应的数取平均。<strong>AUC的数值高，则代表我们可以把绝大多数正例排序到负例前面</strong>。</p>
<p>当然，AUC也不是万能的。AUC的一个最大问题就是它并不在乎所有实例的绝对预测数值，而只在乎它们的相对位置。这在广告系统中可以说是一个非常大的缺陷。我们之前也提过，有很多广告系统组件依赖于对于广告点击率的精确预估，比如收费系统，流量预测等。因此，仅有一个相对位置的正确是不够的。</p>
<p>在这篇论文中，Facebook团队提到了一个概念叫“<strong>归一化的交叉熵</strong>”，简称 <strong>NE</strong>，用于衡量广告系统的好坏。NE实际上是一个比值，比值的分母是数据中观测到的实际的点击率的数值，也可以叫作数据的“背景估计”（Background Estimation）；而分子是某一个模型对点击率的估计。这样做的归一化，目的就是来看，在去除了背景估计的情况下，对点击率的估计是否依然好或者坏。</p>
<h2>层次化的点击率预估模型</h2>
<p>Facebook的研究人员在这篇论文中提出的点击率预估模型分为两个层次。也就是说，从最初的模型特性输入，需要经过两个不同的模型才对点击率做出最终的预测。这个两层架构对后来的很多点击率预估模型有巨大的影响。</p>
<p>我们首先来看第一层模型，这里的输入是最初的特性，其中连续数值的特性已经被转换成了<strong>离散的数值</strong>。然后，这些离散的数值经过了一个<strong>GBDT树</strong>来进行特性转换。这里为什么会用GBDT呢？主要有两层意义。</p>
<p>第一，GBDT可以对特性进行非线性组合。也就是说，GBDT的输出一定是之前特性的非线性的转换，这是由树模型原本的性质所带来的，这个性质对于线性模型来说会有巨大的优势。</p>
<p>第二，经过GBDT转换之后，树模型其实选择出了对目标有用的特性，因此这里还起到一个“特性筛选”（Feature Selection）的作用。也就是说，经过GBDT的模型，最后剩下的特性肯定是要远小于最初的输入特性的，毕竟有作用的特性是少数的。</p>
<p>在经过了GBDT之后，Facebook的研究者用树模型最后的叶节点当做新的特性，然后再学习了一个<strong>线性的分类模型</strong>。这里的思想其实和后来流行的深度学习的想法很类似，也就是先对输入特性进行非线性转换，然后再经过一个线性分类器来进行最后的预测。这个第二层的线性分类器可以用类似SGD的方法进行“在线学习”（Online Learning）。因此，学习到这样一个模型就相对比较容易。</p>
<p>在论文的实验中，作者们不仅展示了两层模型的优势，并且还讨论了很多选取特性方面的经验以及训练模型的经验，比如广告过去的历史信息非常重要，而绝大多数重要的特性都和历史信息有关。</p>
<h2>总结</h2>
<p>今天我为你介绍了Facebook的广告点击率预估的核心算法。一起来回顾下要点：第一，Facebook的广告是社交广告，有其自身的特点和难点；第二，Facebook对广告进行评测的指标主要有AUC和NE；第三，Facebook提出了两层模型的架构，其主要思想是先经过GBDT来进行特性转化，再经过一个线性分类器进行最后的预测。</p>
<p>最后，给你留一个思考题，对于两层架构来说，除了模型性能上的优势以外，在训练的方便程度上，这样的架构还没有什么优势或者劣势呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p><strong><span class="reference">参考文献</span></strong></p>
<p><span class="reference">1.  Xinran He, Junfeng Pan, Ou Jin, Tianbing Xu, Bo Liu, Tao Xu, Yanxin Shi, Antoine Atallah, Ralf Herbrich, Stuart Bowers, and Joaquin Quiñonero Candela. Practical Lessons from Predicting Clicks on Ads at Facebook. Proceedings of the Eighth International Workshop on Data Mining for Online Advertising (ADKDD’14). ACM, New York, NY, USA, , Article 5 , 9 pages, 2014.</span></p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor87">084 | 雅虎的广告点击率预估模型<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>在上一篇文章中，我和你分享了广告回馈预估的一个实例：Facebook的广告点击率预估。我们重点讲了Facebook利用“归一化的交叉熵”这个概念，来衡量广告模型的精准度。另外，我们还分享了Facebook提出的两层模型架构，也就是一开始先利用树模型GBDT来对特性进行非线性转换和选择，然后再利用一个在线学习的线性模型进行最后的预测，这个架构后来得到了很多研究者和实践者的追随。</p>
<p>今天，我们来分析另外一个经典的公司实例：<strong><span class="orange">雅虎的广告点击率预估模型</span></strong>。</p>
<h2>雅虎早期的广告预估模型</h2>
<p>对于曾经的互联网巨头雅虎来说，广告系统很早就成为其重要的经济支柱。早在2007年甚至更早的时候，雅虎的工程师和研究人员就投入到了对广告点击率预估的研究中。这方面的几个代表作我列在了文末的参考文献（[1]、[2]和[3]）里，如感兴趣，你可以进一步学习。</p>
<p>我们在这里集中讲讲这些工作的核心思路。</p>
<!-- [[[read_end]]] -->
<p>首先，雅虎的研发人员很早就注意到了广告预估模型的一个难点，那就是<strong>数据的稀疏性</strong>。这些具有稀疏性的数据带来了一个后果，那就是<strong>模型对很多“罕见事件”（Rare Events）的估计会出现很大的不稳定性</strong>。</p>
<p>我们来举个例子，如果广告1在纽约地区展示了1万次，点击200次，点击率是0.02；而广告2在旧金山地区展示了1百次，点击3次，点击率是0.03，在这样的情况下，我们能判断广告2就一定比广告1有更高的点击率吗？这里面至少有两个因素需要考虑。</p>
<p>第一，<strong>上下文的特性信息非常重要</strong>。这两个广告可能是类型不同，可能展示的地区不同，因此并不能完全直接来对这两个广告进行比较。第二，广告2在旧金山地区的展示次数还比较少，因此0.03这个<strong>预估值</strong>可能是非常不准确的，或者说至少是<strong>不稳定的</strong>，它的误差要大于第一个广告。</p>
<p>这个时候，研发人员就会思考，如何对这些广告的预估进行更加精确的处理呢？</p>
<p>在这样的背景下，雅虎的研发人员提出了一个点击率估计方法，其实也是一种<strong>两层模型</strong>。第一层模型就是最原始的对点击率的估计，也就是类似我们上面所说的直接按照数据进行估计。当然，这里的问题我们刚才也已经提到了，就是估计的不稳定性。第二层模型是对第一层模型的修正。所谓修正，就是<strong>利用层次化信息来对原始的估计值进行“平滑”</strong>（Smoothing）。</p>
<p>什么是层次化信息呢？我们举例来说明。比如，两个广告来自于同一个广告商，因此它们应该有一定的类似的点击率；两个广告被展示到同一个地区，它们也应该有一定的类似的点击率。这些层次信息给了我们一些启示，来对原始估计值进行修正。当然，根据我们这两个例子你就可以看出，一个广告可以受到多个层次信息的影响，比如广告商的层次信息，地理位置的层次信息，以及类别的层次信息等。所以，要想设计一套完善的基于层次信息的平滑方案也并非易事。</p>
<p>这个时期，雅虎在这方面的工作都围绕着一个主题，那就是<strong>如何对平滑方案进行创新</strong>。一种方法是利用“产生式模型”（Generative Model）的概念，把层次信息的叶子节点的数据产生过程，定义为基于其父节点数据的一个概率分布产生过程，从而把整个平滑方案的问题转换成为了一个有向无环图上的每个节点的后验概率参数的估计问题（参考文献[1]和[2]）。另外一种方法则采取了一个不太一样的思路，那就是在做平滑的时候，在这种产生式建模之后，还追加了一个过程，利用树模型来对平滑的结果进行再次修正，使得最后的结果能够达到更高的精度（参考文献[3]）。</p>
<p>这一系列工作虽然在概念上有很高的学术和实践价值，特别是如何利用层次性信息来对预测进行平滑这个方面，但是从整体来说，预估方案变得非常复杂而且环节太多。</p>
<h2>雅虎后期的广告预估模型</h2>
<p>雅虎后期的广告预估模型又从比较复杂的两层模式转换为了<strong>一层模式</strong>。这个转换主要是考虑到了整个流水线（Pipeline）的复杂度以及需要处理的数据规模逐渐变大，那么利用更加稳定和简单的方法就势在必行了。</p>
<p>对于雅虎后期的广告预估模型，我参考论文《简单和可扩展的展示广告响应预测》（Simple and Scalable Response Prediction for Display Advertising）[4]，在这里为你简单做一个总结。</p>
<p>总体来说，整个模型回到了相对简单的“<strong>对数几率回归</strong>”（Logistic Regression），并且直接对所有的特性（Feature）进行建模。这里面唯一可能和之前的很多工作不太一样的地方，是大量使用了“<strong>特性哈希</strong>”（Feature Hashing）的方法。简单来说，特性哈希就是把原来大规模的有可能是极其稀疏的特性给压缩到了一个固定维度的特性空间里。当然，这肯定会对精度等性能有一定影响，因此这是一个需要有一定取舍的决策。</p>
<p>在这篇论文中，作者们还介绍了如何对大量的数据进行采样，以及如何利用配对的特性（也就是把两种不同的特性，比如广告商和地理位置进行配对）来自动产生更多的非线性因素的方法。</p>
<p>那么这个一层模式的方法所达到的效果怎样呢？论文中论述，相比于之前的两层结构，这个方法所达到的效果有很大程度的提升。</p>
<h2>总结</h2>
<p>今天我为你介绍了雅虎的广告点击率预估模型。一起来回顾下要点：第一，雅虎早期的广告预估算法，其重点放在了一种两层模型架构上；第二，雅虎广告预估后期的一些思路，重点则放在了回归到一种更加简单的架构上。</p>
<p>最后，给你留一个思考题，如何在对数几率回归这样的线性模型中引入层次化的平滑思路呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p><strong><span class="reference">参考文献</span></strong></p>
<p><span class="reference">1.  Deepak Agarwal, Andrei Zary Broder, Deepayan Chakrabarti, Dejan Diklic, Vanja Josifovski, and Mayssam Sayyadian. Estimating rates of rare events at multiple resolutions. Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining (KDD '07). ACM, New York, NY, USA, 16-25, 2007.</span></p>
<p><span class="reference">2.  Deepak Agarwal, Rahul Agrawal, Rajiv Khanna, and Nagaraj Kota. Estimating rates of rare events with multiple hierarchies through scalable log-linear models. Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining (KDD '10). ACM, New York, NY, USA, 213-222, 2010.</span></p>
<p><span class="reference">3.  Nagaraj Kota and Deepak Agarwal.Temporal multi-hierarchy smoothing for estimating rates of rare events. Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining (KDD '11). ACM, New York, NY, USA, 1361-1369, 2011.</span></p>
<p><span class="reference">4.  Olivier Chapelle, Eren Manavoglu, and Romer Rosales. Simple and Scalable Response Prediction for Display Advertising. ACM Trans. Intell. Syst. Technol. 5, 4, Article 61 (December 2014), 34 pages, 2014.</span></p>
<p></p>

</div>
</div>

<div class="outline-2">
<h2 id="anchor88">085 | LinkedIn的广告点击率预估模型<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>上一篇文章我们讲了雅虎的广告预估模型。雅虎早期的模型主要集中在如何利用两轮架构来对点击率进行精确建模，后期的模型回归到了比较传统的利用线性模型外加特性哈希来进行大规模点击率预估的模式。</p><p>今天，我们继续来做公司的案例分析，结合论文《LASER：在线广告的可扩展响应预测平台》（LASER: a scalable response prediction platform for online advertising）[1]，来了解LinkedIn这家公司是怎么来做最基本的广告预估的。</p><h2>LinkedIn广告预估模型</h2><p>我们首先来看一看LinkedIn的广告预估模型。这个模型的一大“卖点”就是直接充分考虑了“冷启动”和“热启动”两种模式。</p><p>那么，什么是“冷启动”，什么又是“热启动”呢？</p><p>从我们之前的分享中可以看出，很多点击率预估的模型，都强烈依赖于对用户过去信息以及对广告过去表现的建模。比如刚刚讲过的雅虎预估模型，在它早期的模式中就已经见到了这种信息的作用。</p><p>然而，当我们出现新用户或者新广告时，就会有“冷启动”的问题。也就是说，“冷启动”主要是针对新用户或者新广告而言的。这时候基于历史信息的特性都无法起作用了，一般来说需要有专门的处理。</p><!-- [[[read_end]]] --><p>相对于“冷启动”，“热启动”指的是我们已经掌握了用户或者广告的一定信息，然后利用这些历史信息来对点击率进行预测。</p><p>这么说来，我们一般需要有两套对策，一套针对“冷启动”，一套针对“热启动”。LinkedIn的方法就是<strong>希望通过一个模型来同时解决这两个问题</strong>。</p><p>具体来说，LinkedIn把对点击率的预估拆成了三个部分。</p><p><strong>第一部分，是利用用户、广告和上下文所建立的全局性预测</strong>。什么意思呢？就是我们利用用户特性、广告特性以及上下文特性来对点击率进行预测。这部分的核心思路就是<strong>这些特性所对应的系数是全局性的</strong>。也就是说，对于不同的用户、不同的广告以及不同的上下文所对应的系数是相同的。因为是全局性的系数，因此这部分其实提供了一种“冷启动”的需求，也就是不管是任何新的用户或是广告，只要有一定的特性，我们总能通过这部分得到一种粗略的估计。</p><p><strong>第二部分，是利用第一部分的用户、广告和上下文信息组成交叉特性，从而学习这些特性之间的关系</strong>。如果说第一部分直接就是线性的预测，那么第二部分其实就是“交叉项”形成的非线性的部分。我们之前在讲推荐系统的时候提到过“分解机”（Factorization Machines）这个模型，讲到过这种“交叉项”所带来的非线性预测的好处。虽然这里和分解机的构成不完全一样，但是整体上表达了相似的意思。</p><p><strong>第三部分，是LinkedIn模型提出来的独特之处（和其他公司模型不太一样的地方）</strong>。那就是同样是利用用户、广告和上下文特性，但是LinkedIn所提模型的系数则是每个用户、广告和上下文都不同。作者们认为这可以实现“热启动”效果。也就是说，当某个用户、某个广告或者某个上下文已经有比较多的数据以后，就可以依靠这些用户、广告或者上下文自己的系数了，而不仅仅依靠第一部分的全局系数。这个第三部分只有当数据比较多的时候才能够起作用。</p><h2>模型的其他特性</h2><p>这个模型在增加了这些系数的先验概率信息之后变得相对比较复杂。这篇论文介绍了一系列的模型训练思路，都是不错的可以借鉴的工业界经验。</p><p>首先，作者们认为，刚才模型中所说的<strong>三个部分所需要的模型更新频率是不一样的</strong>。比如第一部分和第二部分都可以认为是全局模型，也就是说系数是全局性的。因此这些模型的变化会比较慢，作者们建议一个星期对模型进行一次更新。而第三部分则是在已经积累了历史信息后慢慢呈现出的效果，因此对于数据会非常敏感，而且每个用户和每个广告都是不同的系数，因此需要在短时间内，比如半个小时甚至几分钟内，就重新训练模型，以达到个性化的目的。</p><p>其次，作者们还把<strong>提出的模型和EE（Exploit &amp; Explore）策略结合了起来</strong>。我们在讲推荐系统时介绍过EE的思路，简单回顾一下EE的目的，主要就是探索那些并没有太多机会被展示的物品，在这里也就是广告。我们刚才说了，所有的系数都加上了先验概率，因此其实可以很容易结合数据计算<strong>后验概率分布</strong>。有了后验概率分布，作者们提出了<strong>以汤普森采样为主的EE模式</strong>。这也可以算是论文提出模型的一大亮点。</p><p>最后我们提一下这个模型的训练算法。因为要在大规模的数据上对模型进行训练，这篇文章采用了一种<strong>ADMM算法</strong>。在文章提出来的时候，作者们还是希望能够利用单个服务器对所有的模型参数进行训练。和其他的算法相比，一般认为ADMM这种算法的收敛速度更快，但是，利用这种算法的其他公司并不太多。</p><h2>总结</h2><p>今天我为你介绍了LinkedIn广告点击率预估的核心算法。一起来回顾下要点：第一，我们讲了LinkedIn把点击率预估分为三个部分，从而分别解决“冷启动”和“热启动”的思路；第二，我们聊了如何更加有效地对这个提出的模型进行训练学习。</p><p>最后，给你留一个思考题，回顾我们讲过的推荐系统模块，我们还介绍过什么方法可以结合“冷启动”和“热启动”呢？</p><p>欢迎你给我留言，和我一起讨论。</p><p><strong>参考文献</strong></p><ol>
<li>Deepak Agarwal, Bo Long, Jonathan Traupman, Doris Xin, and Liang Zhang. LASER: a scalable response prediction platform for online advertising. Proceedings of the 7th ACM international conference on Web search and data mining (WSDM '14). ACM, New York, NY, USA, 173-182, 2014.</li>
</ol><p></p>
</div>
</div>

<div class="outline-2">
<h2 id="anchor89">086 | Twitter的广告点击率预估模型<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>在上一篇文章的分享里，我们了解了LinkedIn这家公司是怎么来做最基本的广告预估的。LinkedIn的广告预估模型分为三部分，这里面的核心思想是直接对“冷启动”和“热启动”进行建模，外加和EE策略（Exploit &amp; Explore）结合在一起，从而提升了效果。</p><p>今天，我们就结合论文《Twitter时间轴上的广告点击率预估》（Click-through Prediction for Advertising in Twitter Timeline）[1]，来看看Twitter的广告预估到底是怎么做的。</p><h2>Twitter的广告预估</h2><p>我们前面提到过最基本的广告形态分类，可以分为“搜索广告”和“展示广告”。当计算广告在互联网上出现以后，这两种广告形态就迅速被很多网站和服务商所采纳。</p><p>在最近的10年里，随着社交媒体的发展，希望在社交媒体的<strong>用户信息流</strong>里投放广告的需求逐渐增强。我们之前谈到的Facebook的案例，其实也是往用户的信息流中插入广告。很多类似的社交媒体都争先恐后地开始进行相似的项目，这一类广告经常被称为<strong>社交广告</strong>。</p><p>社交广告的特点是，需要根据用户的社交圈子以及这些社交圈所产生的内容，而动态产生广告的内容。广告商和社交媒体平台都相信，不管是在投放的精准度上，还是在相关性上，社交广告都有极大的可能要强过搜索广告和展示广告。毕竟，在社交媒体上，用户有相当多的信息，例如年龄、性别，甚至在哪里工作、在哪里上学等，这些信息都有助于广告商的精准投放。而用户自己在社交媒体上追踪的各种信息，又可以让广告商清晰地知道用户的喜好。</p><!-- [[[read_end]]] --><p>Twitter的工程师们在这篇论文里介绍的也是在信息流里投放的社交广告。只不过，Twitter的工程师们认为，我们之前分享的Facebook的解决方案，并没有真正考虑往信息流里插入广告的难点，也就是<strong>广告的排序</strong>，依然把广告的排序问题当做分类问题，也就是用对数几率回归（Logistic Regression）来解决。</p><p>另外，Twitter的工程师们认为，<strong>社交广告比类似Google的搜索广告更具挑战性</strong>。因为在社交信息流里，用户所看到的信息都是随时变化的，比如用户在Twitter中，可能随时有新的信息进入到信息流中，因此信息流的上下文会随时发生变化。那么，如果要投放和上下文相关的广告，这种变化无疑会带来前所未有的挑战。</p><h2>利用排序学习来对广告排序</h2><p>既然Twitter的工程师们认为，信息流广告的建模最重要的就是借鉴排序学习的办法。那么，我们就来看一看他们是怎么利用排序学习来为信息流社交广告建模的。</p><p>首先，排序学习中最基本的就是“<strong>单点法</strong>”（Pointwise）排序学习。回顾一下，单点法其实就是把排序学习的任务转化为分类问题。其实典型的就是直接利用“支持向量机”（SVM）或者对数几率回归模型。</p><p>第二种比较常用的排序学习的方法就是“<strong>配对法</strong>”（Pairwise）排序学习。通俗地讲，配对法排序学习的核心就是学习哪些广告需要排到哪些广告之前。这种二元关系是根据一组一组的配对来体现的。学习的算法，主要是看能否正确学习这些配对的关系，从而实现整个排序正确的目的。对于配对法排序，我们依然可以使用对数几率回归。只是这个时候，我们针对的正负示例变成了某个广告比某个广告排名靠前，或者靠后。</p><p>值得一提的是，通过配对法学习排序学习，对于一般的搜索结果来说，得到最后的排序结果以后就可以了。而对于广告来说，我们还需要<strong>对点击率进行准确的预测</strong>。这个我们之前提到过。于是在这篇文章中专门提到了如何从配对结果到点击率的预测。</p><p>具体来说，原理其实很简单，根据配对法学习排序完成以后的广告之间顺序是绝对的，但是绝对的数值可能是不太精确的。这里进行校准的目的是根据配对法产生的预测值，再去尽可能准确地转换为实际的点击率的数值。一般来说，这里就可以再使用一次对数几率回归。也就是说，这个模型的唯一特性就是配对法产生的预测数值，然后模型的目的是去估计或者说是预测最后的实际数值。<strong>这种使用一个回归模型来进行校准的方法，也用在比如要将支持向量机的结果转换成概率结果这一应用上</strong>。</p><p>虽然从原理上讲，先有一个配对模型进行排序，然后再有一个校准模型对模型的绝对估计值进行重新校正，这是很自然的。但是在实际的工业级应用中，这意味着需要训练两个模型，那无疑就变成了比较繁复的步骤。</p><p>所以，在这篇文章里，作者们想到了一种结合的办法，那就是<strong>结合单点法和配对法</strong>。具体来说，就是直接把两者的目标函数串联在一起。这样做的好处是，可以直接用现在已经有的训练方法，而且同时解决了排序和更加准确预测点击率的问题。我们回顾一下，单点法的特性是尽可能准确地预测每一个广告的点击率，也就是刚才提到的校准的这一个步骤所需要干的事情。这种直接串联的好处是，只需要学习一个模型就可以做到既考虑了排序，又考虑了预测的绝对精准度的问题。</p><p><strong>在机器学习应用中，串联多个目标函数是经常使用的一种技术</strong>。其目的和作用也就和这个串联的想法一样，就是希望针对多个不同的目标进行优化。一般来说，这里面的核心是，多个串联的目标函数需要<strong>共享模型参数</strong>才能形成有关联的总的大的目标函数；如果没有共享参数，那就仅仅是一种形式上的串联。</p><h2>模型的实验</h2><p>在这篇文章里，作者们也是用了Facebook提出的“归一化的交叉熵”，简称NE的概念以及业界比较常用的AUC来针对模型进行线下评价。</p><p>在线下实验中，配对法以及单点法和配对法结合的混合方法都在AUC上要超过单点法本身。这非常容易理解。只是配对法针对单点法在NE上的表现要差很多。这和我们刚才所说的没有对点击率进行估计有很大关系。这一点也在实验中得到了证实。</p><p>在在线实验中，单点法相对于以前的自然排序，点击率好了将近14%，而混合法则好了26%左右。可以说效果非常明显。</p><h2>总结</h2><p>今天我为你介绍了Twitter广告点击率预估的核心算法。一起来回顾下要点：第一，我们讲了Twitter认为社交广告的难点是要解决广告的排序问题；第二，我们聊了如何利用排序学习来为点击率预估进行效果提升。</p><p>最后，给你留一个思考题，为什么Twitter不尝试使用树模型来对点击率进行提升呢？</p><p><strong>参考文献</strong></p><ol>
<li>Cheng Li, Yue Lu, Qiaozhu Mei, Dong Wang, and Sandeep Pandey. Click-through Prediction for Advertising in Twitter Timeline. Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD '15). ACM, New York, NY, USA, 1959-1968, 2015.</li>
</ol><p></p>
</div>
</div>

<div class="outline-2">
<h2 id="anchor90">087 | 阿里巴巴的广告点击率预估模型<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>今天，我们继续来进行点击率预估的案例分析，结合三篇核心论文，来看一看阿里巴巴的广告预估又有哪些值得我们学习的地方。</p><h2>多段线性模型</h2><p>我们之前介绍了多个公司关于点击率或者转化率预估的案例。从这些案例中，你可能已经发现有两个非常重要的特征需要机器学习模型来处理。</p><p>第一，就是<strong>数据中呈现的非线性化的关系</strong>。也就是说，我们的模型必须在某一个地方考虑到特性之间的非线性表征，以及对于目标标签的非线性关系。</p><p>第二，就是<strong>数据的不均衡以及数据的稀疏性</strong>。有很多广告商是新广告商，很多广告是新广告。在这样的情况下，我们就必须要处理“冷启动”和“热启动”这两种局面。</p><p>在《从广告点击率预估的大规模数据中学习多段线性模型》（Learning Piece-wise Linear Models from Large Scale Data for Ad Click Prediction）[1]这篇文章中，作者们提出了一种<strong>多段线性模型</strong>来解决我们刚刚说的这两个问题，这个模型简称为<strong>LS-PLM</strong>（ Large Scale Piecewise Linear Model ）。</p><p>LS-PLM的核心思路其实非常直观。既然数据在整个空间里可能呈现非线性的关系，那么我们是否能够<strong>把整个空间分割成较小的区域</strong>，使得每个区域内依然可以使用<strong>线性模型</strong>来逼近这个区域内的数据点呢？其实在统计学习中，这种模型常常被叫作“<strong>混合模型</strong>”。在很多机器学习教科书中都会讲授的一种混合模型是“<strong>高斯混合模型</strong>”（Gaussian Mixture Model）。</p><!-- [[[read_end]]] --><p>LS-PLM在这篇论文的实际应用中，基本上可以被理解成为一种<strong>混合线性模型</strong>。这个模型的一个子模型叫作“<strong>分割函数</strong>”，也就是模型需要学习每一个数据点到底是依赖于哪一个线性模型来进行预测的。当然，这个分割是一种概率的分割。实际上，每一个数据点都依赖所有的线性模型来进行预测，只不过对每个模型的依赖程度不一样。对于每一个不同的线性模型来说，最大的不同就是每一个模型有自己的系数。也就是说，之前只有一个全局模型并且只有一组系数，相比之下，这里有多组系数来决定模型的预测效果。很明显，<strong>对于LS-PLM来说，每一个局部都是线性的，但是在整体上依然是一个非线性的模型</strong>。</p><p>LS-PLM还借助了<strong>两种正则化机制</strong>。一种叫作<strong>L1正则</strong>，这种正则化主要是希望模型保留尽可能少的特性，从而达到对于模型特性的选择。另外，模型还采用了一种<strong>L2,1正则</strong>的方法，这种方法的目的也是特性选择，但是希望能够把一组特性全部选择或者全部置零。</p><p>在实际的实验中，作者们尝试了不同数目的数据分割，从2个到36个不等。最终，他们发现当数据分割为12个的时候，模型的效果达到最优，而之后，模型效果并没有明显提升。最终推出模型的AUC比直接使用一个对数概率回归的全局模型，效果要好1.4%。</p><h2>广告点击率预估和图像处理的结合</h2><p>我们在电商上购物，对于商品的图像会不会影响我们的点击或者购买，应该有一个直观的感受。那么在广告的点击率预估上，商品的图像特征对于模型性能上的提高到底有没有帮助呢？我们再来看一篇论文[2]，在这篇文章中，阿里巴巴的工程师就尝试对这个问题进行回答。</p><p>这篇文章结合了近期好几个利用深度学习来进行图像处理和广告点击率预估的工作。首先，就是所有的特性都利用一个“嵌入层”（Embedding Layer）<strong>把原始的特性转换成为数值特性</strong>。这种思路我们在之前介绍文本处理，特别是Word2Vec的时候曾经进行了详细的讲解。而在这里，不管是文本信息还是图像信息，都根据自己的特点转换成为了数值特性。</p><p>这里我们要解决的一个核心问题，就是用户和广告之间的匹配问题，这篇论文的模型是这么处理的。首先，对所有广告的ID及其图像进行单独的嵌入。然后对用户过去的喜好，特别是对图像的喜好进行了另外的嵌入，然后这些嵌入向量形成用户的某种“画像”。用户的画像和广告信息的嵌入被直接串联起来，形成最终的特征向量。在此之上，利用一个多层的神经网络来学习最后的点击率的可能性。</p><p>在深度学习建模中，这种把多种来源不同的信息通过简单的拼接，然后利用多层神经网络来进行学习的方法非常普遍和实用。</p><p>在这篇论文的介绍中，除了在模型上对图像进行处理以外，还有一个创新，就是提出了一个叫“<strong>高级模型服务器</strong>”（Advanced Model Server），简称<strong>AMS</strong>的架构理念。AMS是针对深度学习模型的大计算量而专门打造的计算体系。总体来说，<strong>AMS的目的是把深度学习模型中的很多基础步骤进行拆分，然后把这些步骤部署到不同的服务器上，从而能够把复杂的模型拆分成细小的可以互相交流的步骤</strong>。</p><p>从最终的实验结果上来看，基于深度学习的模型要比对数几率回归的模型好2~3%。整体上来看，利用了图像的模型要比没有利用图像的模型都要好，哪怕是线性模型也是一样的效果。但是，这个好的程度非常之小，基本上可以忽略不计。看来如何好好利用图像的信息，依然是一个比较大的挑战。</p><h2>深度兴趣网络</h2><p>我们刚才介绍的这种把其他信息和图像信息进行结合的方法，最近在一篇文章[3]中有一个总结。在这篇论文中，作者们提出了一种叫“<strong>深度兴趣网络</strong>”，或者简称<strong>DIN</strong>的架构。</p><p>DIN依靠一种基本的模型架构，那就是先把所有的特性变换成嵌入向量，然后针对不同的特性进行划组，一些特性得以直接进入下一轮，另一些特性经过类似图像中的池化（Pooling）操作抽取到更加高级的特性。之后，所有的特性都被简单串联起来，然后再经过多层的深度神经网络的操作。</p><p>DIN在这个架构的基础上，提出了一种新的“<strong>激活函数</strong>”（Activation Function），叫<strong>DICE</strong>，目的是可以在不同的用户数据中灵活选择究竟更依赖于哪一部分数据。可以说，在某种意义上，这个架构非常类似深度学习中比较火热的<strong>Attention架构</strong>，其目的也是要看究竟那部分数据对于最终的预测更有效果。</p><p>从最后的实验中看，不管是在内部数据还是外部公开的例如MovieLens或者Amazon的数据上，基于DIN的模型都比线性模型和其他的深度学习模型有显著的提高。</p><h2>总结</h2><p>今天我为你介绍了阿里巴巴广告点击率预估的核心算法。一起来回顾下要点：第一，我们讲了如何利用混合线性模型来引入非线性的因素从而提高预测效果。第二，我们聊了如何利用深度学习模型来对数据进行建模，谈到了图像在这里面起到的作用。</p><p>最后，给你留一个思考题，深度学习模型在点击率预估方面的最大优势是什么？又有什么劣势呢？</p><p>欢迎你给我留言，和我一起讨论。</p><p><strong><span class="reference">参考文献</span></strong></p><p><span class="reference">1.  Kun Gai, Xiaoqiang Zhu, Han Li, Kai Liu, Zhe Wang. Learning Piece-wise Linear Models from Large Scale Data for Ad Click Prediction. CoRR abs/1704.05194 , 2017.</span></p><p><span class="reference">2.  Tiezheng Ge, Liqin Zhao, Guorui Zhou, Keyu Chen, Shuying Liu, Huiming Yi, Zelin Hu, Bochao Liu, Peng Sun, Haoyu Liu, Pengtao Yi, Sui Huang, Zhiqiang Zhang, Xiaoqiang Zhu, Yu Zhang, Kun Gai. Image Matters: Jointly Train Advertising CTR Model with Image Representation of Ad and User Behavior. CoRR abs/1711.06505 , 2017.</span></p><p><span class="reference">3.  Guorui Zhou, Chengru Song, Xiaoqiang Zhu, Xiao Ma, Yanghui Yan, Xingya Dai, Han Zhu, Junqi Jin, Han Li, Kun Gai. Deep Interest Network for Click-Through Rate Prediction. CoRR abs/1706.06978 , 2017.</span></p><p></p>
</div>
</div>

<div class="outline-2">
<h2 id="anchor91">088 | 什么是“基于第二价位的广告竞拍”？<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>在之前一段时间的分享里，我们重点讲解了广告系统中的回馈预测，也就是我们常说的点击率预测或是转化率预测的问题，和你一起分享了一些有代表性的公司对于点击率预测的技术方案。</p><p>在最早介绍计算广告系统的时候，我们介绍了DSP，也就是需求侧平台的基本功能。这个平台的一个很重要的作用就是决定到底投放哪个广告。我们介绍过的点击率预测可以提供对广告优劣的一种预测，除此之外，我们还需要一种机制，来决定如何从众多的广告中进行选取，这就是<strong><span class="orange">广告的竞价排名</span></strong>。</p><p>广告位竞价排名的出现有两个原因。第一，发布商的广告位是有限的。不管是搜索广告还是展示广告，绝大多数的发布商都以一定的比例在原生的内容，例如新闻、社交媒体内容里插入一些广告位。但是这些广告位的数目是有限的，特别是在优质的发布商资源里，就会出现一些广告位有着很大的竞争。第二，既然有竞争，那么如果引入一种竞价机制的话，势必有可能抬高广告的单价，从而让广告中间平台例如DSP，或者是发布商从中获取更高的价值。</p><p>今天，我们就来讲一讲广告位竞价的一个基本原理，特别是目前广泛使用的<strong><span class="orange">基于第二价位的广告竞拍</span></strong>。</p><h2>基于第一价位的竞拍</h2><p>在我们开始讨论基于第二价位的广告竞拍之前，我们首先来看一个更加自然的竞拍手段，<strong>基于第一价位的竞拍</strong>。其实，在现实生活中，基于第一价位的竞拍会显得更加普遍。</p><!-- [[[read_end]]] --><p>所谓基于第一价位的竞拍，指的是所有的投标方都定好自己的出价，然后一次性统一出价。在出价的过程中，所有的投标方都是看不见竞争对手的出价的，这保证了出价的诚实性。</p><p>当竞拍平台接到所有投标方的出价以后，按照出价由高到低排序，出价最高的投标方获得投标的胜利。</p><p>在广告系统中，如果要采用这样的形式，那么，决定最后投标顺序的不再是单纯的价格，而往往是一个投标价格和点击率的函数，最简单的函数就是<strong>点击率乘以投标价格</strong>。这其实也可以被认为是一种“<strong>期望收入</strong>”。也就是说，如果发布商或者DSP是按照广告的每一次点击来收取费用的话，那么，点击率乘以投标价格就是这种收入的一个数学期望值。</p><p>所以，基于第一价位竞价的广告系统，<strong>按照广告收入的期望值</strong>进行竞价排名。排名第一的广告被选为显示的广告。</p><p>这种机制在早期的互联网广告平台中曾被大量使用。但是一段时间以后，大家发现，基于第一价位竞价的竞价结果往往是“虚高”的。</p><p>这也很容易形象地解释，在大家都不知道对方出价的情况下，如果希望自己能在竞拍中胜出，势必就可能报出比较高的价格。另外一个方面，投标方并不清楚这个广告位的真实价值，大家只能在条件允许的情况下，尽量抬高价格来获取这个机会。</p><p>从某种意义上来说，这样的竞价并不利于广告商的长远发展，也打击了广告商的积极性。</p><h2>基于第二价位的竞拍</h2><p>就是在基于第一价位竞价的基础上，互联网广告界逐渐衍生出了一种新的竞拍方法——基于第二价位的竞拍。</p><p>当我们已经熟悉了基于第一价位的竞拍模式以后，理解基于第二价位的竞拍就比较容易了。</p><p>首先，和基于第一价位的竞拍模式一样，基于第二价位的模式也是<strong>按照广告的期望收入</strong>，也就是根据点击率和出价的乘积来进行排序。但和基于第一价位模式不一样的是，中间商或者发布商并不按照第一位的价格来收取费用，而是按照竞价排位第二位的广告商的出价来收取费用。也就是说，<strong>虽然第一名利用自己的出价赢得了排名，但是只需要付第二名所出的价格</strong>。</p><p>很多互联网广告平台采用了基于第二价位的竞拍之后，发现广告商的竞价表现整体上要比基于第一价位的时候要好。<strong>时至今日，基于第二价位的竞拍方式已经成为了互联网广告的主流竞拍模式</strong>。</p><p>那么，基于第二价位的竞拍方式究竟有什么好处呢？文末推荐一个参考文献[1]，有比较详细的描述。简单来说，研究人员发现，在基于第二价位竞拍的形式下，广告商按照自己对于广告位价值的理解来竞拍是相对较优的策略。</p><p>在基于第二价位的竞拍方式的环境中，又有什么值得注意的技术难点呢？</p><p>对于广告商来说，主要是希望知道在当前出价的情况下，究竟有多大的概率赢得当前的竞拍。这也就是所谓的“<strong>赢的概率</strong>”，这对于广告商调整自己的出价有非常重要的指导意义。对于整个出价的概率分布的一个估计，有时候又叫作“<strong>竞价全景观</strong>”（Bid Landscape）预测。这是一个非常形象的说法，因为广告商希望知道整个赢的概率随着出价变化的整个分布，从而调整自己的安排。</p><p>这样的预测工作会用到一些简单的模型。比如，有学者认为，赢的价格服从一个“<strong>对数正态分布</strong>”（Log-normal）。也就是说，广告商出的价格并且最终赢得竞拍的这些价格，在取了对数的情况下，服从一个正态分布。当然，这是一个假设。但是有了这么一个假设以后，我们就可以从数据中估计这个对数正态分布的参数，从而能够对整个“竞价全景观”进行估计。</p><p>对于“竞价全景观”或者是赢的价格分布的估计有一个比较困难的地方，那就是，作为广告商来说，往往并不知道所有其他竞争对手的出价，以及在没有赢得竞拍的情况下，那些赢得竞拍的出价是多少。简而言之，也就是我们<strong>只观测到了一部分数据</strong>，那就是我们赢得这些广告位的出价。在这种只有一部分信息的情况下，所做的估计就会不准确。</p><p>已经有一些研究工作关注这样情况的预测。比如，论文《用截尾数据预测实时招标中的赢价》（Predicting winning price in real time bidding with censored data）[2]就利用了一种<strong>对数几率回归</strong>来估计那些没有赢得竞拍情况下的赢的价格，然后和已知的赢的价格一起对整个“竞价全景观”进行估计，这也算是目前的一项前沿研究。</p><h2>总结</h2><p>今天我为你介绍了广告竞价系统中的基于第二价位的广告竞拍。</p><p>一起来回顾下要点：第一，我们讲了基于第一价位的竞价原理，就是按照广告收入的期望值进行竞价排名，排名第一的广告竞拍成功；第二，我们聊了基于第二价位的竞价原理和一些技术难点，主要是如何对整个“竞价全景观”进行估计。</p><p>最后，给你留一个思考题，既然竞价排名是按照点击率乘以价格，那如何避免下面这样一种情况呢？就是一些点击率比较低的广告商利用很高的价格占据广告位，从而让用户看到很多不相关的广告？</p><p>欢迎你给我留言，和我一起讨论。</p><p><strong>参考文献</strong></p><ol>
<li>
<p>Jun Wang, Weinan Zhang and Shuai Yuan. Display Advertising with Real-Time Bidding (RTB) and Behavioural Targeting. Foundations and Trends® in Information Retrieval: Vol. 11: No. 4-5, pp 297-435, 2017.</p>
</li>
<li>
<p>Wu, W. C.-H., Yeh, M.-Y., and Chen, M.-S. Predicting winning price in real time bidding with censored data. Proceedings of the 21st ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 1305–1314. ACM, 2015.</p>
</li>
</ol><p></p>
</div>
</div>

<div class="outline-2">
<h2 id="anchor92">089 | 广告的竞价策略是怎样的？<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>在上一次的分享里，我们讲了广告位竞价的一个基本原理，那就是目前广泛使用的基于第二价位的广告竞拍。简单来说，基于第二价位的广告竞拍需要利用广告点击率的估计值和竞拍的价格，把所有的竞拍广告进行排序，排名第一的广告赢得竞拍。和基于第一价位的广告竞拍不一样的是，基于第二价位的广告竞拍并不直接利用排名第一的广告的出价来对其进行收费，而是利用排名第二的价位进行收费。在这样的情况下，有理论工作和实际的数据表明，基于第二价位的广告竞拍更加符合广告商对于广告位本身真实价值的判断。</p><p>今天我们来看在基于第二价位的广告竞拍的基础上，DSP或者广告商究竟该<strong><span class="orange">如何形成自己的竞价策略</span></strong>（Bidding Strategy）。</p><h2>竞价策略</h2><p>为什么需要竞价策略？其实这个问题主要是在“<strong>实时竞价</strong>”，或简称<strong>RTB</strong>的背景下来探讨的。</p><p>我们之前提到过，RTB是DSP目前流行的竞价模式，也就是广告商等利用计算机程序来自动对广告竞拍进行出价。从实际的运作中来看，这样的自动竞价模式要比人工竞价更加方便快捷，也更加高效。然而，在自动竞价的模式下，我们势必需要一种指导思想，来让我们的计算机程序能够随着形式的变化来进行出价。</p><p>那么在RTB中，竞价策略的环境究竟是怎样的呢？</p><!-- [[[read_end]]] --><p>首先，竞价的一个重要特征，就是作为一个竞标方，我们并不知道其他竞标方的点击率和出价。因此，我们<strong>处在一个信息不完整的竞价环境中</strong>。在这样的环境中，我们只能根据自己的点击率估计和自己的出价，以及过去出价的成功与否来对整个市场的形势进行判断。这就是在RTB中竞价策略的一大挑战和难点。</p><p>在这样的背景下，RTB竞价策略的研究和开发集中在以下两种思路上。</p><p>一种思路是<strong>把整个竞价策略当做一种“博弈”</strong>（Game），从而根据博弈论中的方法来对竞价环境中各个竞标方的行为和收益进行研究（比较经典的论文例如参考文献[1]）。用博弈论的方法来对竞价进行研究有一个最大的特点，那就是博弈论主要是对各个竞标方行为之间的<strong>关联性</strong>进行建模，这种关联性包括他们之间的<strong>收益</strong>和他们的<strong>动机</strong>。</p><p>另外一种思路是<strong>把整个竞价策略当做是纯粹的统计决策</strong>，也就是直接对广告商的行为进行建模，而把整个竞价环境中的种种联系都当做是当前决策下的不确定因素（这种思路比较有代表性的论文是参考文献[2]）。在这样的思路下，各个竞标方之间的行为关联变得不那么重要，而对于整个不确定性的建模则变得至关重要。</p><p>第一种思路，也就是利用博弈论的方法来对竞价策略进行研究主要存在于学术界。虽然从理论上来说，博弈论可能提供一种比较有说服力的解释，但是这种思路需要对整个竞价环境有非常多的假设（例如竞标方是不是理性，市场是不是充分竞争等等）。而第二种思路，仅仅需要从广告商自身的角度出发，因此在现实中，这种思路的操作性更强，从而受到工业界的青睐。</p><p>总的来说，第二种思路其实就是根据当前的输入信息，例如页面信息、广告信息、用户信息以及上下文信息等，学到一个<strong>输出价格的函数</strong>，也就是说，这个函数的输出就是在现在情况下当前广告的出价。当然，这个函数势必需要考虑各种不确定的因素。</p><h2>搜索广告和展示广告的竞标</h2><p>搜索广告和展示广告的竞标存在着不小的区别，因此，从技术上来讲，就发展出了一系列不同的方法。</p><p><strong>对于搜索广告来讲，在大多数情况下，每一个出价都是针对某一个搜索关键词的</strong>。例如，一个汽车广告商可能会在一个搜索引擎里竞标针对自己车的品牌，如“大众汽车”、“奥迪汽车”相关的关键词，还可能竞标更加宽泛的关键词，如“买车”、“汽车”等。同时，这里的出价也往往是事先设置好的。</p><p>参考文献[3]是第一个利用机器学习方法对搜索广告的出价进行建模的工作。在这个工作里，每一个关键词的出价来自于一个线性函数的输出，而这个线性函数是把用户信息、关键词以及其他的页面信息当做特性，学习了一个<strong>从特性到出价的线性关系</strong>。这可以算是最早的利用线性函数来进行出价的例子了。</p><p>展示广告的竞价则面临着不同的挑战。首先，在展示广告中，场景中并不存在搜索关键词这种概念。因此，很多广告商无法针对场景事先产生出价。这也就要求RTB的提供商要能够在不同的场景中帮助广告商进行出价。</p><p>同时，相比于搜索广告针对<strong>每一个关键词</strong>的出价方式来说，针对<strong>每一个页面显示机会</strong>出价的挑战则更大。理论上讲，每一个页面显示机会的价格都可能有很大的不同。很多RTB都利用一种叫作<strong>CPM的收费模式</strong>，也就是说，一旦某一个广告位被赢得之后，对于广告商来说，这往往就意味着需要被收取费用。所以，在展示广告的情况下，如何针对当前的页面显示机会以及目前的预算剩余等等因素进行统一建模，就成为一个必不可少的步骤。</p><h2>竞价策略的其他问题</h2><p>除了我们谈论到的基本的竞价策略以外，竞价系统还有一些其他问题需要考虑。</p><p>比如，一个广告商现在有1千元的预算参与到RTB竞价中。从广告商的角度来说，通常希望这1千元能够比较均匀地使用到整个广告竞价中。或者说，即便不是完全均匀使用，至少也不希望这笔预算被很快用完。这里面的一个原因是，在每天的各个时段，广告的表现情况，也就是说转化率或点击率是不一样的，广告商通常希望自己的广告能够在比较好的时段进行展示。而如果广告在比较好的时段还没有来临之前就已经将预算消耗殆尽，那就会让广告商觉得整个流程不是很友好。</p><p>因此，在广告竞价策略中，还存在着一个叫“<strong>预算步调</strong>”（Budget Pacing）的技术，也就是希望能够让广告的展示相对平缓而不至于在短时间内使用完全部的预算。这势必对于广告如何出价有着直接的影响。</p><p>另外，对于平台而言，虽然竞价保证了一定的竞争，但是也并不是所有的展示机会都有非常充分的竞争。因此，从平台的角度来说，如何能够保证一定的收益就变得十分重要。在这样的情况下，有的平台有一种叫作“<strong>保留价格</strong>”（Reserved Price）的做法，用来设置一个最低的竞价价格。保留价格虽然能够来保证收益，但是也可能会让广告商觉得不划算，因此如何来设置这个保留价格，也就成为了出价策略中的一个重要组成部分。</p><h2>总结</h2><p>今天我为你介绍了广告竞价的基础知识，也就是如何形成竞价策略。</p><p>一起来回顾下要点：第一，我们讲了RTB背景下竞价策略的两种思路；第二，我们介绍了搜索广告和展示广告竞价策略的不同之处；第三，我们简单聊了广告竞价策略的一些其他相关问题。</p><p>最后，给你留一个思考题，你觉得如何评价一个广告竞价策略的好坏呢？</p><p>欢迎你给我留言，和我一起讨论。</p><p><strong><span class="reference">参考文献</span></strong></p><ol>
<li>
<p><span class="reference">Ramakrishna Gummadi, Peter Key and Alexandre Proutiere. <strong>Repeated auctions under budget constraints: Optimal bidding strategies and equilibria</strong>. In Eighth Workshop on Ad Auctions, 2012.</span></p>
</li>
<li>
<p><span class="reference">Yuan, S., Wang, J., and Zhao, X. <strong>Real-time bidding for online advertising: measurement and analysis</strong>. Proceedings of the Seventh International Workshop on Data Mining for Online Advertising, page 3. ACM, 2013.</span></p>
</li>
<li>
<p><span class="reference"> Andrei Broder, Evgeniy Gabrilovich, Vanja Josifovski, George Mavromatis, and Alex Smola. <strong>Bid generation for advanced match in sponsored search</strong>. Proceedings of the fourth ACM international conference on Web search and data mining (WSDM '11). ACM, New York, NY, USA, 515-524, 2011.</span></p>
</li>
</ol><p></p>
</div>
</div>

<div class="outline-2">
<h2 id="anchor93">090 | 如何优化广告的竞价策略？<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>广告的竞价排名是计算广告系统中非常重要的一个话题，我们介绍了目前广泛使用的基于第二价位的广告竞拍，以及在此基础上，DSP或者广告商究竟该如何形成自己的竞价策略（Bidding Strategy）。</p><p>今天，我们就来看一些<strong><span class="orange">具体的广告竞价策略方法</span></strong>。</p><h2>单个广告推广计划优化</h2><p>我们首先来看单个广告“推广计划”（Campaign）的竞价策略的优化。</p><p>在上一次的分享里我们介绍了，利用统计决策的一个重要假设就是最终的出价是一个各种输入（例如环境、用户、页面等）的函数输出。这里我们采用一个简化的假设，认为一个推广计划的出价是点击率的一个函数。在这样的情况下，我们先来理清一些概念。</p><p>第一个概念是“<strong>赢的概率</strong>”（Winning Probability）。这里面，如果我们知道现在市场的一个价格分布以及我们的出价。那么，赢的概率就是一个已知概率密度函数求概率的计算，也就是通常情况下的一个积分计算。</p><p>第二个概念就是“<strong>效用</strong>”（Utility）。这是一个广告商关注的指标，通常情况下是点击率的某种函数，比如利润，那就是每一次点击后的价值减去成本。</p><p>在这种情况下的成本其实主要就是<strong>出价后产生的交易价格</strong>。如果是基于第一价位的竞价，那么这个成本就是出价；如果是基于第二价位的竞价，这个成本就是超过第二价位多少还能赢得竞价的价格。</p><!-- [[[read_end]]] --><p>最后还有一点需要说明，那就是所有的广告推广计划都必须要在预算内，这是一个很明显的限制条件。</p><p>理清了这些基本的概念和限制条件以后，我们来看一看最一般的竞价策略。为了方便讨论，我们先假设不需要考虑预算，同时也假设，我们竞价的核心是所谓的“<strong>按照价值</strong>”的竞价。那么，在这种情况下，<strong>最优的策略其实就是按照点击率乘以点击后产生的价值来进行出价</strong>。可以说，这种策略其实是业界接纳程度最好、也是最直观的一种竞价策略。</p><p>然而，在有了预算和当前的交易流量信息的情况下，这种竞价策略就并不是最优的策略了。为什么呢？因为在有了这些限制条件的情况下，我们是否还会按照自己客观认为的广告价值来竞标就成了一个疑问。</p><p>那么，如何来应对预算和交易流量的限制呢？有没有什么优化方法？ 我就结合几篇论文来跟你聊聊这个问题。</p><p>有一篇文章题目是《目标在线广告中的出价优化和库存评分》（Bid Optimizing And Inventory Scoring in Targeted Online Advertising）[1]，这篇文章提供了一种简单的思路来应对预算和交易流量的限制优化问题。</p><p>具体来说，与其完全按照广告的价值来进行出价，不如采用这个价值乘以某个系数，而利用这个系数来动态调整目前的出价。由于是在一个已知的可能出价前面乘以一个系数，所以整个出价策略其实是一种线性变换，因此也被叫作是<strong>线性出价策略</strong>。</p><p>线性出价策略在实际操作中比较方便灵活，在这篇论文中，这种算法也取得了比较好的效果。不过遗憾的是，这种做法并没有太多的理论支持。</p><p>相比之下，另外的两个研究工作（[2]和[3]）则提供了一种比较通用的理论框架，可以用于不同的效用函数和损失函数。在这里，我们不展开讲这个通用框架的细节，重点介绍它的核心思路。</p><p>这个框架的整体思路是把寻找最优出价，或者说是竞价函数的过程表达成为一个“<strong>有限制的最优化问题</strong>”（Constrained Optimization）。最优化的优化目标，自然就是当前竞价流量下的收益。而最优化的限制条件，就是竞价流量下的成本要等于预算。也就是说，在我们期望达到预算的情况下，我们需要尽可能地扩大收益，这就是最优化目标的最大化这个意思。而限制条件决定了这个最大化问题的解的空间，因此，那些不符合条件的解就可以不考虑了。</p><p>一旦我们的问题可以用有限制的最优化问题来表达以后，整个问题的求解就变得相对比较规范化了。对于这类问题有一个标准的求解过程，就是利用“拉格朗日乘数法”，把“有限制的优化问题”转换成为“无限制的优化问题”，然后针对最后的目标函数，求导并置零从而推导出最优解的结果。这一部分的步骤是标准的高等数学微积分的内容。</p><p>这个框架最后推导出了基于第一价位和基于第二价位的最优的出价函数形式。在两种情况下，最优的出价函数都是一个基于点击率、当前竞价流量和预算的非线性函数。那么，从这个框架来看，刚才我们提到的线性竞价策略就并不是最优的。</p><h2>多个广告推广计划优化</h2><p>了解了单个广告推广计划的优化后，很自然地，多个广告推广计划的优化也是一个很重要的话题。在这方面比较经典的论文，推荐你读一读《展示广告的统计套利挖掘》（Statistical Arbitrage Mining for Display Advertising）[4]。</p><p>从基本的思路上来讲，我们需要做的是把刚才的<strong>基于单个广告推广计划的有限制优化问题给扩展到多个广告推广计划上去</strong>。除了满足各种限制条件以外（比如需要满足总的预算要求），论文也提出了一种基于风险控制的思路，来计算每一个广告推广计划的均值和方差，从而限制方差的大小来降低风险。比较遗憾的是，论文提出的优化是一个基于EM算法的过程，也就是说相对于单个广告推广计划来说，多个广告推广计划找到的解可能并不是全局的最优解。</p><h2>总结</h2><p>今天我为你介绍了广告竞价的一些具体的竞价策略。</p><p>一起来回顾下要点：第一，广告竞价会有预算和交易流量的限制问题，我们介绍了单个广告推广计划的两种思路，分别是“线性出价策略”和转化为“有限制的最优化问题”；第二，我们简单聊了多个广告推广计划的思路，简单介绍了论文提出的一种基于风险控制的思路。</p><p>最后，给你留一个思考题，在广告竞价策略的诸多框架中，都基本假定我们知道了广告的点击率，这样的假设有没有问题呢？</p><p>欢迎你给我留言，和我一起讨论。</p><p><strong><span class="reference">参考文献</span></strong></p><p><span class="reference">1. Perlich, C., Dalessandro, B., Hook, R., Stitelman, O., Raeder, T., and Provost, F. <strong>Bid Optimizing And Inventory Scoring in Targeted Online Advertising</strong>. Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 804–812. ACM, 2012.</span></p><p><span class="reference">2.  Zhang, W., Yuan, S., and Wang, J. <strong>Optimal Real-Time Bidding for Display Advertising</strong>. Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 1077–1086. ACM, 2014.</span></p><p><span class="reference">3.  Zhang, W., Ren, K., and Wang, J. <strong>Optimal Real-time Bidding Frameworks Discussion</strong>. arXiv preprint arXiv:1602.01007, 2016.</span></p><p><span class="reference">4.  Zhang, W. and Wang, J. <strong>Statistical Arbitrage Mining for Display Advertising</strong>. Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 1465–1474. ACM, 2015.</span></p><p></p>
</div>
</div>

<div class="outline-2">
<h2 id="anchor94">091 | 如何控制广告预算？<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>我们在前面的一系列分享里讲了广告位竞价的基本原理，那就是目前广泛使用的基于第二价位的广告竞拍。也分享了广告的竞价策略，以及具体的竞价策略优化方法，比如单个广告推广计划的优化等。</p><p>今天，我们来看在广告竞价策略中一个比较重要的问题，这个问题我们在前一篇的分享里也提到过，那就是如何能够比较流畅地利用广告商的预算，而不是把广告商的钱一下子都花完。</p><h2>预算步调优化</h2><p>控制广告预算的第一种方法是<strong>预算步调优化</strong>（Budget Pacing），这个方法的目的就是在某一个时间段里均匀地分配广告商的预算。同时，在每一个时段，发布商所面临的受众都有可能不太一样，所以，对于广告商而言，比较理想的状态是一个广告可以在一天的不同时段被不同的受众所看到，从而达到扩大受众面的目的。</p><p>预算步调优化有两种比较常见的思路，一种叫“<strong>节流</strong>”（Throttling），一种叫“<strong>修改出价</strong>”。</p><p>节流这种方法主要是把单位时间的支出或者是成本给控制在某一个速率内，使得预算能够被均匀地使用。这种方法往往是在我们已经介绍过的竞价模型之外运行。修改出价这个思路很直观，也就是直接修改我们的竞价，从而带来预算均匀化的结果。</p><p>关于节流思路，有一种做法[1]是把如何节流当做一种<strong>“线性优化”问题</strong>，并且是<strong>有限制的最大化问题</strong>。具体来说，对于每一个出价的请求，我们都可以做一个二元的决定，决定我们是否接受这个出价请求。当然，对于每一个出价请求，这里都有一个价值和一个成本。根据对不同出价请求的设置，我们来做优化，从而能够最大化总价值。但同时，我们需要遵守一个限制，总的成本不能超过预算。这其实就是在两种目标之间实现一个均衡，简言之，我们需要在不超过总预算的情况下达到总价值的最大化。</p><!-- [[[read_end]]] --><p>虽然这种算法本身能够通过我们之前介绍过的“拉格朗日乘数法”来求解，但是还存在一个根本的问题，那就是这种算法并不能<strong>实时地</strong>对整个竞价的安排进行计算和更新。因为，这种线性优化方法一般都是在线下计算好了以后再到线上运行。很明显，这种方法并不适合快速变化的竞价环境。因此，也就有一些工作[2]和[3]，尝试通过节流，或者更确切地说，通过<strong>在线优化</strong>来控制预算的使用情况。</p><p>对竞价直接进行修改的相关工作也很多[4]和[5]，这个思路是把<strong>控制理论</strong>中的一些思想借鉴到了对竞价的直接优化上，目标是让广告商的预算能够平滑使用。这里面的控制是指什么呢？主要是指我们引入一个新的模块在DSP中，从而能够<strong>实时监测各种指标</strong>，例如竞价赢的比率、点击率等，然后利用这些数据作为一个参考点，从而能够形成一种<strong>回馈信息</strong>以供控制系统来对出价进行实时的调整。</p><p>和节流的思想相对比，利用控制理论对出价进行直接优化这种思路明显要更加灵活。然而在实际的工作中，更加灵活的框架依赖于对点击率以及竞价全景观的准确预测，这其实是很困难的。在真实的情况下，利用节流的思想，也就是不去修改出价，只是在其基础上直接进行操作，则往往来得简单有效。</p><h2>频率上限</h2><p>在工业界，还有一种经常会使用的控制预算的方法叫“<strong>频率上限</strong>”（Frequency Cap）。简单来说，这种策略就是<strong>限制某一个或者某一种广告在某一种媒介上一段时间内出现的次数</strong>。比如，是否限制一个肯德基的广告在半天之内让同一个用户看见的次数？5次、10次还是20次？</p><p>为什么要限制频率呢？一个因素当然是我们希望广告的预算不要在短时间内消耗完。另外，短时间内反复观看某一个广告，很可能会让用户对某一个广告或者广告商产生厌烦情绪，那么广告的有效度就会降低。这对于一些广告商来说，其实是消耗了一些资源。因此，限制广告的投放是一种策略选择，从而让广告的投放花钱少、效率高。</p><p>这种频率上限的做法在工业界非常普遍，不过比较遗憾的是，关于这样做究竟是不是有很大的效果，用户多次看到广告是否会真正产生非常大的厌烦情绪从而使得广告效果降低，有没有理论支持等问题，目前还没有比较好的研究来解决。</p><h2>总结</h2><p>今天我为你介绍了广告竞价中的预算步调优化和频率上限两个思路。</p><p>一起来回顾下要点：第一，预算步调优化有两种常见思路，分别是“节流”和“修改出价”；第二，频率上限是一种工业界常用的方法，但是目前这方面缺乏理论依据。</p><p>最后，给你留一个思考题：今天我们介绍了使用节流的方法来控制预算，其中一种方法是线性优化，需要在预算允许的情况下最大化广告的价值。那么，对于广告商来说，如何衡量广告的价值？</p><p>欢迎你给我留言，和我一起讨论。</p><p><strong><span class="reference">参考文献</span></strong></p><p><span class="reference">1.  Lee, K.-C., Jalali, A., and Dasdan, A. <strong>Real Time Bid Optimization with Smooth Budget Delivery in Online Advertising</strong>. Proceedings of the Seventh International Workshop on Data Mining for Online Advertising, page 1. ACM, 2013.</span></p><p><span class="reference">2.  Xu, J., Lee, K.-c., Li, W., Qi, H., and Lu, Q. <strong>Smart Pacing for Effective Online Ad Campaign Optimization</strong>. Proceedings of the 21st ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 2217–2226. ACM, 2015.</span></p><p><span class="reference">3.  Agarwal, D., Ghosh, S., Wei, K., and You, S. <strong>Budget Pacing for Targeted Online Advertisements at Linkedin</strong>. Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 1613–1619. ACM, 2014.</span></p><p><span class="reference">4.  Chen, Y., Berkhin, P., Anderson, B., and Devanur, N. R. <strong>Real-time Bidding Algorithms for Performance-based Display Ad Allocation</strong>. Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 1307–1315. ACM, 2011.</span></p><p><span class="reference">5.  Zhang, W., Rong, Y., Wang, J., Zhu, T., and Wang, X. <strong>Feedback Control of Real-time Display Advertising</strong>. Proceedings of the Ninth ACM International Conference on Web Search and Data Mining, pages 407–416. ACM, 2016.</span></p><p></p>
</div>
</div>

<div class="outline-2">
<h2 id="anchor95">092 | 如何设置广告竞价的底价？<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>在互联网广告生态系统的环境中，我们已经分享了不少关于点击率优化和竞价排名以及如何优化出价的内容，相信你对于广告的整体运作以及其中的核心算法都有了一定的了解。</p><p>我们首先来简单回顾一下，发布商和广告商或者DSP之间的关系。发布商，往往是类似于新闻网站、社交媒体网站和视频网站这样的内容提供方。这些网站的一个特点就是他们本身并不产生收益，甚至往往是免费提供服务。因为流量巨大，这些内容提供方希望能够通过在自身的网站上发布广告从而获得巨额收益。对于广告商和DSP来说，则是希望能够利用发布商的巨大流量来接触更多的用户从而推销自己的服务和产品。</p><p>我们之前的很多讨论，其实重点都放到了需求侧平台，也就是常说的DSP方面，包括点击率预估和很多调整竞价排名的方法等等。今天，我们就来看一个<strong>发布商</strong>在广告竞价流程中可以参与调优的地方，那就是<span class="orange">广告竞价中的底价优化</span>。</p><h2>底价</h2><p>底价，顾名思义，就是在广告的竞价中给竞拍设定一个最低价。</p><p>为什么需要这么做呢？其实在理想的状态下，一个充分竞争的，并且有着充分广告源的市场，广告的单价应该是逐渐升高的。因为广告位资源毕竟是有限的，在有充分广告源的情况下，所有的广告商为了竞争这些有限的广告位，必定是会逐渐抬高广告位的价格。而作为内容发布商，在这个过程中则可以享受到逐渐升高的广告位价值。</p><!-- [[[read_end]]] --><p>然而，在现实中的很多情况下，这种理想状态的竞争态势并不完全存在。比如，对于一个新闻内容提供商来说，在新闻首页顶端出现的广告位一般更能吸引眼球，这种广告位常常可以引起充分竞争，但是在新闻页面下方的广告位则很有可能无法带来充分竞争，因为这些广告位的点击率可能只有顶端广告位点击率的十分之一甚至更少。那么，对于那些无法带来充分竞争的广告位，内容发布商就有可能无法收取理想状态下的收益，甚至在一些比较极端的情况下，会以非常便宜的价格给予广告商。</p><p>也就是说，<strong>在真实的广告竞争市场中，很多时候广告位都无法得到充分竞争</strong>。除了我们刚才所说的因为广告位的位置所导致的不充分竞争以外，同一广告位在一天中的不同时段的竞争程度也是不尽相同的。另外，在搜索广告中，不同的搜索关键词也会有不同的竞争情况。</p><p>综合这些原因，对于内容发布商来说，如何保护自己的广告位价值并且保证最低收益呢？一种方法就是设置一个广告竞价的最低价格，也就是我们这里所说的<strong>底价</strong>。当我们设置了底价以后，所有的广告竞价都不会低于这个价格，也就人为地抬高了广告位的竞争水准。</p><p>既然这是一种保护广告位价值的简单做法，那么会不会带来一些其他的问题呢？答案是，当然会。一个重要的因素就是，这个底价设置得太高，会打击广告商的积极性，进一步影响广告位的竞争，从而让整个市场变得竞争不足拉低价格。而如果这个底价设置得太低，则没有起到实际的作用，广告商仍然可以利用较低的价格获得广告位，而内容发布商可能也没有获得足够的收益。</p><h2>底价优化</h2><p>在了解了这些关于底价的背景知识以后，我们来思考一下该<strong>如何设置底价</strong>。</p><p>在一个基于第二价位的竞价系统中，底价存在三种情况，这些情况的不同会导致发布商有不同的收益。</p><p>第一种情况，底价高于竞价的最高价。很明显，这个时候发布商没有收益，因为所有其他的出价都低于底价，也就是说底价过高。在实际的操作中，这一次广告位请求可能会被重新拍卖（Re-Sell）。</p><p>第二种情况，底价高于第二价位。因为是基于第二价位的竞价，所以已经用第一价位获取了广告位的广告商，这个时候就需要支付底价，而不是原本的第二价位的价格。这种情况下，发布商就获取了额外的收益。这个额外的收益就是底价减去之前原本的第二价位。</p><p>第三种情况，底价低于第二价位。同理，因为是基于第二价位的竞价，所以这个时候的底价并没有影响原本的第二价位，因此发布商的收益没有变化。</p><p>我们讨论了这三种情况以后，就会发现，对于发布商来说，在绝大部分情况下，第二种情况是最理想的，因为这种时候会有额外的收益。那么，如何学习到这个底价就成为了一个挑战。</p><p>这里面发布商面临的一个困难是，广告商在提交出价的时候，发布商往往是不知道这个出价的。因此，发布商需要去“猜”所有出价的分布，这无疑是一件非常困难的任务。</p><p>在比较早期的研究中[1]，研究者们借用了“<strong>最优化竞拍理论</strong>”（Optimal Auction Theory）来研究究竟该如何设置这个出价。</p><p>最优化竞拍理论其实假设了发布商知道<strong>出价的一个概率密度函数</strong>，再进一步假设这个密度函数是服从“对数正态”（Log-Normal）分布的，然后推导出了一个最佳的底价。在有了这个假设之后，就可以利用最佳的底价对广告的竞价进行管理，最终在实验中显示，对于某一些广告，发布商的收益增加了10%以上。</p><p>一个更加近期的研究[2]则指出，在实时竞价（RTB）的很多场景中，出价的分布未必是对数正态分布，整个竞价的环境中也有很多并不符合最优化竞拍理论的情况，比如广告商出价未必是按照心中的价值出价，而是为了赢得更多的广告位。</p><p>在这项研究中，作者们提出了一种非常直观的<strong>类似于决策树的策略</strong>，然后研究了在不同情况下发布商策略的不同所带来收益的区别。总体说来，发布商可以采用这样一种策略来调整底价：当发现底价低于最高的出价时，保持或者提高底价；当发现底价高于最高出价时，降级底价。在这种策略的指导下，发布商能够达到一种最佳的收益。</p><h2>总结</h2><p>今天我为你介绍了广告竞价中底价的设置。</p><p>一起来回顾下要点：第一，在真实的广告竞争市场中，很多时候广告位都无法得到充分竞争，为了保证发布商的最佳收益，需要给竞拍设置一个最低价，也就是底价；第二，如何设置底价是一个很困难的任务，以往的研究给我们提供了两种策略可以借鉴，分别是最优化竞拍理论和类似于决策树的策略。</p><p>最后，给你留一个思考题，我们应该对所有广告位设置统一的底价吗？还是不同的广告位有不同的底价呢？</p><p>欢迎你给我留言，和我一起讨论。</p><p><strong><span class="reference">参考文献</span></strong></p><p><span class="reference">1.  Ostrovsky, M. and Schwarz, M. <strong>Reserve Prices in Internet Advertising Auctions: A Field Experiment</strong>. Search, pages 1–18, 2009.</span></p><p><span class="reference">2.  Yuan, S., Wang, J., Chen, B., Mason, P., and Seljan, S. <strong>An Empirical Study of Reserve Price Optimisation in Real-Time Bidding</strong>. Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 1897–1906. ACM, 2014.</span></p><p></p>
</div>
</div>

<div class="outline-2">
<h2 id="anchor96">093 | 聊一聊“程序化直接购买”和“广告期货”<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>在周一的分享里，我们讨论了内容发布商优化自己收益策略的<strong>底价方案</strong>。如果能够把这种底价方案运用得当，就可以增加市场的竞争程度，从而人为地抬高竞价，达到增加收益的目的。</p><p>今天，我们来看关于计算广告竞价的另外两个话题：一个是<span class="orange">程序化直接购买</span>，另一个是<span class="orange">广告期货</span>。</p><h2>程序化直接购买</h2><p>程序化直接购买（Programmatic Direct）是指广告商不通过竞价的方式获取发布商的广告位。这往往意味着广告商需要和发布商<strong>直接签订合同来购买一定量的展示机会</strong>（Impression）。</p><p>在互联网的早期，其实有很多广告合同是通过直接购买的方式进行的。这一类合同的签订通常是经过相对比较传统的模式，也就是由公司的销售人员直接进行接洽。</p><p>直接购买的广告合作合同往往是比较大的。例如，可口可乐公司需要在雅虎主页显示一类新饮料的广告。这种广告要求涵盖的人群广，并且时间也比较长。如果按照竞标的方式，这可能是要竞标上百万次甚至上千万次的展示机会。在这样的情况下，对于广告商和发布商来说，比较快捷的方式反而可能是一次性购买下这些展示机会。</p><p>以雅虎为例，在很长的一段时间里，广告的销售都是分为“有保证的销售”和“无保证的销售”。后者类似于今天的RTB市场，而前者就是我们现在所说的直接购买。</p><!-- [[[read_end]]] --><p>时至今日，对于顶级的内容发布商来说，大家依然喜欢把最优价值的一些广告位，比如较好的位置或者尺寸较大的广告，留下来当做“独家”（Premium）广告位用于直接购买的合同。而近些年，如何使用程序让直接购买更加便捷就成为了很多广告中间平台的一个重要任务。</p><p>那么，对于内容发布商或者SSP（供应侧平台）来说，需要做什么事情来推动程序化直接购买呢？</p><p>首先，内容发布商需要预估未来一段时间内展示机会的数量。例如，在下一个小时内，一共有多少展示机会。这种预估其实就是网站或者服务对流量的估计。然后，把这些预估的展示机会分为两个部分，一部分送入RTB，用于我们之前介绍过的广告竞价排名，而另一部分则用于程序化直接购买。</p><p>和传统的直接购买不同的是，这时候的直接购买是程序化的，因此并不需要广告商和发布商之间直接建立联系，而是通过平台进行交易。从某种意义上来说，这种交易和股票交易十分类似。通常情况下，平台显示的是对这一批展示机会的一个统一价格。广告商以及DSP（需求侧平台）可以根据自己的需要直接购买这个统一价格的展示机会。一般来说，这种购买可以提前几个星期甚至几个月。</p><p>一旦直接购买和通过竞价排名的方式都程序化以后，对于广告商来说，他们愿意提前直接购买广告位，因为这样购买的广告位价值低于他们的一个心理价位。而对于发布商来说，就需要权衡这两种渠道之间的收益平衡，其实在某种情况下，特别是市场竞争不完全的情况下，这也是发布商希望确保一定收益的方法，也就是在有一定折扣的情况下卖掉广告位。</p><p>在程序化直接购买方面进行研究的相关论文非常稀少[1]，一个原因是这种技术的探讨往往需要比较高级的广告系统作为支撑。</p><h2>广告的期权</h2><p>到现在为止，我们已经讨论了广告的竞价排名以及程序化直接购买等话题，你是不是已经慢慢感受到，广告生态系统的构架和我们熟悉的另外一个领域的很多概念有着千丝万缕的联系。对，这个领域就是金融系统，特别是股票或者大宗商品的交易。</p><p>这里面的联系其实是非常直观的。第一，广告和股票交易一样，都有大量的交易机会。这就需要出现第三方系统和平台，对于股票来说是股票交易所，而对于广告来说则是广告的DSP和SSP。第二，广告和股票交易一样，价值和价格都有可能因为交易带来瞬息万变的差别，因此越来越多的金融工具被制造出来，来为这个生态系统中的种种角色进行风险控制。</p><p>比如对于RTB来说，虽然这种机制为广告商和发布商创造了一种交易的模式，但是这种模式中，基于第二价位的竞价让广告商无法对最终的成交价进行有效控制；而且对于发布商而言，对于利润的把握也有一定的风险；同时广告商和发布商之间也谈不上什么“忠诚度”，因为相同的广告位还有可能在其他的发布商那里找到。在这种情况下，<strong>“期权”（Option）这种金融工具就被介绍到了计算广告的环境中</strong>。</p><p>最近一段时间以来，已经有了一些零星的研究工作讨论<strong>广告期权的理论和应用</strong>（[2]和[3]）。当前，很多发布商是这么设置广告期权的。发布商设置一个未来某个时间点的某个或某些广告展示机会的一个提前价格。这个价格并不是展示机会的实际价格，而是一个权利。对于广告商来说，可以购买这个权利，用于得到未来的这个展示机会。当然，广告商在未来并不一定购买这个展示机会，也可以放弃这个权利。</p><p>对于广告商来说，如何参与竞拍，如何在最佳的时机去购买期权，就变成了一个<strong>复杂的优化问题</strong>。当下关于这方面的很多研究，都借用了金融领域的一些模型和算法。</p><h2>总结</h2><p>今天我为你介绍了在线计算广告的另外两个重要话题：程序化直接购买和广告期权。到此为止，我们就完整地介绍了DSP和SSP中所有有关出价和竞价的话题。</p><p>一起来回顾下要点：第一，我们从广告的历史发展中介绍了程序化直接购买的意义；第二，我们简单聊了聊广告期权存在的目的。</p><p>最后，给你留一个思考题，对于一个DSP来说，能不能通过直接购买获得大量的展示机会，然后又通过RTB竞价排名把这些机会卖出去，这样做的风险是什么？</p><p>欢迎你给我留言，和我一起讨论。</p><p><strong><span class="reference">参考文献</span></strong></p><p><span class="reference">1.  Chen, B., Yuan, S., and Wang, J. <strong>A dynamic pricing model for unifying programmatic guarantee and real-time bidding in display advertising</strong>. In Proceedings of the Eighth International Workshop on Data Mining for Online Advertising, pages 1:1–1:9. ACM, 2014.</span></p><p><span class="reference">2.  Chen, B., Wang, J., Cox, I. J., and Kankanhalli, M. S. <strong>Multi-keyword multi-click advertisement option contracts for sponsored search</strong>. ACM Transactions on Intelligent Systems and Technology (TIST), 7(1):5, 2015.</span></p><p><span class="reference">3.  Chen, B. and Wang, J. <strong>A lattice framework for pricing display advertisement options with the stochastic volatility underlying model</strong>. Electronic Commerce Research and Applications, 14(6):465–479, 2015.</span></p><p></p>
</div>
</div>

<div class="outline-2">
<h2 id="anchor97">094 | 归因模型：如何来衡量广告的有效性<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>在互联网广告生态系统的环境中，我们已经分享了不少关于点击率优化和竞价排名以及如何优化出价的内容。接下来我们开始讨论一些计算广告相关的高级话题。之所以说这些是高级话题，是因为作为机器学习在计算广告的应用，这些话题往往都比较偏冷，但在现实中又特别有实用价值。</p><p>今天我们先来聊一聊<span class="orange">归因模型</span>，这种技术在计算广告业中被广泛使用。</p><h2>什么是归因模型</h2><p><strong>归因模型（Attribution Model）是一种计算广告中分配“贡献”的机制</strong>。</p><p>在现代网站或者应用中，每一个用户都有可能在每一次会话中看到多个不同的广告，或者在多个不同的会话中看到相同广告的不同展示。那么，当用户点击了某个广告，或者是当用户转化以后，比如购买了某个商品或是订阅了某种服务，广告商通常希望知道究竟是哪一个广告起了更大的作用。也就是说，广告商想知道用户接收到的不同广告对这个最后的转化事件都起了什么作用，这个问题就是归因模型研究的核心。</p><p>归因模型之所以重要，是因为这里面牵涉到了<strong>广告有效性</strong>这个话题。那么，如何来衡量广告的有效性呢？</p><p>衡量广告的有效性，就需要利用归因模型，针对每一个转化来分配“贡献”。这样，对于广告商来说，就可以通过<strong>贡献值的叠加</strong>来看某一个渠道或者某一个内容发布平台的转化效果。</p><!-- [[[read_end]]] --><p>然而，归因模型的难点在于，这里面并没有完全的“基本事实”（Ground Truth），全部都基于一定的假设。同时，归因模型直接关系到广告是否有效的计算，也就关系到我们能否推行一个“公平”的市场，以及能否防止其他的广告商在整个平台上进行博弈。</p><p>那么，现在各个平台普遍都在使用的是什么样的归因模型呢？下面我给你介绍几个最基本的归因模型。当然了，说这些方法是模型其实也是不够准确的，因为这些方法大多没有理论支撑，主要是基于经验或者基于传统的方法。</p><p>第一种经验方法叫“<strong>最后触碰</strong>”（Last Touch）。</p><p>顾名思义，最后触碰指的就是<strong>在转化前的最后一个广告拿走100%的贡献值</strong>。这是目前使用最广泛的归因方法，主要是因为它的简单直观。</p><p>我们之前讨论过的所有点击率或者转化率的计算都是基于这个归因方法的。一个可以去博弈“最后触碰”的方法就是让DSP（需求侧平台）把广告投放给那些已经对品牌或者服务产生兴趣的人，从而能够以较大的概率获得用户的转化。在这个过程中，广告的投放其实并没有起作用，而DSP也并没有试图去转化新用户。</p><p>举一个例子，如果我们已知一个用户喜欢可口可乐，并且很可能在过去购买过可口可乐，那么给这个用户展示最新的可口可乐促销广告，就很有可能让这个用户点击广告并购买了一箱促销的可乐。但是，在这个情况下，我们还可以认为，这个用户很有可能不需要看这个广告也会购买可乐，所以这个广告其实是浪费了资源。<strong>“最后触碰”其实是鼓励了DSP采用更加保守的投放方式</strong>。</p><p>既然有“最后触碰”，那肯定就有“<strong>第一次触碰</strong>”（First Touch）的经验方法。这种方式和“最后触碰”截然相反，那就是只要一个用户最后转化了，那么这个用户第一次看到的广告就获得了100%的贡献值。尽管用户可能在第一次看到这个广告后还看了其他的广告，但是这些其他广告都不算数了。<strong>“第一次触碰”其实鼓励了DSP尽可能广地投放广告，把广告的投放当做品牌宣传</strong>。</p><p>除了这两种比较极端但是被广泛使用的归因方法以外，还有一系列的经验方法，都算是这两种方法的某种平衡状态。比如一种叫“<strong>线性碰触</strong>”（Linear Touch）的方法，是给用户在转化的道路上每一个广告都赋予一样的贡献值。还有一种叫“<strong>位置触碰</strong>”（Position Based）的方法，其实就是“最后触碰”和“第一次触碰”的结合。另外一种经验方法“<strong>时间递减</strong>”（Time Decay），则是按照由远到近，对所有的广告位都给一定的贡献值。离转化事件时间越近的广告获得的贡献值越多。</p><p>总之，你可以看到，这些林林总总的经验方法虽然都比较直观，但是在实践中，都有可能给一些广告商利用系统进行不公平投放的机会。</p><h2>基于模型的归因方法</h2><p>下面我们来看一些具备一定理论基础的归因方法，介绍一个在这方面比较早的探索研究[1]。在这个研究里，作者们首先介绍了一种叫<strong>Bagged Logistic Regression</strong>的方法，这个方法根据当前广告的“触碰”信息，也就是用户看了什么广告，来预测用户是否将会转化。在这个模型里，所有的特征就是二元的用户是否观看了某个广告的信息，然后标签就是用户是否转化。通过这些二元的特征学习到的系数就表达了这个广告在这个预测模型下的贡献度。当然，作者们利用了Bagged的方法学习到所有的系数都是正的，确保能够解释这个模型的含义。</p><p>同时，作者们还提出了一个对归因问题的概率解法，我来介绍下这个概率解法的直观思路。某一个广告对用户转化的最后作用都来自两个部分：第一部分是这个广告对用户转化的直接作用；第二个部分是当前这个广告和另外一个广告一起作用使用户转化的概率。当然，这个第二部分的联合作用需要减去这两个广告分别单独作用于用户的情况。那么，一个广告对于用户的影响，就是这两个部分概率的加和，这其实就是考虑了一阶和二阶的关系下的归因模型。</p><p>知道了归因信息之后，我们还可以把这个信息利用到广告的竞价中。直白来说，就是针对有价值的渠道进行有效的出价，而对没有效果的渠道进行控制[2]。除此以外，归因信息还可以帮助广告商来分配自己的预算，把大部分的预算用在优质的渠道中来投放广告[3]。</p><h2>总结</h2><p>今天我为你介绍了在线计算广告的一个高级话题：归因模型。</p><p>一起来回顾下要点：第一，归因模型是一种计算广告中分配贡献的机制，广泛使用的方法有最后触碰和第一次触碰等；第二，有一些有一定理论基础的归因方法，我们其实可以拓展归因信息的应用场景。</p><p>最后，给你留一个思考题，如何来衡量一个归因方法是否有效呢？</p><p>欢迎你给我留言，和我一起讨论。</p><p><strong>参考文献</strong></p><ol>
<li>
<p>Shao, X. and Li, L. <strong>Data-driven multi-touch attribution models</strong>. Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 258–264. ACM, 2011.</p>
</li>
<li>
<p>Xu, J., Shao, X., Ma, J., Lee, K.-c., Qi, H., and Lu, Q. <strong>Lift-based bidding in ad selection</strong>. Proceedings of the 30th AAAI Conference on Artificial Intelligence, 2016.</p>
</li>
<li>
<p>Geyik, S. C., Saxena, A., and Dasdan, A. <strong>Multitouch attribution based budget allocation in online advertising</strong>. Proceedings of 20th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages 1–9. ACM, 2014.</p>
</li>
</ol><p></p>
</div>
</div>

<div class="outline-2">
<h2 id="anchor98">095 | 广告投放如何选择受众？如何扩展受众群？<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>从上一期的分享开始，我们来讨论计算广告相关的一些高级话题。作为机器学习在计算广告的应用，这些话题往往偏冷，但在现实中又有很大的实用价值。我们首先聊了归因模型，介绍了几种经验方法和一些基于模型的归因方法，这种模型在计算广告业中举足轻重，不过也常常被人忽视。</p><p>今天，我们来看另外一个重要的话题，那就是如何帮助广告商扩大受众群，我们也把这种技术称为<span class="orange">受众扩展</span>（Audience Expansion）技术。</p><h2>什么是受众</h2><p>广告商在投放广告时有一个最根本的需求，就是希望通过广告平台接触到更多有可能被转化的受众群。所以，对于绝大多数的广告平台而言，满足广告商的这个需求就成为了一个非常重要的功能。</p><p>为了让广告商来选择受众，不少广告平台提供两种最基本的功能。</p><p>第一种方式是<strong>搜索广告的模式</strong>，也就是广告商可以选择<strong>通过某个关键词或者一系列关键词</strong>来接触到希望投放的受众。这里面其实有一个假设，那就是受众的兴趣或者意图是和关键词联系在一起的，而如果投放的广告内容和受众的兴趣以及意图相符，那么对于广告商来说，就可以假设这种情况下受众的转化率是最高的。</p><p>第二种就是<strong>通过某种选择受众群的方式来让广告商自由地选择广告投放的对象</strong>。这里，最基本的方式是通过受众的“人口”（Demographic）信息来进行投放。典型的人口信息包括年龄、性别和地域。</p><!-- [[[read_end]]] --><p>不管是采用关键词还是人口信息来进行受众选择，这些方法看似简单直观，但其实也给广告商带来了不小的挑战。</p><p>首先，我们来看关于搜索关键词的难点。作为一个广告商，你怎么知道所有的跟你产品或者服务相关的关键词呢？理论上说，可能会有无穷无尽的关键词可供投放。但是关键词的投放数量也和成本有着密切的关系。所以，从现实的角度来讲，肯定是无法投放所有的关键词的。</p><p>其次，利用人口信息来选择受众，那如何来找到比较合适的人口信息呢？这里面就有很大的挑战了。广告商可以利用一些研究结果来找到对应的人口信息从而增强广告投放的效果。然而针对很多中小广告商来说，花费很大的精力和时间去研究这些不同的人口信息和广告效果之间的关系显然是不可能的。</p><p>除了我们刚才所说的这两种广告商选择受众的方式以外，现在也有不少的广告平台并不需要广告商进行“显式”的受众选择。这些服务其实就是看到了这种选择带给广告商的复杂性，与其让广告商来选择，还不如让广告平台来优化。于是，有很多广告平台提供的就是“<strong>傻瓜式</strong>”的广告服务，广告商仅需要设置预算信息，对于人群的投放则完全由广告平台来负责。</p><h2>受众扩展</h2><p>了解了受众的选择以后，一个很现实的问题就摆在了广告平台商的面前，如何帮助广告商来扩展已经选择了的受众群体，从而能够实现受众转化的最大化呢？</p><p>来自LinkedIn的几位作者就探讨了在社交媒体广告中受众扩展的这个问题[1]。在LinkedIn平台上，广告商，也就是雇主，可以针对不同的群体限制条件，也就是我们所说的受众，来投放广告，以吸引潜在的雇员和候选人。广告商在投放广告的时候，可以按照雇员的职业技能（比如是否会Java，是否会机器学习等）以及一些其他的信息（例如来自哪个公司、地理位置）来选择投放的受众。这和我们之前介绍的场景一样，很明显，即便是广告商精心选择一个看似比较有效的受众，在这种情况下，其实依然有很多种其他选择的可能性。</p><p>在这篇文章里，作者们介绍了这么几种受众扩展的思路。</p><p>第一种思路是和某一个广告推广计划（Campaign）无关的。这里主要是<strong>通过一种“类似”算法而找到类似的公司、类似的技能等等</strong>。这种扩展的好处是可以对任何广告推广进行扩展而无需积累数据。</p><p>第二种思路是广告推广相关的扩展。这里其实还是利用了“类似”算法，但是在扩展的时候是根据广告商<strong>对当前这个广告推广所选择的条件来进行选择</strong>，这样的选择自然就会和当前的广告推广更加相关。</p><p>在实际操作中，LinkedIn采用了这两种思路结合的方法。先利用于推广无关的扩展方法来获取最初的一些扩展用户，尽管这部分用户可能质量不高。然后，当广告推广已经运行了一段时间以后，再针对这个广告推广的选择进行扩展，就可以找到更加高质量的扩展用户群体。</p><p>我们看到这些扩展方法都依赖于“<strong>类似</strong>”算法，这里我简单说一下这个算法的核心思想。</p><p>总体来说，这个算法是针对某一个实体（可以是公司、人名、地域、技能等），通过搜索的方法来返回最相关的K个其他实体。作者们把这个问题看成了一个<strong>监督学习的问题</strong>。其核心就是利用了一个<strong>对数几率模型</strong>，对相似的正例和负例进行学习。</p><p>那么，哪些实体是正例，哪些是负例呢？作者们把用户频繁选择放在一起投放的实体当做了正例，而把其他的实体当做负例。对于特性来说，这里广泛采用了<strong>文本特性</strong>，包括文本的词包表达、以及N元语法（N-gram）组成的特性。同时，这里还利用了<strong>图相关度</strong>来推算，比如两个公司在社交关系上的相关程度。然后，两个实体之间的<strong>余弦相关度</strong>也作为一种特性被包含在了模型中。</p><p>在线上实验的结果中，所有受众扩展的效果都比不用扩展有显著的提升。特别是在混合扩展的模式下，展示机会、点击率和总的收益都提升了10%以上。这个实验结果可以用来说明受众扩展的重要性。</p><h2>总结</h2><p>今天我为你介绍了在线计算广告的另外一个高级话题：受众扩展。</p><p>一起来回顾下要点：第一，广告商可以通过关键词或者人口信息等方式来选择受众，不过受众选择也并不容易，有很大的挑战性；第二，我们介绍了和推广计划有关的与无关的两种受众扩展思路，以及将两种思路结合的方法，并简单介绍了两种思路都依赖的“类似”算法。</p><p>最后，给你留一个思考题，在什么情况下受众扩展可能会出现问题，如何来衡量这些问题？</p><p>欢迎你给我留言，和我一起讨论。</p><p><strong>参考文献</strong></p><ol>
<li>Haishan Liu, David Pardoe, Kun Liu, Manoj Thakur, Frank Cao, and Chongzhe Li. <strong>Audience Expansion for Online Social Network Advertising</strong>. Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD '16). ACM, New York, NY, USA, 165-174, 2016.</li>
</ol><p></p>
</div>
</div>

<div class="outline-2">
<h2 id="anchor99">096 | 如何利用机器学习技术来检测广告欺诈？<a href="#table-of-contents">#</a></h2>
<div class="outline-text-2">
<p>在上一期的内容中，我们聊了如何帮助广告商扩大受众群这个话题，也就是受众扩展技术。受众扩展的目的是让广告商投放的广告能够接触到更广泛的受众，甚至有可能提高广告效果。</p><p>在计算广告高级话题的最后一篇分享，同时也是整个广告模块的最后一篇分享里，我想来聊一聊广告中一个非常棘手，同时也是一个非常实际的问题：<span class="orange">欺诈检测</span>（Fraud Detection）。</p><h2>什么是广告欺诈</h2><p>广告欺诈是一个多大规模的问题呢？</p><p>根据一个统计数字[1]，到2015年的时候，就因为广告欺诈，全美的市场营销和媒体业每年的耗费约为82亿美元。这个数字中大约有56%，也就是46亿多美元的耗费来自于“<strong>非法流量</strong>”（Invalid Traffic）。我们把这个数字和全美每年596亿的广告支出进行对比，就可以看出这是一个惊人的数字。当然，因为各种欺诈手段层出不穷，并不是所有的欺诈都能够被甄别出来。因此，我们其实有理由相信真实的数字会更高。</p><p>那么，怎么来定义广告欺诈呢？什么样的行为算是广告欺诈呢？</p><p>我们这里主要讨论三种形式的广告欺诈。这三种广告欺诈模式其实对应着三种流行的广告计费模式。</p><p>第一种欺诈叫“<strong>展示欺诈</strong>”（Impression Fraud），也就是造假者产生虚假的竞价信息，然后把这些竞价展示放到广告交易平台上去贩卖，并且在广告商购买了这些展示后获利。</p><!-- [[[read_end]]] --><p>第二种欺诈叫“<strong>点击欺诈</strong>”（Click Fraud），也就是造假者在广告商产生虚假的点击行为。</p><p>第三种欺诈叫“<strong>转化欺诈</strong>”（Conversion Fraud），也就是造假者完成某种虚假的动作，例如填写表格，下载某个应用等来虚拟真实的转化事件。</p><p>在真实的场景中，这三种欺诈手段经常混合出现。例如点击欺诈和展示欺诈可能同时出现，这样就能在报表中展示一个看似合理的点击率。</p><h2>广告欺诈的产生源</h2><p>了解了广告欺诈的基本形式之后，我们来看一下这些欺诈产生的源头都在什么地方。因为广告产业的有利可图，产生欺诈的途径也是多种多样的，我们这里就看一些经典的形式。</p><p>首先，有一种欺诈来源途径叫<strong>PPV</strong>（Pay-Per-View）网络。</p><p>利用PPV进行欺诈的主要流程就是尝试通过购买流量，然后在一些合法的展示机会中插入用户肉眼看不见的0像素的标签（Tag），诱导广告商，让广告商以为产生了更多的合法流量。</p><p>对于这样的欺诈，一般来说，广告商必须去检测展示机会用户是不是看不见，或者是否是由0像素产生的。然后还可以采用黑名单的方式，对屡次利用PPV来进行欺诈的IP地址进行屏蔽。</p><p>另外一种欺诈手段是通过“<strong>僵尸网络</strong>”（Botnets）。</p><p>这种方法主要是试图直接控制用户的终端电脑或者其他的移动设备，从而进行很多方面的攻击。在过去，僵尸网络的一大应用主要是来产生拒接服务的DDoS（Distributed Denial of Service）攻击和发送垃圾信息。</p><p>近年来，因为其灵活性，很多僵尸网络也被用于广告欺诈。僵尸网络的一大作用就是产生浏览信息，而这些浏览的行为是宿主电脑的用户所无法得知的。因此，对付僵尸网络的一大方法，就是检测从某些IP地址或者DNS产生的流量行为是否发生了突然的根本性的变化。</p><p>第三类欺诈手段是“<strong>竞者攻击</strong>”（Competitor Attack）。</p><p>正常的广告商设立预算参与竞价购买广告位。而竞争对手可以利用“点击欺诈”的方式产生虚假无效的点击信息，从而消耗广告商的预算。当把竞争对手的预算消耗光以后，攻击者反而可以用比较小的成本拿到这些广告位，因为竞争减少了。</p><p>另外，还有一种情况是仅仅大量调入竞争对手的广告而不点击。在这样的情况下，就容易产生非常低的点击率。而很多广告平台依赖点击率来进行排序，因此，如果点击率很低，那代价就是难以赢得竞价，通过这种方式也就间接打压了竞争对手。</p><h2>欺诈检测</h2><p>了解了什么是广告欺诈以及不同的广告欺诈来源之后，我们来看一看如何利用机器学习技术，来对各种不同的欺诈行为进行检测和挖掘。</p><p>首先介绍一个研究[2]，作者们提出了一种技术，<strong>利用“同访问”图来分析异常的浏览行为</strong>。这里面有一个最基本的假设：对于大多数用户来说，对两个不同的网站并不具有相同的喜好程度，除非这些网站非常流行。也就是说，对于绝大多数的网站来说，其用户群体是不一样的。</p><p>如果用户和这些网站的相互关系发生了变化，那可能就是出现了一些异常的情况。当然，利用图分析的方法，就是把异常发掘当成了一种无监督学习的任务，自然也就会有无标签的困难。</p><p>还有一个研究[3]，作者们提出了一种方法，来<strong>分析用户到底需要花多少时间来浏览显示的像素</strong>。这个方法其实就是来检测是否是0像素的展示欺诈。作者们通过研究发现，对于50%以上的像素，绝大多数用户至少需要1~3秒时间来观看。于是，广告商或者平台就可以用这种停留时间来作为一个最基本的检测手段。</p><p>当然，一种最普遍的做法就是把广告欺诈当做一个<strong>监督学习任务</strong>。通过产生各种格样的特性以及把过去已知的欺诈数据当做训练数据来进行学习。这种做法的难点是，欺诈数据在真实世界中毕竟是少数。于是，我们就有了数据不足以及需要训练和不平衡的分类问题。正是因为存在这些问题，欺诈检测依然是一个非常前沿的研究领域。</p><h2>总结</h2><p>今天我为你介绍了在线计算广告的最后一个高级话题：欺诈检测。</p><p>一起来回顾下要点：第一，我们讲了三种形式的广告欺诈，分别是展示欺诈、点击欺诈和转化欺诈，在真实场景中，这三种欺诈手段经常混合出现；第二，产生欺诈的源头很多，我们简单介绍了三种不同类型的广告欺诈来源，分别是PPV网络、僵尸网络和“竞者攻击；第三，我们讨论了欺诈检测的一些基本思路，比如利用图分析、利用停留时间的方法等等。</p><p>最后，给你留一个思考题，如何来检测转化欺诈，也就是我们怎么知道广告转化中哪些是虚假的呢？</p><p>欢迎你给我留言，和我一起讨论。</p><p><strong><span class="reference">参考文献</span></strong></p><p><span class="reference">1.  Interactive Advertising Bureau (2015). <strong>What is an untrustworthy supply chain costing the us digital advertising industry</strong>?</span></p><p><span class="reference">2.  Stitelman, O., Perlich, C., Dalessandro, B., Hook, R., Raeder, T., and Provost, F. <strong>Using co-visitation networks for detecting large scale online display advertising exchange fraud</strong>. In Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 1240–1248. ACM, 2013.</span></p><p><span class="reference">3.  Zhang, W., Pan, Y., Zhou, T., and Wang, J. <strong>An empirical study on display ad impression viewability measurements</strong>. arXiv preprint arXiv:1505.05788, 2015.</span></p><p></p>
</div>
</div>


</div>
</body>
</html>