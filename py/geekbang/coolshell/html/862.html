
<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta  name="viewport" content="width=device-width, initial-scale=1" />
<title>14 | 推荐阅读：机器学习101</title>
<meta  name="generator" content="Org-mode" />
<meta  name="author" content="dirtysalt" />

<style type="text/css">html {
    font-family: Georgia, "Microsoft Yahei", "WenQuanYi Micro Hei";
}

/* pre { */
/*     background-color: #eee; */
/*     box-shadow: 5px 5px 5px #888; */
/*     border: none; */
/*     padding: 5pt; */
/*     margin-bottom: 14pt; */
/*     color: black; */
/*     padding: 12pt; */
/*     font-family: Consolas; */
/*     font-size: 95%; */
/*     overflow: auto; */
/* } */

.title  { /* text-align: center; */
          margin-bottom: 1em; }
.subtitle { /* text-align: center; */
            font-size: medium;
            font-weight: bold;
            margin-top:0; }
.todo   { font-family: monospace; color: red; }
.done   { font-family: monospace; color: green; }
.priority { font-family: monospace; color: orange; }
.tag    { background-color: #eee; font-family: monospace;
          padding: 2px; font-size: 80%; font-weight: normal; }
.timestamp { color: #bebebe; }
.timestamp-kwd { color: #5f9ea0; }
.org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
.org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
.org-center { margin-left: auto; margin-right: auto; text-align: center; }
.org-ul { padding-left: 10px; }
.org-ol { padding-left: 20px; }
ul { padding-left: 10px; }
ol { padding-left: 20px; }

.underline { text-decoration: underline; }
#postamble p, #preamble p { font-size: 90%; margin: .2em; }
p.verse { margin-left: 3%; }
pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
}
pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
}
pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
}
pre.src:hover:before { display: inline;}
pre.src-sh:before    { content: 'sh'; }
pre.src-bash:before  { content: 'sh'; }
pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
pre.src-R:before     { content: 'R'; }
pre.src-perl:before  { content: 'Perl'; }
pre.src-java:before  { content: 'Java'; }
pre.src-sql:before   { content: 'SQL'; }

table { border-collapse:collapse; }
caption.t-above { caption-side: top; }
caption.t-bottom { caption-side: bottom; }
td, th { vertical-align:top;  }
th.org-right  { text-align: center;  }
th.org-left   { text-align: center;   }
th.org-center { text-align: center; }
td.org-right  { text-align: right;  }
td.org-left   { text-align: left;   }
td.org-center { text-align: center; }
dt { font-weight: bold; }
.footpara { display: inline; }
.footdef  { margin-bottom: 1em; }
.figure { padding: 1em; }
.figure p { /* text-align: center; */ }
.inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
}
#org-div-home-and-up
{ text-align: right; font-size: 70%; white-space: nowrap; }
textarea { overflow-x: auto; }
.linenr { font-size: smaller }
.code-highlighted { background-color: #ffff00; }
.org-info-js_info-navigation { border-style: none; }
#org-info-js_console-label
{ font-size: 10px; font-weight: bold; white-space: nowrap; }
.org-info-js_search-highlight
{ background-color: #ffff00; color: #000000; font-weight: bold; }

/* http://www.yinwang.org/main.css */

body {
    /* font-family:"lucida grande", "lucida sans unicode", lucida, helvetica, "Hiragino Sans GB", "Microsoft YaHei", "WenQuanYi Micro Hei", sans-serif; */
    font-size: 18px;
    margin: 5% 5% 5% 5%;
    padding: 2% 5% 5% 5%;
    width: 80%;
    line-height: 150%;
    border: 1px solid LightGrey;
}

H1 {
    /* font-family: "Palatino Linotype", "Book Antiqua", Palatino, Helvetica, STKaiti, SimSun, serif; */
}

H2 {
    /* font-family: "Palatino Linotype", "Book Antiqua", Palatino, Helvetica, STKaiti, SimSun, serif; */
    margin-bottom: 60px;
    margin-bottom: 40px;
    padding: 5px;
    border-bottom: 2px LightGrey solid;
    width: 98%;
    line-height: 150%;
    color: #666666;
}


H3 {
    /* font-family: "Palatino Linotype", "Book Antiqua", Palatino, Helvetica, STKaiti, SimSun, serif; */
    margin-top: 40px;
    margin-bottom: 30px;
    border-bottom: 1px LightGrey solid;
    width: 98%;
    line-height: 150%;
    color: #666666;
}


H4 {
    /* font-family: "Palatino Linotype", "Book Antiqua", Palatino, Helvetica, STKaiti, SimSun, serif; */
    margin-top: 40px;
    margin-bottom: 30px;
    border-bottom: 1px LightGrey solid;
    width: 98%;
    line-height: 150%;
    color: #666666;
}


li {
    margin-left: 10px;
}


blockquote {
    border-left: 4px lightgrey solid;
    padding-left: 5px;
    margin-left: 20px;
}


pre {
    font-family: Inconsolata, Consolas, "DEJA VU SANS MONO", "DROID SANS MONO", Proggy, monospace;
    font-size: 75%;
    border: solid 1px lightgrey;
    background-color: Ivory;
    padding: 5px;
    line-height: 130%;
    margin-left: 10px;
    width: 95%;
}


code {
    font-family: Inconsolata, Consolas, "DEJA VU SANS MONO", "DROID SANS MONO", Proggy, monospace;
    font-size: 90%;
}


a {
    text-decoration: none;
    # cursor: crosshair;
    border-bottom: 1px dashed Red;
    padding: 1px;
    # color: black;
}


a:hover {
	background-color: LightGrey;
}


img {
    box-shadow: 0 0 10px #555;
    border-radius: 6px;
    margin-left: auto;
    margin-right: auto;
    margin-top: 10px;
    margin-bottom: 10px;
    -webkit-box-shadow: 0 0 10px #555;
    width: 100%;
    max-width: 600px;
}

img.displayed {
    display: block;
    margin-left: auto;
    margin-right: auto;
}

#table-of-contents {
    border-bottom: 2px LightGrey solid;
}</style>

</head>

<body>

<div class="outline-2">
<h2>14 | 推荐阅读：机器学习101</h2>
<div class="outline-text-2">
<p>自从2012年在亚马逊第一次接触机器学习（一个关于预测商品需求的Demand Forecasting的项目）以来，我一直在用一些零星的时间学习机器学习相关的东西。所以，说实话，在机器学习方面，我也只是一个新手，也在入门阶段。</p>
<p>在前面文章的评论中，有网友希望我写一篇有关大数据和机器学习的文章，老实说，有点为难我了。所以，我只能结合自己的学习过程写一篇入门级的文章，希望能看到高手的指教和指正。</p>
<p>首先，简单介绍一下机器学习的一些原理。机器学习主要来说有两种方法，监督式学习（Supervised Learning）和非监督式学习（Unsupervised Learning）。</p>
<h1>监督式学习</h1>
<p>所谓监督式学习，也就是说，我们需要提供一组学习样本，包括相关的特征数据以及相应的标签。程序可以通过这组样本来学习相关的规律或是模式，然后通过得到的规律或模式来判断没有被打过标签的数据是什么样的数据。</p>
<p>举个例子，假设需要识别一些手写的数字，那么我们就需要找到尽可能多的手写体数字的图像样本，然后人工或是通过某种算法来明确地标注什么是这些手写体的图片，谁是1，谁是2，谁是3……这组数据就叫样本数据，又叫训练数据（training data）。</p>
<p>通过机器学习的算法，我们可以找到每个数字在不同手写体下的特征，进而找到规律和模式。然后通过得到的规律或模式来识别那些没有被打过标签的手写数据，以此完成识别手写体数字的目标。</p>
<p>一种比较常见的监督式学习，就是从历史数据中获得数据的走向趋势，来预测未来的走向。比如，我们使用历史上的股票走势数据来预测接下来的股价涨跌，或者通过历史上的一些垃圾邮件的样本来识别新的垃圾邮件。</p>
<p>在监督式学习下，需要有样本数据或是历史数据来进行学习，这种方式会有一些问题。比如</p>
<ul>
<li>如果一个事物没有历史数据，那么就不好做了。变通的解决方式是通过一个和其类似事物的历史数据。我以前做过的需求预测，就属于这种情况。对于新上市的商品来说，完全没有历史数据，比如，iPhone X，那么就需要从其类似的商品上找历史数据，如iPhone 7或是别的智能手机。</li>
</ul>
<!-- [[[read_end]]] -->
<ul>
<li>历史数据中可能会有一些是噪音数据，需要把这些噪音数据给过滤掉。一般这样的过滤方式要通过人工判断和标注。举两个例子，某名人在其微博或是演讲上推荐了一本书，于是这本书的销量就上升了。这段时间的历史数据不是规律性的，所以就不能成为样本数据，需要去掉。同样，如果某名人（如Michael Jackson）去世导致和其有关的商品销售量很好，那么，这个事件所产生的数据则不属于噪音数据。因为每年这个名人忌日的时候出现销量上升的可能性非常高，所以，需要标注一下，这是有规律的样本，可以放入样本进行学习。</li>
</ul>
<h1>非监督式学习</h1>
<p>对于非监督式学习，也就是说，数据是没有被标注过的，所以相关的机器学习算法需要找到这些数据中的共性。因为大量的数据是没有被标识过的，所以这种学习方式可以让大量未标识的数据能够更有价值。</p>
<p>而且，非监督式的学习，可以为我们找到人类很难发现的数据里的规律或模型。所以，也有人将这种学习称为“特征点学习”。其可以让我们自动地为数据进行分类，并找到分类的模型。</p>
<p>一般来说，非监督式学习会应用在一些交易型的数据中。比如，有一堆的用户购买数据，但是对于人类来说，我们很难找到用户属性和购买商品类型之间的关系，而非监督式学习算法可以帮助我们找到他们之间的关系。</p>
<p>比如，一个在某一年龄段区间的女生购买了某种肥皂，有可能说明这个女生在怀孕期，或是某人购买儿童用品，有可能说明这个人的关系链中有孩子，等等。于是这些信息会被用作一些所谓的精准市场营销活动，从而可以增加商品销量。</p>
<p>我们这么来说吧，监督式学习是在被告诉过正确的答案之后的学习，而非监督式学习是在没有被告诉正确答案时的学习，所以说，非监督式的学习是在大量的非常混乱的数据中找寻一些潜在的关系，这个成本也比较高。</p>
<p>这种非监督式学习也会经常被用来检测一些不正常的事情发生，比如信用卡的诈骗或是盗刷。也有被用在推荐系统中，比如买了这个商品的人又买了别的什么东西，或是如果某个人喜欢某篇文章、某个音乐、某个餐馆，那么可能他会喜欢某款车、某个明星，或某个地方。</p>
<p>在监督式的学习的算法下，我们可以用一组“狗”的照片来确定某个照片中的物体是不是狗。而在非监督式的学习算法下，我们可以通过一个照片来找到与其相似事物的照片。这两种学习方式都有各自适用的场景。</p>
<h1>如何找到数据的规律和关联</h1>
<p>机器学习基本就是在已知的样本数据中寻找数据的规律，在未知的数据中找数据的关系。所以，这就需要一定的数学知识了，但对于刚入门的人来说，学好高数、线性代数、概率论、数据建模等大学本科的数学知识应该就够用了。以前上大学时，总觉得这些知识没什么用处，原来只不过是自己太low，还没有从事会运用到这些知识的工作。</p>
<p>总之，机器学习中的基本方法论是这样的。</p>
<ol>
<li>
<p>要找到数据中的规律，你需要找到数据中的特征点。</p>
</li>
<li>
<p>把特征点抽象成数学中的向量，也就是所谓的坐标轴。一个复杂的学习可能会有成十上百的坐标轴。</p>
</li>
<li>
<p>抽象成数学向量后，就可以通过某种数学公式来表达这类数据（就像y=ax+b是直线的公式），这就是数据建模。</p>
</li>
</ol>
<p>这个数据公式就是我们找出来的规律。通过这个规律，我们才可能关联类似的数据。</p>
<p>当然，也有更为简单粗暴的玩法。</p>
<ol>
<li>
<p>把数据中的特征点抽象成数学中的向量。</p>
</li>
<li>
<p>每个向量一个权重。</p>
</li>
<li>
<p>写个算法来找各个向量的权重是什么。</p>
</li>
</ol>
<p>有人把这个事叫“数据搅拌机”。据说，这种简单粗暴的方式超过了那些所谓的明确的数学公式或规则。这种“土办法”有时候会比高大上的数学更有效，哈哈。</p>
<p>关于机器学习这个事，你可以读一读 <a href="https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471">Machine Learning is Fun!</a> 这篇文章，以及它的<a href="https://zhuanlan.zhihu.com/p/24339995">中文翻译版</a>。</p>
<h1>相关算法</h1>
<p>对于监督式学习，有如下经典算法。</p>
<ol>
<li>
<p>决策树（Decision Tree）。比如自动化放贷、风控。</p>
</li>
<li>
<p>朴素贝叶斯分类（Naive Bayesian classification）。可以用于判断垃圾邮件，对新闻的类别进行分类，比如科技、政治、运动，判断文本表达的感情是积极的还是消极的，以及人脸识别等。</p>
</li>
<li>
<p>最小二乘法（Ordinary Least Squares Regression）。算是一种线性回归。</p>
</li>
<li>
<p>逻辑回归（Logisitic Regression）。一种强大的统计学方法，可以用一个或多个变量来表示一个二项式结果。它可以用于信用评分、计算营销活动的成功率、预测某个产品的收入等。</p>
</li>
<li>
<p>支持向量机（Support Vector Machine，SVM）。可以用于基于图像的性别检测，图像分类等。</p>
</li>
<li>
<p>集成方法（Ensemble methods）。通过构建一组分类器，然后根据它们的预测结果进行加权投票来对新的数据点进行分类。原始的集成方法是贝叶斯平均，但是最近的算法包括纠错输出编码、Bagging和Boosting。</p>
</li>
</ol>
<p>对于非监督式的学习，有如下经典算法。</p>
<ol>
<li>
<p>聚类算法（Clustering Algorithms）。聚类算法有很多，目标是给数据分类。</p>
</li>
<li>
<p>主成分分析（Principal Component Analysis，PCA）。PCA的一些应用包括压缩、简化数据，便于学习和可视化等。</p>
</li>
<li>
<p>奇异值分解（Singular Value Decomposition，SVD）。实际上，PCA是SVD的一个简单应用。在计算机视觉中，第一个人脸识别算法使用PCA和SVD来将面部表示为“特征面”的线性组合，进行降维，然后通过简单的方法将面部匹配到身份。虽然现代方法更复杂，但很多方面仍然依赖于类似的技术。</p>
</li>
<li>
<p>独立成分分析（Independent Component Analysis，ICA）。ICA是一种统计技术，主要用于揭示随机变量、测量值或信号集中的隐藏因素。</p>
</li>
</ol>
<p>上面的这些相关算法来源自博文《<a href="https://www.kdnuggets.com/2016/08/10-algorithms-machine-learning-engineers.html">The 10 Algorithms Machine Learning Engineers Need to Know</a>》。</p>
<h1>相关推荐</h1>
<p>学习机器学习有几个课是必须要上的，具体如下。</p>
<ul>
<li>
<p>吴恩达教授（Andrew Ng）在 <a href="https://www.coursera.org/learn/machine-learning">Coursera 上的机器学习课程</a>非常棒。我强烈建议从此入手。对于任何拥有计算机科学学位的人，或是还能记住一点点数学的人来说，都非常容易入门。这个斯坦福大学的课程后面是有作业的，请尽量拿满分。另外，<a href="http://open.163.com/special/opencourse/machinelearning.html">网易公开课上也有该课程</a>。</p>
</li>
<li>
<p>卡内基梅隆大学计算机科学学院汤姆·米切尔（Tom Mitchell）教授的机器学习课程，这里有<a href="http://www.cs.cmu.edu/~tom/10701_sp11/lectures.shtml">英文原版视频和课件PDF</a> 。汤姆·米切尔是全球AI界顶级大牛，在机器学习、人工智能、认知神经科学等领域都有建树，撰写了机器学习方面最早的教科书之一<a href="http://item.jd.com/10131321.html">《机器学习》</a>，被誉为入门必读图书。</p>
</li>
<li>
<p>加利福尼亚理工学院亚瑟·阿布·穆斯塔法（Yaser Abu-Mostafa）教授的 <a href="http://work.caltech.edu/lectures.html">Learning from Data 系列课程</a> 。本课程涵盖机器学习的基本理论和算法，并将理论与实践相结合，更具实践指导意义，适合进阶。</p>
</li>
</ul>
<p>除了上述的那些课程外，下面这些资源也很不错。</p>
<ul>
<li>
<p>YouTube 上的 Google Developers 的 <a href="https://www.youtube.com/playlist?list=PLOU2XLYxmsIIuiBfYad6rFYQU_jL2ryal">Machine Learning Recipes with Josh Gordon</a> 。这 9 集视频，每集不到10分钟，从Hello World讲到如何使用TensorFlow，值得一看。</p>
</li>
<li>
<p>还有 <a href="https://pythonprogramming.net/machine-learning-tutorial-python-introduction/">Practical Machine Learning Tutorial with Python Introduction</a> 上面一系列的用Python带着你玩Machine Learning的教程。</p>
</li>
<li>
<p>Medium 上的 <a href="https://medium.com/machine-learning-101">Machine Learning - 101</a> 讲述了好多我们上面提到过的经典算法。</p>
</li>
<li>
<p>还有，Medium 上的 <a href="https://medium.com/machine-learning-for-humans">Machine Learning for Humans</a>，不仅提供了入门指导，更介绍了各种优质的学习资源。</p>
</li>
<li>
<p><a href="https://machinelearningmastery.com/blog/">杰森·布朗利（Jason Brownlee）博士的博客</a> 也是非常值得一读，其中好多的 “How-To”，会让你有很多的收获。</p>
</li>
<li>
<p><a href="http://iamtrask.github.io">i am trask</a> 也是一个很不错的博客。</p>
</li>
<li>
<p>关于Deep Learning中神经网络的学习，推荐YouTube介绍视频 <a href="https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi">Neural Networks</a>。</p>
</li>
<li>
<p>用Python做自然语言处理<a href="http://www.nltk.org/book/">Natural Language Processing with Python</a>。</p>
</li>
<li>
<p>以及GitHub上的 <a href="https://github.com/ujjwalkarn/Machine-Learning-Tutorials">Machine Learning 和 Deep Learning</a> 的相关教程列表。</p>
</li>
</ul>
<p>此外，还有一些值得翻阅的图书。</p>
<ul>
<li>
<p><a href="https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/MLbook2016.htm">《机器学习》</a>，南京大学周志华教授著。它是一本机器学习方面的入门级教科书，适合本科三年级以上的学生学习。这本书如同一张地图一般，让你能“观其大略”，了解机器学习的各个种类、各个学派，其覆盖面与同类英文书籍相较不遑多让。</p>
</li>
<li>
<p><a href="http://ciml.info/">A Course In Machine Learning</a>，马里兰大学哈尔·道姆（Hal Daumé III）副教授著。 这本书讲述了几种经典机器学习算法，包括决策树、感知器神经元、kNN算法、K-means聚类算法、各种线性模型（包括对梯度下降、支持向量机等的介绍）、概率建模、神经网络、非监督学习等很多主题，还讲了各种算法使用时的经验技巧，适合初学者学习。此外，官网还提供了免费电子版。</p>
</li>
<li>
<p><a href="http://www.deeplearningbook.org/">Deep Learning</a>，麻省理工学院伊恩·古德费洛（Ian Goodfellow）、友华·本吉奥（Yoshua Benjio）和亚伦·考维尔（Aaron Courville）著。这本书是深度学习专题的经典图书。它从历史的角度，将读者带进深度学习的世界。深度学习使用多层的（深度的）神经元网络，通过梯度下降算法来实现机器学习，对于监督式和非监督式学习都有大量应用。如果读者对该领域有兴趣，可以深入阅读本书。本书官网提供免费电子版，但不提供下载。实体书（英文原版或中文翻译版）可以在网上买到。</p>
</li>
<li>
<p><a href="http://www.freetechbooks.com/reinforcement-learning-an-introduction-second-edition-draft-t1282.html">Reinforcement Learning</a>，安德鲁·巴托（Andrew G.Barto）和理查德·萨顿（Richard S. Sutton）著。这本书是强化学习（Reinforcement Learning）方面的入门书。它覆盖了马尔可夫决策过程（MDP）、Q-Learning、Sarsa、TD-Lamda等方面。这本书的作者是强化学习方面的创始人之一。强化学习（结合深度学习）在围棋程序AlphaGo和自动驾驶等方面都有着重要的应用。</p>
</li>
<li>
<p><a href="https://www.amazon.com/Pattern-Recognition-Learning-Information-Statistics/dp/0387310738">Pattern Recognition and Machine Learning</a> ，微软剑桥研究院克里斯托夫·比肖普（Christoph M. Bishop）著。这本书讲述了模式识别的技术，包括机器学习在模式识别中的应用。模式识别在图像识别、自然语言处理、控制论等多个领域都有应用。日常生活中扫描仪的OCR、平板或手机的手写输入等都属于该领域的研究。</p>
</li>
</ul>
<p>好了，今天推荐的内容就这些。我目前也在学习中，希望能够跟你一起交流探讨，也期望能得到你的指教和帮助。</p>
<p></p>

</div>
</div>

</body>
</html>